{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMEai5UI68X4Y3huERp4QLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Notebooks/FriendlySAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SBvoMn6lfo8",
        "outputId": "b0d374dc-1a47-4985-d7a0-0945ec966aa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/hsam/trains.py \\\n",
        "    --optimizer FriendlySAM \\\n",
        "    --z_threshold 1.0 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --lmbda 0.6 \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR100 \\\n",
        "    --arch resnet18 \\\n",
        "    --epochs 200 \\\n",
        "    --batch-size 128\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pqgiEk2ltLp",
        "outputId": "094cc303-eb6f-48c3-f1f9-3501220caf7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: resnet18\n",
            "lambda: 0.6\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar100 dataset!\n",
            "100% 169M/169M [00:02<00:00, 77.4MB/s]\n",
            "391\n",
            "50000\n",
            "optimizer: FriendlySAM\n",
            "FriendlySAM sigma: 1 lambda: 0.6\n",
            "FriendlySAM (\n",
            "Parameter Group 0\n",
            "    adaptive: 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 0.1\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "Epoch: [0][0/391]\tTime 2.478 (2.478)\tData 0.144 (0.144)\tLoss 4.7223 (4.7223)\tPrec@1 0.000 (0.000)\n",
            "Epoch: [0][100/391]\tTime 0.041 (0.061)\tData 0.000 (0.002)\tLoss 4.0065 (4.3340)\tPrec@1 3.906 (4.394)\n",
            "Epoch: [0][200/391]\tTime 0.040 (0.049)\tData 0.000 (0.001)\tLoss 3.9507 (4.1587)\tPrec@1 9.375 (6.102)\n",
            "Epoch: [0][300/391]\tTime 0.035 (0.045)\tData 0.000 (0.001)\tLoss 3.7305 (4.0584)\tPrec@1 8.594 (7.267)\n",
            "Epoch: [0][390/391]\tTime 0.200 (0.044)\tData 0.000 (0.001)\tLoss 3.8158 (3.9874)\tPrec@1 10.000 (8.216)\n",
            "Total time : 17.085\n",
            "Train Loss: 3.9874, Train Accuracy: 0.0822\n",
            "Test Loss : 3.6243, Test Accuracy : 0.1323 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.218 (0.218)\tData 0.144 (0.144)\tLoss 3.7393 (3.7393)\tPrec@1 12.500 (12.500)\n",
            "Epoch: [1][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 3.4043 (3.6412)\tPrec@1 15.625 (13.026)\n",
            "Epoch: [1][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 3.4633 (3.5824)\tPrec@1 17.188 (14.012)\n",
            "Epoch: [1][300/391]\tTime 0.041 (0.036)\tData 0.000 (0.001)\tLoss 3.1708 (3.5376)\tPrec@1 17.969 (14.906)\n",
            "Epoch: [1][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 3.0748 (3.4951)\tPrec@1 22.500 (15.686)\n",
            "Total time : 14.398\n",
            "Train Loss: 3.4951, Train Accuracy: 0.1569\n",
            "Test Loss : 3.2069, Test Accuracy : 0.2116 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.182 (0.182)\tData 0.137 (0.137)\tLoss 3.2800 (3.2800)\tPrec@1 17.969 (17.969)\n",
            "Epoch: [2][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 3.1463 (3.2494)\tPrec@1 23.438 (19.949)\n",
            "Epoch: [2][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 3.2548 (3.2044)\tPrec@1 25.000 (20.946)\n",
            "Epoch: [2][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 2.9837 (3.1599)\tPrec@1 26.562 (21.709)\n",
            "Epoch: [2][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 3.0382 (3.1296)\tPrec@1 22.500 (22.216)\n",
            "Total time : 14.644\n",
            "Train Loss: 3.1296, Train Accuracy: 0.2222\n",
            "Test Loss : 2.9738, Test Accuracy : 0.2512 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.196 (0.196)\tData 0.134 (0.134)\tLoss 2.8035 (2.8035)\tPrec@1 29.688 (29.688)\n",
            "Epoch: [3][100/391]\tTime 0.039 (0.039)\tData 0.000 (0.002)\tLoss 2.6734 (2.8960)\tPrec@1 33.594 (26.756)\n",
            "Epoch: [3][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 3.0915 (2.8795)\tPrec@1 24.219 (27.184)\n",
            "Epoch: [3][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 2.8557 (2.8459)\tPrec@1 30.469 (27.772)\n",
            "Epoch: [3][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 2.7853 (2.8115)\tPrec@1 25.000 (28.426)\n",
            "Total time : 14.512\n",
            "Train Loss: 2.8115, Train Accuracy: 0.2843\n",
            "Test Loss : 2.6846, Test Accuracy : 0.3088 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.195 (0.195)\tData 0.150 (0.150)\tLoss 2.6492 (2.6492)\tPrec@1 30.469 (30.469)\n",
            "Epoch: [4][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 2.5037 (2.5629)\tPrec@1 36.719 (33.083)\n",
            "Epoch: [4][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 2.5523 (2.5518)\tPrec@1 29.688 (33.419)\n",
            "Epoch: [4][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 2.4348 (2.5204)\tPrec@1 41.406 (34.180)\n",
            "Epoch: [4][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 2.6858 (2.4906)\tPrec@1 31.250 (34.616)\n",
            "Total time : 14.583\n",
            "Train Loss: 2.4906, Train Accuracy: 0.3462\n",
            "Test Loss : 2.3197, Test Accuracy : 0.3795 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.207 (0.207)\tData 0.144 (0.144)\tLoss 2.3200 (2.3200)\tPrec@1 40.625 (40.625)\n",
            "Epoch: [5][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 2.1339 (2.2759)\tPrec@1 42.188 (39.341)\n",
            "Epoch: [5][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 2.3337 (2.2759)\tPrec@1 34.375 (39.385)\n",
            "Epoch: [5][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 2.1312 (2.2578)\tPrec@1 42.188 (39.828)\n",
            "Epoch: [5][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 2.1228 (2.2420)\tPrec@1 37.500 (40.128)\n",
            "Total time : 14.386\n",
            "Train Loss: 2.2420, Train Accuracy: 0.4013\n",
            "Test Loss : 2.0549, Test Accuracy : 0.4402 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.186 (0.186)\tData 0.136 (0.136)\tLoss 2.2525 (2.2525)\tPrec@1 41.406 (41.406)\n",
            "Epoch: [6][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 2.1427 (2.0798)\tPrec@1 42.188 (43.704)\n",
            "Epoch: [6][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 1.9349 (2.0651)\tPrec@1 47.656 (43.983)\n",
            "Epoch: [6][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 2.1907 (2.0595)\tPrec@1 42.188 (44.243)\n",
            "Epoch: [6][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 2.0336 (2.0532)\tPrec@1 40.000 (44.500)\n",
            "Total time : 14.457\n",
            "Train Loss: 2.0532, Train Accuracy: 0.4450\n",
            "Test Loss : 1.8909, Test Accuracy : 0.4764 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.199 (0.199)\tData 0.138 (0.138)\tLoss 1.7053 (1.7053)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [7][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 2.0901 (1.9240)\tPrec@1 46.094 (47.571)\n",
            "Epoch: [7][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 2.2794 (1.9204)\tPrec@1 38.281 (47.190)\n",
            "Epoch: [7][300/391]\tTime 0.039 (0.037)\tData 0.000 (0.001)\tLoss 1.9934 (1.9282)\tPrec@1 45.312 (47.129)\n",
            "Epoch: [7][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 1.7599 (1.9211)\tPrec@1 55.000 (47.394)\n",
            "Total time : 14.649\n",
            "Train Loss: 1.9211, Train Accuracy: 0.4739\n",
            "Test Loss : 1.9878, Test Accuracy : 0.4634 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.186 (0.186)\tData 0.133 (0.133)\tLoss 1.8635 (1.8635)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [8][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 1.9697 (1.8119)\tPrec@1 46.094 (50.162)\n",
            "Epoch: [8][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.8548 (1.8176)\tPrec@1 49.219 (49.887)\n",
            "Epoch: [8][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.7754 (1.8178)\tPrec@1 51.562 (49.938)\n",
            "Epoch: [8][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.7795 (1.8143)\tPrec@1 46.250 (50.020)\n",
            "Total time : 14.357\n",
            "Train Loss: 1.8143, Train Accuracy: 0.5002\n",
            "Test Loss : 1.8753, Test Accuracy : 0.4865 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.188 (0.188)\tData 0.143 (0.143)\tLoss 1.6283 (1.6283)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [9][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 1.6712 (1.7298)\tPrec@1 53.125 (52.591)\n",
            "Epoch: [9][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.7579 (1.7267)\tPrec@1 47.656 (52.480)\n",
            "Epoch: [9][300/391]\tTime 0.040 (0.037)\tData 0.000 (0.001)\tLoss 1.5768 (1.7282)\tPrec@1 55.469 (52.310)\n",
            "Epoch: [9][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.8549 (1.7312)\tPrec@1 45.000 (52.200)\n",
            "Total time : 14.432\n",
            "Train Loss: 1.7312, Train Accuracy: 0.5220\n",
            "Test Loss : 1.6560, Test Accuracy : 0.5322 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.188 (0.188)\tData 0.144 (0.144)\tLoss 1.6465 (1.6465)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [10][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 1.8258 (1.6535)\tPrec@1 53.906 (53.929)\n",
            "Epoch: [10][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 1.6631 (1.6570)\tPrec@1 56.250 (54.027)\n",
            "Epoch: [10][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 1.6633 (1.6561)\tPrec@1 47.656 (54.098)\n",
            "Epoch: [10][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.4690 (1.6626)\tPrec@1 66.250 (53.940)\n",
            "Total time : 14.793\n",
            "Train Loss: 1.6626, Train Accuracy: 0.5394\n",
            "Test Loss : 1.7533, Test Accuracy : 0.5162 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.194 (0.194)\tData 0.137 (0.137)\tLoss 1.7561 (1.7561)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [11][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 1.8712 (1.5778)\tPrec@1 46.094 (56.219)\n",
            "Epoch: [11][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.5908 (1.5970)\tPrec@1 52.344 (55.278)\n",
            "Epoch: [11][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.7140 (1.6094)\tPrec@1 52.344 (55.092)\n",
            "Epoch: [11][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.5984 (1.6162)\tPrec@1 53.750 (55.040)\n",
            "Total time : 14.311\n",
            "Train Loss: 1.6162, Train Accuracy: 0.5504\n",
            "Test Loss : 1.6337, Test Accuracy : 0.5504 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.198 (0.198)\tData 0.138 (0.138)\tLoss 1.6319 (1.6319)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [12][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 1.6554 (1.5626)\tPrec@1 53.906 (57.031)\n",
            "Epoch: [12][200/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 1.5222 (1.5681)\tPrec@1 57.031 (56.678)\n",
            "Epoch: [12][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.8270 (1.5663)\tPrec@1 50.781 (56.468)\n",
            "Epoch: [12][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.7417 (1.5696)\tPrec@1 57.500 (56.336)\n",
            "Total time : 14.390\n",
            "Train Loss: 1.5696, Train Accuracy: 0.5634\n",
            "Test Loss : 1.6041, Test Accuracy : 0.5519 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.195 (0.195)\tData 0.150 (0.150)\tLoss 1.4614 (1.4614)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [13][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 1.2396 (1.5101)\tPrec@1 71.094 (57.998)\n",
            "Epoch: [13][200/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 1.4496 (1.5212)\tPrec@1 58.594 (57.735)\n",
            "Epoch: [13][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.6693 (1.5226)\tPrec@1 53.906 (57.670)\n",
            "Epoch: [13][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.5516 (1.5192)\tPrec@1 53.750 (57.788)\n",
            "Total time : 14.392\n",
            "Train Loss: 1.5192, Train Accuracy: 0.5779\n",
            "Test Loss : 1.6320, Test Accuracy : 0.5442 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.186 (0.186)\tData 0.142 (0.142)\tLoss 1.3844 (1.3844)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [14][100/391]\tTime 0.038 (0.037)\tData 0.000 (0.002)\tLoss 1.4685 (1.4696)\tPrec@1 57.812 (59.143)\n",
            "Epoch: [14][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.7373 (1.4724)\tPrec@1 56.250 (59.025)\n",
            "Epoch: [14][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 1.5321 (1.4772)\tPrec@1 59.375 (58.879)\n",
            "Epoch: [14][390/391]\tTime 0.033 (0.036)\tData 0.000 (0.001)\tLoss 1.4897 (1.4808)\tPrec@1 56.250 (58.804)\n",
            "Total time : 14.269\n",
            "Train Loss: 1.4808, Train Accuracy: 0.5880\n",
            "Test Loss : 1.7585, Test Accuracy : 0.5130 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.182 (0.182)\tData 0.136 (0.136)\tLoss 1.4216 (1.4216)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [15][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 1.3018 (1.4088)\tPrec@1 64.844 (60.381)\n",
            "Epoch: [15][200/391]\tTime 0.034 (0.036)\tData 0.000 (0.001)\tLoss 1.3931 (1.4244)\tPrec@1 56.250 (59.993)\n",
            "Epoch: [15][300/391]\tTime 0.034 (0.036)\tData 0.000 (0.001)\tLoss 1.3520 (1.4357)\tPrec@1 66.406 (59.790)\n",
            "Epoch: [15][390/391]\tTime 0.031 (0.036)\tData 0.000 (0.001)\tLoss 1.5375 (1.4458)\tPrec@1 51.250 (59.632)\n",
            "Total time : 14.040\n",
            "Train Loss: 1.4458, Train Accuracy: 0.5963\n",
            "Test Loss : 1.6507, Test Accuracy : 0.5396 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.194 (0.194)\tData 0.145 (0.145)\tLoss 1.5050 (1.5050)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [16][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 1.1935 (1.4053)\tPrec@1 67.969 (61.077)\n",
            "Epoch: [16][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.4073 (1.4165)\tPrec@1 64.062 (60.580)\n",
            "Epoch: [16][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.3131 (1.4222)\tPrec@1 63.281 (60.559)\n",
            "Epoch: [16][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 1.5007 (1.4230)\tPrec@1 56.250 (60.342)\n",
            "Total time : 14.491\n",
            "Train Loss: 1.4230, Train Accuracy: 0.6034\n",
            "Test Loss : 1.6011, Test Accuracy : 0.5554 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.189 (0.189)\tData 0.136 (0.136)\tLoss 1.3520 (1.3520)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [17][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 1.3481 (1.3649)\tPrec@1 58.594 (61.394)\n",
            "Epoch: [17][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 1.4302 (1.3758)\tPrec@1 57.812 (61.264)\n",
            "Epoch: [17][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.5488 (1.3901)\tPrec@1 52.344 (60.914)\n",
            "Epoch: [17][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 1.3247 (1.4046)\tPrec@1 58.750 (60.590)\n",
            "Total time : 14.696\n",
            "Train Loss: 1.4046, Train Accuracy: 0.6059\n",
            "Test Loss : 1.5756, Test Accuracy : 0.5566 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.196 (0.196)\tData 0.141 (0.141)\tLoss 1.2780 (1.2780)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [18][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 1.3148 (1.3492)\tPrec@1 61.719 (62.206)\n",
            "Epoch: [18][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.4285 (1.3731)\tPrec@1 61.719 (61.684)\n",
            "Epoch: [18][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.6431 (1.3803)\tPrec@1 52.344 (61.436)\n",
            "Epoch: [18][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.7131 (1.3750)\tPrec@1 56.250 (61.522)\n",
            "Total time : 14.415\n",
            "Train Loss: 1.3750, Train Accuracy: 0.6152\n",
            "Test Loss : 1.4871, Test Accuracy : 0.5805 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.204 (0.204)\tData 0.148 (0.148)\tLoss 1.0492 (1.0492)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [19][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 1.0624 (1.3177)\tPrec@1 73.438 (63.459)\n",
            "Epoch: [19][200/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 1.3117 (1.3222)\tPrec@1 61.719 (63.238)\n",
            "Epoch: [19][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 1.2868 (1.3438)\tPrec@1 66.406 (62.479)\n",
            "Epoch: [19][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.3316 (1.3513)\tPrec@1 61.250 (62.238)\n",
            "Total time : 14.281\n",
            "Train Loss: 1.3513, Train Accuracy: 0.6224\n",
            "Test Loss : 1.6067, Test Accuracy : 0.5573 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.199 (0.199)\tData 0.145 (0.145)\tLoss 1.5847 (1.5847)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [20][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 1.1425 (1.3174)\tPrec@1 70.312 (63.591)\n",
            "Epoch: [20][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.3162 (1.3234)\tPrec@1 61.719 (63.052)\n",
            "Epoch: [20][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 1.4158 (1.3365)\tPrec@1 63.281 (62.651)\n",
            "Epoch: [20][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.4841 (1.3387)\tPrec@1 60.000 (62.542)\n",
            "Total time : 14.277\n",
            "Train Loss: 1.3387, Train Accuracy: 0.6254\n",
            "Test Loss : 1.5438, Test Accuracy : 0.5730 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.186 (0.186)\tData 0.137 (0.137)\tLoss 1.3198 (1.3198)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [21][100/391]\tTime 0.040 (0.040)\tData 0.000 (0.002)\tLoss 1.0364 (1.2896)\tPrec@1 70.312 (63.861)\n",
            "Epoch: [21][200/391]\tTime 0.052 (0.039)\tData 0.000 (0.001)\tLoss 1.2906 (1.2997)\tPrec@1 63.281 (63.476)\n",
            "Epoch: [21][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 1.5034 (1.3150)\tPrec@1 59.375 (63.092)\n",
            "Epoch: [21][390/391]\tTime 0.032 (0.039)\tData 0.000 (0.001)\tLoss 1.6532 (1.3251)\tPrec@1 53.750 (62.894)\n",
            "Total time : 15.175\n",
            "Train Loss: 1.3251, Train Accuracy: 0.6289\n",
            "Test Loss : 1.5006, Test Accuracy : 0.5775 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.194 (0.194)\tData 0.149 (0.149)\tLoss 1.0866 (1.0866)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [22][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 1.0966 (1.2760)\tPrec@1 71.094 (63.861)\n",
            "Epoch: [22][200/391]\tTime 0.042 (0.037)\tData 0.000 (0.001)\tLoss 1.2301 (1.2860)\tPrec@1 67.969 (63.775)\n",
            "Epoch: [22][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.4656 (1.2942)\tPrec@1 61.719 (63.686)\n",
            "Epoch: [22][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.2609 (1.3047)\tPrec@1 58.750 (63.428)\n",
            "Total time : 14.482\n",
            "Train Loss: 1.3047, Train Accuracy: 0.6343\n",
            "Test Loss : 1.5784, Test Accuracy : 0.5703 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.190 (0.190)\tData 0.139 (0.139)\tLoss 1.2116 (1.2116)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [23][100/391]\tTime 0.041 (0.040)\tData 0.000 (0.002)\tLoss 1.2751 (1.2652)\tPrec@1 64.844 (64.434)\n",
            "Epoch: [23][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.1480 (1.2674)\tPrec@1 63.281 (64.432)\n",
            "Epoch: [23][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.1471 (1.2773)\tPrec@1 67.188 (64.270)\n",
            "Epoch: [23][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.3851 (1.2845)\tPrec@1 65.000 (64.068)\n",
            "Total time : 14.712\n",
            "Train Loss: 1.2845, Train Accuracy: 0.6407\n",
            "Test Loss : 1.3924, Test Accuracy : 0.6094 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.185 (0.185)\tData 0.140 (0.140)\tLoss 1.3574 (1.3574)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [24][100/391]\tTime 0.041 (0.039)\tData 0.000 (0.002)\tLoss 1.2412 (1.2285)\tPrec@1 64.844 (65.780)\n",
            "Epoch: [24][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.0061 (1.2450)\tPrec@1 76.562 (65.221)\n",
            "Epoch: [24][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.2530 (1.2552)\tPrec@1 60.938 (64.836)\n",
            "Epoch: [24][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 1.3127 (1.2694)\tPrec@1 60.000 (64.392)\n",
            "Total time : 14.555\n",
            "Train Loss: 1.2694, Train Accuracy: 0.6439\n",
            "Test Loss : 1.4498, Test Accuracy : 0.5873 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.185 (0.185)\tData 0.139 (0.139)\tLoss 1.1471 (1.1471)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [25][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 1.1116 (1.2136)\tPrec@1 71.094 (65.849)\n",
            "Epoch: [25][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.1674 (1.2225)\tPrec@1 71.094 (65.512)\n",
            "Epoch: [25][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.0999 (1.2417)\tPrec@1 68.750 (65.189)\n",
            "Epoch: [25][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.3647 (1.2512)\tPrec@1 57.500 (64.966)\n",
            "Total time : 14.385\n",
            "Train Loss: 1.2512, Train Accuracy: 0.6497\n",
            "Test Loss : 1.5250, Test Accuracy : 0.5849 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.190 (0.190)\tData 0.146 (0.146)\tLoss 1.3645 (1.3645)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [26][100/391]\tTime 0.036 (0.041)\tData 0.000 (0.002)\tLoss 1.1766 (1.2234)\tPrec@1 67.188 (65.973)\n",
            "Epoch: [26][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 1.2288 (1.2324)\tPrec@1 67.188 (65.641)\n",
            "Epoch: [26][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.3095 (1.2466)\tPrec@1 64.844 (65.145)\n",
            "Epoch: [26][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 1.4665 (1.2546)\tPrec@1 56.250 (64.848)\n",
            "Total time : 14.744\n",
            "Train Loss: 1.2546, Train Accuracy: 0.6485\n",
            "Test Loss : 1.6243, Test Accuracy : 0.5493 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.200 (0.200)\tData 0.140 (0.140)\tLoss 1.1850 (1.1850)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [27][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 1.1455 (1.1670)\tPrec@1 66.406 (67.071)\n",
            "Epoch: [27][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.3238 (1.1993)\tPrec@1 60.156 (66.165)\n",
            "Epoch: [27][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 1.3470 (1.2149)\tPrec@1 57.812 (65.809)\n",
            "Epoch: [27][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 1.2069 (1.2297)\tPrec@1 65.000 (65.372)\n",
            "Total time : 14.271\n",
            "Train Loss: 1.2297, Train Accuracy: 0.6537\n",
            "Test Loss : 1.4762, Test Accuracy : 0.5860 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.191 (0.191)\tData 0.142 (0.142)\tLoss 1.1636 (1.1636)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [28][100/391]\tTime 0.040 (0.040)\tData 0.000 (0.002)\tLoss 1.3507 (1.1858)\tPrec@1 64.062 (66.615)\n",
            "Epoch: [28][200/391]\tTime 0.043 (0.039)\tData 0.000 (0.001)\tLoss 1.0725 (1.1953)\tPrec@1 68.750 (66.309)\n",
            "Epoch: [28][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 1.1936 (1.2105)\tPrec@1 66.406 (65.903)\n",
            "Epoch: [28][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 1.3468 (1.2289)\tPrec@1 61.250 (65.338)\n",
            "Total time : 14.954\n",
            "Train Loss: 1.2289, Train Accuracy: 0.6534\n",
            "Test Loss : 1.5697, Test Accuracy : 0.5702 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.190 (0.190)\tData 0.144 (0.144)\tLoss 1.2882 (1.2882)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [29][100/391]\tTime 0.039 (0.041)\tData 0.000 (0.002)\tLoss 1.1423 (1.1581)\tPrec@1 70.312 (67.334)\n",
            "Epoch: [29][200/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 1.1111 (1.1844)\tPrec@1 71.875 (66.678)\n",
            "Epoch: [29][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.1566 (1.1879)\tPrec@1 64.844 (66.666)\n",
            "Epoch: [29][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 1.3536 (1.2079)\tPrec@1 60.000 (66.098)\n",
            "Total time : 14.728\n",
            "Train Loss: 1.2079, Train Accuracy: 0.6610\n",
            "Test Loss : 1.3742, Test Accuracy : 0.6075 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.201 (0.201)\tData 0.156 (0.156)\tLoss 0.9242 (0.9242)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [30][100/391]\tTime 0.040 (0.038)\tData 0.000 (0.002)\tLoss 1.3814 (1.1526)\tPrec@1 53.125 (67.164)\n",
            "Epoch: [30][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.1760 (1.1802)\tPrec@1 67.969 (66.550)\n",
            "Epoch: [30][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.5300 (1.1884)\tPrec@1 59.375 (66.443)\n",
            "Epoch: [30][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.2636 (1.2009)\tPrec@1 58.750 (66.204)\n",
            "Total time : 14.362\n",
            "Train Loss: 1.2009, Train Accuracy: 0.6620\n",
            "Test Loss : 1.3606, Test Accuracy : 0.6211 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.185 (0.185)\tData 0.141 (0.141)\tLoss 1.1039 (1.1039)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [31][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 1.2009 (1.1302)\tPrec@1 67.969 (68.680)\n",
            "Epoch: [31][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.3030 (1.1580)\tPrec@1 59.375 (67.456)\n",
            "Epoch: [31][300/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 1.2657 (1.1711)\tPrec@1 60.156 (66.982)\n",
            "Epoch: [31][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.2758 (1.1848)\tPrec@1 56.250 (66.644)\n",
            "Total time : 14.311\n",
            "Train Loss: 1.1848, Train Accuracy: 0.6664\n",
            "Test Loss : 1.3472, Test Accuracy : 0.6194 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.191 (0.191)\tData 0.143 (0.143)\tLoss 1.0808 (1.0808)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [32][100/391]\tTime 0.034 (0.039)\tData 0.000 (0.002)\tLoss 1.2800 (1.1576)\tPrec@1 66.406 (67.497)\n",
            "Epoch: [32][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 1.0984 (1.1618)\tPrec@1 66.406 (67.176)\n",
            "Epoch: [32][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.3486 (1.1729)\tPrec@1 60.938 (66.793)\n",
            "Epoch: [32][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 1.1897 (1.1858)\tPrec@1 63.750 (66.458)\n",
            "Total time : 14.723\n",
            "Train Loss: 1.1858, Train Accuracy: 0.6646\n",
            "Test Loss : 1.5234, Test Accuracy : 0.5784 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.210 (0.210)\tData 0.144 (0.144)\tLoss 1.3100 (1.3100)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [33][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 1.2518 (1.1443)\tPrec@1 61.719 (67.837)\n",
            "Epoch: [33][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.0653 (1.1526)\tPrec@1 70.312 (67.331)\n",
            "Epoch: [33][300/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 1.2368 (1.1616)\tPrec@1 66.406 (67.278)\n",
            "Epoch: [33][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.4185 (1.1707)\tPrec@1 60.000 (66.962)\n",
            "Total time : 14.826\n",
            "Train Loss: 1.1707, Train Accuracy: 0.6696\n",
            "Test Loss : 1.5005, Test Accuracy : 0.5852 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.182 (0.182)\tData 0.137 (0.137)\tLoss 1.0814 (1.0814)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [34][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 1.0634 (1.1270)\tPrec@1 72.656 (68.232)\n",
            "Epoch: [34][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.1810 (1.1431)\tPrec@1 70.312 (67.767)\n",
            "Epoch: [34][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.2917 (1.1529)\tPrec@1 64.062 (67.398)\n",
            "Epoch: [34][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.1549 (1.1660)\tPrec@1 62.500 (66.992)\n",
            "Total time : 14.467\n",
            "Train Loss: 1.1660, Train Accuracy: 0.6699\n",
            "Test Loss : 1.3050, Test Accuracy : 0.6340 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.199 (0.199)\tData 0.147 (0.147)\tLoss 0.9536 (0.9536)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [35][100/391]\tTime 0.039 (0.039)\tData 0.000 (0.002)\tLoss 1.1601 (1.1105)\tPrec@1 68.750 (68.959)\n",
            "Epoch: [35][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.9595 (1.1260)\tPrec@1 73.438 (68.361)\n",
            "Epoch: [35][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.1514 (1.1426)\tPrec@1 67.188 (67.987)\n",
            "Epoch: [35][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.1876 (1.1567)\tPrec@1 62.500 (67.562)\n",
            "Total time : 14.539\n",
            "Train Loss: 1.1567, Train Accuracy: 0.6756\n",
            "Test Loss : 1.3800, Test Accuracy : 0.6148 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 0.9529 (0.9529)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [36][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 1.1445 (1.0987)\tPrec@1 71.875 (69.075)\n",
            "Epoch: [36][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 1.3078 (1.1182)\tPrec@1 64.844 (68.536)\n",
            "Epoch: [36][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.1634 (1.1336)\tPrec@1 65.625 (68.221)\n",
            "Epoch: [36][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.2346 (1.1490)\tPrec@1 70.000 (67.862)\n",
            "Total time : 14.357\n",
            "Train Loss: 1.1490, Train Accuracy: 0.6786\n",
            "Test Loss : 1.5191, Test Accuracy : 0.5813 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.189 (0.189)\tData 0.143 (0.143)\tLoss 1.0600 (1.0600)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [37][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 0.9115 (1.0792)\tPrec@1 74.219 (69.431)\n",
            "Epoch: [37][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.0278 (1.0981)\tPrec@1 70.312 (69.014)\n",
            "Epoch: [37][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.2806 (1.1239)\tPrec@1 64.844 (68.381)\n",
            "Epoch: [37][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.0815 (1.1376)\tPrec@1 72.500 (68.008)\n",
            "Total time : 14.570\n",
            "Train Loss: 1.1376, Train Accuracy: 0.6801\n",
            "Test Loss : 1.3982, Test Accuracy : 0.6105 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.190 (0.190)\tData 0.139 (0.139)\tLoss 1.0382 (1.0382)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [38][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 1.0630 (1.0741)\tPrec@1 70.312 (69.222)\n",
            "Epoch: [38][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.1980 (1.0979)\tPrec@1 64.844 (68.874)\n",
            "Epoch: [38][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 1.1205 (1.1180)\tPrec@1 68.750 (68.501)\n",
            "Epoch: [38][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.1411 (1.1313)\tPrec@1 66.250 (68.022)\n",
            "Total time : 14.319\n",
            "Train Loss: 1.1313, Train Accuracy: 0.6802\n",
            "Test Loss : 1.2740, Test Accuracy : 0.6422 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.205 (0.205)\tData 0.138 (0.138)\tLoss 1.0825 (1.0825)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [39][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 1.1905 (1.0630)\tPrec@1 67.188 (70.073)\n",
            "Epoch: [39][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 1.2532 (1.0928)\tPrec@1 64.062 (69.271)\n",
            "Epoch: [39][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.2168 (1.1088)\tPrec@1 67.188 (68.877)\n",
            "Epoch: [39][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.0259 (1.1151)\tPrec@1 73.750 (68.702)\n",
            "Total time : 14.809\n",
            "Train Loss: 1.1151, Train Accuracy: 0.6870\n",
            "Test Loss : 1.3761, Test Accuracy : 0.6142 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.192 (0.192)\tData 0.147 (0.147)\tLoss 1.0844 (1.0844)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [40][100/391]\tTime 0.039 (0.040)\tData 0.000 (0.002)\tLoss 1.1183 (1.0496)\tPrec@1 64.062 (69.995)\n",
            "Epoch: [40][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.1168 (1.0787)\tPrec@1 71.094 (69.500)\n",
            "Epoch: [40][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.1525 (1.0999)\tPrec@1 62.500 (69.056)\n",
            "Epoch: [40][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.2284 (1.1148)\tPrec@1 66.250 (68.566)\n",
            "Total time : 14.284\n",
            "Train Loss: 1.1148, Train Accuracy: 0.6857\n",
            "Test Loss : 1.4309, Test Accuracy : 0.5979 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.199 (0.199)\tData 0.135 (0.135)\tLoss 0.8815 (0.8815)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [41][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 1.0346 (1.0599)\tPrec@1 68.750 (69.895)\n",
            "Epoch: [41][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.1407 (1.0752)\tPrec@1 72.656 (69.457)\n",
            "Epoch: [41][300/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 1.1188 (1.0949)\tPrec@1 64.062 (69.023)\n",
            "Epoch: [41][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.1206 (1.1011)\tPrec@1 66.250 (68.964)\n",
            "Total time : 14.508\n",
            "Train Loss: 1.1011, Train Accuracy: 0.6896\n",
            "Test Loss : 1.2877, Test Accuracy : 0.6355 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.189 (0.189)\tData 0.145 (0.145)\tLoss 1.0132 (1.0132)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [42][100/391]\tTime 0.040 (0.038)\tData 0.000 (0.002)\tLoss 0.8974 (1.0478)\tPrec@1 75.781 (70.537)\n",
            "Epoch: [42][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 1.1069 (1.0632)\tPrec@1 69.531 (70.176)\n",
            "Epoch: [42][300/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 1.1005 (1.0899)\tPrec@1 67.969 (69.376)\n",
            "Epoch: [42][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 1.1110 (1.1022)\tPrec@1 66.250 (68.946)\n",
            "Total time : 14.786\n",
            "Train Loss: 1.1022, Train Accuracy: 0.6895\n",
            "Test Loss : 1.2835, Test Accuracy : 0.6411 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.189 (0.189)\tData 0.137 (0.137)\tLoss 0.9593 (0.9593)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [43][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 1.0235 (1.0320)\tPrec@1 71.875 (70.800)\n",
            "Epoch: [43][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.1432 (1.0541)\tPrec@1 67.188 (70.487)\n",
            "Epoch: [43][300/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 1.1550 (1.0750)\tPrec@1 64.062 (69.861)\n",
            "Epoch: [43][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.2891 (1.0850)\tPrec@1 67.500 (69.514)\n",
            "Total time : 14.828\n",
            "Train Loss: 1.0850, Train Accuracy: 0.6951\n",
            "Test Loss : 1.3594, Test Accuracy : 0.6190 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.192 (0.192)\tData 0.142 (0.142)\tLoss 0.9924 (0.9924)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [44][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 1.0709 (1.0553)\tPrec@1 68.750 (70.537)\n",
            "Epoch: [44][200/391]\tTime 0.040 (0.039)\tData 0.000 (0.001)\tLoss 1.2619 (1.0707)\tPrec@1 62.500 (69.932)\n",
            "Epoch: [44][300/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.8726 (1.0787)\tPrec@1 74.219 (69.617)\n",
            "Epoch: [44][390/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.2076 (1.0867)\tPrec@1 61.250 (69.464)\n",
            "Total time : 14.853\n",
            "Train Loss: 1.0867, Train Accuracy: 0.6946\n",
            "Test Loss : 1.3266, Test Accuracy : 0.6271 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.207 (0.207)\tData 0.136 (0.136)\tLoss 1.0057 (1.0057)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [45][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 1.1153 (1.0349)\tPrec@1 59.375 (70.808)\n",
            "Epoch: [45][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.3619 (1.0497)\tPrec@1 70.312 (70.406)\n",
            "Epoch: [45][300/391]\tTime 0.038 (0.038)\tData 0.000 (0.001)\tLoss 1.2831 (1.0613)\tPrec@1 61.719 (70.048)\n",
            "Epoch: [45][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.0649 (1.0704)\tPrec@1 67.500 (69.860)\n",
            "Total time : 14.788\n",
            "Train Loss: 1.0704, Train Accuracy: 0.6986\n",
            "Test Loss : 1.2617, Test Accuracy : 0.6405 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.195 (0.195)\tData 0.145 (0.145)\tLoss 1.2617 (1.2617)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [46][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 1.0420 (1.0410)\tPrec@1 67.969 (70.529)\n",
            "Epoch: [46][200/391]\tTime 0.038 (0.038)\tData 0.000 (0.001)\tLoss 1.0567 (1.0612)\tPrec@1 68.750 (69.850)\n",
            "Epoch: [46][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.2303 (1.0632)\tPrec@1 69.531 (69.765)\n",
            "Epoch: [46][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.1127 (1.0737)\tPrec@1 72.500 (69.622)\n",
            "Total time : 14.540\n",
            "Train Loss: 1.0737, Train Accuracy: 0.6962\n",
            "Test Loss : 1.3652, Test Accuracy : 0.6231 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.209 (0.209)\tData 0.142 (0.142)\tLoss 1.0931 (1.0931)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [47][100/391]\tTime 0.042 (0.039)\tData 0.000 (0.002)\tLoss 0.9170 (1.0185)\tPrec@1 74.219 (71.597)\n",
            "Epoch: [47][200/391]\tTime 0.034 (0.038)\tData 0.000 (0.001)\tLoss 0.9428 (1.0418)\tPrec@1 73.438 (70.690)\n",
            "Epoch: [47][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8473 (1.0585)\tPrec@1 79.688 (70.120)\n",
            "Epoch: [47][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 1.0503 (1.0622)\tPrec@1 67.500 (69.958)\n",
            "Total time : 14.400\n",
            "Train Loss: 1.0622, Train Accuracy: 0.6996\n",
            "Test Loss : 1.4188, Test Accuracy : 0.6085 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.189 (0.189)\tData 0.144 (0.144)\tLoss 0.9901 (0.9901)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [48][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 1.1036 (0.9915)\tPrec@1 67.969 (71.945)\n",
            "Epoch: [48][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 1.3205 (1.0186)\tPrec@1 63.281 (71.424)\n",
            "Epoch: [48][300/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 1.0395 (1.0407)\tPrec@1 67.188 (70.699)\n",
            "Epoch: [48][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 1.1253 (1.0533)\tPrec@1 67.500 (70.222)\n",
            "Total time : 14.014\n",
            "Train Loss: 1.0533, Train Accuracy: 0.7022\n",
            "Test Loss : 1.2930, Test Accuracy : 0.6359 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.193 (0.193)\tData 0.149 (0.149)\tLoss 0.9568 (0.9568)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [49][100/391]\tTime 0.039 (0.038)\tData 0.000 (0.002)\tLoss 0.9802 (0.9952)\tPrec@1 65.625 (72.099)\n",
            "Epoch: [49][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.9147 (1.0215)\tPrec@1 74.219 (71.074)\n",
            "Epoch: [49][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.0601 (1.0382)\tPrec@1 74.219 (70.673)\n",
            "Epoch: [49][390/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 1.2459 (1.0457)\tPrec@1 65.000 (70.412)\n",
            "Total time : 14.392\n",
            "Train Loss: 1.0457, Train Accuracy: 0.7041\n",
            "Test Loss : 1.3223, Test Accuracy : 0.6356 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.193 (0.193)\tData 0.148 (0.148)\tLoss 1.2399 (1.2399)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [50][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 1.0506 (1.0194)\tPrec@1 74.219 (71.550)\n",
            "Epoch: [50][200/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.9462 (1.0201)\tPrec@1 75.000 (71.451)\n",
            "Epoch: [50][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 1.0272 (1.0348)\tPrec@1 71.875 (70.881)\n",
            "Epoch: [50][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.2398 (1.0423)\tPrec@1 63.750 (70.740)\n",
            "Total time : 14.310\n",
            "Train Loss: 1.0423, Train Accuracy: 0.7074\n",
            "Test Loss : 1.5927, Test Accuracy : 0.5740 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.195 (0.195)\tData 0.135 (0.135)\tLoss 0.8362 (0.8362)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [51][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.9696 (0.9884)\tPrec@1 73.438 (72.184)\n",
            "Epoch: [51][200/391]\tTime 0.043 (0.038)\tData 0.000 (0.001)\tLoss 1.1044 (1.0076)\tPrec@1 67.969 (71.436)\n",
            "Epoch: [51][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 1.2938 (1.0272)\tPrec@1 64.062 (70.998)\n",
            "Epoch: [51][390/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.9038 (1.0352)\tPrec@1 70.000 (70.792)\n",
            "Total time : 14.903\n",
            "Train Loss: 1.0352, Train Accuracy: 0.7079\n",
            "Test Loss : 1.2348, Test Accuracy : 0.6492 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.228 (0.228)\tData 0.160 (0.160)\tLoss 1.0798 (1.0798)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [52][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.9589 (0.9725)\tPrec@1 75.000 (72.734)\n",
            "Epoch: [52][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9405 (0.9895)\tPrec@1 74.219 (72.147)\n",
            "Epoch: [52][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.1794 (1.0139)\tPrec@1 71.875 (71.335)\n",
            "Epoch: [52][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.9343 (1.0228)\tPrec@1 77.500 (71.214)\n",
            "Total time : 14.343\n",
            "Train Loss: 1.0228, Train Accuracy: 0.7121\n",
            "Test Loss : 1.2874, Test Accuracy : 0.6349 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.183 (0.183)\tData 0.138 (0.138)\tLoss 0.8214 (0.8214)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [53][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.9804 (0.9740)\tPrec@1 71.094 (72.834)\n",
            "Epoch: [53][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.3014 (0.9980)\tPrec@1 62.500 (71.821)\n",
            "Epoch: [53][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9475 (1.0126)\tPrec@1 75.000 (71.327)\n",
            "Epoch: [53][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.9739 (1.0197)\tPrec@1 70.000 (71.188)\n",
            "Total time : 14.200\n",
            "Train Loss: 1.0197, Train Accuracy: 0.7119\n",
            "Test Loss : 1.2740, Test Accuracy : 0.6417 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.184 (0.184)\tData 0.138 (0.138)\tLoss 1.0313 (1.0313)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [54][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 1.1508 (0.9697)\tPrec@1 65.625 (72.772)\n",
            "Epoch: [54][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.8932 (0.9844)\tPrec@1 75.781 (72.252)\n",
            "Epoch: [54][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.1368 (0.9960)\tPrec@1 69.531 (71.789)\n",
            "Epoch: [54][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.9549 (1.0071)\tPrec@1 72.500 (71.576)\n",
            "Total time : 14.407\n",
            "Train Loss: 1.0071, Train Accuracy: 0.7158\n",
            "Test Loss : 1.2636, Test Accuracy : 0.6425 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.194 (0.194)\tData 0.149 (0.149)\tLoss 1.0540 (1.0540)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [55][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.9652 (0.9760)\tPrec@1 72.656 (72.401)\n",
            "Epoch: [55][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9084 (0.9950)\tPrec@1 72.656 (71.789)\n",
            "Epoch: [55][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.0316 (1.0015)\tPrec@1 68.750 (71.540)\n",
            "Epoch: [55][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8757 (1.0040)\tPrec@1 70.000 (71.586)\n",
            "Total time : 14.370\n",
            "Train Loss: 1.0040, Train Accuracy: 0.7159\n",
            "Test Loss : 1.4193, Test Accuracy : 0.6091 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.222 (0.222)\tData 0.169 (0.169)\tLoss 0.8424 (0.8424)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [56][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.9895 (0.9394)\tPrec@1 70.312 (73.592)\n",
            "Epoch: [56][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.9584 (0.9640)\tPrec@1 74.219 (73.037)\n",
            "Epoch: [56][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.0839 (0.9788)\tPrec@1 71.875 (72.488)\n",
            "Epoch: [56][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 1.1471 (0.9895)\tPrec@1 65.000 (72.118)\n",
            "Total time : 14.842\n",
            "Train Loss: 0.9895, Train Accuracy: 0.7212\n",
            "Test Loss : 1.2798, Test Accuracy : 0.6444 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.180 (0.180)\tData 0.136 (0.136)\tLoss 0.8893 (0.8893)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [57][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 1.0496 (0.9295)\tPrec@1 67.969 (74.157)\n",
            "Epoch: [57][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.0251 (0.9611)\tPrec@1 73.438 (72.987)\n",
            "Epoch: [57][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.0424 (0.9774)\tPrec@1 74.219 (72.503)\n",
            "Epoch: [57][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8039 (0.9864)\tPrec@1 80.000 (72.284)\n",
            "Total time : 14.623\n",
            "Train Loss: 0.9864, Train Accuracy: 0.7228\n",
            "Test Loss : 1.2192, Test Accuracy : 0.6526 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.205 (0.205)\tData 0.143 (0.143)\tLoss 0.7773 (0.7773)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [58][100/391]\tTime 0.041 (0.040)\tData 0.000 (0.002)\tLoss 1.0094 (0.9369)\tPrec@1 72.656 (73.561)\n",
            "Epoch: [58][200/391]\tTime 0.037 (0.040)\tData 0.000 (0.001)\tLoss 1.0475 (0.9539)\tPrec@1 70.312 (73.130)\n",
            "Epoch: [58][300/391]\tTime 0.037 (0.039)\tData 0.000 (0.001)\tLoss 0.9622 (0.9670)\tPrec@1 72.656 (72.799)\n",
            "Epoch: [58][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 1.1031 (0.9752)\tPrec@1 71.250 (72.546)\n",
            "Total time : 14.917\n",
            "Train Loss: 0.9752, Train Accuracy: 0.7255\n",
            "Test Loss : 1.2455, Test Accuracy : 0.6501 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.207 (0.207)\tData 0.137 (0.137)\tLoss 0.9861 (0.9861)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [59][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.8846 (0.9408)\tPrec@1 74.219 (73.113)\n",
            "Epoch: [59][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.0514 (0.9563)\tPrec@1 68.750 (72.645)\n",
            "Epoch: [59][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 1.0108 (0.9692)\tPrec@1 70.312 (72.490)\n",
            "Epoch: [59][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.1783 (0.9816)\tPrec@1 65.000 (72.190)\n",
            "Total time : 14.306\n",
            "Train Loss: 0.9816, Train Accuracy: 0.7219\n",
            "Test Loss : 1.3519, Test Accuracy : 0.6275 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.185 (0.185)\tData 0.140 (0.140)\tLoss 0.8330 (0.8330)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [60][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.9267 (0.9502)\tPrec@1 75.000 (73.198)\n",
            "Epoch: [60][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9794 (0.9510)\tPrec@1 74.219 (73.165)\n",
            "Epoch: [60][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 1.1073 (0.9632)\tPrec@1 71.875 (72.872)\n",
            "Epoch: [60][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.9549 (0.9709)\tPrec@1 78.750 (72.628)\n",
            "Total time : 14.379\n",
            "Train Loss: 0.9709, Train Accuracy: 0.7263\n",
            "Test Loss : 1.2566, Test Accuracy : 0.6458 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.206 (0.206)\tData 0.139 (0.139)\tLoss 0.8478 (0.8478)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [61][100/391]\tTime 0.041 (0.039)\tData 0.000 (0.002)\tLoss 1.0216 (0.9199)\tPrec@1 72.656 (74.443)\n",
            "Epoch: [61][200/391]\tTime 0.042 (0.039)\tData 0.000 (0.001)\tLoss 0.9401 (0.9410)\tPrec@1 72.656 (73.294)\n",
            "Epoch: [61][300/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 1.0207 (0.9527)\tPrec@1 69.531 (73.046)\n",
            "Epoch: [61][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.8254 (0.9645)\tPrec@1 76.250 (72.712)\n",
            "Total time : 14.965\n",
            "Train Loss: 0.9645, Train Accuracy: 0.7271\n",
            "Test Loss : 1.2855, Test Accuracy : 0.6392 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.182 (0.182)\tData 0.137 (0.137)\tLoss 0.8634 (0.8634)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [62][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.7422 (0.9178)\tPrec@1 81.250 (74.381)\n",
            "Epoch: [62][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 1.0826 (0.9365)\tPrec@1 69.531 (73.745)\n",
            "Epoch: [62][300/391]\tTime 0.038 (0.038)\tData 0.000 (0.001)\tLoss 0.9014 (0.9522)\tPrec@1 75.000 (73.313)\n",
            "Epoch: [62][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.7582 (0.9609)\tPrec@1 76.250 (73.098)\n",
            "Total time : 14.910\n",
            "Train Loss: 0.9609, Train Accuracy: 0.7310\n",
            "Test Loss : 1.2190, Test Accuracy : 0.6547 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.216 (0.216)\tData 0.152 (0.152)\tLoss 0.8083 (0.8083)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [63][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 1.0910 (0.9055)\tPrec@1 71.875 (74.714)\n",
            "Epoch: [63][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.0804 (0.9233)\tPrec@1 71.875 (74.188)\n",
            "Epoch: [63][300/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 1.0401 (0.9405)\tPrec@1 68.750 (73.585)\n",
            "Epoch: [63][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.1410 (0.9505)\tPrec@1 71.250 (73.270)\n",
            "Total time : 14.506\n",
            "Train Loss: 0.9505, Train Accuracy: 0.7327\n",
            "Test Loss : 1.1847, Test Accuracy : 0.6632 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 0.7874 (0.7874)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [64][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.9841 (0.8845)\tPrec@1 70.312 (75.217)\n",
            "Epoch: [64][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8369 (0.9155)\tPrec@1 71.094 (74.363)\n",
            "Epoch: [64][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.9071 (0.9274)\tPrec@1 76.562 (73.964)\n",
            "Epoch: [64][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.9395 (0.9378)\tPrec@1 70.000 (73.704)\n",
            "Total time : 14.251\n",
            "Train Loss: 0.9378, Train Accuracy: 0.7370\n",
            "Test Loss : 1.2837, Test Accuracy : 0.6420 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.185 (0.185)\tData 0.140 (0.140)\tLoss 0.8377 (0.8377)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [65][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 1.0064 (0.8813)\tPrec@1 67.188 (75.317)\n",
            "Epoch: [65][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9286 (0.8975)\tPrec@1 74.219 (74.724)\n",
            "Epoch: [65][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.8414 (0.9171)\tPrec@1 79.688 (74.234)\n",
            "Epoch: [65][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.9453 (0.9323)\tPrec@1 77.500 (73.742)\n",
            "Total time : 14.121\n",
            "Train Loss: 0.9323, Train Accuracy: 0.7374\n",
            "Test Loss : 1.1895, Test Accuracy : 0.6579 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.191 (0.191)\tData 0.146 (0.146)\tLoss 0.8329 (0.8329)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [66][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.9352 (0.8950)\tPrec@1 73.438 (74.892)\n",
            "Epoch: [66][200/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.7533 (0.9037)\tPrec@1 82.031 (74.518)\n",
            "Epoch: [66][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.8958 (0.9212)\tPrec@1 76.562 (73.977)\n",
            "Epoch: [66][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 0.8248 (0.9241)\tPrec@1 75.000 (73.992)\n",
            "Total time : 14.914\n",
            "Train Loss: 0.9241, Train Accuracy: 0.7399\n",
            "Test Loss : 1.2736, Test Accuracy : 0.6449 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.190 (0.190)\tData 0.146 (0.146)\tLoss 0.6958 (0.6958)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [67][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.8113 (0.8762)\tPrec@1 77.344 (75.480)\n",
            "Epoch: [67][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.9731 (0.9010)\tPrec@1 74.219 (74.662)\n",
            "Epoch: [67][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 0.9609 (0.9136)\tPrec@1 71.875 (74.206)\n",
            "Epoch: [67][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8787 (0.9245)\tPrec@1 78.750 (73.892)\n",
            "Total time : 14.534\n",
            "Train Loss: 0.9245, Train Accuracy: 0.7389\n",
            "Test Loss : 1.2196, Test Accuracy : 0.6600 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.182 (0.182)\tData 0.137 (0.137)\tLoss 0.9632 (0.9632)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [68][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 0.7157 (0.8804)\tPrec@1 81.250 (75.627)\n",
            "Epoch: [68][200/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.7747 (0.8955)\tPrec@1 77.344 (74.996)\n",
            "Epoch: [68][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 1.0855 (0.9043)\tPrec@1 68.750 (74.595)\n",
            "Epoch: [68][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.7534 (0.9147)\tPrec@1 82.500 (74.328)\n",
            "Total time : 14.344\n",
            "Train Loss: 0.9147, Train Accuracy: 0.7433\n",
            "Test Loss : 1.1382, Test Accuracy : 0.6772 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.204 (0.204)\tData 0.137 (0.137)\tLoss 0.7519 (0.7519)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [69][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.9563 (0.8479)\tPrec@1 77.344 (76.191)\n",
            "Epoch: [69][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9355 (0.8620)\tPrec@1 74.219 (75.812)\n",
            "Epoch: [69][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9066 (0.8859)\tPrec@1 72.656 (75.039)\n",
            "Epoch: [69][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.7975 (0.8983)\tPrec@1 82.500 (74.726)\n",
            "Total time : 14.342\n",
            "Train Loss: 0.8983, Train Accuracy: 0.7473\n",
            "Test Loss : 1.2206, Test Accuracy : 0.6571 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.197 (0.197)\tData 0.150 (0.150)\tLoss 0.8750 (0.8750)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [70][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.8225 (0.8559)\tPrec@1 77.344 (75.774)\n",
            "Epoch: [70][200/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 1.1182 (0.8652)\tPrec@1 67.188 (75.630)\n",
            "Epoch: [70][300/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.9878 (0.8783)\tPrec@1 71.094 (75.184)\n",
            "Epoch: [70][390/391]\tTime 0.033 (0.036)\tData 0.000 (0.001)\tLoss 1.2477 (0.8925)\tPrec@1 70.000 (74.838)\n",
            "Total time : 14.215\n",
            "Train Loss: 0.8925, Train Accuracy: 0.7484\n",
            "Test Loss : 1.2419, Test Accuracy : 0.6512 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.207 (0.207)\tData 0.146 (0.146)\tLoss 0.8045 (0.8045)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [71][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.9441 (0.8503)\tPrec@1 71.875 (76.416)\n",
            "Epoch: [71][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9623 (0.8646)\tPrec@1 75.781 (75.754)\n",
            "Epoch: [71][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.9001 (0.8830)\tPrec@1 79.688 (75.182)\n",
            "Epoch: [71][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.7241 (0.8874)\tPrec@1 82.500 (75.034)\n",
            "Total time : 14.487\n",
            "Train Loss: 0.8874, Train Accuracy: 0.7503\n",
            "Test Loss : 1.1586, Test Accuracy : 0.6724 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.186 (0.186)\tData 0.141 (0.141)\tLoss 0.8914 (0.8914)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [72][100/391]\tTime 0.034 (0.037)\tData 0.000 (0.002)\tLoss 0.8965 (0.8341)\tPrec@1 76.562 (76.671)\n",
            "Epoch: [72][200/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.8488 (0.8593)\tPrec@1 75.781 (75.894)\n",
            "Epoch: [72][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8171 (0.8780)\tPrec@1 75.000 (75.239)\n",
            "Epoch: [72][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.9127 (0.8833)\tPrec@1 71.250 (75.116)\n",
            "Total time : 14.414\n",
            "Train Loss: 0.8833, Train Accuracy: 0.7512\n",
            "Test Loss : 1.1175, Test Accuracy : 0.6825 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.199 (0.199)\tData 0.149 (0.149)\tLoss 0.6997 (0.6997)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [73][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.8910 (0.8178)\tPrec@1 75.781 (77.251)\n",
            "Epoch: [73][200/391]\tTime 0.040 (0.039)\tData 0.000 (0.001)\tLoss 0.8401 (0.8352)\tPrec@1 76.562 (76.617)\n",
            "Epoch: [73][300/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.8432 (0.8593)\tPrec@1 77.344 (76.004)\n",
            "Epoch: [73][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 0.6426 (0.8789)\tPrec@1 83.750 (75.472)\n",
            "Total time : 15.037\n",
            "Train Loss: 0.8789, Train Accuracy: 0.7547\n",
            "Test Loss : 1.1598, Test Accuracy : 0.6705 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.188 (0.188)\tData 0.143 (0.143)\tLoss 0.7877 (0.7877)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [74][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.6913 (0.8216)\tPrec@1 81.250 (77.235)\n",
            "Epoch: [74][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 1.0279 (0.8451)\tPrec@1 75.000 (76.489)\n",
            "Epoch: [74][300/391]\tTime 0.040 (0.037)\tData 0.000 (0.001)\tLoss 0.8030 (0.8565)\tPrec@1 78.906 (76.051)\n",
            "Epoch: [74][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8965 (0.8650)\tPrec@1 73.750 (75.778)\n",
            "Total time : 14.546\n",
            "Train Loss: 0.8650, Train Accuracy: 0.7578\n",
            "Test Loss : 1.1794, Test Accuracy : 0.6673 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.209 (0.209)\tData 0.141 (0.141)\tLoss 0.8330 (0.8330)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [75][100/391]\tTime 0.038 (0.039)\tData 0.000 (0.002)\tLoss 0.8914 (0.8122)\tPrec@1 71.094 (77.444)\n",
            "Epoch: [75][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 1.0392 (0.8385)\tPrec@1 67.188 (76.543)\n",
            "Epoch: [75][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.7435 (0.8551)\tPrec@1 82.031 (76.095)\n",
            "Epoch: [75][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.6051 (0.8653)\tPrec@1 87.500 (75.732)\n",
            "Total time : 14.295\n",
            "Train Loss: 0.8653, Train Accuracy: 0.7573\n",
            "Test Loss : 1.1946, Test Accuracy : 0.6644 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.181 (0.181)\tData 0.137 (0.137)\tLoss 0.9438 (0.9438)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [76][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.8320 (0.8155)\tPrec@1 79.688 (77.591)\n",
            "Epoch: [76][200/391]\tTime 0.040 (0.037)\tData 0.000 (0.001)\tLoss 0.9211 (0.8315)\tPrec@1 69.531 (76.873)\n",
            "Epoch: [76][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.7844 (0.8352)\tPrec@1 78.906 (76.612)\n",
            "Epoch: [76][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 1.1291 (0.8503)\tPrec@1 66.250 (76.164)\n",
            "Total time : 14.336\n",
            "Train Loss: 0.8503, Train Accuracy: 0.7616\n",
            "Test Loss : 1.1622, Test Accuracy : 0.6703 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.209 (0.209)\tData 0.141 (0.141)\tLoss 0.7131 (0.7131)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [77][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.7024 (0.7840)\tPrec@1 82.812 (78.287)\n",
            "Epoch: [77][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.8869 (0.8061)\tPrec@1 76.562 (77.433)\n",
            "Epoch: [77][300/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.9865 (0.8285)\tPrec@1 74.219 (76.757)\n",
            "Epoch: [77][390/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.9780 (0.8408)\tPrec@1 70.000 (76.316)\n",
            "Total time : 14.286\n",
            "Train Loss: 0.8408, Train Accuracy: 0.7632\n",
            "Test Loss : 1.1785, Test Accuracy : 0.6686 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.211 (0.211)\tData 0.144 (0.144)\tLoss 0.7528 (0.7528)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [78][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.7790 (0.7982)\tPrec@1 85.156 (77.746)\n",
            "Epoch: [78][200/391]\tTime 0.040 (0.039)\tData 0.000 (0.001)\tLoss 0.8457 (0.8141)\tPrec@1 76.562 (77.247)\n",
            "Epoch: [78][300/391]\tTime 0.054 (0.039)\tData 0.000 (0.001)\tLoss 0.9171 (0.8306)\tPrec@1 73.438 (76.697)\n",
            "Epoch: [78][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.9205 (0.8380)\tPrec@1 78.750 (76.450)\n",
            "Total time : 14.920\n",
            "Train Loss: 0.8380, Train Accuracy: 0.7645\n",
            "Test Loss : 1.1564, Test Accuracy : 0.6737 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.188 (0.188)\tData 0.138 (0.138)\tLoss 0.7311 (0.7311)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [79][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.7007 (0.7663)\tPrec@1 83.594 (78.736)\n",
            "Epoch: [79][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8009 (0.7828)\tPrec@1 78.125 (78.211)\n",
            "Epoch: [79][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.7074 (0.8037)\tPrec@1 80.469 (77.614)\n",
            "Epoch: [79][390/391]\tTime 0.031 (0.036)\tData 0.000 (0.001)\tLoss 0.8818 (0.8190)\tPrec@1 75.000 (77.150)\n",
            "Total time : 14.242\n",
            "Train Loss: 0.8190, Train Accuracy: 0.7715\n",
            "Test Loss : 1.1469, Test Accuracy : 0.6744 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 0.7068 (0.7068)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [80][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.7733 (0.7851)\tPrec@1 79.688 (78.365)\n",
            "Epoch: [80][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.9354 (0.7952)\tPrec@1 71.094 (78.071)\n",
            "Epoch: [80][300/391]\tTime 0.034 (0.036)\tData 0.000 (0.001)\tLoss 0.7975 (0.8030)\tPrec@1 82.812 (77.764)\n",
            "Epoch: [80][390/391]\tTime 0.031 (0.036)\tData 0.000 (0.001)\tLoss 0.9169 (0.8135)\tPrec@1 77.500 (77.384)\n",
            "Total time : 13.996\n",
            "Train Loss: 0.8135, Train Accuracy: 0.7738\n",
            "Test Loss : 1.1811, Test Accuracy : 0.6711 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.188 (0.188)\tData 0.138 (0.138)\tLoss 0.8302 (0.8302)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [81][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.6642 (0.7768)\tPrec@1 80.469 (78.504)\n",
            "Epoch: [81][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.7881 (0.7803)\tPrec@1 80.469 (78.354)\n",
            "Epoch: [81][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.8361 (0.7940)\tPrec@1 76.562 (77.832)\n",
            "Epoch: [81][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.8208 (0.8066)\tPrec@1 77.500 (77.382)\n",
            "Total time : 14.776\n",
            "Train Loss: 0.8066, Train Accuracy: 0.7738\n",
            "Test Loss : 1.1763, Test Accuracy : 0.6710 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.181 (0.181)\tData 0.137 (0.137)\tLoss 0.6197 (0.6197)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [82][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.8825 (0.7817)\tPrec@1 75.781 (78.326)\n",
            "Epoch: [82][200/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.8795 (0.7911)\tPrec@1 75.000 (77.900)\n",
            "Epoch: [82][300/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.9331 (0.7989)\tPrec@1 72.656 (77.707)\n",
            "Epoch: [82][390/391]\tTime 0.031 (0.036)\tData 0.000 (0.001)\tLoss 0.6766 (0.8043)\tPrec@1 81.250 (77.522)\n",
            "Total time : 14.176\n",
            "Train Loss: 0.8043, Train Accuracy: 0.7752\n",
            "Test Loss : 1.1862, Test Accuracy : 0.6660 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.186 (0.186)\tData 0.136 (0.136)\tLoss 0.6162 (0.6162)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [83][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.7210 (0.7371)\tPrec@1 82.031 (79.742)\n",
            "Epoch: [83][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.7191 (0.7643)\tPrec@1 82.031 (78.805)\n",
            "Epoch: [83][300/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 0.8833 (0.7797)\tPrec@1 77.344 (78.182)\n",
            "Epoch: [83][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8190 (0.7958)\tPrec@1 81.250 (77.644)\n",
            "Total time : 14.420\n",
            "Train Loss: 0.7958, Train Accuracy: 0.7764\n",
            "Test Loss : 1.1787, Test Accuracy : 0.6659 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.197 (0.197)\tData 0.146 (0.146)\tLoss 0.8287 (0.8287)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [84][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.7234 (0.7398)\tPrec@1 83.594 (79.533)\n",
            "Epoch: [84][200/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.8563 (0.7581)\tPrec@1 75.000 (79.174)\n",
            "Epoch: [84][300/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.5786 (0.7757)\tPrec@1 83.594 (78.649)\n",
            "Epoch: [84][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.9129 (0.7861)\tPrec@1 73.750 (78.294)\n",
            "Total time : 14.691\n",
            "Train Loss: 0.7861, Train Accuracy: 0.7829\n",
            "Test Loss : 1.1030, Test Accuracy : 0.6920 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.200 (0.200)\tData 0.148 (0.148)\tLoss 0.6386 (0.6386)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [85][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.6095 (0.7327)\tPrec@1 84.375 (79.626)\n",
            "Epoch: [85][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8183 (0.7565)\tPrec@1 77.344 (79.066)\n",
            "Epoch: [85][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8189 (0.7649)\tPrec@1 79.688 (78.631)\n",
            "Epoch: [85][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8208 (0.7729)\tPrec@1 81.250 (78.460)\n",
            "Total time : 14.423\n",
            "Train Loss: 0.7729, Train Accuracy: 0.7846\n",
            "Test Loss : 1.1050, Test Accuracy : 0.6877 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.202 (0.202)\tData 0.134 (0.134)\tLoss 0.6381 (0.6381)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [86][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.7537 (0.7132)\tPrec@1 81.250 (80.430)\n",
            "Epoch: [86][200/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.7251 (0.7341)\tPrec@1 80.469 (79.598)\n",
            "Epoch: [86][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.7531 (0.7520)\tPrec@1 78.906 (78.911)\n",
            "Epoch: [86][390/391]\tTime 0.031 (0.036)\tData 0.000 (0.001)\tLoss 1.0123 (0.7711)\tPrec@1 71.250 (78.376)\n",
            "Total time : 14.174\n",
            "Train Loss: 0.7711, Train Accuracy: 0.7838\n",
            "Test Loss : 1.1160, Test Accuracy : 0.6810 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.201 (0.201)\tData 0.136 (0.136)\tLoss 0.6953 (0.6953)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [87][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.6679 (0.7288)\tPrec@1 79.688 (80.082)\n",
            "Epoch: [87][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.8796 (0.7422)\tPrec@1 73.438 (79.400)\n",
            "Epoch: [87][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.7450 (0.7480)\tPrec@1 82.812 (79.148)\n",
            "Epoch: [87][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8603 (0.7636)\tPrec@1 78.750 (78.674)\n",
            "Total time : 14.394\n",
            "Train Loss: 0.7636, Train Accuracy: 0.7867\n",
            "Test Loss : 1.1449, Test Accuracy : 0.6766 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 0.6008 (0.6008)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [88][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.6779 (0.7162)\tPrec@1 79.688 (80.144)\n",
            "Epoch: [88][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8197 (0.7228)\tPrec@1 75.000 (79.722)\n",
            "Epoch: [88][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.7146 (0.7408)\tPrec@1 81.250 (79.181)\n",
            "Epoch: [88][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8102 (0.7552)\tPrec@1 76.250 (78.864)\n",
            "Total time : 14.397\n",
            "Train Loss: 0.7552, Train Accuracy: 0.7886\n",
            "Test Loss : 1.1029, Test Accuracy : 0.6878 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.191 (0.191)\tData 0.140 (0.140)\tLoss 0.6029 (0.6029)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [89][100/391]\tTime 0.040 (0.041)\tData 0.000 (0.002)\tLoss 0.6794 (0.7029)\tPrec@1 78.906 (80.724)\n",
            "Epoch: [89][200/391]\tTime 0.036 (0.040)\tData 0.000 (0.001)\tLoss 0.9885 (0.7199)\tPrec@1 70.312 (80.018)\n",
            "Epoch: [89][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.5751 (0.7287)\tPrec@1 79.688 (79.700)\n",
            "Epoch: [89][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.9703 (0.7435)\tPrec@1 75.000 (79.252)\n",
            "Total time : 14.887\n",
            "Train Loss: 0.7435, Train Accuracy: 0.7925\n",
            "Test Loss : 1.0785, Test Accuracy : 0.6942 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 0.5596 (0.5596)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [90][100/391]\tTime 0.038 (0.039)\tData 0.000 (0.002)\tLoss 0.6898 (0.7081)\tPrec@1 84.375 (80.678)\n",
            "Epoch: [90][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.7333 (0.7138)\tPrec@1 81.250 (80.426)\n",
            "Epoch: [90][300/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.9905 (0.7271)\tPrec@1 74.219 (79.952)\n",
            "Epoch: [90][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.7988 (0.7359)\tPrec@1 72.500 (79.700)\n",
            "Total time : 14.752\n",
            "Train Loss: 0.7359, Train Accuracy: 0.7970\n",
            "Test Loss : 1.1086, Test Accuracy : 0.6874 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.180 (0.180)\tData 0.136 (0.136)\tLoss 0.5220 (0.5220)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [91][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.5832 (0.6934)\tPrec@1 83.594 (81.103)\n",
            "Epoch: [91][200/391]\tTime 0.041 (0.038)\tData 0.000 (0.001)\tLoss 0.7226 (0.7002)\tPrec@1 81.250 (80.718)\n",
            "Epoch: [91][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.7805 (0.7167)\tPrec@1 76.562 (80.173)\n",
            "Epoch: [91][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.7206 (0.7248)\tPrec@1 76.250 (79.962)\n",
            "Total time : 14.649\n",
            "Train Loss: 0.7248, Train Accuracy: 0.7996\n",
            "Test Loss : 1.1082, Test Accuracy : 0.6882 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.184 (0.184)\tData 0.141 (0.141)\tLoss 0.6585 (0.6585)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [92][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.6805 (0.6784)\tPrec@1 81.250 (81.528)\n",
            "Epoch: [92][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.7804 (0.6866)\tPrec@1 75.000 (81.145)\n",
            "Epoch: [92][300/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.7254 (0.7004)\tPrec@1 83.594 (80.705)\n",
            "Epoch: [92][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.8592 (0.7167)\tPrec@1 72.500 (80.142)\n",
            "Total time : 14.085\n",
            "Train Loss: 0.7167, Train Accuracy: 0.8014\n",
            "Test Loss : 1.0747, Test Accuracy : 0.6947 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.215 (0.215)\tData 0.165 (0.165)\tLoss 0.6401 (0.6401)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [93][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.7446 (0.6705)\tPrec@1 78.906 (81.513)\n",
            "Epoch: [93][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.6062 (0.6844)\tPrec@1 82.031 (80.924)\n",
            "Epoch: [93][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.7692 (0.6987)\tPrec@1 78.125 (80.393)\n",
            "Epoch: [93][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.9215 (0.7104)\tPrec@1 76.250 (80.084)\n",
            "Total time : 14.183\n",
            "Train Loss: 0.7104, Train Accuracy: 0.8008\n",
            "Test Loss : 1.0491, Test Accuracy : 0.6994 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.203 (0.203)\tData 0.138 (0.138)\tLoss 0.5509 (0.5509)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [94][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 0.7040 (0.6698)\tPrec@1 79.688 (81.505)\n",
            "Epoch: [94][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.7255 (0.6824)\tPrec@1 78.906 (81.017)\n",
            "Epoch: [94][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.7723 (0.6984)\tPrec@1 78.906 (80.606)\n",
            "Epoch: [94][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8964 (0.7067)\tPrec@1 72.500 (80.316)\n",
            "Total time : 14.378\n",
            "Train Loss: 0.7067, Train Accuracy: 0.8032\n",
            "Test Loss : 1.0759, Test Accuracy : 0.6941 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 0.5278 (0.5278)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [95][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.6064 (0.6599)\tPrec@1 84.375 (81.884)\n",
            "Epoch: [95][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.7128 (0.6709)\tPrec@1 79.688 (81.491)\n",
            "Epoch: [95][300/391]\tTime 0.040 (0.037)\tData 0.000 (0.001)\tLoss 1.0173 (0.6913)\tPrec@1 70.312 (80.892)\n",
            "Epoch: [95][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.9710 (0.6996)\tPrec@1 67.500 (80.630)\n",
            "Total time : 14.493\n",
            "Train Loss: 0.6996, Train Accuracy: 0.8063\n",
            "Test Loss : 1.0731, Test Accuracy : 0.6966 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.207 (0.207)\tData 0.142 (0.142)\tLoss 0.5065 (0.5065)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [96][100/391]\tTime 0.037 (0.040)\tData 0.000 (0.002)\tLoss 0.6510 (0.6564)\tPrec@1 79.688 (81.590)\n",
            "Epoch: [96][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.6724 (0.6655)\tPrec@1 79.688 (81.398)\n",
            "Epoch: [96][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.7683 (0.6759)\tPrec@1 76.562 (81.128)\n",
            "Epoch: [96][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.6948 (0.6856)\tPrec@1 80.000 (80.856)\n",
            "Total time : 14.509\n",
            "Train Loss: 0.6856, Train Accuracy: 0.8086\n",
            "Test Loss : 1.0008, Test Accuracy : 0.7134 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.204 (0.204)\tData 0.134 (0.134)\tLoss 0.5846 (0.5846)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [97][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.7028 (0.6323)\tPrec@1 82.031 (82.580)\n",
            "Epoch: [97][200/391]\tTime 0.040 (0.039)\tData 0.000 (0.001)\tLoss 0.5778 (0.6387)\tPrec@1 81.250 (82.331)\n",
            "Epoch: [97][300/391]\tTime 0.038 (0.038)\tData 0.000 (0.001)\tLoss 0.6189 (0.6582)\tPrec@1 75.781 (81.878)\n",
            "Epoch: [97][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.7534 (0.6710)\tPrec@1 81.250 (81.420)\n",
            "Total time : 14.835\n",
            "Train Loss: 0.6710, Train Accuracy: 0.8142\n",
            "Test Loss : 1.1000, Test Accuracy : 0.6857 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.184 (0.184)\tData 0.139 (0.139)\tLoss 0.5654 (0.5654)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [98][100/391]\tTime 0.034 (0.037)\tData 0.000 (0.002)\tLoss 0.6827 (0.6337)\tPrec@1 80.469 (82.743)\n",
            "Epoch: [98][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.6782 (0.6428)\tPrec@1 85.156 (82.358)\n",
            "Epoch: [98][300/391]\tTime 0.039 (0.037)\tData 0.000 (0.001)\tLoss 0.6822 (0.6562)\tPrec@1 79.688 (81.920)\n",
            "Epoch: [98][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.7720 (0.6653)\tPrec@1 82.500 (81.632)\n",
            "Total time : 14.440\n",
            "Train Loss: 0.6653, Train Accuracy: 0.8163\n",
            "Test Loss : 1.1419, Test Accuracy : 0.6812 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.193 (0.193)\tData 0.138 (0.138)\tLoss 0.5105 (0.5105)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [99][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.7136 (0.6165)\tPrec@1 82.031 (83.509)\n",
            "Epoch: [99][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.6339 (0.6336)\tPrec@1 81.250 (82.910)\n",
            "Epoch: [99][300/391]\tTime 0.039 (0.037)\tData 0.000 (0.001)\tLoss 0.8265 (0.6487)\tPrec@1 78.125 (82.395)\n",
            "Epoch: [99][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.7295 (0.6568)\tPrec@1 78.750 (82.056)\n",
            "Total time : 14.393\n",
            "Train Loss: 0.6568, Train Accuracy: 0.8206\n",
            "Test Loss : 1.0940, Test Accuracy : 0.6890 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 0.6819 (0.6819)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [100][100/391]\tTime 0.040 (0.038)\tData 0.000 (0.002)\tLoss 0.6951 (0.6049)\tPrec@1 78.906 (83.338)\n",
            "Epoch: [100][200/391]\tTime 0.040 (0.037)\tData 0.000 (0.001)\tLoss 0.5801 (0.6133)\tPrec@1 83.594 (83.046)\n",
            "Epoch: [100][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.6004 (0.6317)\tPrec@1 85.156 (82.462)\n",
            "Epoch: [100][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.8615 (0.6432)\tPrec@1 80.000 (82.138)\n",
            "Total time : 14.433\n",
            "Train Loss: 0.6432, Train Accuracy: 0.8214\n",
            "Test Loss : 1.0733, Test Accuracy : 0.6990 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.187 (0.187)\tData 0.142 (0.142)\tLoss 0.6749 (0.6749)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [101][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.6569 (0.5928)\tPrec@1 82.031 (84.066)\n",
            "Epoch: [101][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.5320 (0.6083)\tPrec@1 86.719 (83.434)\n",
            "Epoch: [101][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.6418 (0.6286)\tPrec@1 84.375 (82.831)\n",
            "Epoch: [101][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.6167 (0.6412)\tPrec@1 85.000 (82.458)\n",
            "Total time : 14.713\n",
            "Train Loss: 0.6412, Train Accuracy: 0.8246\n",
            "Test Loss : 1.0677, Test Accuracy : 0.7018 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.190 (0.190)\tData 0.138 (0.138)\tLoss 0.5412 (0.5412)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [102][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.6785 (0.6003)\tPrec@1 82.031 (84.220)\n",
            "Epoch: [102][200/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.5657 (0.6062)\tPrec@1 82.812 (83.769)\n",
            "Epoch: [102][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.6607 (0.6207)\tPrec@1 85.938 (83.285)\n",
            "Epoch: [102][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 0.6386 (0.6291)\tPrec@1 81.250 (82.960)\n",
            "Total time : 14.842\n",
            "Train Loss: 0.6291, Train Accuracy: 0.8296\n",
            "Test Loss : 1.0773, Test Accuracy : 0.6996 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.182 (0.182)\tData 0.137 (0.137)\tLoss 0.5302 (0.5302)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [103][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 0.5708 (0.5727)\tPrec@1 86.719 (84.847)\n",
            "Epoch: [103][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.6025 (0.5913)\tPrec@1 83.594 (84.068)\n",
            "Epoch: [103][300/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.7791 (0.6110)\tPrec@1 82.031 (83.451)\n",
            "Epoch: [103][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 1.0236 (0.6171)\tPrec@1 65.000 (83.246)\n",
            "Total time : 14.973\n",
            "Train Loss: 0.6171, Train Accuracy: 0.8325\n",
            "Test Loss : 0.9669, Test Accuracy : 0.7258 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.187 (0.187)\tData 0.143 (0.143)\tLoss 0.5476 (0.5476)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [104][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.6607 (0.5765)\tPrec@1 82.812 (84.777)\n",
            "Epoch: [104][200/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 0.6414 (0.5913)\tPrec@1 82.031 (84.196)\n",
            "Epoch: [104][300/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.6922 (0.6031)\tPrec@1 79.688 (83.729)\n",
            "Epoch: [104][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.5818 (0.6115)\tPrec@1 85.000 (83.488)\n",
            "Total time : 14.677\n",
            "Train Loss: 0.6115, Train Accuracy: 0.8349\n",
            "Test Loss : 1.0052, Test Accuracy : 0.7126 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.186 (0.186)\tData 0.136 (0.136)\tLoss 0.6036 (0.6036)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [105][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.4700 (0.5684)\tPrec@1 88.281 (85.025)\n",
            "Epoch: [105][200/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 0.4745 (0.5780)\tPrec@1 87.500 (84.519)\n",
            "Epoch: [105][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.6811 (0.5895)\tPrec@1 80.469 (84.165)\n",
            "Epoch: [105][390/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.8874 (0.6054)\tPrec@1 76.250 (83.542)\n",
            "Total time : 14.325\n",
            "Train Loss: 0.6054, Train Accuracy: 0.8354\n",
            "Test Loss : 1.0111, Test Accuracy : 0.7148 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.187 (0.187)\tData 0.142 (0.142)\tLoss 0.7566 (0.7566)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [106][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.5527 (0.5485)\tPrec@1 86.719 (85.574)\n",
            "Epoch: [106][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.4998 (0.5681)\tPrec@1 85.938 (84.907)\n",
            "Epoch: [106][300/391]\tTime 0.042 (0.037)\tData 0.000 (0.001)\tLoss 0.6955 (0.5820)\tPrec@1 82.812 (84.313)\n",
            "Epoch: [106][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 0.5386 (0.5914)\tPrec@1 85.000 (83.946)\n",
            "Total time : 14.528\n",
            "Train Loss: 0.5914, Train Accuracy: 0.8395\n",
            "Test Loss : 1.0162, Test Accuracy : 0.7169 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.206 (0.206)\tData 0.143 (0.143)\tLoss 0.5767 (0.5767)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [107][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.5984 (0.5376)\tPrec@1 84.375 (85.651)\n",
            "Epoch: [107][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.6187 (0.5519)\tPrec@1 84.375 (85.273)\n",
            "Epoch: [107][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.6614 (0.5658)\tPrec@1 80.469 (84.873)\n",
            "Epoch: [107][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.7605 (0.5796)\tPrec@1 80.000 (84.452)\n",
            "Total time : 14.477\n",
            "Train Loss: 0.5796, Train Accuracy: 0.8445\n",
            "Test Loss : 1.0101, Test Accuracy : 0.7128 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.183 (0.183)\tData 0.138 (0.138)\tLoss 0.6208 (0.6208)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [108][100/391]\tTime 0.038 (0.037)\tData 0.000 (0.002)\tLoss 0.5651 (0.5274)\tPrec@1 85.938 (86.286)\n",
            "Epoch: [108][200/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.5000 (0.5384)\tPrec@1 89.844 (85.794)\n",
            "Epoch: [108][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 0.4967 (0.5517)\tPrec@1 86.719 (85.348)\n",
            "Epoch: [108][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.5656 (0.5632)\tPrec@1 83.750 (84.874)\n",
            "Total time : 14.349\n",
            "Train Loss: 0.5632, Train Accuracy: 0.8487\n",
            "Test Loss : 1.0740, Test Accuracy : 0.6988 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 0.5395 (0.5395)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [109][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.6284 (0.5363)\tPrec@1 80.469 (85.675)\n",
            "Epoch: [109][200/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.6005 (0.5503)\tPrec@1 83.594 (85.292)\n",
            "Epoch: [109][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.5453 (0.5617)\tPrec@1 85.156 (84.876)\n",
            "Epoch: [109][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.6619 (0.5659)\tPrec@1 82.500 (84.798)\n",
            "Total time : 14.460\n",
            "Train Loss: 0.5659, Train Accuracy: 0.8480\n",
            "Test Loss : 1.0265, Test Accuracy : 0.7106 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.188 (0.188)\tData 0.137 (0.137)\tLoss 0.6008 (0.6008)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [110][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.5083 (0.5259)\tPrec@1 86.719 (86.108)\n",
            "Epoch: [110][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.5365 (0.5272)\tPrec@1 86.719 (85.879)\n",
            "Epoch: [110][300/391]\tTime 0.034 (0.036)\tData 0.000 (0.001)\tLoss 0.6687 (0.5382)\tPrec@1 83.594 (85.551)\n",
            "Epoch: [110][390/391]\tTime 0.031 (0.036)\tData 0.000 (0.001)\tLoss 0.4666 (0.5428)\tPrec@1 85.000 (85.442)\n",
            "Total time : 14.196\n",
            "Train Loss: 0.5428, Train Accuracy: 0.8544\n",
            "Test Loss : 1.0105, Test Accuracy : 0.7120 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.228 (0.228)\tData 0.162 (0.162)\tLoss 0.5191 (0.5191)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [111][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.5435 (0.5110)\tPrec@1 82.812 (86.788)\n",
            "Epoch: [111][200/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.4224 (0.5199)\tPrec@1 88.281 (86.318)\n",
            "Epoch: [111][300/391]\tTime 0.042 (0.038)\tData 0.000 (0.001)\tLoss 0.5327 (0.5343)\tPrec@1 89.062 (85.803)\n",
            "Epoch: [111][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.5981 (0.5401)\tPrec@1 81.250 (85.674)\n",
            "Total time : 14.945\n",
            "Train Loss: 0.5401, Train Accuracy: 0.8567\n",
            "Test Loss : 0.9470, Test Accuracy : 0.7280 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.203 (0.203)\tData 0.158 (0.158)\tLoss 0.4244 (0.4244)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [112][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.4909 (0.5103)\tPrec@1 87.500 (86.873)\n",
            "Epoch: [112][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.4753 (0.5168)\tPrec@1 85.938 (86.657)\n",
            "Epoch: [112][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.6307 (0.5262)\tPrec@1 79.688 (86.153)\n",
            "Epoch: [112][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 0.5809 (0.5312)\tPrec@1 87.500 (85.916)\n",
            "Total time : 14.884\n",
            "Train Loss: 0.5312, Train Accuracy: 0.8592\n",
            "Test Loss : 0.9966, Test Accuracy : 0.7165 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.192 (0.192)\tData 0.147 (0.147)\tLoss 0.5066 (0.5066)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [113][100/391]\tTime 0.037 (0.040)\tData 0.000 (0.002)\tLoss 0.4515 (0.4911)\tPrec@1 89.844 (87.090)\n",
            "Epoch: [113][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.5864 (0.4969)\tPrec@1 85.156 (86.874)\n",
            "Epoch: [113][300/391]\tTime 0.034 (0.038)\tData 0.000 (0.001)\tLoss 0.5881 (0.5106)\tPrec@1 84.375 (86.446)\n",
            "Epoch: [113][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.4767 (0.5185)\tPrec@1 90.000 (86.196)\n",
            "Total time : 14.728\n",
            "Train Loss: 0.5185, Train Accuracy: 0.8620\n",
            "Test Loss : 1.0014, Test Accuracy : 0.7118 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.190 (0.190)\tData 0.138 (0.138)\tLoss 0.4854 (0.4854)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [114][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.4440 (0.4757)\tPrec@1 87.500 (87.693)\n",
            "Epoch: [114][200/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.5083 (0.4865)\tPrec@1 85.156 (87.263)\n",
            "Epoch: [114][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.5285 (0.4990)\tPrec@1 85.938 (86.950)\n",
            "Epoch: [114][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.5656 (0.5104)\tPrec@1 87.500 (86.658)\n",
            "Total time : 14.365\n",
            "Train Loss: 0.5104, Train Accuracy: 0.8666\n",
            "Test Loss : 0.9642, Test Accuracy : 0.7268 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.194 (0.194)\tData 0.144 (0.144)\tLoss 0.3412 (0.3412)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [115][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.5261 (0.4718)\tPrec@1 85.938 (87.717)\n",
            "Epoch: [115][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.4992 (0.4784)\tPrec@1 83.594 (87.512)\n",
            "Epoch: [115][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.5186 (0.4884)\tPrec@1 87.500 (87.305)\n",
            "Epoch: [115][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.4329 (0.4987)\tPrec@1 85.000 (86.872)\n",
            "Total time : 14.905\n",
            "Train Loss: 0.4987, Train Accuracy: 0.8687\n",
            "Test Loss : 0.9494, Test Accuracy : 0.7329 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.182 (0.182)\tData 0.138 (0.138)\tLoss 0.3089 (0.3089)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [116][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.4328 (0.4456)\tPrec@1 86.719 (88.722)\n",
            "Epoch: [116][200/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.3609 (0.4645)\tPrec@1 90.625 (88.126)\n",
            "Epoch: [116][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.4784 (0.4766)\tPrec@1 84.375 (87.843)\n",
            "Epoch: [116][390/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 0.4947 (0.4861)\tPrec@1 87.500 (87.506)\n",
            "Total time : 14.929\n",
            "Train Loss: 0.4861, Train Accuracy: 0.8751\n",
            "Test Loss : 1.0177, Test Accuracy : 0.7163 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.185 (0.185)\tData 0.136 (0.136)\tLoss 0.5471 (0.5471)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [117][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.4792 (0.4653)\tPrec@1 89.844 (88.003)\n",
            "Epoch: [117][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.4818 (0.4686)\tPrec@1 87.500 (87.889)\n",
            "Epoch: [117][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.4848 (0.4763)\tPrec@1 89.062 (87.638)\n",
            "Epoch: [117][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.5269 (0.4843)\tPrec@1 85.000 (87.370)\n",
            "Total time : 14.536\n",
            "Train Loss: 0.4843, Train Accuracy: 0.8737\n",
            "Test Loss : 0.9271, Test Accuracy : 0.7369 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.196 (0.196)\tData 0.143 (0.143)\tLoss 0.3962 (0.3962)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [118][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.4067 (0.4239)\tPrec@1 89.062 (89.380)\n",
            "Epoch: [118][200/391]\tTime 0.037 (0.039)\tData 0.000 (0.001)\tLoss 0.3329 (0.4462)\tPrec@1 91.406 (88.557)\n",
            "Epoch: [118][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.5131 (0.4611)\tPrec@1 81.250 (88.092)\n",
            "Epoch: [118][390/391]\tTime 0.032 (0.039)\tData 0.000 (0.001)\tLoss 0.5108 (0.4760)\tPrec@1 87.500 (87.640)\n",
            "Total time : 15.064\n",
            "Train Loss: 0.4760, Train Accuracy: 0.8764\n",
            "Test Loss : 0.9763, Test Accuracy : 0.7256 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.192 (0.192)\tData 0.141 (0.141)\tLoss 0.4660 (0.4660)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [119][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.4296 (0.4244)\tPrec@1 86.719 (89.387)\n",
            "Epoch: [119][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.4617 (0.4429)\tPrec@1 89.062 (88.697)\n",
            "Epoch: [119][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.3368 (0.4507)\tPrec@1 92.188 (88.504)\n",
            "Epoch: [119][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.5398 (0.4577)\tPrec@1 82.500 (88.260)\n",
            "Total time : 14.584\n",
            "Train Loss: 0.4577, Train Accuracy: 0.8826\n",
            "Test Loss : 0.9347, Test Accuracy : 0.7336 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.179 (0.179)\tData 0.135 (0.135)\tLoss 0.3431 (0.3431)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [120][100/391]\tTime 0.039 (0.039)\tData 0.000 (0.002)\tLoss 0.3449 (0.4262)\tPrec@1 90.625 (89.217)\n",
            "Epoch: [120][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.5466 (0.4334)\tPrec@1 89.062 (89.070)\n",
            "Epoch: [120][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.3878 (0.4414)\tPrec@1 92.969 (88.829)\n",
            "Epoch: [120][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.4141 (0.4503)\tPrec@1 87.500 (88.570)\n",
            "Total time : 14.948\n",
            "Train Loss: 0.4503, Train Accuracy: 0.8857\n",
            "Test Loss : 0.9198, Test Accuracy : 0.7392 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 0.3920 (0.3920)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [121][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.3285 (0.4135)\tPrec@1 93.750 (89.619)\n",
            "Epoch: [121][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.4491 (0.4194)\tPrec@1 90.625 (89.436)\n",
            "Epoch: [121][300/391]\tTime 0.039 (0.037)\tData 0.000 (0.001)\tLoss 0.5499 (0.4339)\tPrec@1 87.500 (89.044)\n",
            "Epoch: [121][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.4344 (0.4432)\tPrec@1 88.750 (88.818)\n",
            "Total time : 14.467\n",
            "Train Loss: 0.4432, Train Accuracy: 0.8882\n",
            "Test Loss : 0.9278, Test Accuracy : 0.7370 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.198 (0.198)\tData 0.138 (0.138)\tLoss 0.4350 (0.4350)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [122][100/391]\tTime 0.041 (0.040)\tData 0.000 (0.002)\tLoss 0.4450 (0.4032)\tPrec@1 89.062 (90.292)\n",
            "Epoch: [122][200/391]\tTime 0.040 (0.039)\tData 0.000 (0.001)\tLoss 0.3762 (0.4084)\tPrec@1 91.406 (90.050)\n",
            "Epoch: [122][300/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.4140 (0.4207)\tPrec@1 88.281 (89.561)\n",
            "Epoch: [122][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.4072 (0.4302)\tPrec@1 91.250 (89.250)\n",
            "Total time : 14.915\n",
            "Train Loss: 0.4302, Train Accuracy: 0.8925\n",
            "Test Loss : 0.9452, Test Accuracy : 0.7353 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.199 (0.199)\tData 0.135 (0.135)\tLoss 0.3844 (0.3844)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [123][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 0.3527 (0.4040)\tPrec@1 92.188 (90.215)\n",
            "Epoch: [123][200/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.4625 (0.4121)\tPrec@1 89.844 (89.747)\n",
            "Epoch: [123][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.4238 (0.4221)\tPrec@1 85.938 (89.384)\n",
            "Epoch: [123][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.5934 (0.4279)\tPrec@1 88.750 (89.196)\n",
            "Total time : 14.794\n",
            "Train Loss: 0.4279, Train Accuracy: 0.8920\n",
            "Test Loss : 0.9098, Test Accuracy : 0.7458 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.190 (0.190)\tData 0.145 (0.145)\tLoss 0.3098 (0.3098)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [124][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.4052 (0.3848)\tPrec@1 88.281 (90.478)\n",
            "Epoch: [124][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.3608 (0.3936)\tPrec@1 90.625 (90.267)\n",
            "Epoch: [124][300/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.5255 (0.4019)\tPrec@1 89.062 (90.007)\n",
            "Epoch: [124][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.5591 (0.4093)\tPrec@1 87.500 (89.828)\n",
            "Total time : 14.798\n",
            "Train Loss: 0.4093, Train Accuracy: 0.8983\n",
            "Test Loss : 0.9251, Test Accuracy : 0.7399 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.191 (0.191)\tData 0.146 (0.146)\tLoss 0.3428 (0.3428)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [125][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.3315 (0.3723)\tPrec@1 91.406 (90.950)\n",
            "Epoch: [125][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.4030 (0.3843)\tPrec@1 89.844 (90.574)\n",
            "Epoch: [125][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.4594 (0.3963)\tPrec@1 88.281 (90.220)\n",
            "Epoch: [125][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.3751 (0.4051)\tPrec@1 86.250 (89.918)\n",
            "Total time : 14.436\n",
            "Train Loss: 0.4051, Train Accuracy: 0.8992\n",
            "Test Loss : 0.9145, Test Accuracy : 0.7435 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.187 (0.187)\tData 0.143 (0.143)\tLoss 0.3372 (0.3372)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [126][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.4553 (0.3650)\tPrec@1 85.938 (91.515)\n",
            "Epoch: [126][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.3925 (0.3707)\tPrec@1 89.844 (91.200)\n",
            "Epoch: [126][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.4219 (0.3842)\tPrec@1 92.188 (90.690)\n",
            "Epoch: [126][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.5563 (0.3902)\tPrec@1 86.250 (90.496)\n",
            "Total time : 14.295\n",
            "Train Loss: 0.3902, Train Accuracy: 0.9050\n",
            "Test Loss : 0.8917, Test Accuracy : 0.7454 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.196 (0.196)\tData 0.137 (0.137)\tLoss 0.3390 (0.3390)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [127][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.2363 (0.3494)\tPrec@1 94.531 (91.909)\n",
            "Epoch: [127][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.3100 (0.3626)\tPrec@1 92.969 (91.430)\n",
            "Epoch: [127][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.4791 (0.3735)\tPrec@1 86.719 (91.007)\n",
            "Epoch: [127][390/391]\tTime 0.033 (0.036)\tData 0.000 (0.001)\tLoss 0.5176 (0.3820)\tPrec@1 85.000 (90.788)\n",
            "Total time : 14.191\n",
            "Train Loss: 0.3820, Train Accuracy: 0.9079\n",
            "Test Loss : 0.9198, Test Accuracy : 0.7427 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.209 (0.209)\tData 0.153 (0.153)\tLoss 0.3924 (0.3924)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [128][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.2921 (0.3521)\tPrec@1 95.312 (91.778)\n",
            "Epoch: [128][200/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.4150 (0.3636)\tPrec@1 88.281 (91.375)\n",
            "Epoch: [128][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.3587 (0.3679)\tPrec@1 89.062 (91.235)\n",
            "Epoch: [128][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.4565 (0.3732)\tPrec@1 93.750 (91.076)\n",
            "Total time : 14.446\n",
            "Train Loss: 0.3732, Train Accuracy: 0.9108\n",
            "Test Loss : 0.9284, Test Accuracy : 0.7329 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.183 (0.183)\tData 0.140 (0.140)\tLoss 0.2768 (0.2768)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [129][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.3872 (0.3434)\tPrec@1 89.062 (92.265)\n",
            "Epoch: [129][200/391]\tTime 0.037 (0.036)\tData 0.000 (0.001)\tLoss 0.3368 (0.3496)\tPrec@1 91.406 (91.880)\n",
            "Epoch: [129][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 0.4839 (0.3590)\tPrec@1 89.062 (91.580)\n",
            "Epoch: [129][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.2995 (0.3664)\tPrec@1 93.750 (91.290)\n",
            "Total time : 14.278\n",
            "Train Loss: 0.3664, Train Accuracy: 0.9129\n",
            "Test Loss : 0.8427, Test Accuracy : 0.7621 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.191 (0.191)\tData 0.141 (0.141)\tLoss 0.3255 (0.3255)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [130][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.3501 (0.3398)\tPrec@1 89.844 (91.917)\n",
            "Epoch: [130][200/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 0.3111 (0.3405)\tPrec@1 92.969 (91.927)\n",
            "Epoch: [130][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.3887 (0.3511)\tPrec@1 90.625 (91.598)\n",
            "Epoch: [130][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.3609 (0.3552)\tPrec@1 88.750 (91.468)\n",
            "Total time : 14.414\n",
            "Train Loss: 0.3552, Train Accuracy: 0.9147\n",
            "Test Loss : 0.9044, Test Accuracy : 0.7421 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.184 (0.184)\tData 0.140 (0.140)\tLoss 0.2325 (0.2325)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [131][100/391]\tTime 0.037 (0.040)\tData 0.000 (0.002)\tLoss 0.3147 (0.3193)\tPrec@1 91.406 (92.860)\n",
            "Epoch: [131][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.3759 (0.3249)\tPrec@1 87.500 (92.666)\n",
            "Epoch: [131][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.3110 (0.3316)\tPrec@1 96.094 (92.478)\n",
            "Epoch: [131][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.4378 (0.3385)\tPrec@1 86.250 (92.190)\n",
            "Total time : 14.848\n",
            "Train Loss: 0.3385, Train Accuracy: 0.9219\n",
            "Test Loss : 0.8963, Test Accuracy : 0.7465 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.187 (0.187)\tData 0.139 (0.139)\tLoss 0.2598 (0.2598)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [132][100/391]\tTime 0.039 (0.039)\tData 0.000 (0.002)\tLoss 0.3428 (0.3227)\tPrec@1 91.406 (92.744)\n",
            "Epoch: [132][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.3582 (0.3264)\tPrec@1 92.188 (92.654)\n",
            "Epoch: [132][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.4478 (0.3311)\tPrec@1 88.281 (92.447)\n",
            "Epoch: [132][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.4230 (0.3395)\tPrec@1 91.250 (92.112)\n",
            "Total time : 14.587\n",
            "Train Loss: 0.3395, Train Accuracy: 0.9211\n",
            "Test Loss : 0.8928, Test Accuracy : 0.7481 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.202 (0.202)\tData 0.151 (0.151)\tLoss 0.3413 (0.3413)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [133][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.3804 (0.3200)\tPrec@1 92.188 (92.922)\n",
            "Epoch: [133][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.3164 (0.3194)\tPrec@1 93.750 (92.922)\n",
            "Epoch: [133][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.3254 (0.3221)\tPrec@1 93.750 (92.792)\n",
            "Epoch: [133][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.3503 (0.3266)\tPrec@1 90.000 (92.528)\n",
            "Total time : 14.727\n",
            "Train Loss: 0.3266, Train Accuracy: 0.9253\n",
            "Test Loss : 0.8632, Test Accuracy : 0.7542 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.190 (0.190)\tData 0.139 (0.139)\tLoss 0.2542 (0.2542)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [134][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.2576 (0.2961)\tPrec@1 96.094 (93.657)\n",
            "Epoch: [134][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.3148 (0.3077)\tPrec@1 90.625 (93.186)\n",
            "Epoch: [134][300/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.2747 (0.3144)\tPrec@1 95.312 (92.982)\n",
            "Epoch: [134][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.5634 (0.3187)\tPrec@1 83.750 (92.814)\n",
            "Total time : 14.598\n",
            "Train Loss: 0.3187, Train Accuracy: 0.9281\n",
            "Test Loss : 0.8575, Test Accuracy : 0.7585 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.184 (0.184)\tData 0.140 (0.140)\tLoss 0.2590 (0.2590)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [135][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.2880 (0.2823)\tPrec@1 95.312 (93.812)\n",
            "Epoch: [135][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.2839 (0.2920)\tPrec@1 92.969 (93.723)\n",
            "Epoch: [135][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.2683 (0.2981)\tPrec@1 96.094 (93.498)\n",
            "Epoch: [135][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.4646 (0.3075)\tPrec@1 86.250 (93.140)\n",
            "Total time : 14.161\n",
            "Train Loss: 0.3075, Train Accuracy: 0.9314\n",
            "Test Loss : 0.8731, Test Accuracy : 0.7541 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.205 (0.205)\tData 0.142 (0.142)\tLoss 0.2759 (0.2759)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [136][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 0.3941 (0.2816)\tPrec@1 91.406 (94.005)\n",
            "Epoch: [136][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.2753 (0.2872)\tPrec@1 95.312 (93.781)\n",
            "Epoch: [136][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.2979 (0.2933)\tPrec@1 91.406 (93.511)\n",
            "Epoch: [136][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.4068 (0.3014)\tPrec@1 87.500 (93.264)\n",
            "Total time : 14.330\n",
            "Train Loss: 0.3014, Train Accuracy: 0.9326\n",
            "Test Loss : 0.8758, Test Accuracy : 0.7531 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 0.2721 (0.2721)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [137][100/391]\tTime 0.042 (0.040)\tData 0.000 (0.002)\tLoss 0.2002 (0.2748)\tPrec@1 97.656 (94.315)\n",
            "Epoch: [137][200/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.3094 (0.2781)\tPrec@1 93.750 (94.259)\n",
            "Epoch: [137][300/391]\tTime 0.035 (0.039)\tData 0.000 (0.001)\tLoss 0.4167 (0.2882)\tPrec@1 89.844 (93.851)\n",
            "Epoch: [137][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.4308 (0.2921)\tPrec@1 90.000 (93.710)\n",
            "Total time : 14.838\n",
            "Train Loss: 0.2921, Train Accuracy: 0.9371\n",
            "Test Loss : 0.8266, Test Accuracy : 0.7712 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.194 (0.194)\tData 0.144 (0.144)\tLoss 0.3428 (0.3428)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [138][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.2835 (0.2709)\tPrec@1 94.531 (94.500)\n",
            "Epoch: [138][200/391]\tTime 0.034 (0.038)\tData 0.000 (0.001)\tLoss 0.3783 (0.2756)\tPrec@1 89.844 (94.193)\n",
            "Epoch: [138][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.2921 (0.2822)\tPrec@1 93.750 (93.895)\n",
            "Epoch: [138][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.2797 (0.2848)\tPrec@1 93.750 (93.844)\n",
            "Total time : 14.696\n",
            "Train Loss: 0.2848, Train Accuracy: 0.9384\n",
            "Test Loss : 0.8256, Test Accuracy : 0.7634 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.195 (0.195)\tData 0.144 (0.144)\tLoss 0.3241 (0.3241)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [139][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.2490 (0.2535)\tPrec@1 94.531 (94.926)\n",
            "Epoch: [139][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.2531 (0.2596)\tPrec@1 93.750 (94.737)\n",
            "Epoch: [139][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.2132 (0.2646)\tPrec@1 97.656 (94.614)\n",
            "Epoch: [139][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.3544 (0.2719)\tPrec@1 91.250 (94.352)\n",
            "Total time : 14.579\n",
            "Train Loss: 0.2719, Train Accuracy: 0.9435\n",
            "Test Loss : 0.8574, Test Accuracy : 0.7604 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.204 (0.204)\tData 0.138 (0.138)\tLoss 0.1737 (0.1737)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [140][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.2050 (0.2532)\tPrec@1 93.750 (94.802)\n",
            "Epoch: [140][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1691 (0.2565)\tPrec@1 97.656 (94.671)\n",
            "Epoch: [140][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.2380 (0.2625)\tPrec@1 95.312 (94.531)\n",
            "Epoch: [140][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.3807 (0.2697)\tPrec@1 91.250 (94.352)\n",
            "Total time : 14.472\n",
            "Train Loss: 0.2697, Train Accuracy: 0.9435\n",
            "Test Loss : 0.8296, Test Accuracy : 0.7682 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.191 (0.191)\tData 0.141 (0.141)\tLoss 0.2247 (0.2247)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [141][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.2783 (0.2425)\tPrec@1 91.406 (95.359)\n",
            "Epoch: [141][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.1988 (0.2488)\tPrec@1 95.312 (95.114)\n",
            "Epoch: [141][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.2601 (0.2541)\tPrec@1 95.312 (94.926)\n",
            "Epoch: [141][390/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.2033 (0.2598)\tPrec@1 96.250 (94.746)\n",
            "Total time : 14.554\n",
            "Train Loss: 0.2598, Train Accuracy: 0.9475\n",
            "Test Loss : 0.8269, Test Accuracy : 0.7648 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.187 (0.187)\tData 0.140 (0.140)\tLoss 0.2296 (0.2296)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [142][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 0.2440 (0.2363)\tPrec@1 95.312 (95.545)\n",
            "Epoch: [142][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.2104 (0.2472)\tPrec@1 96.875 (95.029)\n",
            "Epoch: [142][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1774 (0.2493)\tPrec@1 99.219 (94.931)\n",
            "Epoch: [142][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.2560 (0.2523)\tPrec@1 95.000 (94.860)\n",
            "Total time : 14.445\n",
            "Train Loss: 0.2523, Train Accuracy: 0.9486\n",
            "Test Loss : 0.8160, Test Accuracy : 0.7683 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.202 (0.202)\tData 0.148 (0.148)\tLoss 0.2334 (0.2334)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [143][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.3042 (0.2268)\tPrec@1 92.188 (95.746)\n",
            "Epoch: [143][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.2660 (0.2359)\tPrec@1 94.531 (95.328)\n",
            "Epoch: [143][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.2363 (0.2440)\tPrec@1 95.312 (95.043)\n",
            "Epoch: [143][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.2212 (0.2491)\tPrec@1 96.250 (94.888)\n",
            "Total time : 14.910\n",
            "Train Loss: 0.2491, Train Accuracy: 0.9489\n",
            "Test Loss : 0.8203, Test Accuracy : 0.7712 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.186 (0.186)\tData 0.136 (0.136)\tLoss 0.1701 (0.1701)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [144][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.2251 (0.2254)\tPrec@1 93.750 (95.715)\n",
            "Epoch: [144][200/391]\tTime 0.054 (0.037)\tData 0.000 (0.001)\tLoss 0.2642 (0.2291)\tPrec@1 93.750 (95.472)\n",
            "Epoch: [144][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1716 (0.2330)\tPrec@1 96.875 (95.406)\n",
            "Epoch: [144][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.1954 (0.2360)\tPrec@1 96.250 (95.336)\n",
            "Total time : 14.262\n",
            "Train Loss: 0.2360, Train Accuracy: 0.9534\n",
            "Test Loss : 0.8306, Test Accuracy : 0.7684 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.198 (0.198)\tData 0.149 (0.149)\tLoss 0.2788 (0.2788)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [145][100/391]\tTime 0.041 (0.038)\tData 0.000 (0.002)\tLoss 0.1710 (0.2187)\tPrec@1 98.438 (95.808)\n",
            "Epoch: [145][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1609 (0.2173)\tPrec@1 96.875 (95.946)\n",
            "Epoch: [145][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1673 (0.2218)\tPrec@1 97.656 (95.813)\n",
            "Epoch: [145][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.2732 (0.2261)\tPrec@1 93.750 (95.682)\n",
            "Total time : 14.256\n",
            "Train Loss: 0.2261, Train Accuracy: 0.9568\n",
            "Test Loss : 0.7987, Test Accuracy : 0.7745 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.188 (0.188)\tData 0.138 (0.138)\tLoss 0.2017 (0.2017)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [146][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 0.2152 (0.2116)\tPrec@1 96.875 (96.279)\n",
            "Epoch: [146][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.1658 (0.2141)\tPrec@1 97.656 (96.195)\n",
            "Epoch: [146][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1865 (0.2206)\tPrec@1 96.875 (95.907)\n",
            "Epoch: [146][390/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.2506 (0.2229)\tPrec@1 93.750 (95.826)\n",
            "Total time : 14.545\n",
            "Train Loss: 0.2229, Train Accuracy: 0.9583\n",
            "Test Loss : 0.8158, Test Accuracy : 0.7706 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.194 (0.194)\tData 0.144 (0.144)\tLoss 0.1632 (0.1632)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [147][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.2544 (0.2051)\tPrec@1 93.750 (96.457)\n",
            "Epoch: [147][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.2623 (0.2085)\tPrec@1 92.969 (96.269)\n",
            "Epoch: [147][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.2651 (0.2128)\tPrec@1 95.312 (96.070)\n",
            "Epoch: [147][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.3172 (0.2148)\tPrec@1 92.500 (96.030)\n",
            "Total time : 14.463\n",
            "Train Loss: 0.2148, Train Accuracy: 0.9603\n",
            "Test Loss : 0.8076, Test Accuracy : 0.7768 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.210 (0.210)\tData 0.144 (0.144)\tLoss 0.1794 (0.1794)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [148][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.2731 (0.2087)\tPrec@1 95.312 (96.109)\n",
            "Epoch: [148][200/391]\tTime 0.041 (0.038)\tData 0.000 (0.001)\tLoss 0.1781 (0.2053)\tPrec@1 97.656 (96.245)\n",
            "Epoch: [148][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.1350 (0.2060)\tPrec@1 98.438 (96.234)\n",
            "Epoch: [148][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.3092 (0.2095)\tPrec@1 90.000 (96.116)\n",
            "Total time : 14.608\n",
            "Train Loss: 0.2095, Train Accuracy: 0.9612\n",
            "Test Loss : 0.8010, Test Accuracy : 0.7757 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.190 (0.190)\tData 0.139 (0.139)\tLoss 0.1776 (0.1776)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [149][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.1801 (0.1896)\tPrec@1 98.438 (96.937)\n",
            "Epoch: [149][200/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.2691 (0.1941)\tPrec@1 93.750 (96.688)\n",
            "Epoch: [149][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.2840 (0.1997)\tPrec@1 96.094 (96.452)\n",
            "Epoch: [149][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.2225 (0.2034)\tPrec@1 96.250 (96.378)\n",
            "Total time : 14.313\n",
            "Train Loss: 0.2034, Train Accuracy: 0.9638\n",
            "Test Loss : 0.7895, Test Accuracy : 0.7793 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.195 (0.195)\tData 0.150 (0.150)\tLoss 0.1969 (0.1969)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [150][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.2427 (0.1899)\tPrec@1 96.094 (96.651)\n",
            "Epoch: [150][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1711 (0.1928)\tPrec@1 95.312 (96.622)\n",
            "Epoch: [150][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1850 (0.1928)\tPrec@1 97.656 (96.631)\n",
            "Epoch: [150][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 0.1623 (0.1957)\tPrec@1 98.750 (96.566)\n",
            "Total time : 14.312\n",
            "Train Loss: 0.1957, Train Accuracy: 0.9657\n",
            "Test Loss : 0.7873, Test Accuracy : 0.7812 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.193 (0.193)\tData 0.146 (0.146)\tLoss 0.2039 (0.2039)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [151][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.2001 (0.1792)\tPrec@1 96.875 (97.076)\n",
            "Epoch: [151][200/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.2158 (0.1846)\tPrec@1 96.094 (96.813)\n",
            "Epoch: [151][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.2073 (0.1871)\tPrec@1 96.875 (96.722)\n",
            "Epoch: [151][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.2903 (0.1893)\tPrec@1 92.500 (96.670)\n",
            "Total time : 14.736\n",
            "Train Loss: 0.1893, Train Accuracy: 0.9667\n",
            "Test Loss : 0.7944, Test Accuracy : 0.7801 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.207 (0.207)\tData 0.139 (0.139)\tLoss 0.2061 (0.2061)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [152][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1440 (0.1773)\tPrec@1 96.875 (97.014)\n",
            "Epoch: [152][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.1772 (0.1810)\tPrec@1 97.656 (96.945)\n",
            "Epoch: [152][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.2195 (0.1850)\tPrec@1 96.094 (96.805)\n",
            "Epoch: [152][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.2034 (0.1863)\tPrec@1 98.750 (96.780)\n",
            "Total time : 14.512\n",
            "Train Loss: 0.1863, Train Accuracy: 0.9678\n",
            "Test Loss : 0.7879, Test Accuracy : 0.7762 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.191 (0.191)\tData 0.140 (0.140)\tLoss 0.1356 (0.1356)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [153][100/391]\tTime 0.037 (0.042)\tData 0.000 (0.002)\tLoss 0.1830 (0.1701)\tPrec@1 98.438 (97.169)\n",
            "Epoch: [153][200/391]\tTime 0.039 (0.039)\tData 0.000 (0.001)\tLoss 0.1778 (0.1714)\tPrec@1 97.656 (97.163)\n",
            "Epoch: [153][300/391]\tTime 0.039 (0.039)\tData 0.000 (0.001)\tLoss 0.1328 (0.1778)\tPrec@1 99.219 (97.010)\n",
            "Epoch: [153][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.2502 (0.1795)\tPrec@1 95.000 (96.960)\n",
            "Total time : 15.022\n",
            "Train Loss: 0.1795, Train Accuracy: 0.9696\n",
            "Test Loss : 0.7620, Test Accuracy : 0.7898 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.221 (0.221)\tData 0.174 (0.174)\tLoss 0.1165 (0.1165)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [154][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.1796 (0.1636)\tPrec@1 96.875 (97.401)\n",
            "Epoch: [154][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.1560 (0.1714)\tPrec@1 97.656 (97.077)\n",
            "Epoch: [154][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.1804 (0.1714)\tPrec@1 97.656 (97.119)\n",
            "Epoch: [154][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1454 (0.1727)\tPrec@1 98.750 (97.126)\n",
            "Total time : 14.823\n",
            "Train Loss: 0.1727, Train Accuracy: 0.9713\n",
            "Test Loss : 0.7751, Test Accuracy : 0.7819 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.195 (0.195)\tData 0.143 (0.143)\tLoss 0.2214 (0.2214)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [155][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.1603 (0.1602)\tPrec@1 96.875 (97.424)\n",
            "Epoch: [155][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.1876 (0.1646)\tPrec@1 98.438 (97.338)\n",
            "Epoch: [155][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.1584 (0.1655)\tPrec@1 96.875 (97.347)\n",
            "Epoch: [155][390/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.1566 (0.1684)\tPrec@1 98.750 (97.268)\n",
            "Total time : 14.441\n",
            "Train Loss: 0.1684, Train Accuracy: 0.9727\n",
            "Test Loss : 0.7534, Test Accuracy : 0.7904 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.192 (0.192)\tData 0.142 (0.142)\tLoss 0.2289 (0.2289)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [156][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.1165 (0.1579)\tPrec@1 97.656 (97.563)\n",
            "Epoch: [156][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1634 (0.1620)\tPrec@1 98.438 (97.407)\n",
            "Epoch: [156][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1889 (0.1646)\tPrec@1 96.875 (97.342)\n",
            "Epoch: [156][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.1738 (0.1656)\tPrec@1 95.000 (97.334)\n",
            "Total time : 14.299\n",
            "Train Loss: 0.1656, Train Accuracy: 0.9733\n",
            "Test Loss : 0.7603, Test Accuracy : 0.7892 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.189 (0.189)\tData 0.140 (0.140)\tLoss 0.1323 (0.1323)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [157][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1258 (0.1545)\tPrec@1 100.000 (97.672)\n",
            "Epoch: [157][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1507 (0.1549)\tPrec@1 96.094 (97.656)\n",
            "Epoch: [157][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1268 (0.1553)\tPrec@1 98.438 (97.641)\n",
            "Epoch: [157][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1481 (0.1581)\tPrec@1 100.000 (97.572)\n",
            "Total time : 14.314\n",
            "Train Loss: 0.1581, Train Accuracy: 0.9757\n",
            "Test Loss : 0.7589, Test Accuracy : 0.7874 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.181 (0.181)\tData 0.137 (0.137)\tLoss 0.2197 (0.2197)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [158][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.1740 (0.1533)\tPrec@1 97.656 (97.610)\n",
            "Epoch: [158][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1085 (0.1516)\tPrec@1 100.000 (97.753)\n",
            "Epoch: [158][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1385 (0.1560)\tPrec@1 98.438 (97.638)\n",
            "Epoch: [158][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1762 (0.1573)\tPrec@1 97.500 (97.640)\n",
            "Total time : 14.493\n",
            "Train Loss: 0.1573, Train Accuracy: 0.9764\n",
            "Test Loss : 0.7457, Test Accuracy : 0.7907 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.202 (0.202)\tData 0.139 (0.139)\tLoss 0.1258 (0.1258)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [159][100/391]\tTime 0.043 (0.041)\tData 0.000 (0.002)\tLoss 0.1795 (0.1459)\tPrec@1 95.312 (97.819)\n",
            "Epoch: [159][200/391]\tTime 0.036 (0.040)\tData 0.000 (0.001)\tLoss 0.1767 (0.1470)\tPrec@1 96.094 (97.804)\n",
            "Epoch: [159][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.1520 (0.1487)\tPrec@1 98.438 (97.776)\n",
            "Epoch: [159][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.2116 (0.1504)\tPrec@1 96.250 (97.718)\n",
            "Total time : 14.779\n",
            "Train Loss: 0.1504, Train Accuracy: 0.9772\n",
            "Test Loss : 0.7274, Test Accuracy : 0.8010 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 0.1223 (0.1223)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [160][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1316 (0.1378)\tPrec@1 98.438 (98.035)\n",
            "Epoch: [160][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1292 (0.1423)\tPrec@1 99.219 (97.956)\n",
            "Epoch: [160][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1111 (0.1433)\tPrec@1 98.438 (97.957)\n",
            "Epoch: [160][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 0.1398 (0.1462)\tPrec@1 98.750 (97.822)\n",
            "Total time : 14.330\n",
            "Train Loss: 0.1462, Train Accuracy: 0.9782\n",
            "Test Loss : 0.7377, Test Accuracy : 0.7949 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.186 (0.186)\tData 0.140 (0.140)\tLoss 0.1442 (0.1442)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [161][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.1257 (0.1378)\tPrec@1 100.000 (98.058)\n",
            "Epoch: [161][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1715 (0.1385)\tPrec@1 95.312 (98.045)\n",
            "Epoch: [161][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1868 (0.1411)\tPrec@1 96.094 (97.950)\n",
            "Epoch: [161][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.1739 (0.1410)\tPrec@1 98.750 (98.004)\n",
            "Total time : 14.606\n",
            "Train Loss: 0.1410, Train Accuracy: 0.9800\n",
            "Test Loss : 0.7422, Test Accuracy : 0.7925 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.185 (0.185)\tData 0.139 (0.139)\tLoss 0.1558 (0.1558)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [162][100/391]\tTime 0.034 (0.038)\tData 0.000 (0.002)\tLoss 0.1617 (0.1344)\tPrec@1 97.656 (98.097)\n",
            "Epoch: [162][200/391]\tTime 0.040 (0.037)\tData 0.000 (0.001)\tLoss 0.1240 (0.1382)\tPrec@1 99.219 (97.987)\n",
            "Epoch: [162][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1758 (0.1387)\tPrec@1 96.875 (97.999)\n",
            "Epoch: [162][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.1606 (0.1396)\tPrec@1 97.500 (97.982)\n",
            "Total time : 14.375\n",
            "Train Loss: 0.1396, Train Accuracy: 0.9798\n",
            "Test Loss : 0.7201, Test Accuracy : 0.8006 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.198 (0.198)\tData 0.140 (0.140)\tLoss 0.1263 (0.1263)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [163][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.002)\tLoss 0.0714 (0.1276)\tPrec@1 100.000 (98.213)\n",
            "Epoch: [163][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1461 (0.1301)\tPrec@1 98.438 (98.142)\n",
            "Epoch: [163][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1208 (0.1309)\tPrec@1 99.219 (98.105)\n",
            "Epoch: [163][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1855 (0.1337)\tPrec@1 98.750 (98.054)\n",
            "Total time : 14.370\n",
            "Train Loss: 0.1337, Train Accuracy: 0.9805\n",
            "Test Loss : 0.7421, Test Accuracy : 0.7922 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.190 (0.190)\tData 0.144 (0.144)\tLoss 0.0855 (0.0855)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [164][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1520 (0.1259)\tPrec@1 96.875 (98.190)\n",
            "Epoch: [164][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1546 (0.1282)\tPrec@1 98.438 (98.189)\n",
            "Epoch: [164][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.0963 (0.1303)\tPrec@1 98.438 (98.134)\n",
            "Epoch: [164][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1717 (0.1313)\tPrec@1 96.250 (98.120)\n",
            "Total time : 14.314\n",
            "Train Loss: 0.1313, Train Accuracy: 0.9812\n",
            "Test Loss : 0.7338, Test Accuracy : 0.7981 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.198 (0.198)\tData 0.148 (0.148)\tLoss 0.1322 (0.1322)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [165][100/391]\tTime 0.038 (0.040)\tData 0.000 (0.002)\tLoss 0.0577 (0.1208)\tPrec@1 100.000 (98.383)\n",
            "Epoch: [165][200/391]\tTime 0.043 (0.038)\tData 0.000 (0.001)\tLoss 0.1249 (0.1231)\tPrec@1 97.656 (98.375)\n",
            "Epoch: [165][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0891 (0.1248)\tPrec@1 99.219 (98.323)\n",
            "Epoch: [165][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.0659 (0.1263)\tPrec@1 100.000 (98.288)\n",
            "Total time : 14.761\n",
            "Train Loss: 0.1263, Train Accuracy: 0.9829\n",
            "Test Loss : 0.7198, Test Accuracy : 0.8019 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.210 (0.210)\tData 0.145 (0.145)\tLoss 0.0923 (0.0923)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [166][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1058 (0.1232)\tPrec@1 98.438 (98.360)\n",
            "Epoch: [166][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.1062 (0.1229)\tPrec@1 98.438 (98.336)\n",
            "Epoch: [166][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.1624 (0.1223)\tPrec@1 98.438 (98.349)\n",
            "Epoch: [166][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1749 (0.1224)\tPrec@1 98.750 (98.336)\n",
            "Total time : 14.574\n",
            "Train Loss: 0.1224, Train Accuracy: 0.9834\n",
            "Test Loss : 0.7299, Test Accuracy : 0.7995 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.189 (0.189)\tData 0.137 (0.137)\tLoss 0.1140 (0.1140)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [167][100/391]\tTime 0.037 (0.040)\tData 0.000 (0.002)\tLoss 0.1267 (0.1269)\tPrec@1 98.438 (98.283)\n",
            "Epoch: [167][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.1247 (0.1265)\tPrec@1 100.000 (98.274)\n",
            "Epoch: [167][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.1307 (0.1255)\tPrec@1 98.438 (98.287)\n",
            "Epoch: [167][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1718 (0.1245)\tPrec@1 96.250 (98.288)\n",
            "Total time : 14.585\n",
            "Train Loss: 0.1245, Train Accuracy: 0.9829\n",
            "Test Loss : 0.7181, Test Accuracy : 0.8033 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.188 (0.188)\tData 0.144 (0.144)\tLoss 0.1229 (0.1229)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [168][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.0925 (0.1162)\tPrec@1 98.438 (98.499)\n",
            "Epoch: [168][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0768 (0.1156)\tPrec@1 100.000 (98.523)\n",
            "Epoch: [168][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.1271 (0.1155)\tPrec@1 99.219 (98.508)\n",
            "Epoch: [168][390/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.1394 (0.1175)\tPrec@1 97.500 (98.454)\n",
            "Total time : 14.684\n",
            "Train Loss: 0.1175, Train Accuracy: 0.9845\n",
            "Test Loss : 0.7162, Test Accuracy : 0.8055 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.205 (0.205)\tData 0.143 (0.143)\tLoss 0.0892 (0.0892)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [169][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.1066 (0.1067)\tPrec@1 98.438 (98.708)\n",
            "Epoch: [169][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0992 (0.1106)\tPrec@1 98.438 (98.593)\n",
            "Epoch: [169][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0796 (0.1122)\tPrec@1 100.000 (98.549)\n",
            "Epoch: [169][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.0925 (0.1130)\tPrec@1 100.000 (98.532)\n",
            "Total time : 14.317\n",
            "Train Loss: 0.1130, Train Accuracy: 0.9853\n",
            "Test Loss : 0.7107, Test Accuracy : 0.8021 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.209 (0.209)\tData 0.163 (0.163)\tLoss 0.0677 (0.0677)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [170][100/391]\tTime 0.035 (0.040)\tData 0.000 (0.002)\tLoss 0.0939 (0.1058)\tPrec@1 100.000 (98.840)\n",
            "Epoch: [170][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.1036 (0.1110)\tPrec@1 99.219 (98.601)\n",
            "Epoch: [170][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0804 (0.1101)\tPrec@1 99.219 (98.663)\n",
            "Epoch: [170][390/391]\tTime 0.031 (0.038)\tData 0.000 (0.001)\tLoss 0.1792 (0.1106)\tPrec@1 96.250 (98.636)\n",
            "Total time : 14.703\n",
            "Train Loss: 0.1106, Train Accuracy: 0.9864\n",
            "Test Loss : 0.7096, Test Accuracy : 0.8036 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.188 (0.188)\tData 0.144 (0.144)\tLoss 0.1025 (0.1025)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [171][100/391]\tTime 0.040 (0.038)\tData 0.000 (0.002)\tLoss 0.0975 (0.1084)\tPrec@1 99.219 (98.438)\n",
            "Epoch: [171][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.0912 (0.1074)\tPrec@1 99.219 (98.628)\n",
            "Epoch: [171][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0943 (0.1088)\tPrec@1 99.219 (98.593)\n",
            "Epoch: [171][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.1053 (0.1101)\tPrec@1 100.000 (98.554)\n",
            "Total time : 14.498\n",
            "Train Loss: 0.1101, Train Accuracy: 0.9855\n",
            "Test Loss : 0.7054, Test Accuracy : 0.8064 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.202 (0.202)\tData 0.136 (0.136)\tLoss 0.1091 (0.1091)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [172][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.0700 (0.1044)\tPrec@1 100.000 (98.755)\n",
            "Epoch: [172][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0851 (0.1051)\tPrec@1 99.219 (98.675)\n",
            "Epoch: [172][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1107 (0.1077)\tPrec@1 97.656 (98.585)\n",
            "Epoch: [172][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1041 (0.1083)\tPrec@1 98.750 (98.572)\n",
            "Total time : 14.381\n",
            "Train Loss: 0.1083, Train Accuracy: 0.9857\n",
            "Test Loss : 0.6997, Test Accuracy : 0.8114 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.200 (0.200)\tData 0.155 (0.155)\tLoss 0.1038 (0.1038)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [173][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1249 (0.1044)\tPrec@1 96.875 (98.731)\n",
            "Epoch: [173][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1177 (0.1080)\tPrec@1 98.438 (98.678)\n",
            "Epoch: [173][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.1755 (0.1092)\tPrec@1 95.312 (98.632)\n",
            "Epoch: [173][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.1339 (0.1096)\tPrec@1 96.250 (98.612)\n",
            "Total time : 14.304\n",
            "Train Loss: 0.1096, Train Accuracy: 0.9861\n",
            "Test Loss : 0.7034, Test Accuracy : 0.8056 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.197 (0.197)\tData 0.146 (0.146)\tLoss 0.0812 (0.0812)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [174][100/391]\tTime 0.042 (0.039)\tData 0.000 (0.002)\tLoss 0.0752 (0.1002)\tPrec@1 100.000 (98.739)\n",
            "Epoch: [174][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.1224 (0.1035)\tPrec@1 96.875 (98.690)\n",
            "Epoch: [174][300/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.0791 (0.1038)\tPrec@1 99.219 (98.692)\n",
            "Epoch: [174][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1535 (0.1041)\tPrec@1 97.500 (98.696)\n",
            "Total time : 14.869\n",
            "Train Loss: 0.1041, Train Accuracy: 0.9870\n",
            "Test Loss : 0.7047, Test Accuracy : 0.8077 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.183 (0.183)\tData 0.140 (0.140)\tLoss 0.0623 (0.0623)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [175][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.0910 (0.1032)\tPrec@1 98.438 (98.770)\n",
            "Epoch: [175][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.0883 (0.1026)\tPrec@1 99.219 (98.752)\n",
            "Epoch: [175][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0816 (0.1008)\tPrec@1 98.438 (98.798)\n",
            "Epoch: [175][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1508 (0.1001)\tPrec@1 98.750 (98.824)\n",
            "Total time : 14.272\n",
            "Train Loss: 0.1001, Train Accuracy: 0.9882\n",
            "Test Loss : 0.6964, Test Accuracy : 0.8080 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.205 (0.205)\tData 0.155 (0.155)\tLoss 0.0915 (0.0915)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [176][100/391]\tTime 0.038 (0.038)\tData 0.000 (0.002)\tLoss 0.1116 (0.1002)\tPrec@1 99.219 (98.824)\n",
            "Epoch: [176][200/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 0.1187 (0.0993)\tPrec@1 98.438 (98.923)\n",
            "Epoch: [176][300/391]\tTime 0.041 (0.037)\tData 0.000 (0.001)\tLoss 0.0883 (0.1009)\tPrec@1 99.219 (98.845)\n",
            "Epoch: [176][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1961 (0.1014)\tPrec@1 95.000 (98.796)\n",
            "Total time : 14.547\n",
            "Train Loss: 0.1014, Train Accuracy: 0.9880\n",
            "Test Loss : 0.6981, Test Accuracy : 0.8099 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.220 (0.220)\tData 0.149 (0.149)\tLoss 0.1111 (0.1111)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [177][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1070 (0.0983)\tPrec@1 98.438 (98.933)\n",
            "Epoch: [177][200/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.0882 (0.0974)\tPrec@1 99.219 (98.919)\n",
            "Epoch: [177][300/391]\tTime 0.039 (0.039)\tData 0.000 (0.001)\tLoss 0.0966 (0.0979)\tPrec@1 99.219 (98.879)\n",
            "Epoch: [177][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1201 (0.0992)\tPrec@1 100.000 (98.832)\n",
            "Total time : 14.955\n",
            "Train Loss: 0.0992, Train Accuracy: 0.9883\n",
            "Test Loss : 0.6926, Test Accuracy : 0.8063 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.189 (0.189)\tData 0.143 (0.143)\tLoss 0.0960 (0.0960)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [178][100/391]\tTime 0.052 (0.039)\tData 0.000 (0.002)\tLoss 0.1069 (0.0966)\tPrec@1 98.438 (99.049)\n",
            "Epoch: [178][200/391]\tTime 0.039 (0.038)\tData 0.000 (0.001)\tLoss 0.0583 (0.0944)\tPrec@1 100.000 (99.032)\n",
            "Epoch: [178][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.1116 (0.0947)\tPrec@1 99.219 (98.967)\n",
            "Epoch: [178][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1073 (0.0950)\tPrec@1 97.500 (98.938)\n",
            "Total time : 14.702\n",
            "Train Loss: 0.0950, Train Accuracy: 0.9894\n",
            "Test Loss : 0.6936, Test Accuracy : 0.8086 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.195 (0.195)\tData 0.149 (0.149)\tLoss 0.0712 (0.0712)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [179][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 0.0783 (0.0964)\tPrec@1 99.219 (98.948)\n",
            "Epoch: [179][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.0842 (0.0945)\tPrec@1 98.438 (98.970)\n",
            "Epoch: [179][300/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.0841 (0.0950)\tPrec@1 98.438 (98.905)\n",
            "Epoch: [179][390/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.2148 (0.0936)\tPrec@1 98.750 (98.940)\n",
            "Total time : 14.256\n",
            "Train Loss: 0.0936, Train Accuracy: 0.9894\n",
            "Test Loss : 0.6913, Test Accuracy : 0.8097 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.184 (0.184)\tData 0.139 (0.139)\tLoss 0.0580 (0.0580)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [180][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.0848 (0.0913)\tPrec@1 99.219 (98.956)\n",
            "Epoch: [180][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0547 (0.0921)\tPrec@1 100.000 (98.978)\n",
            "Epoch: [180][300/391]\tTime 0.038 (0.038)\tData 0.000 (0.001)\tLoss 0.0702 (0.0925)\tPrec@1 100.000 (98.936)\n",
            "Epoch: [180][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1031 (0.0931)\tPrec@1 100.000 (98.934)\n",
            "Total time : 14.616\n",
            "Train Loss: 0.0931, Train Accuracy: 0.9893\n",
            "Test Loss : 0.6925, Test Accuracy : 0.8119 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.188 (0.188)\tData 0.143 (0.143)\tLoss 0.0797 (0.0797)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [181][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.0804 (0.0889)\tPrec@1 99.219 (99.103)\n",
            "Epoch: [181][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0776 (0.0888)\tPrec@1 99.219 (99.048)\n",
            "Epoch: [181][300/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.1388 (0.0905)\tPrec@1 97.656 (98.980)\n",
            "Epoch: [181][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.0761 (0.0904)\tPrec@1 100.000 (99.006)\n",
            "Total time : 14.445\n",
            "Train Loss: 0.0904, Train Accuracy: 0.9901\n",
            "Test Loss : 0.6910, Test Accuracy : 0.8090 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.212 (0.212)\tData 0.146 (0.146)\tLoss 0.0491 (0.0491)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [182][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.0570 (0.0861)\tPrec@1 100.000 (99.110)\n",
            "Epoch: [182][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.0802 (0.0887)\tPrec@1 99.219 (99.063)\n",
            "Epoch: [182][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.001)\tLoss 0.0881 (0.0889)\tPrec@1 98.438 (99.034)\n",
            "Epoch: [182][390/391]\tTime 0.033 (0.036)\tData 0.000 (0.001)\tLoss 0.1079 (0.0900)\tPrec@1 97.500 (98.982)\n",
            "Total time : 14.172\n",
            "Train Loss: 0.0900, Train Accuracy: 0.9898\n",
            "Test Loss : 0.6912, Test Accuracy : 0.8114 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.190 (0.190)\tData 0.144 (0.144)\tLoss 0.0676 (0.0676)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [183][100/391]\tTime 0.034 (0.039)\tData 0.000 (0.002)\tLoss 0.0905 (0.0908)\tPrec@1 98.438 (98.971)\n",
            "Epoch: [183][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0914 (0.0883)\tPrec@1 98.438 (99.071)\n",
            "Epoch: [183][300/391]\tTime 0.035 (0.038)\tData 0.000 (0.001)\tLoss 0.0702 (0.0898)\tPrec@1 100.000 (98.959)\n",
            "Epoch: [183][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1038 (0.0897)\tPrec@1 98.750 (98.986)\n",
            "Total time : 14.719\n",
            "Train Loss: 0.0897, Train Accuracy: 0.9899\n",
            "Test Loss : 0.6912, Test Accuracy : 0.8116 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.216 (0.216)\tData 0.145 (0.145)\tLoss 0.1224 (0.1224)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [184][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.0727 (0.0877)\tPrec@1 99.219 (99.072)\n",
            "Epoch: [184][200/391]\tTime 0.034 (0.038)\tData 0.000 (0.001)\tLoss 0.1068 (0.0871)\tPrec@1 98.438 (99.079)\n",
            "Epoch: [184][300/391]\tTime 0.042 (0.038)\tData 0.000 (0.001)\tLoss 0.0450 (0.0870)\tPrec@1 100.000 (99.086)\n",
            "Epoch: [184][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1002 (0.0876)\tPrec@1 98.750 (99.062)\n",
            "Total time : 14.910\n",
            "Train Loss: 0.0876, Train Accuracy: 0.9906\n",
            "Test Loss : 0.6860, Test Accuracy : 0.8131 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.191 (0.191)\tData 0.146 (0.146)\tLoss 0.0927 (0.0927)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [185][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.0794 (0.0878)\tPrec@1 99.219 (98.894)\n",
            "Epoch: [185][200/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.0772 (0.0876)\tPrec@1 99.219 (98.896)\n",
            "Epoch: [185][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.1107 (0.0873)\tPrec@1 97.656 (98.954)\n",
            "Epoch: [185][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.1231 (0.0871)\tPrec@1 98.750 (98.994)\n",
            "Total time : 14.239\n",
            "Train Loss: 0.0871, Train Accuracy: 0.9899\n",
            "Test Loss : 0.6837, Test Accuracy : 0.8120 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.189 (0.189)\tData 0.139 (0.139)\tLoss 0.0928 (0.0928)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [186][100/391]\tTime 0.036 (0.039)\tData 0.000 (0.002)\tLoss 0.0747 (0.0886)\tPrec@1 100.000 (99.010)\n",
            "Epoch: [186][200/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.0781 (0.0869)\tPrec@1 99.219 (99.024)\n",
            "Epoch: [186][300/391]\tTime 0.036 (0.039)\tData 0.000 (0.001)\tLoss 0.0799 (0.0864)\tPrec@1 100.000 (99.053)\n",
            "Epoch: [186][390/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.1254 (0.0863)\tPrec@1 97.500 (99.066)\n",
            "Total time : 15.047\n",
            "Train Loss: 0.0863, Train Accuracy: 0.9907\n",
            "Test Loss : 0.6869, Test Accuracy : 0.8114 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.205 (0.205)\tData 0.139 (0.139)\tLoss 0.1060 (0.1060)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [187][100/391]\tTime 0.045 (0.039)\tData 0.000 (0.002)\tLoss 0.0809 (0.0853)\tPrec@1 97.656 (99.049)\n",
            "Epoch: [187][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0836 (0.0861)\tPrec@1 99.219 (99.052)\n",
            "Epoch: [187][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0787 (0.0859)\tPrec@1 99.219 (99.034)\n",
            "Epoch: [187][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.0972 (0.0857)\tPrec@1 100.000 (99.030)\n",
            "Total time : 14.631\n",
            "Train Loss: 0.0857, Train Accuracy: 0.9903\n",
            "Test Loss : 0.6847, Test Accuracy : 0.8138 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.205 (0.205)\tData 0.142 (0.142)\tLoss 0.0890 (0.0890)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [188][100/391]\tTime 0.041 (0.039)\tData 0.000 (0.002)\tLoss 0.0772 (0.0895)\tPrec@1 99.219 (98.847)\n",
            "Epoch: [188][200/391]\tTime 0.041 (0.038)\tData 0.000 (0.001)\tLoss 0.1297 (0.0861)\tPrec@1 96.875 (99.036)\n",
            "Epoch: [188][300/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0582 (0.0854)\tPrec@1 100.000 (99.055)\n",
            "Epoch: [188][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.1184 (0.0849)\tPrec@1 98.750 (99.078)\n",
            "Total time : 14.582\n",
            "Train Loss: 0.0849, Train Accuracy: 0.9908\n",
            "Test Loss : 0.6821, Test Accuracy : 0.8142 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.189 (0.189)\tData 0.145 (0.145)\tLoss 0.0731 (0.0731)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [189][100/391]\tTime 0.043 (0.038)\tData 0.000 (0.002)\tLoss 0.1202 (0.0863)\tPrec@1 98.438 (98.979)\n",
            "Epoch: [189][200/391]\tTime 0.039 (0.037)\tData 0.000 (0.001)\tLoss 0.0656 (0.0835)\tPrec@1 97.656 (99.075)\n",
            "Epoch: [189][300/391]\tTime 0.035 (0.037)\tData 0.000 (0.001)\tLoss 0.0743 (0.0822)\tPrec@1 100.000 (99.105)\n",
            "Epoch: [189][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.0905 (0.0839)\tPrec@1 98.750 (99.092)\n",
            "Total time : 14.528\n",
            "Train Loss: 0.0839, Train Accuracy: 0.9909\n",
            "Test Loss : 0.6852, Test Accuracy : 0.8143 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.193 (0.193)\tData 0.144 (0.144)\tLoss 0.0564 (0.0564)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [190][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.0705 (0.0862)\tPrec@1 99.219 (98.948)\n",
            "Epoch: [190][200/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.1052 (0.0861)\tPrec@1 98.438 (98.974)\n",
            "Epoch: [190][300/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 0.0970 (0.0855)\tPrec@1 99.219 (99.014)\n",
            "Epoch: [190][390/391]\tTime 0.032 (0.036)\tData 0.000 (0.001)\tLoss 0.0990 (0.0856)\tPrec@1 98.750 (99.004)\n",
            "Total time : 14.140\n",
            "Train Loss: 0.0856, Train Accuracy: 0.9900\n",
            "Test Loss : 0.6828, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.191 (0.191)\tData 0.139 (0.139)\tLoss 0.0901 (0.0901)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [191][100/391]\tTime 0.036 (0.040)\tData 0.000 (0.002)\tLoss 0.0804 (0.0813)\tPrec@1 100.000 (99.180)\n",
            "Epoch: [191][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0604 (0.0819)\tPrec@1 100.000 (99.122)\n",
            "Epoch: [191][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0988 (0.0822)\tPrec@1 99.219 (99.133)\n",
            "Epoch: [191][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.0923 (0.0821)\tPrec@1 98.750 (99.140)\n",
            "Total time : 14.719\n",
            "Train Loss: 0.0821, Train Accuracy: 0.9914\n",
            "Test Loss : 0.6848, Test Accuracy : 0.8129 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.187 (0.187)\tData 0.141 (0.141)\tLoss 0.0814 (0.0814)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [192][100/391]\tTime 0.037 (0.038)\tData 0.000 (0.002)\tLoss 0.0672 (0.0844)\tPrec@1 99.219 (99.056)\n",
            "Epoch: [192][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0929 (0.0842)\tPrec@1 98.438 (99.024)\n",
            "Epoch: [192][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.0974 (0.0838)\tPrec@1 98.438 (99.045)\n",
            "Epoch: [192][390/391]\tTime 0.034 (0.037)\tData 0.000 (0.001)\tLoss 0.1051 (0.0836)\tPrec@1 98.750 (99.048)\n",
            "Total time : 14.528\n",
            "Train Loss: 0.0836, Train Accuracy: 0.9905\n",
            "Test Loss : 0.6813, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.189 (0.189)\tData 0.144 (0.144)\tLoss 0.0731 (0.0731)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [193][100/391]\tTime 0.041 (0.040)\tData 0.000 (0.002)\tLoss 0.0958 (0.0844)\tPrec@1 98.438 (99.002)\n",
            "Epoch: [193][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0830 (0.0836)\tPrec@1 99.219 (99.071)\n",
            "Epoch: [193][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0880 (0.0822)\tPrec@1 98.438 (99.115)\n",
            "Epoch: [193][390/391]\tTime 0.033 (0.037)\tData 0.000 (0.001)\tLoss 0.1063 (0.0811)\tPrec@1 100.000 (99.160)\n",
            "Total time : 14.505\n",
            "Train Loss: 0.0811, Train Accuracy: 0.9916\n",
            "Test Loss : 0.6838, Test Accuracy : 0.8133 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.202 (0.202)\tData 0.149 (0.149)\tLoss 0.1356 (0.1356)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [194][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1147 (0.0821)\tPrec@1 97.656 (99.149)\n",
            "Epoch: [194][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0958 (0.0821)\tPrec@1 97.656 (99.114)\n",
            "Epoch: [194][300/391]\tTime 0.037 (0.037)\tData 0.000 (0.001)\tLoss 0.0937 (0.0828)\tPrec@1 99.219 (99.076)\n",
            "Epoch: [194][390/391]\tTime 0.031 (0.037)\tData 0.000 (0.001)\tLoss 0.1225 (0.0825)\tPrec@1 96.250 (99.082)\n",
            "Total time : 14.284\n",
            "Train Loss: 0.0825, Train Accuracy: 0.9908\n",
            "Test Loss : 0.6813, Test Accuracy : 0.8142 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.185 (0.185)\tData 0.134 (0.134)\tLoss 0.0593 (0.0593)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [195][100/391]\tTime 0.035 (0.039)\tData 0.000 (0.002)\tLoss 0.0560 (0.0795)\tPrec@1 100.000 (99.211)\n",
            "Epoch: [195][200/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0569 (0.0781)\tPrec@1 100.000 (99.273)\n",
            "Epoch: [195][300/391]\tTime 0.036 (0.038)\tData 0.000 (0.001)\tLoss 0.0557 (0.0793)\tPrec@1 100.000 (99.214)\n",
            "Epoch: [195][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.0915 (0.0791)\tPrec@1 98.750 (99.220)\n",
            "Total time : 14.580\n",
            "Train Loss: 0.0791, Train Accuracy: 0.9922\n",
            "Test Loss : 0.6819, Test Accuracy : 0.8150 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.189 (0.189)\tData 0.138 (0.138)\tLoss 0.0616 (0.0616)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [196][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.002)\tLoss 0.1185 (0.0840)\tPrec@1 97.656 (99.095)\n",
            "Epoch: [196][200/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.0735 (0.0833)\tPrec@1 98.438 (99.083)\n",
            "Epoch: [196][300/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.0986 (0.0831)\tPrec@1 98.438 (99.063)\n",
            "Epoch: [196][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.0722 (0.0822)\tPrec@1 100.000 (99.098)\n",
            "Total time : 14.578\n",
            "Train Loss: 0.0822, Train Accuracy: 0.9910\n",
            "Test Loss : 0.6825, Test Accuracy : 0.8142 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.593 (0.593)\tData 0.387 (0.387)\tLoss 0.0931 (0.0931)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [197][100/391]\tTime 0.041 (0.044)\tData 0.000 (0.004)\tLoss 0.0935 (0.0805)\tPrec@1 99.219 (99.257)\n",
            "Epoch: [197][200/391]\tTime 0.041 (0.041)\tData 0.000 (0.002)\tLoss 0.0465 (0.0802)\tPrec@1 100.000 (99.207)\n",
            "Epoch: [197][300/391]\tTime 0.041 (0.040)\tData 0.000 (0.002)\tLoss 0.0946 (0.0818)\tPrec@1 98.438 (99.149)\n",
            "Epoch: [197][390/391]\tTime 0.032 (0.040)\tData 0.000 (0.001)\tLoss 0.0654 (0.0818)\tPrec@1 98.750 (99.132)\n",
            "Total time : 15.650\n",
            "Train Loss: 0.0818, Train Accuracy: 0.9913\n",
            "Test Loss : 0.6835, Test Accuracy : 0.8142 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.209 (0.209)\tData 0.145 (0.145)\tLoss 0.0656 (0.0656)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [198][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.002)\tLoss 0.0965 (0.0827)\tPrec@1 98.438 (99.157)\n",
            "Epoch: [198][200/391]\tTime 0.036 (0.037)\tData 0.000 (0.001)\tLoss 0.0753 (0.0813)\tPrec@1 100.000 (99.223)\n",
            "Epoch: [198][300/391]\tTime 0.038 (0.037)\tData 0.000 (0.001)\tLoss 0.0989 (0.0820)\tPrec@1 100.000 (99.201)\n",
            "Epoch: [198][390/391]\tTime 0.032 (0.037)\tData 0.000 (0.001)\tLoss 0.0929 (0.0821)\tPrec@1 98.750 (99.194)\n",
            "Total time : 14.550\n",
            "Train Loss: 0.0821, Train Accuracy: 0.9919\n",
            "Test Loss : 0.6807, Test Accuracy : 0.8142 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.202 (0.202)\tData 0.155 (0.155)\tLoss 0.0847 (0.0847)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [199][100/391]\tTime 0.037 (0.039)\tData 0.000 (0.002)\tLoss 0.0545 (0.0819)\tPrec@1 100.000 (99.165)\n",
            "Epoch: [199][200/391]\tTime 0.037 (0.038)\tData 0.000 (0.001)\tLoss 0.1110 (0.0825)\tPrec@1 97.656 (99.122)\n",
            "Epoch: [199][300/391]\tTime 0.040 (0.038)\tData 0.000 (0.001)\tLoss 0.0579 (0.0816)\tPrec@1 99.219 (99.133)\n",
            "Epoch: [199][390/391]\tTime 0.032 (0.038)\tData 0.000 (0.001)\tLoss 0.1152 (0.0819)\tPrec@1 98.750 (99.120)\n",
            "Total time : 14.702\n",
            "Train Loss: 0.0819, Train Accuracy: 0.9912\n",
            "Test Loss : 0.6808, Test Accuracy : 0.8136 \n",
            "\n",
            "train loss:  [3.9874, 3.4951, 3.1296, 2.8115, 2.4906, 2.242, 2.0532, 1.9211, 1.8143, 1.7312, 1.6626, 1.6162, 1.5696, 1.5192, 1.4808, 1.4458, 1.423, 1.4046, 1.375, 1.3513, 1.3387, 1.3251, 1.3047, 1.2845, 1.2694, 1.2512, 1.2546, 1.2297, 1.2289, 1.2079, 1.2009, 1.1848, 1.1858, 1.1707, 1.166, 1.1567, 1.149, 1.1376, 1.1313, 1.1151, 1.1148, 1.1011, 1.1022, 1.085, 1.0867, 1.0704, 1.0737, 1.0622, 1.0533, 1.0457, 1.0423, 1.0352, 1.0228, 1.0197, 1.0071, 1.004, 0.9895, 0.9864, 0.9752, 0.9816, 0.9709, 0.9645, 0.9609, 0.9505, 0.9378, 0.9323, 0.9241, 0.9245, 0.9147, 0.8983, 0.8925, 0.8874, 0.8833, 0.8789, 0.865, 0.8653, 0.8503, 0.8408, 0.838, 0.819, 0.8135, 0.8066, 0.8043, 0.7958, 0.7861, 0.7729, 0.7711, 0.7636, 0.7552, 0.7435, 0.7359, 0.7248, 0.7167, 0.7104, 0.7067, 0.6996, 0.6856, 0.671, 0.6653, 0.6568, 0.6432, 0.6412, 0.6291, 0.6171, 0.6115, 0.6054, 0.5914, 0.5796, 0.5632, 0.5659, 0.5428, 0.5401, 0.5312, 0.5185, 0.5104, 0.4987, 0.4861, 0.4843, 0.476, 0.4577, 0.4503, 0.4432, 0.4302, 0.4279, 0.4093, 0.4051, 0.3902, 0.382, 0.3732, 0.3664, 0.3552, 0.3385, 0.3395, 0.3266, 0.3187, 0.3075, 0.3014, 0.2921, 0.2848, 0.2719, 0.2697, 0.2598, 0.2523, 0.2491, 0.236, 0.2261, 0.2229, 0.2148, 0.2095, 0.2034, 0.1957, 0.1893, 0.1863, 0.1795, 0.1727, 0.1684, 0.1656, 0.1581, 0.1573, 0.1504, 0.1462, 0.141, 0.1396, 0.1337, 0.1313, 0.1263, 0.1224, 0.1245, 0.1175, 0.113, 0.1106, 0.1101, 0.1083, 0.1096, 0.1041, 0.1001, 0.1014, 0.0992, 0.095, 0.0936, 0.0931, 0.0904, 0.09, 0.0897, 0.0876, 0.0871, 0.0863, 0.0857, 0.0849, 0.0839, 0.0856, 0.0821, 0.0836, 0.0811, 0.0825, 0.0791, 0.0822, 0.0818, 0.0821, 0.0819]\n",
            "train err:  [0.9178, 0.8431, 0.7778, 0.7157, 0.6538, 0.5987, 0.555, 0.5261, 0.4998, 0.478, 0.4606, 0.4496, 0.4366, 0.4221, 0.412, 0.4037, 0.3966, 0.3941, 0.3848, 0.3776, 0.3746, 0.3711, 0.3657, 0.3593, 0.3561, 0.3503, 0.3515, 0.3463, 0.3466, 0.339, 0.338, 0.3336, 0.3354, 0.3304, 0.3301, 0.3244, 0.3214, 0.3199, 0.3198, 0.313, 0.3143, 0.3104, 0.3105, 0.3049, 0.3054, 0.3014, 0.3038, 0.3004, 0.2978, 0.2959, 0.2926, 0.2921, 0.2879, 0.2881, 0.2842, 0.2841, 0.2788, 0.2772, 0.2745, 0.2781, 0.2737, 0.2729, 0.269, 0.2673, 0.263, 0.2626, 0.2601, 0.2611, 0.2567, 0.2527, 0.2516, 0.2497, 0.2488, 0.2453, 0.2422, 0.2427, 0.2384, 0.2368, 0.2355, 0.2285, 0.2262, 0.2262, 0.2248, 0.2236, 0.2171, 0.2154, 0.2162, 0.2133, 0.2114, 0.2075, 0.203, 0.2004, 0.1986, 0.1992, 0.1968, 0.1937, 0.1914, 0.1858, 0.1837, 0.1794, 0.1786, 0.1754, 0.1704, 0.1675, 0.1651, 0.1646, 0.1605, 0.1555, 0.1513, 0.152, 0.1456, 0.1433, 0.1408, 0.138, 0.1334, 0.1313, 0.1249, 0.1263, 0.1236, 0.1174, 0.1143, 0.1118, 0.1075, 0.108, 0.1017, 0.1008, 0.095, 0.0921, 0.0892, 0.0871, 0.0853, 0.0781, 0.0789, 0.0747, 0.0719, 0.0686, 0.0674, 0.0629, 0.0616, 0.0565, 0.0565, 0.0525, 0.0514, 0.0511, 0.0466, 0.0432, 0.0417, 0.0397, 0.0388, 0.0362, 0.0343, 0.0333, 0.0322, 0.0304, 0.0287, 0.0273, 0.0267, 0.0243, 0.0236, 0.0228, 0.0218, 0.02, 0.0202, 0.0195, 0.0188, 0.0171, 0.0166, 0.0171, 0.0155, 0.0147, 0.0136, 0.0145, 0.0143, 0.0139, 0.013, 0.0118, 0.012, 0.0117, 0.0106, 0.0106, 0.0107, 0.0099, 0.0102, 0.0101, 0.0094, 0.0101, 0.0093, 0.0097, 0.0092, 0.0091, 0.01, 0.0086, 0.0095, 0.0084, 0.0092, 0.0078, 0.009, 0.0087, 0.0081, 0.0088]\n",
            "train acc:  [0.0822, 0.1569, 0.2222, 0.2843, 0.3462, 0.4013, 0.445, 0.4739, 0.5002, 0.522, 0.5394, 0.5504, 0.5634, 0.5779, 0.588, 0.5963, 0.6034, 0.6059, 0.6152, 0.6224, 0.6254, 0.6289, 0.6343, 0.6407, 0.6439, 0.6497, 0.6485, 0.6537, 0.6534, 0.661, 0.662, 0.6664, 0.6646, 0.6696, 0.6699, 0.6756, 0.6786, 0.6801, 0.6802, 0.687, 0.6857, 0.6896, 0.6895, 0.6951, 0.6946, 0.6986, 0.6962, 0.6996, 0.7022, 0.7041, 0.7074, 0.7079, 0.7121, 0.7119, 0.7158, 0.7159, 0.7212, 0.7228, 0.7255, 0.7219, 0.7263, 0.7271, 0.731, 0.7327, 0.737, 0.7374, 0.7399, 0.7389, 0.7433, 0.7473, 0.7484, 0.7503, 0.7512, 0.7547, 0.7578, 0.7573, 0.7616, 0.7632, 0.7645, 0.7715, 0.7738, 0.7738, 0.7752, 0.7764, 0.7829, 0.7846, 0.7838, 0.7867, 0.7886, 0.7925, 0.797, 0.7996, 0.8014, 0.8008, 0.8032, 0.8063, 0.8086, 0.8142, 0.8163, 0.8206, 0.8214, 0.8246, 0.8296, 0.8325, 0.8349, 0.8354, 0.8395, 0.8445, 0.8487, 0.848, 0.8544, 0.8567, 0.8592, 0.862, 0.8666, 0.8687, 0.8751, 0.8737, 0.8764, 0.8826, 0.8857, 0.8882, 0.8925, 0.892, 0.8983, 0.8992, 0.905, 0.9079, 0.9108, 0.9129, 0.9147, 0.9219, 0.9211, 0.9253, 0.9281, 0.9314, 0.9326, 0.9371, 0.9384, 0.9435, 0.9435, 0.9475, 0.9486, 0.9489, 0.9534, 0.9568, 0.9583, 0.9603, 0.9612, 0.9638, 0.9657, 0.9667, 0.9678, 0.9696, 0.9713, 0.9727, 0.9733, 0.9757, 0.9764, 0.9772, 0.9782, 0.98, 0.9798, 0.9805, 0.9812, 0.9829, 0.9834, 0.9829, 0.9845, 0.9853, 0.9864, 0.9855, 0.9857, 0.9861, 0.987, 0.9882, 0.988, 0.9883, 0.9894, 0.9894, 0.9893, 0.9901, 0.9898, 0.9899, 0.9906, 0.9899, 0.9907, 0.9903, 0.9908, 0.9909, 0.99, 0.9914, 0.9905, 0.9916, 0.9908, 0.9922, 0.991, 0.9913, 0.9919, 0.9912]\n",
            "test loss:  [3.6243, 3.2069, 2.9738, 2.6846, 2.3197, 2.0549, 1.8909, 1.9878, 1.8753, 1.656, 1.7533, 1.6337, 1.6041, 1.632, 1.7585, 1.6507, 1.6011, 1.5756, 1.4871, 1.6067, 1.5438, 1.5006, 1.5784, 1.3924, 1.4498, 1.525, 1.6243, 1.4762, 1.5697, 1.3742, 1.3606, 1.3472, 1.5234, 1.5005, 1.305, 1.38, 1.5191, 1.3982, 1.274, 1.3761, 1.4309, 1.2877, 1.2835, 1.3594, 1.3266, 1.2617, 1.3652, 1.4188, 1.293, 1.3223, 1.5927, 1.2348, 1.2874, 1.274, 1.2636, 1.4193, 1.2798, 1.2192, 1.2455, 1.3519, 1.2566, 1.2855, 1.219, 1.1847, 1.2837, 1.1895, 1.2736, 1.2196, 1.1382, 1.2206, 1.2419, 1.1586, 1.1175, 1.1598, 1.1794, 1.1946, 1.1622, 1.1785, 1.1564, 1.1469, 1.1811, 1.1763, 1.1862, 1.1787, 1.103, 1.105, 1.116, 1.1449, 1.1029, 1.0785, 1.1086, 1.1082, 1.0747, 1.0491, 1.0759, 1.0731, 1.0008, 1.1, 1.1419, 1.094, 1.0733, 1.0677, 1.0773, 0.9669, 1.0052, 1.0111, 1.0162, 1.0101, 1.074, 1.0265, 1.0105, 0.947, 0.9966, 1.0014, 0.9642, 0.9494, 1.0177, 0.9271, 0.9763, 0.9347, 0.9198, 0.9278, 0.9452, 0.9098, 0.9251, 0.9145, 0.8917, 0.9198, 0.9284, 0.8427, 0.9044, 0.8963, 0.8928, 0.8632, 0.8575, 0.8731, 0.8758, 0.8266, 0.8256, 0.8574, 0.8296, 0.8269, 0.816, 0.8203, 0.8306, 0.7987, 0.8158, 0.8076, 0.801, 0.7895, 0.7873, 0.7944, 0.7879, 0.762, 0.7751, 0.7534, 0.7603, 0.7589, 0.7457, 0.7274, 0.7377, 0.7422, 0.7201, 0.7421, 0.7338, 0.7198, 0.7299, 0.7181, 0.7162, 0.7107, 0.7096, 0.7054, 0.6997, 0.7034, 0.7047, 0.6964, 0.6981, 0.6926, 0.6936, 0.6913, 0.6925, 0.691, 0.6912, 0.6912, 0.686, 0.6837, 0.6869, 0.6847, 0.6821, 0.6852, 0.6828, 0.6848, 0.6813, 0.6838, 0.6813, 0.6819, 0.6825, 0.6835, 0.6807, 0.6808]\n",
            "test err:  [0.8677, 0.7884, 0.7488, 0.6912, 0.6205, 0.5598, 0.5236, 0.5366, 0.5135, 0.4678, 0.4838, 0.4496, 0.4481, 0.4558, 0.487, 0.4604, 0.4446, 0.4434, 0.4195, 0.4427, 0.427, 0.4225, 0.4297, 0.3906, 0.4127, 0.4151, 0.4507, 0.414, 0.4298, 0.3925, 0.3789, 0.3806, 0.4216, 0.4148, 0.366, 0.3852, 0.4187, 0.3895, 0.3578, 0.3858, 0.4021, 0.3645, 0.3589, 0.381, 0.3729, 0.3595, 0.3769, 0.3915, 0.3641, 0.3644, 0.426, 0.3508, 0.3651, 0.3583, 0.3575, 0.3909, 0.3556, 0.3474, 0.3499, 0.3725, 0.3542, 0.3608, 0.3453, 0.3368, 0.358, 0.3421, 0.3551, 0.34, 0.3228, 0.3429, 0.3488, 0.3276, 0.3175, 0.3295, 0.3327, 0.3356, 0.3297, 0.3314, 0.3263, 0.3256, 0.3289, 0.329, 0.334, 0.3341, 0.308, 0.3123, 0.319, 0.3234, 0.3122, 0.3058, 0.3126, 0.3118, 0.3053, 0.3006, 0.3059, 0.3034, 0.2866, 0.3143, 0.3188, 0.311, 0.301, 0.2982, 0.3004, 0.2742, 0.2874, 0.2852, 0.2831, 0.2872, 0.3012, 0.2894, 0.288, 0.272, 0.2835, 0.2882, 0.2732, 0.2671, 0.2837, 0.2631, 0.2744, 0.2664, 0.2608, 0.263, 0.2647, 0.2542, 0.2601, 0.2565, 0.2546, 0.2573, 0.2671, 0.2379, 0.2579, 0.2535, 0.2519, 0.2458, 0.2415, 0.2459, 0.2469, 0.2288, 0.2366, 0.2396, 0.2318, 0.2352, 0.2317, 0.2288, 0.2316, 0.2255, 0.2294, 0.2232, 0.2243, 0.2207, 0.2188, 0.2199, 0.2238, 0.2102, 0.2181, 0.2096, 0.2108, 0.2126, 0.2093, 0.199, 0.2051, 0.2075, 0.1994, 0.2078, 0.2019, 0.1981, 0.2005, 0.1967, 0.1945, 0.1979, 0.1964, 0.1936, 0.1886, 0.1944, 0.1923, 0.192, 0.1901, 0.1937, 0.1914, 0.1903, 0.1881, 0.191, 0.1886, 0.1884, 0.1869, 0.188, 0.1886, 0.1862, 0.1858, 0.1857, 0.1861, 0.1871, 0.1861, 0.1867, 0.1858, 0.185, 0.1858, 0.1858, 0.1858, 0.1864]\n",
            "test acc:  [0.1323, 0.2116, 0.2512, 0.3088, 0.3795, 0.4402, 0.4764, 0.4634, 0.4865, 0.5322, 0.5162, 0.5504, 0.5519, 0.5442, 0.513, 0.5396, 0.5554, 0.5566, 0.5805, 0.5573, 0.573, 0.5775, 0.5703, 0.6094, 0.5873, 0.5849, 0.5493, 0.586, 0.5702, 0.6075, 0.6211, 0.6194, 0.5784, 0.5852, 0.634, 0.6148, 0.5813, 0.6105, 0.6422, 0.6142, 0.5979, 0.6355, 0.6411, 0.619, 0.6271, 0.6405, 0.6231, 0.6085, 0.6359, 0.6356, 0.574, 0.6492, 0.6349, 0.6417, 0.6425, 0.6091, 0.6444, 0.6526, 0.6501, 0.6275, 0.6458, 0.6392, 0.6547, 0.6632, 0.642, 0.6579, 0.6449, 0.66, 0.6772, 0.6571, 0.6512, 0.6724, 0.6825, 0.6705, 0.6673, 0.6644, 0.6703, 0.6686, 0.6737, 0.6744, 0.6711, 0.671, 0.666, 0.6659, 0.692, 0.6877, 0.681, 0.6766, 0.6878, 0.6942, 0.6874, 0.6882, 0.6947, 0.6994, 0.6941, 0.6966, 0.7134, 0.6857, 0.6812, 0.689, 0.699, 0.7018, 0.6996, 0.7258, 0.7126, 0.7148, 0.7169, 0.7128, 0.6988, 0.7106, 0.712, 0.728, 0.7165, 0.7118, 0.7268, 0.7329, 0.7163, 0.7369, 0.7256, 0.7336, 0.7392, 0.737, 0.7353, 0.7458, 0.7399, 0.7435, 0.7454, 0.7427, 0.7329, 0.7621, 0.7421, 0.7465, 0.7481, 0.7542, 0.7585, 0.7541, 0.7531, 0.7712, 0.7634, 0.7604, 0.7682, 0.7648, 0.7683, 0.7712, 0.7684, 0.7745, 0.7706, 0.7768, 0.7757, 0.7793, 0.7812, 0.7801, 0.7762, 0.7898, 0.7819, 0.7904, 0.7892, 0.7874, 0.7907, 0.801, 0.7949, 0.7925, 0.8006, 0.7922, 0.7981, 0.8019, 0.7995, 0.8033, 0.8055, 0.8021, 0.8036, 0.8064, 0.8114, 0.8056, 0.8077, 0.808, 0.8099, 0.8063, 0.8086, 0.8097, 0.8119, 0.809, 0.8114, 0.8116, 0.8131, 0.812, 0.8114, 0.8138, 0.8142, 0.8143, 0.8139, 0.8129, 0.8139, 0.8133, 0.8142, 0.815, 0.8142, 0.8142, 0.8142, 0.8136]\n",
            "ori train loss:  [4.105, 3.624, 3.2771, 2.9706, 2.6584, 2.4152, 2.231, 2.1036, 2.0021, 1.924, 1.8589, 1.8142, 1.77, 1.7224, 1.6849, 1.6528, 1.6311, 1.6149, 1.5847, 1.5636, 1.5526, 1.5393, 1.52, 1.5004, 1.4868, 1.4695, 1.4747, 1.4502, 1.4507, 1.4294, 1.4237, 1.4069, 1.4097, 1.3947, 1.3913, 1.3822, 1.3757, 1.3645, 1.3592, 1.3431, 1.345, 1.3313, 1.3335, 1.3157, 1.3186, 1.3023, 1.308, 1.2968, 1.2875, 1.2807, 1.2786, 1.271, 1.2594, 1.2568, 1.2452, 1.2438, 1.2279, 1.2258, 1.2158, 1.2239, 1.2126, 1.2061, 1.2043, 1.1941, 1.1823, 1.1769, 1.1702, 1.1709, 1.1613, 1.1463, 1.1402, 1.1362, 1.133, 1.1294, 1.116, 1.1179, 1.102, 1.0945, 1.0932, 1.0727, 1.0681, 1.0624, 1.0631, 1.0544, 1.043, 1.0314, 1.0316, 1.0242, 1.0167, 1.0035, 1.0005, 0.9874, 0.9819, 0.976, 0.9734, 0.9661, 0.9517, 0.9385, 0.9352, 0.9269, 0.9123, 0.9133, 0.8997, 0.8889, 0.8843, 0.8795, 0.8647, 0.856, 0.8375, 0.8437, 0.8177, 0.8173, 0.8097, 0.7964, 0.788, 0.7769, 0.7662, 0.7642, 0.7582, 0.736, 0.7316, 0.7257, 0.7114, 0.7109, 0.6906, 0.6876, 0.6723, 0.6642, 0.6529, 0.6488, 0.6362, 0.6182, 0.6227, 0.6071, 0.5993, 0.5858, 0.5793, 0.5704, 0.561, 0.5479, 0.5454, 0.5352, 0.5262, 0.5238, 0.5066, 0.4936, 0.4907, 0.4818, 0.4744, 0.4687, 0.4566, 0.4494, 0.4451, 0.4351, 0.4267, 0.4181, 0.4171, 0.4051, 0.4054, 0.3959, 0.3893, 0.3808, 0.3781, 0.3714, 0.3642, 0.358, 0.3519, 0.3537, 0.3429, 0.3366, 0.3322, 0.3304, 0.3274, 0.329, 0.3182, 0.313, 0.3155, 0.3109, 0.3025, 0.3002, 0.299, 0.2958, 0.2906, 0.2935, 0.2884, 0.2861, 0.2825, 0.2837, 0.2824, 0.28, 0.2819, 0.2771, 0.2804, 0.2742, 0.2763, 0.2723, 0.2755, 0.2753, 0.2776, 0.2754]\n",
            "ori train err:  [0.9332, 0.8662, 0.806, 0.7487, 0.6913, 0.6392, 0.599, 0.5721, 0.5462, 0.5269, 0.5096, 0.4987, 0.4867, 0.475, 0.4635, 0.4587, 0.4501, 0.4516, 0.4412, 0.4348, 0.4315, 0.4284, 0.4214, 0.4155, 0.4139, 0.4094, 0.4107, 0.4051, 0.4049, 0.3967, 0.3965, 0.3942, 0.397, 0.3914, 0.3905, 0.3849, 0.3835, 0.3818, 0.3804, 0.3757, 0.375, 0.3732, 0.3732, 0.3687, 0.367, 0.3632, 0.3673, 0.3647, 0.3602, 0.3581, 0.3598, 0.3581, 0.3542, 0.354, 0.3498, 0.3502, 0.3455, 0.3429, 0.3414, 0.3437, 0.3405, 0.3384, 0.3379, 0.3361, 0.331, 0.3309, 0.3281, 0.3286, 0.3256, 0.32, 0.3212, 0.3205, 0.32, 0.3189, 0.3134, 0.3135, 0.3093, 0.3083, 0.3091, 0.303, 0.3015, 0.3011, 0.3012, 0.2963, 0.2913, 0.2907, 0.2919, 0.2896, 0.2872, 0.2838, 0.2834, 0.2792, 0.2781, 0.2772, 0.275, 0.273, 0.2703, 0.2641, 0.2652, 0.2604, 0.258, 0.2574, 0.2528, 0.2498, 0.2463, 0.2486, 0.2424, 0.2427, 0.2372, 0.2373, 0.2301, 0.2288, 0.2272, 0.2233, 0.2203, 0.2164, 0.2126, 0.2149, 0.2121, 0.204, 0.203, 0.2015, 0.197, 0.1947, 0.1897, 0.1875, 0.1855, 0.1827, 0.1772, 0.1752, 0.1715, 0.1693, 0.1669, 0.1631, 0.1601, 0.1554, 0.1532, 0.1526, 0.1466, 0.1433, 0.1415, 0.1398, 0.136, 0.1338, 0.1291, 0.1254, 0.1246, 0.1228, 0.1197, 0.1172, 0.1147, 0.1108, 0.1082, 0.106, 0.1034, 0.1001, 0.0997, 0.0973, 0.0967, 0.0934, 0.0922, 0.0887, 0.0882, 0.0856, 0.0833, 0.0806, 0.08, 0.0798, 0.0762, 0.0742, 0.074, 0.0735, 0.0708, 0.0712, 0.0701, 0.0676, 0.0688, 0.0687, 0.0651, 0.0646, 0.0633, 0.0631, 0.0618, 0.0629, 0.0616, 0.0602, 0.06, 0.0605, 0.0598, 0.0597, 0.0586, 0.0594, 0.0599, 0.0587, 0.0573, 0.0582, 0.0573, 0.0579, 0.0583, 0.0579]\n",
            "ori train acc:  [0.0668, 0.1338, 0.194, 0.2513, 0.3087, 0.3608, 0.401, 0.4279, 0.4538, 0.4731, 0.4904, 0.5013, 0.5133, 0.525, 0.5365, 0.5413, 0.5499, 0.5484, 0.5588, 0.5652, 0.5685, 0.5716, 0.5786, 0.5845, 0.5861, 0.5906, 0.5893, 0.5949, 0.5951, 0.6033, 0.6035, 0.6058, 0.603, 0.6086, 0.6095, 0.6151, 0.6165, 0.6182, 0.6196, 0.6243, 0.625, 0.6268, 0.6268, 0.6313, 0.633, 0.6368, 0.6327, 0.6353, 0.6398, 0.6419, 0.6402, 0.6419, 0.6458, 0.646, 0.6502, 0.6498, 0.6545, 0.6571, 0.6586, 0.6563, 0.6595, 0.6616, 0.6621, 0.6639, 0.669, 0.6691, 0.6719, 0.6714, 0.6744, 0.68, 0.6788, 0.6795, 0.68, 0.6811, 0.6866, 0.6865, 0.6907, 0.6917, 0.6909, 0.697, 0.6985, 0.6989, 0.6988, 0.7037, 0.7087, 0.7093, 0.7081, 0.7104, 0.7128, 0.7162, 0.7166, 0.7208, 0.7219, 0.7228, 0.725, 0.727, 0.7297, 0.7359, 0.7348, 0.7396, 0.742, 0.7426, 0.7472, 0.7502, 0.7537, 0.7514, 0.7576, 0.7573, 0.7628, 0.7627, 0.7699, 0.7712, 0.7728, 0.7767, 0.7797, 0.7836, 0.7874, 0.7851, 0.7879, 0.796, 0.797, 0.7985, 0.803, 0.8053, 0.8103, 0.8125, 0.8145, 0.8173, 0.8228, 0.8248, 0.8285, 0.8307, 0.8331, 0.8369, 0.8399, 0.8446, 0.8468, 0.8474, 0.8534, 0.8567, 0.8585, 0.8602, 0.864, 0.8662, 0.8709, 0.8746, 0.8754, 0.8772, 0.8803, 0.8828, 0.8853, 0.8892, 0.8918, 0.894, 0.8966, 0.8999, 0.9003, 0.9027, 0.9033, 0.9066, 0.9078, 0.9113, 0.9118, 0.9144, 0.9167, 0.9194, 0.92, 0.9202, 0.9238, 0.9258, 0.926, 0.9265, 0.9292, 0.9288, 0.9299, 0.9324, 0.9312, 0.9313, 0.9349, 0.9354, 0.9367, 0.9369, 0.9382, 0.9371, 0.9384, 0.9398, 0.94, 0.9395, 0.9402, 0.9403, 0.9414, 0.9406, 0.9401, 0.9413, 0.9427, 0.9418, 0.9427, 0.9421, 0.9417, 0.9421]\n",
            "time:  [17.08, 14.4, 14.64, 14.51, 14.58, 14.39, 14.46, 14.65, 14.36, 14.43, 14.79, 14.31, 14.39, 14.39, 14.27, 14.04, 14.49, 14.7, 14.41, 14.28, 14.28, 15.17, 14.48, 14.71, 14.56, 14.39, 14.74, 14.27, 14.95, 14.73, 14.36, 14.31, 14.72, 14.83, 14.47, 14.54, 14.36, 14.57, 14.32, 14.81, 14.28, 14.51, 14.79, 14.83, 14.85, 14.79, 14.54, 14.4, 14.01, 14.39, 14.31, 14.9, 14.34, 14.2, 14.41, 14.37, 14.84, 14.62, 14.92, 14.31, 14.38, 14.96, 14.91, 14.51, 14.25, 14.12, 14.91, 14.53, 14.34, 14.34, 14.22, 14.49, 14.41, 15.04, 14.55, 14.3, 14.34, 14.29, 14.92, 14.24, 14.0, 14.78, 14.18, 14.42, 14.69, 14.42, 14.17, 14.39, 14.4, 14.89, 14.75, 14.65, 14.08, 14.18, 14.38, 14.49, 14.51, 14.83, 14.44, 14.39, 14.43, 14.71, 14.84, 14.97, 14.68, 14.33, 14.53, 14.48, 14.35, 14.46, 14.2, 14.95, 14.88, 14.73, 14.36, 14.91, 14.93, 14.54, 15.06, 14.58, 14.95, 14.47, 14.91, 14.79, 14.8, 14.44, 14.29, 14.19, 14.45, 14.28, 14.41, 14.85, 14.59, 14.73, 14.6, 14.16, 14.33, 14.84, 14.7, 14.58, 14.47, 14.55, 14.45, 14.91, 14.26, 14.26, 14.55, 14.46, 14.61, 14.31, 14.31, 14.74, 14.51, 15.02, 14.82, 14.44, 14.3, 14.31, 14.49, 14.78, 14.33, 14.61, 14.38, 14.37, 14.31, 14.76, 14.57, 14.59, 14.68, 14.32, 14.7, 14.5, 14.38, 14.3, 14.87, 14.27, 14.55, 14.96, 14.7, 14.26, 14.62, 14.45, 14.17, 14.72, 14.91, 14.24, 15.05, 14.63, 14.58, 14.53, 14.14, 14.72, 14.53, 14.5, 14.28, 14.58, 14.58, 15.65, 14.55, 14.7]\n"
          ]
        }
      ]
    }
  ]
}