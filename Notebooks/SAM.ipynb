{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOEhnCNVB2EnK8gfM/Rw0W1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Notebooks/SAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA0W9rOYiot5",
        "outputId": "e99f4a42-b80a-4cf6-e10a-a176a79a66da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/src/trains.py \\\n",
        "    --optimizer SAM \\\n",
        "    --z_threshold 1.0 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR100 \\\n",
        "    --arch resnet18 \\\n",
        "    --epochs 200 \\\n",
        "    --batch-size 128\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duaYkJzckjMb",
        "outputId": "070e91bd-c21d-4e6f-ebd0-3e48d7f6339e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: resnet18\n",
            "lambda: 0.95\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar100 dataset!\n",
            "100% 169M/169M [00:13<00:00, 12.4MB/s]\n",
            "391\n",
            "50000\n",
            "optimizer: SAM\n",
            "SAM (\n",
            "Parameter Group 0\n",
            "    adaptive: 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 0.1\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "Epoch: [0][0/391]\tTime 2.136 (2.136)\tData 0.148 (0.148)\tLoss 4.7223 (4.7223)\tPrec@1 0.000 (0.000)\n",
            "Epoch: [0][100/391]\tTime 0.030 (0.054)\tData 0.000 (0.002)\tLoss 4.0240 (4.3665)\tPrec@1 5.469 (4.045)\n",
            "Epoch: [0][200/391]\tTime 0.031 (0.043)\tData 0.000 (0.001)\tLoss 4.0159 (4.1950)\tPrec@1 7.031 (5.512)\n",
            "Epoch: [0][300/391]\tTime 0.034 (0.039)\tData 0.000 (0.001)\tLoss 3.7449 (4.0963)\tPrec@1 9.375 (6.572)\n",
            "Epoch: [0][390/391]\tTime 0.193 (0.038)\tData 0.000 (0.001)\tLoss 3.8484 (4.0224)\tPrec@1 7.500 (7.608)\n",
            "Total time : 14.723\n",
            "Train Loss: 4.0224, Train Accuracy: 0.0761\n",
            "Test Loss : 3.6602, Test Accuracy : 0.1164 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.217 (0.217)\tData 0.158 (0.158)\tLoss 3.7809 (3.7809)\tPrec@1 10.156 (10.156)\n",
            "Epoch: [1][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 3.4142 (3.6679)\tPrec@1 14.062 (12.732)\n",
            "Epoch: [1][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 3.5235 (3.6141)\tPrec@1 17.969 (13.674)\n",
            "Epoch: [1][300/391]\tTime 0.030 (0.031)\tData 0.000 (0.001)\tLoss 3.1865 (3.5708)\tPrec@1 17.188 (14.415)\n",
            "Epoch: [1][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 3.1166 (3.5286)\tPrec@1 25.000 (15.154)\n",
            "Total time : 12.294\n",
            "Train Loss: 3.5286, Train Accuracy: 0.1515\n",
            "Test Loss : 3.2287, Test Accuracy : 0.2024 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.188 (0.188)\tData 0.143 (0.143)\tLoss 3.3201 (3.3201)\tPrec@1 17.969 (17.969)\n",
            "Epoch: [2][100/391]\tTime 0.036 (0.033)\tData 0.000 (0.002)\tLoss 3.2476 (3.2947)\tPrec@1 24.219 (18.967)\n",
            "Epoch: [2][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 3.2696 (3.2513)\tPrec@1 25.000 (20.134)\n",
            "Epoch: [2][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 3.0772 (3.2082)\tPrec@1 24.219 (21.008)\n",
            "Epoch: [2][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 3.0881 (3.1770)\tPrec@1 20.000 (21.550)\n",
            "Total time : 12.498\n",
            "Train Loss: 3.1770, Train Accuracy: 0.2155\n",
            "Test Loss : 3.0104, Test Accuracy : 0.2463 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.179 (0.179)\tData 0.135 (0.135)\tLoss 2.8236 (2.8236)\tPrec@1 24.219 (24.219)\n",
            "Epoch: [3][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 2.7091 (2.9509)\tPrec@1 28.125 (25.232)\n",
            "Epoch: [3][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 3.0909 (2.9376)\tPrec@1 22.656 (25.890)\n",
            "Epoch: [3][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 2.9612 (2.9098)\tPrec@1 25.000 (26.342)\n",
            "Epoch: [3][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 2.9000 (2.8793)\tPrec@1 27.500 (26.924)\n",
            "Total time : 12.383\n",
            "Train Loss: 2.8793, Train Accuracy: 0.2692\n",
            "Test Loss : 2.7964, Test Accuracy : 0.2883 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.195 (0.195)\tData 0.141 (0.141)\tLoss 2.6369 (2.6369)\tPrec@1 32.812 (32.812)\n",
            "Epoch: [4][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 2.6752 (2.6602)\tPrec@1 34.375 (31.033)\n",
            "Epoch: [4][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 2.6401 (2.6430)\tPrec@1 27.344 (31.697)\n",
            "Epoch: [4][300/391]\tTime 0.034 (0.032)\tData 0.000 (0.001)\tLoss 2.5421 (2.6097)\tPrec@1 39.062 (32.462)\n",
            "Epoch: [4][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 2.7738 (2.5816)\tPrec@1 30.000 (32.864)\n",
            "Total time : 12.441\n",
            "Train Loss: 2.5816, Train Accuracy: 0.3286\n",
            "Test Loss : 2.3624, Test Accuracy : 0.3747 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.194 (0.194)\tData 0.140 (0.140)\tLoss 2.3459 (2.3459)\tPrec@1 36.719 (36.719)\n",
            "Epoch: [5][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 2.1783 (2.3641)\tPrec@1 39.844 (37.167)\n",
            "Epoch: [5][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 2.4536 (2.3642)\tPrec@1 34.375 (37.329)\n",
            "Epoch: [5][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 2.1020 (2.3406)\tPrec@1 46.875 (38.027)\n",
            "Epoch: [5][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 2.1513 (2.3227)\tPrec@1 38.750 (38.398)\n",
            "Total time : 12.569\n",
            "Train Loss: 2.3227, Train Accuracy: 0.3840\n",
            "Test Loss : 2.2038, Test Accuracy : 0.4089 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.180 (0.180)\tData 0.135 (0.135)\tLoss 2.3229 (2.3229)\tPrec@1 39.844 (39.844)\n",
            "Epoch: [6][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 2.2653 (2.1472)\tPrec@1 40.625 (42.180)\n",
            "Epoch: [6][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 2.0534 (2.1284)\tPrec@1 45.312 (42.522)\n",
            "Epoch: [6][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 2.2596 (2.1224)\tPrec@1 39.062 (42.727)\n",
            "Epoch: [6][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 2.0036 (2.1131)\tPrec@1 40.000 (43.002)\n",
            "Total time : 12.544\n",
            "Train Loss: 2.1131, Train Accuracy: 0.4300\n",
            "Test Loss : 1.9693, Test Accuracy : 0.4542 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.175 (0.175)\tData 0.136 (0.136)\tLoss 1.7271 (1.7271)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [7][100/391]\tTime 0.036 (0.034)\tData 0.000 (0.002)\tLoss 2.1063 (1.9736)\tPrec@1 43.750 (46.450)\n",
            "Epoch: [7][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 2.2835 (1.9698)\tPrec@1 35.156 (46.152)\n",
            "Epoch: [7][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.9983 (1.9750)\tPrec@1 46.094 (46.078)\n",
            "Epoch: [7][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.8084 (1.9671)\tPrec@1 51.250 (46.318)\n",
            "Total time : 12.620\n",
            "Train Loss: 1.9671, Train Accuracy: 0.4632\n",
            "Test Loss : 1.9489, Test Accuracy : 0.4663 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.189 (0.189)\tData 0.143 (0.143)\tLoss 1.9169 (1.9169)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [8][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 2.0058 (1.8563)\tPrec@1 44.531 (49.304)\n",
            "Epoch: [8][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.9020 (1.8562)\tPrec@1 50.781 (49.394)\n",
            "Epoch: [8][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.8186 (1.8537)\tPrec@1 55.469 (49.564)\n",
            "Epoch: [8][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.8182 (1.8459)\tPrec@1 47.500 (49.694)\n",
            "Total time : 12.743\n",
            "Train Loss: 1.8459, Train Accuracy: 0.4969\n",
            "Test Loss : 1.8107, Test Accuracy : 0.4949 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 1.6534 (1.6534)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [9][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 1.6199 (1.7575)\tPrec@1 52.344 (51.679)\n",
            "Epoch: [9][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.8452 (1.7563)\tPrec@1 48.438 (51.943)\n",
            "Epoch: [9][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.6458 (1.7557)\tPrec@1 57.812 (51.853)\n",
            "Epoch: [9][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.9513 (1.7558)\tPrec@1 46.250 (51.842)\n",
            "Total time : 12.433\n",
            "Train Loss: 1.7558, Train Accuracy: 0.5184\n",
            "Test Loss : 1.7600, Test Accuracy : 0.5169 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.223 (0.223)\tData 0.161 (0.161)\tLoss 1.6673 (1.6673)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [10][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 1.8689 (1.6821)\tPrec@1 47.656 (53.782)\n",
            "Epoch: [10][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.7474 (1.6851)\tPrec@1 53.906 (53.521)\n",
            "Epoch: [10][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.6334 (1.6829)\tPrec@1 52.344 (53.610)\n",
            "Epoch: [10][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.4671 (1.6888)\tPrec@1 63.750 (53.454)\n",
            "Total time : 12.571\n",
            "Train Loss: 1.6888, Train Accuracy: 0.5345\n",
            "Test Loss : 1.7217, Test Accuracy : 0.5160 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.184 (0.184)\tData 0.138 (0.138)\tLoss 1.7503 (1.7503)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [11][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 1.7881 (1.5918)\tPrec@1 46.094 (55.979)\n",
            "Epoch: [11][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.6160 (1.6099)\tPrec@1 54.688 (55.173)\n",
            "Epoch: [11][300/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 1.7465 (1.6212)\tPrec@1 49.219 (54.872)\n",
            "Epoch: [11][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.6694 (1.6275)\tPrec@1 52.500 (54.752)\n",
            "Total time : 12.741\n",
            "Train Loss: 1.6275, Train Accuracy: 0.5475\n",
            "Test Loss : 1.6866, Test Accuracy : 0.5295 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.197 (0.197)\tData 0.137 (0.137)\tLoss 1.6858 (1.6858)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [12][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.7585 (1.5787)\tPrec@1 50.781 (56.358)\n",
            "Epoch: [12][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.5193 (1.5767)\tPrec@1 56.250 (56.534)\n",
            "Epoch: [12][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.7638 (1.5775)\tPrec@1 51.562 (56.349)\n",
            "Epoch: [12][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.8789 (1.5832)\tPrec@1 58.750 (56.080)\n",
            "Total time : 12.849\n",
            "Train Loss: 1.5832, Train Accuracy: 0.5608\n",
            "Test Loss : 1.6943, Test Accuracy : 0.5368 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.185 (0.185)\tData 0.140 (0.140)\tLoss 1.4933 (1.4933)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [13][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2690 (1.5125)\tPrec@1 66.406 (57.921)\n",
            "Epoch: [13][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.5593 (1.5308)\tPrec@1 58.594 (57.311)\n",
            "Epoch: [13][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.7215 (1.5383)\tPrec@1 50.781 (57.018)\n",
            "Epoch: [13][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.5547 (1.5337)\tPrec@1 52.500 (57.362)\n",
            "Total time : 12.484\n",
            "Train Loss: 1.5337, Train Accuracy: 0.5736\n",
            "Test Loss : 1.5934, Test Accuracy : 0.5585 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.195 (0.195)\tData 0.155 (0.155)\tLoss 1.3586 (1.3586)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [14][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 1.4105 (1.4716)\tPrec@1 59.375 (59.166)\n",
            "Epoch: [14][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.7634 (1.4822)\tPrec@1 49.219 (58.671)\n",
            "Epoch: [14][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.5058 (1.4859)\tPrec@1 60.938 (58.438)\n",
            "Epoch: [14][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.4917 (1.4920)\tPrec@1 52.500 (58.372)\n",
            "Total time : 12.367\n",
            "Train Loss: 1.4920, Train Accuracy: 0.5837\n",
            "Test Loss : 1.5907, Test Accuracy : 0.5555 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.194 (0.194)\tData 0.138 (0.138)\tLoss 1.4944 (1.4944)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [15][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2996 (1.4258)\tPrec@1 66.406 (60.582)\n",
            "Epoch: [15][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.5004 (1.4446)\tPrec@1 53.125 (59.822)\n",
            "Epoch: [15][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.3476 (1.4512)\tPrec@1 62.500 (59.609)\n",
            "Epoch: [15][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.4755 (1.4614)\tPrec@1 58.750 (59.366)\n",
            "Total time : 12.320\n",
            "Train Loss: 1.4614, Train Accuracy: 0.5937\n",
            "Test Loss : 1.5614, Test Accuracy : 0.5601 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.190 (0.190)\tData 0.137 (0.137)\tLoss 1.5220 (1.5220)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [16][100/391]\tTime 0.033 (0.033)\tData 0.000 (0.002)\tLoss 1.1716 (1.4119)\tPrec@1 64.844 (60.605)\n",
            "Epoch: [16][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.4953 (1.4248)\tPrec@1 60.156 (59.993)\n",
            "Epoch: [16][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.3420 (1.4334)\tPrec@1 63.281 (59.977)\n",
            "Epoch: [16][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.4757 (1.4313)\tPrec@1 57.500 (59.952)\n",
            "Total time : 12.398\n",
            "Train Loss: 1.4313, Train Accuracy: 0.5995\n",
            "Test Loss : 1.7824, Test Accuracy : 0.5189 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.187 (0.187)\tData 0.148 (0.148)\tLoss 1.4033 (1.4033)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [17][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.3666 (1.3796)\tPrec@1 56.250 (61.649)\n",
            "Epoch: [17][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.3566 (1.3857)\tPrec@1 62.500 (61.423)\n",
            "Epoch: [17][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.5673 (1.4040)\tPrec@1 55.469 (60.901)\n",
            "Epoch: [17][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 1.2339 (1.4113)\tPrec@1 65.000 (60.478)\n",
            "Total time : 12.466\n",
            "Train Loss: 1.4113, Train Accuracy: 0.6048\n",
            "Test Loss : 1.6032, Test Accuracy : 0.5534 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.197 (0.197)\tData 0.142 (0.142)\tLoss 1.3507 (1.3507)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [18][100/391]\tTime 0.034 (0.035)\tData 0.000 (0.002)\tLoss 1.2782 (1.3556)\tPrec@1 60.156 (61.904)\n",
            "Epoch: [18][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 1.4379 (1.3857)\tPrec@1 60.156 (61.248)\n",
            "Epoch: [18][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.5370 (1.3898)\tPrec@1 49.219 (61.145)\n",
            "Epoch: [18][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.7270 (1.3845)\tPrec@1 56.250 (61.292)\n",
            "Total time : 12.887\n",
            "Train Loss: 1.3845, Train Accuracy: 0.6129\n",
            "Test Loss : 1.5565, Test Accuracy : 0.5638 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.201 (0.201)\tData 0.151 (0.151)\tLoss 1.0993 (1.0993)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [19][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 1.1679 (1.3267)\tPrec@1 71.094 (62.631)\n",
            "Epoch: [19][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.3152 (1.3371)\tPrec@1 61.719 (62.481)\n",
            "Epoch: [19][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.2745 (1.3550)\tPrec@1 63.281 (61.971)\n",
            "Epoch: [19][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.4397 (1.3600)\tPrec@1 61.250 (61.818)\n",
            "Total time : 12.435\n",
            "Train Loss: 1.3600, Train Accuracy: 0.6182\n",
            "Test Loss : 1.4678, Test Accuracy : 0.5905 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.197 (0.197)\tData 0.141 (0.141)\tLoss 1.5842 (1.5842)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [20][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2245 (1.3270)\tPrec@1 67.188 (63.034)\n",
            "Epoch: [20][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.3482 (1.3297)\tPrec@1 60.938 (62.749)\n",
            "Epoch: [20][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 1.4066 (1.3428)\tPrec@1 63.281 (62.417)\n",
            "Epoch: [20][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.3715 (1.3448)\tPrec@1 58.750 (62.388)\n",
            "Total time : 12.395\n",
            "Train Loss: 1.3448, Train Accuracy: 0.6239\n",
            "Test Loss : 1.5594, Test Accuracy : 0.5667 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.197 (0.197)\tData 0.142 (0.142)\tLoss 1.2831 (1.2831)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [21][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.0472 (1.2802)\tPrec@1 71.875 (64.171)\n",
            "Epoch: [21][200/391]\tTime 0.041 (0.033)\tData 0.000 (0.001)\tLoss 1.3560 (1.2955)\tPrec@1 62.500 (63.744)\n",
            "Epoch: [21][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.5271 (1.3117)\tPrec@1 57.812 (63.203)\n",
            "Epoch: [21][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.6001 (1.3232)\tPrec@1 53.750 (62.862)\n",
            "Total time : 12.554\n",
            "Train Loss: 1.3232, Train Accuracy: 0.6286\n",
            "Test Loss : 1.4965, Test Accuracy : 0.5781 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.192 (0.192)\tData 0.137 (0.137)\tLoss 1.0972 (1.0972)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [22][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.0532 (1.2823)\tPrec@1 70.312 (63.521)\n",
            "Epoch: [22][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 1.3020 (1.2943)\tPrec@1 62.500 (63.448)\n",
            "Epoch: [22][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.3599 (1.3033)\tPrec@1 66.406 (63.281)\n",
            "Epoch: [22][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.3283 (1.3102)\tPrec@1 58.750 (63.212)\n",
            "Total time : 12.917\n",
            "Train Loss: 1.3102, Train Accuracy: 0.6321\n",
            "Test Loss : 1.5363, Test Accuracy : 0.5691 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.187 (0.187)\tData 0.148 (0.148)\tLoss 1.1294 (1.1294)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [23][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2606 (1.2540)\tPrec@1 63.281 (64.581)\n",
            "Epoch: [23][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2938 (1.2689)\tPrec@1 67.969 (64.214)\n",
            "Epoch: [23][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0911 (1.2812)\tPrec@1 70.312 (64.073)\n",
            "Epoch: [23][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.4770 (1.2879)\tPrec@1 65.000 (64.008)\n",
            "Total time : 12.334\n",
            "Train Loss: 1.2879, Train Accuracy: 0.6401\n",
            "Test Loss : 1.3506, Test Accuracy : 0.6171 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.188 (0.188)\tData 0.144 (0.144)\tLoss 1.2506 (1.2506)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [24][100/391]\tTime 0.030 (0.036)\tData 0.000 (0.002)\tLoss 1.1896 (1.2285)\tPrec@1 64.844 (65.509)\n",
            "Epoch: [24][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.0755 (1.2478)\tPrec@1 75.000 (65.143)\n",
            "Epoch: [24][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.2366 (1.2594)\tPrec@1 62.500 (64.794)\n",
            "Epoch: [24][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.2383 (1.2736)\tPrec@1 68.750 (64.340)\n",
            "Total time : 12.687\n",
            "Train Loss: 1.2736, Train Accuracy: 0.6434\n",
            "Test Loss : 1.4754, Test Accuracy : 0.5832 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.195 (0.195)\tData 0.139 (0.139)\tLoss 1.1779 (1.1779)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [25][100/391]\tTime 0.036 (0.036)\tData 0.000 (0.002)\tLoss 1.2024 (1.2284)\tPrec@1 64.062 (65.207)\n",
            "Epoch: [25][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.1517 (1.2293)\tPrec@1 71.094 (65.473)\n",
            "Epoch: [25][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.2182 (1.2493)\tPrec@1 62.500 (64.903)\n",
            "Epoch: [25][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.3524 (1.2562)\tPrec@1 56.250 (64.592)\n",
            "Total time : 12.700\n",
            "Train Loss: 1.2562, Train Accuracy: 0.6459\n",
            "Test Loss : 1.5080, Test Accuracy : 0.5886 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.198 (0.198)\tData 0.142 (0.142)\tLoss 1.3943 (1.3943)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [26][100/391]\tTime 0.036 (0.034)\tData 0.000 (0.002)\tLoss 1.1782 (1.2117)\tPrec@1 64.062 (66.252)\n",
            "Epoch: [26][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.1520 (1.2281)\tPrec@1 69.531 (65.726)\n",
            "Epoch: [26][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.3445 (1.2451)\tPrec@1 62.500 (65.158)\n",
            "Epoch: [26][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.4823 (1.2531)\tPrec@1 63.750 (64.928)\n",
            "Total time : 12.519\n",
            "Train Loss: 1.2531, Train Accuracy: 0.6493\n",
            "Test Loss : 1.4836, Test Accuracy : 0.5820 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.191 (0.191)\tData 0.135 (0.135)\tLoss 1.1664 (1.1664)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [27][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 1.1795 (1.1689)\tPrec@1 63.281 (67.149)\n",
            "Epoch: [27][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.3065 (1.2033)\tPrec@1 65.625 (66.018)\n",
            "Epoch: [27][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.4031 (1.2173)\tPrec@1 60.938 (65.711)\n",
            "Epoch: [27][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.2109 (1.2300)\tPrec@1 67.500 (65.470)\n",
            "Total time : 12.599\n",
            "Train Loss: 1.2300, Train Accuracy: 0.6547\n",
            "Test Loss : 1.4146, Test Accuracy : 0.6005 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.181 (0.181)\tData 0.136 (0.136)\tLoss 1.1141 (1.1141)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [28][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.3590 (1.1824)\tPrec@1 60.938 (66.971)\n",
            "Epoch: [28][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.0411 (1.1938)\tPrec@1 70.312 (66.709)\n",
            "Epoch: [28][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.3157 (1.2099)\tPrec@1 64.844 (66.139)\n",
            "Epoch: [28][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.2596 (1.2256)\tPrec@1 67.500 (65.696)\n",
            "Total time : 12.410\n",
            "Train Loss: 1.2256, Train Accuracy: 0.6570\n",
            "Test Loss : 1.5655, Test Accuracy : 0.5663 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.191 (0.191)\tData 0.140 (0.140)\tLoss 1.2420 (1.2420)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [29][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2199 (1.1721)\tPrec@1 65.625 (67.342)\n",
            "Epoch: [29][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.1965 (1.1904)\tPrec@1 67.188 (66.717)\n",
            "Epoch: [29][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.1949 (1.1921)\tPrec@1 67.188 (66.689)\n",
            "Epoch: [29][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.3876 (1.2131)\tPrec@1 62.500 (66.128)\n",
            "Total time : 12.476\n",
            "Train Loss: 1.2131, Train Accuracy: 0.6613\n",
            "Test Loss : 1.6519, Test Accuracy : 0.5482 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.173 (0.173)\tData 0.134 (0.134)\tLoss 0.9389 (0.9389)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [30][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 1.4255 (1.1612)\tPrec@1 53.906 (67.118)\n",
            "Epoch: [30][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 1.2479 (1.1864)\tPrec@1 64.062 (66.608)\n",
            "Epoch: [30][300/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 1.4348 (1.1913)\tPrec@1 56.250 (66.419)\n",
            "Epoch: [30][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 1.0985 (1.2030)\tPrec@1 76.250 (66.262)\n",
            "Total time : 12.311\n",
            "Train Loss: 1.2030, Train Accuracy: 0.6626\n",
            "Test Loss : 1.3943, Test Accuracy : 0.6133 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.184 (0.184)\tData 0.143 (0.143)\tLoss 1.1164 (1.1164)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [31][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 1.0961 (1.1185)\tPrec@1 67.969 (68.549)\n",
            "Epoch: [31][200/391]\tTime 0.034 (0.032)\tData 0.000 (0.001)\tLoss 1.4147 (1.1539)\tPrec@1 56.250 (67.689)\n",
            "Epoch: [31][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 1.2428 (1.1733)\tPrec@1 63.281 (67.164)\n",
            "Epoch: [31][390/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 1.3458 (1.1868)\tPrec@1 57.500 (66.776)\n",
            "Total time : 12.341\n",
            "Train Loss: 1.1868, Train Accuracy: 0.6678\n",
            "Test Loss : 1.3087, Test Accuracy : 0.6310 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.191 (0.191)\tData 0.144 (0.144)\tLoss 1.0894 (1.0894)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [32][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2979 (1.1586)\tPrec@1 64.062 (67.605)\n",
            "Epoch: [32][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.1051 (1.1597)\tPrec@1 71.094 (67.463)\n",
            "Epoch: [32][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2509 (1.1716)\tPrec@1 69.531 (67.094)\n",
            "Epoch: [32][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.1616 (1.1830)\tPrec@1 71.250 (66.830)\n",
            "Total time : 12.338\n",
            "Train Loss: 1.1830, Train Accuracy: 0.6683\n",
            "Test Loss : 1.4486, Test Accuracy : 0.5957 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.194 (0.194)\tData 0.139 (0.139)\tLoss 1.2700 (1.2700)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [33][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2405 (1.1327)\tPrec@1 64.062 (68.085)\n",
            "Epoch: [33][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 1.1186 (1.1440)\tPrec@1 69.531 (67.576)\n",
            "Epoch: [33][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2771 (1.1549)\tPrec@1 64.062 (67.400)\n",
            "Epoch: [33][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.5276 (1.1669)\tPrec@1 61.250 (67.110)\n",
            "Total time : 12.508\n",
            "Train Loss: 1.1669, Train Accuracy: 0.6711\n",
            "Test Loss : 1.5756, Test Accuracy : 0.5655 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.178 (0.178)\tData 0.138 (0.138)\tLoss 1.1259 (1.1259)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [34][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 1.0508 (1.1200)\tPrec@1 71.094 (68.487)\n",
            "Epoch: [34][200/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 1.1949 (1.1406)\tPrec@1 64.844 (67.891)\n",
            "Epoch: [34][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.2839 (1.1519)\tPrec@1 66.406 (67.489)\n",
            "Epoch: [34][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.3007 (1.1622)\tPrec@1 63.750 (67.254)\n",
            "Total time : 12.744\n",
            "Train Loss: 1.1622, Train Accuracy: 0.6725\n",
            "Test Loss : 1.2611, Test Accuracy : 0.6466 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.180 (0.180)\tData 0.135 (0.135)\tLoss 0.8334 (0.8334)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [35][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1719 (1.1026)\tPrec@1 62.500 (69.036)\n",
            "Epoch: [35][200/391]\tTime 0.034 (0.034)\tData 0.000 (0.001)\tLoss 0.9461 (1.1205)\tPrec@1 72.656 (68.808)\n",
            "Epoch: [35][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 1.1690 (1.1395)\tPrec@1 64.062 (68.093)\n",
            "Epoch: [35][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.2530 (1.1546)\tPrec@1 60.000 (67.618)\n",
            "Total time : 13.080\n",
            "Train Loss: 1.1546, Train Accuracy: 0.6762\n",
            "Test Loss : 1.3549, Test Accuracy : 0.6202 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.175 (0.175)\tData 0.135 (0.135)\tLoss 0.8984 (0.8984)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [36][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 1.0369 (1.0991)\tPrec@1 73.438 (69.485)\n",
            "Epoch: [36][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.2551 (1.1196)\tPrec@1 64.062 (68.917)\n",
            "Epoch: [36][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 1.1676 (1.1317)\tPrec@1 69.531 (68.553)\n",
            "Epoch: [36][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.3422 (1.1471)\tPrec@1 63.750 (68.004)\n",
            "Total time : 12.341\n",
            "Train Loss: 1.1471, Train Accuracy: 0.6800\n",
            "Test Loss : 1.3783, Test Accuracy : 0.6204 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.183 (0.183)\tData 0.142 (0.142)\tLoss 1.1058 (1.1058)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [37][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9294 (1.0884)\tPrec@1 75.781 (70.042)\n",
            "Epoch: [37][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0946 (1.1035)\tPrec@1 72.656 (69.251)\n",
            "Epoch: [37][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2620 (1.1250)\tPrec@1 66.406 (68.545)\n",
            "Epoch: [37][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 1.2047 (1.1391)\tPrec@1 67.500 (68.148)\n",
            "Total time : 12.294\n",
            "Train Loss: 1.1391, Train Accuracy: 0.6815\n",
            "Test Loss : 1.3524, Test Accuracy : 0.6197 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.206 (0.206)\tData 0.148 (0.148)\tLoss 1.0384 (1.0384)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [38][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.1074 (1.0910)\tPrec@1 66.406 (69.446)\n",
            "Epoch: [38][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2098 (1.1017)\tPrec@1 64.844 (69.154)\n",
            "Epoch: [38][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0631 (1.1165)\tPrec@1 71.094 (68.828)\n",
            "Epoch: [38][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 1.1599 (1.1273)\tPrec@1 65.000 (68.346)\n",
            "Total time : 12.250\n",
            "Train Loss: 1.1273, Train Accuracy: 0.6835\n",
            "Test Loss : 1.4134, Test Accuracy : 0.6087 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.182 (0.182)\tData 0.142 (0.142)\tLoss 1.0006 (1.0006)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [39][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.2281 (1.0548)\tPrec@1 65.625 (70.127)\n",
            "Epoch: [39][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.1264 (1.0868)\tPrec@1 68.750 (69.411)\n",
            "Epoch: [39][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 1.1720 (1.0988)\tPrec@1 67.188 (69.077)\n",
            "Epoch: [39][390/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.2502 (1.1111)\tPrec@1 66.250 (68.744)\n",
            "Total time : 12.389\n",
            "Train Loss: 1.1111, Train Accuracy: 0.6874\n",
            "Test Loss : 1.2692, Test Accuracy : 0.6364 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.207 (0.207)\tData 0.146 (0.146)\tLoss 1.1091 (1.1091)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [40][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 1.0655 (1.0473)\tPrec@1 65.625 (70.289)\n",
            "Epoch: [40][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0850 (1.0744)\tPrec@1 67.969 (69.527)\n",
            "Epoch: [40][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2034 (1.0959)\tPrec@1 65.625 (69.041)\n",
            "Epoch: [40][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.1569 (1.1110)\tPrec@1 66.250 (68.746)\n",
            "Total time : 12.622\n",
            "Train Loss: 1.1110, Train Accuracy: 0.6875\n",
            "Test Loss : 1.3983, Test Accuracy : 0.6028 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.196 (0.196)\tData 0.151 (0.151)\tLoss 0.9399 (0.9399)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [41][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.0346 (1.0611)\tPrec@1 64.844 (70.026)\n",
            "Epoch: [41][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0504 (1.0784)\tPrec@1 72.656 (69.465)\n",
            "Epoch: [41][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.1430 (1.0947)\tPrec@1 69.531 (69.145)\n",
            "Epoch: [41][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.1429 (1.1024)\tPrec@1 65.000 (68.942)\n",
            "Total time : 12.446\n",
            "Train Loss: 1.1024, Train Accuracy: 0.6894\n",
            "Test Loss : 1.2666, Test Accuracy : 0.6444 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.183 (0.183)\tData 0.144 (0.144)\tLoss 1.0635 (1.0635)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [42][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.8919 (1.0450)\tPrec@1 80.469 (70.684)\n",
            "Epoch: [42][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.1511 (1.0562)\tPrec@1 67.969 (70.542)\n",
            "Epoch: [42][300/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 1.1081 (1.0820)\tPrec@1 67.188 (69.669)\n",
            "Epoch: [42][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0669 (1.0949)\tPrec@1 73.750 (69.268)\n",
            "Total time : 12.351\n",
            "Train Loss: 1.0949, Train Accuracy: 0.6927\n",
            "Test Loss : 1.3005, Test Accuracy : 0.6329 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.203 (0.203)\tData 0.151 (0.151)\tLoss 0.9424 (0.9424)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [43][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.0254 (1.0257)\tPrec@1 71.094 (70.653)\n",
            "Epoch: [43][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.0716 (1.0431)\tPrec@1 69.531 (70.550)\n",
            "Epoch: [43][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.1363 (1.0602)\tPrec@1 66.406 (70.089)\n",
            "Epoch: [43][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.3168 (1.0743)\tPrec@1 67.500 (69.674)\n",
            "Total time : 12.840\n",
            "Train Loss: 1.0743, Train Accuracy: 0.6967\n",
            "Test Loss : 1.3278, Test Accuracy : 0.6242 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.182 (0.182)\tData 0.142 (0.142)\tLoss 1.0309 (1.0309)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [44][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.1514 (1.0538)\tPrec@1 67.969 (70.545)\n",
            "Epoch: [44][200/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 1.1729 (1.0696)\tPrec@1 67.969 (69.943)\n",
            "Epoch: [44][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9048 (1.0764)\tPrec@1 75.781 (69.752)\n",
            "Epoch: [44][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.2321 (1.0835)\tPrec@1 61.250 (69.610)\n",
            "Total time : 12.857\n",
            "Train Loss: 1.0835, Train Accuracy: 0.6961\n",
            "Test Loss : 1.3272, Test Accuracy : 0.6232 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.193 (0.193)\tData 0.139 (0.139)\tLoss 0.9140 (0.9140)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [45][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1323 (1.0301)\tPrec@1 63.281 (71.117)\n",
            "Epoch: [45][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.3282 (1.0392)\tPrec@1 62.500 (70.655)\n",
            "Epoch: [45][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.3530 (1.0535)\tPrec@1 63.281 (70.437)\n",
            "Epoch: [45][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0302 (1.0682)\tPrec@1 71.250 (69.980)\n",
            "Total time : 12.323\n",
            "Train Loss: 1.0682, Train Accuracy: 0.6998\n",
            "Test Loss : 1.2662, Test Accuracy : 0.6427 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 1.2412 (1.2412)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [46][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 1.2047 (1.0452)\tPrec@1 64.844 (70.367)\n",
            "Epoch: [46][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0508 (1.0549)\tPrec@1 74.219 (70.375)\n",
            "Epoch: [46][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2440 (1.0526)\tPrec@1 64.844 (70.398)\n",
            "Epoch: [46][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.1679 (1.0592)\tPrec@1 66.250 (70.280)\n",
            "Total time : 12.329\n",
            "Train Loss: 1.0592, Train Accuracy: 0.7028\n",
            "Test Loss : 1.2928, Test Accuracy : 0.6352 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.203 (0.203)\tData 0.141 (0.141)\tLoss 1.0229 (1.0229)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [47][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 0.8897 (1.0181)\tPrec@1 75.000 (71.496)\n",
            "Epoch: [47][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9682 (1.0398)\tPrec@1 71.094 (70.701)\n",
            "Epoch: [47][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.8813 (1.0566)\tPrec@1 75.781 (70.320)\n",
            "Epoch: [47][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.0275 (1.0588)\tPrec@1 70.000 (70.298)\n",
            "Total time : 12.391\n",
            "Train Loss: 1.0588, Train Accuracy: 0.7030\n",
            "Test Loss : 1.2809, Test Accuracy : 0.6360 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.189 (0.189)\tData 0.144 (0.144)\tLoss 1.1424 (1.1424)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [48][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.1021 (0.9980)\tPrec@1 67.188 (71.960)\n",
            "Epoch: [48][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.1411 (1.0132)\tPrec@1 62.500 (71.681)\n",
            "Epoch: [48][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.9915 (1.0373)\tPrec@1 71.875 (70.969)\n",
            "Epoch: [48][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0357 (1.0479)\tPrec@1 67.500 (70.716)\n",
            "Total time : 12.343\n",
            "Train Loss: 1.0479, Train Accuracy: 0.7072\n",
            "Test Loss : 1.3011, Test Accuracy : 0.6303 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.189 (0.189)\tData 0.144 (0.144)\tLoss 1.0179 (1.0179)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [49][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9670 (0.9979)\tPrec@1 68.750 (72.192)\n",
            "Epoch: [49][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9594 (1.0228)\tPrec@1 73.438 (71.444)\n",
            "Epoch: [49][300/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 1.1034 (1.0354)\tPrec@1 71.875 (71.008)\n",
            "Epoch: [49][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.2704 (1.0410)\tPrec@1 60.000 (70.790)\n",
            "Total time : 12.641\n",
            "Train Loss: 1.0410, Train Accuracy: 0.7079\n",
            "Test Loss : 1.3855, Test Accuracy : 0.6221 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.178 (0.178)\tData 0.138 (0.138)\tLoss 1.2430 (1.2430)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [50][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.0184 (1.0202)\tPrec@1 74.219 (71.434)\n",
            "Epoch: [50][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9466 (1.0219)\tPrec@1 71.875 (71.288)\n",
            "Epoch: [50][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 1.0208 (1.0322)\tPrec@1 78.125 (71.024)\n",
            "Epoch: [50][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0593 (1.0391)\tPrec@1 67.500 (70.834)\n",
            "Total time : 12.602\n",
            "Train Loss: 1.0391, Train Accuracy: 0.7083\n",
            "Test Loss : 1.2990, Test Accuracy : 0.6346 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.187 (0.187)\tData 0.136 (0.136)\tLoss 0.8719 (0.8719)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [51][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.8777 (0.9733)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [51][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.1149 (0.9919)\tPrec@1 67.188 (71.910)\n",
            "Epoch: [51][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.4206 (1.0168)\tPrec@1 58.594 (71.268)\n",
            "Epoch: [51][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.8231 (1.0254)\tPrec@1 72.500 (71.116)\n",
            "Total time : 12.695\n",
            "Train Loss: 1.0254, Train Accuracy: 0.7112\n",
            "Test Loss : 1.2091, Test Accuracy : 0.6609 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 1.0829 (1.0829)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [52][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 1.0309 (0.9634)\tPrec@1 72.656 (73.113)\n",
            "Epoch: [52][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.1018 (0.9789)\tPrec@1 68.750 (72.501)\n",
            "Epoch: [52][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 1.1328 (1.0062)\tPrec@1 71.875 (71.667)\n",
            "Epoch: [52][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.9417 (1.0117)\tPrec@1 76.250 (71.598)\n",
            "Total time : 12.248\n",
            "Train Loss: 1.0117, Train Accuracy: 0.7160\n",
            "Test Loss : 1.2425, Test Accuracy : 0.6455 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 0.8862 (0.8862)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [53][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 0.9945 (0.9691)\tPrec@1 72.656 (73.430)\n",
            "Epoch: [53][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.2004 (0.9908)\tPrec@1 62.500 (72.547)\n",
            "Epoch: [53][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 0.9620 (1.0000)\tPrec@1 74.219 (71.940)\n",
            "Epoch: [53][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.9426 (1.0114)\tPrec@1 67.500 (71.562)\n",
            "Total time : 12.166\n",
            "Train Loss: 1.0114, Train Accuracy: 0.7156\n",
            "Test Loss : 1.2037, Test Accuracy : 0.6560 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.180 (0.180)\tData 0.139 (0.139)\tLoss 0.9850 (0.9850)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [54][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.1906 (0.9673)\tPrec@1 66.406 (73.120)\n",
            "Epoch: [54][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8593 (0.9791)\tPrec@1 78.906 (72.761)\n",
            "Epoch: [54][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0626 (0.9928)\tPrec@1 71.094 (72.173)\n",
            "Epoch: [54][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.9419 (1.0034)\tPrec@1 72.500 (71.836)\n",
            "Total time : 12.359\n",
            "Train Loss: 1.0034, Train Accuracy: 0.7184\n",
            "Test Loss : 1.2922, Test Accuracy : 0.6378 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.176 (0.176)\tData 0.137 (0.137)\tLoss 1.0259 (1.0259)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [55][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9188 (0.9641)\tPrec@1 72.656 (72.904)\n",
            "Epoch: [55][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8965 (0.9859)\tPrec@1 75.000 (72.306)\n",
            "Epoch: [55][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.0198 (0.9933)\tPrec@1 68.750 (71.893)\n",
            "Epoch: [55][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.9222 (1.0006)\tPrec@1 73.750 (71.822)\n",
            "Total time : 12.279\n",
            "Train Loss: 1.0006, Train Accuracy: 0.7182\n",
            "Test Loss : 1.2651, Test Accuracy : 0.6411 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.177 (0.177)\tData 0.138 (0.138)\tLoss 0.8604 (0.8604)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [56][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 0.9677 (0.9379)\tPrec@1 72.656 (73.832)\n",
            "Epoch: [56][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9594 (0.9679)\tPrec@1 78.906 (73.018)\n",
            "Epoch: [56][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0599 (0.9811)\tPrec@1 67.188 (72.591)\n",
            "Epoch: [56][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0279 (0.9958)\tPrec@1 66.250 (72.120)\n",
            "Total time : 12.418\n",
            "Train Loss: 0.9958, Train Accuracy: 0.7212\n",
            "Test Loss : 1.2462, Test Accuracy : 0.6492 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.183 (0.183)\tData 0.139 (0.139)\tLoss 0.8602 (0.8602)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [57][100/391]\tTime 0.037 (0.033)\tData 0.000 (0.002)\tLoss 0.9600 (0.9210)\tPrec@1 74.219 (74.443)\n",
            "Epoch: [57][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.1040 (0.9542)\tPrec@1 67.969 (73.301)\n",
            "Epoch: [57][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9693 (0.9701)\tPrec@1 73.438 (72.866)\n",
            "Epoch: [57][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.9147 (0.9831)\tPrec@1 76.250 (72.506)\n",
            "Total time : 12.945\n",
            "Train Loss: 0.9831, Train Accuracy: 0.7251\n",
            "Test Loss : 1.1544, Test Accuracy : 0.6688 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.194 (0.194)\tData 0.138 (0.138)\tLoss 0.7879 (0.7879)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [58][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9459 (0.9239)\tPrec@1 68.750 (74.196)\n",
            "Epoch: [58][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0354 (0.9400)\tPrec@1 71.875 (73.612)\n",
            "Epoch: [58][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0954 (0.9579)\tPrec@1 70.312 (73.056)\n",
            "Epoch: [58][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.1583 (0.9684)\tPrec@1 66.250 (72.790)\n",
            "Total time : 12.564\n",
            "Train Loss: 0.9684, Train Accuracy: 0.7279\n",
            "Test Loss : 1.2139, Test Accuracy : 0.6543 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.188 (0.188)\tData 0.144 (0.144)\tLoss 0.9469 (0.9469)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [59][100/391]\tTime 0.035 (0.035)\tData 0.000 (0.002)\tLoss 0.9073 (0.9402)\tPrec@1 71.875 (73.391)\n",
            "Epoch: [59][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.0259 (0.9518)\tPrec@1 71.094 (73.173)\n",
            "Epoch: [59][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.0928 (0.9634)\tPrec@1 69.531 (72.957)\n",
            "Epoch: [59][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 1.0866 (0.9748)\tPrec@1 71.250 (72.582)\n",
            "Total time : 12.708\n",
            "Train Loss: 0.9748, Train Accuracy: 0.7258\n",
            "Test Loss : 1.1959, Test Accuracy : 0.6588 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.188 (0.188)\tData 0.147 (0.147)\tLoss 0.8766 (0.8766)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [60][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9572 (0.9377)\tPrec@1 75.000 (73.298)\n",
            "Epoch: [60][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 1.0103 (0.9439)\tPrec@1 73.438 (73.119)\n",
            "Epoch: [60][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 1.1266 (0.9581)\tPrec@1 66.406 (72.957)\n",
            "Epoch: [60][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0271 (0.9650)\tPrec@1 70.000 (72.810)\n",
            "Total time : 12.533\n",
            "Train Loss: 0.9650, Train Accuracy: 0.7281\n",
            "Test Loss : 1.2828, Test Accuracy : 0.6396 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.205 (0.205)\tData 0.148 (0.148)\tLoss 0.8441 (0.8441)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [61][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.0589 (0.9118)\tPrec@1 72.656 (74.644)\n",
            "Epoch: [61][200/391]\tTime 0.037 (0.032)\tData 0.000 (0.001)\tLoss 0.9941 (0.9349)\tPrec@1 71.875 (73.647)\n",
            "Epoch: [61][300/391]\tTime 0.037 (0.032)\tData 0.000 (0.001)\tLoss 1.1222 (0.9436)\tPrec@1 66.406 (73.386)\n",
            "Epoch: [61][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.9308 (0.9566)\tPrec@1 76.250 (73.038)\n",
            "Total time : 12.763\n",
            "Train Loss: 0.9566, Train Accuracy: 0.7304\n",
            "Test Loss : 1.2284, Test Accuracy : 0.6544 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.193 (0.193)\tData 0.138 (0.138)\tLoss 0.7819 (0.7819)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [62][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7400 (0.9156)\tPrec@1 76.562 (74.428)\n",
            "Epoch: [62][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.1043 (0.9278)\tPrec@1 64.062 (74.044)\n",
            "Epoch: [62][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9819 (0.9412)\tPrec@1 73.438 (73.580)\n",
            "Epoch: [62][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7285 (0.9489)\tPrec@1 81.250 (73.372)\n",
            "Total time : 12.485\n",
            "Train Loss: 0.9489, Train Accuracy: 0.7337\n",
            "Test Loss : 1.2177, Test Accuracy : 0.6566 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 0.7681 (0.7681)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [63][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 1.0470 (0.9106)\tPrec@1 71.875 (74.776)\n",
            "Epoch: [63][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0763 (0.9208)\tPrec@1 70.312 (74.394)\n",
            "Epoch: [63][300/391]\tTime 0.034 (0.032)\tData 0.000 (0.001)\tLoss 1.1070 (0.9367)\tPrec@1 67.969 (73.874)\n",
            "Epoch: [63][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.1447 (0.9447)\tPrec@1 63.750 (73.650)\n",
            "Total time : 12.339\n",
            "Train Loss: 0.9447, Train Accuracy: 0.7365\n",
            "Test Loss : 1.1662, Test Accuracy : 0.6707 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.191 (0.191)\tData 0.145 (0.145)\tLoss 0.7743 (0.7743)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [64][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 1.0394 (0.8855)\tPrec@1 67.969 (75.541)\n",
            "Epoch: [64][200/391]\tTime 0.038 (0.033)\tData 0.000 (0.001)\tLoss 0.8959 (0.9117)\tPrec@1 73.438 (74.740)\n",
            "Epoch: [64][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8965 (0.9259)\tPrec@1 76.562 (74.265)\n",
            "Epoch: [64][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.0692 (0.9368)\tPrec@1 66.250 (73.848)\n",
            "Total time : 12.605\n",
            "Train Loss: 0.9368, Train Accuracy: 0.7385\n",
            "Test Loss : 1.2677, Test Accuracy : 0.6431 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.194 (0.194)\tData 0.138 (0.138)\tLoss 0.8383 (0.8383)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [65][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 1.0401 (0.8782)\tPrec@1 72.656 (75.681)\n",
            "Epoch: [65][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.0152 (0.8954)\tPrec@1 75.000 (75.008)\n",
            "Epoch: [65][300/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 0.8049 (0.9100)\tPrec@1 80.469 (74.647)\n",
            "Epoch: [65][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.9345 (0.9260)\tPrec@1 75.000 (74.156)\n",
            "Total time : 12.465\n",
            "Train Loss: 0.9260, Train Accuracy: 0.7416\n",
            "Test Loss : 1.1851, Test Accuracy : 0.6588 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.194 (0.194)\tData 0.148 (0.148)\tLoss 0.8117 (0.8117)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [66][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9828 (0.8891)\tPrec@1 71.094 (74.830)\n",
            "Epoch: [66][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7274 (0.9003)\tPrec@1 79.688 (74.736)\n",
            "Epoch: [66][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8288 (0.9140)\tPrec@1 78.906 (74.255)\n",
            "Epoch: [66][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 1.0173 (0.9205)\tPrec@1 68.750 (74.162)\n",
            "Total time : 12.454\n",
            "Train Loss: 0.9205, Train Accuracy: 0.7416\n",
            "Test Loss : 1.3429, Test Accuracy : 0.6337 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.174 (0.174)\tData 0.135 (0.135)\tLoss 0.7429 (0.7429)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [67][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7162 (0.8730)\tPrec@1 79.688 (75.704)\n",
            "Epoch: [67][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.9146 (0.8943)\tPrec@1 73.438 (74.942)\n",
            "Epoch: [67][300/391]\tTime 0.030 (0.031)\tData 0.000 (0.001)\tLoss 0.9454 (0.9071)\tPrec@1 71.875 (74.362)\n",
            "Epoch: [67][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.8279 (0.9153)\tPrec@1 80.000 (74.126)\n",
            "Total time : 12.190\n",
            "Train Loss: 0.9153, Train Accuracy: 0.7413\n",
            "Test Loss : 1.1928, Test Accuracy : 0.6624 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.187 (0.187)\tData 0.146 (0.146)\tLoss 0.9441 (0.9441)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [68][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7894 (0.8767)\tPrec@1 78.906 (75.642)\n",
            "Epoch: [68][200/391]\tTime 0.039 (0.034)\tData 0.000 (0.001)\tLoss 0.8469 (0.8900)\tPrec@1 75.781 (75.210)\n",
            "Epoch: [68][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.0562 (0.8977)\tPrec@1 71.094 (75.003)\n",
            "Epoch: [68][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.7831 (0.9064)\tPrec@1 80.000 (74.710)\n",
            "Total time : 12.759\n",
            "Train Loss: 0.9064, Train Accuracy: 0.7471\n",
            "Test Loss : 1.2992, Test Accuracy : 0.6372 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.177 (0.177)\tData 0.138 (0.138)\tLoss 0.7498 (0.7498)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [69][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.0115 (0.8492)\tPrec@1 75.000 (76.207)\n",
            "Epoch: [69][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8804 (0.8656)\tPrec@1 78.906 (75.665)\n",
            "Epoch: [69][300/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 0.9286 (0.8845)\tPrec@1 75.000 (75.099)\n",
            "Epoch: [69][390/391]\tTime 0.029 (0.031)\tData 0.000 (0.001)\tLoss 0.8794 (0.8957)\tPrec@1 81.250 (74.814)\n",
            "Total time : 12.292\n",
            "Train Loss: 0.8957, Train Accuracy: 0.7481\n",
            "Test Loss : 1.1278, Test Accuracy : 0.6794 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.176 (0.176)\tData 0.135 (0.135)\tLoss 0.9176 (0.9176)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [70][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.9404 (0.8534)\tPrec@1 73.438 (76.300)\n",
            "Epoch: [70][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.0005 (0.8640)\tPrec@1 73.438 (75.602)\n",
            "Epoch: [70][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 1.0530 (0.8773)\tPrec@1 71.094 (75.345)\n",
            "Epoch: [70][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 1.2450 (0.8901)\tPrec@1 66.250 (74.964)\n",
            "Total time : 12.313\n",
            "Train Loss: 0.8901, Train Accuracy: 0.7496\n",
            "Test Loss : 1.1977, Test Accuracy : 0.6607 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 0.8562 (0.8562)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [71][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9653 (0.8548)\tPrec@1 67.969 (76.300)\n",
            "Epoch: [71][200/391]\tTime 0.037 (0.032)\tData 0.000 (0.001)\tLoss 0.9325 (0.8650)\tPrec@1 76.562 (75.847)\n",
            "Epoch: [71][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.8614 (0.8802)\tPrec@1 77.344 (75.273)\n",
            "Epoch: [71][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7210 (0.8851)\tPrec@1 85.000 (75.112)\n",
            "Total time : 12.687\n",
            "Train Loss: 0.8851, Train Accuracy: 0.7511\n",
            "Test Loss : 1.1698, Test Accuracy : 0.6692 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.200 (0.200)\tData 0.148 (0.148)\tLoss 0.8959 (0.8959)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [72][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.8787 (0.8350)\tPrec@1 75.781 (76.539)\n",
            "Epoch: [72][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.7565 (0.8498)\tPrec@1 75.781 (76.224)\n",
            "Epoch: [72][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.8739 (0.8628)\tPrec@1 74.219 (75.779)\n",
            "Epoch: [72][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.9819 (0.8705)\tPrec@1 67.500 (75.586)\n",
            "Total time : 12.731\n",
            "Train Loss: 0.8705, Train Accuracy: 0.7559\n",
            "Test Loss : 1.1857, Test Accuracy : 0.6625 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.177 (0.177)\tData 0.137 (0.137)\tLoss 0.7221 (0.7221)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [73][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.9258 (0.8104)\tPrec@1 72.656 (77.243)\n",
            "Epoch: [73][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.7935 (0.8271)\tPrec@1 75.781 (76.609)\n",
            "Epoch: [73][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9183 (0.8500)\tPrec@1 73.438 (76.095)\n",
            "Epoch: [73][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.6367 (0.8686)\tPrec@1 82.500 (75.582)\n",
            "Total time : 12.296\n",
            "Train Loss: 0.8686, Train Accuracy: 0.7558\n",
            "Test Loss : 1.1754, Test Accuracy : 0.6672 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 0.7411 (0.7411)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [74][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.7204 (0.8252)\tPrec@1 79.688 (77.127)\n",
            "Epoch: [74][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9664 (0.8391)\tPrec@1 70.312 (76.586)\n",
            "Epoch: [74][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.8090 (0.8524)\tPrec@1 78.125 (76.235)\n",
            "Epoch: [74][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.9154 (0.8585)\tPrec@1 73.750 (76.060)\n",
            "Total time : 12.383\n",
            "Train Loss: 0.8585, Train Accuracy: 0.7606\n",
            "Test Loss : 1.1047, Test Accuracy : 0.6856 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.199 (0.199)\tData 0.143 (0.143)\tLoss 0.8356 (0.8356)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [75][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.9695 (0.8079)\tPrec@1 74.219 (77.638)\n",
            "Epoch: [75][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8727 (0.8280)\tPrec@1 76.562 (77.060)\n",
            "Epoch: [75][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7732 (0.8442)\tPrec@1 79.688 (76.550)\n",
            "Epoch: [75][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.4898 (0.8540)\tPrec@1 87.500 (76.260)\n",
            "Total time : 12.427\n",
            "Train Loss: 0.8540, Train Accuracy: 0.7626\n",
            "Test Loss : 1.1450, Test Accuracy : 0.6759 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.182 (0.182)\tData 0.140 (0.140)\tLoss 0.9441 (0.9441)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [76][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7809 (0.8010)\tPrec@1 76.562 (77.622)\n",
            "Epoch: [76][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8690 (0.8190)\tPrec@1 73.438 (77.041)\n",
            "Epoch: [76][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8164 (0.8265)\tPrec@1 78.906 (76.757)\n",
            "Epoch: [76][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0666 (0.8435)\tPrec@1 68.750 (76.364)\n",
            "Total time : 12.361\n",
            "Train Loss: 0.8435, Train Accuracy: 0.7636\n",
            "Test Loss : 1.1391, Test Accuracy : 0.6781 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.186 (0.186)\tData 0.143 (0.143)\tLoss 0.7809 (0.7809)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [77][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7894 (0.7883)\tPrec@1 79.688 (78.643)\n",
            "Epoch: [77][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7951 (0.8047)\tPrec@1 76.562 (77.779)\n",
            "Epoch: [77][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.9488 (0.8239)\tPrec@1 73.438 (77.115)\n",
            "Epoch: [77][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.9744 (0.8369)\tPrec@1 73.750 (76.706)\n",
            "Total time : 12.454\n",
            "Train Loss: 0.8369, Train Accuracy: 0.7671\n",
            "Test Loss : 1.1104, Test Accuracy : 0.6799 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.176 (0.176)\tData 0.137 (0.137)\tLoss 0.7472 (0.7472)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [78][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.7075 (0.7900)\tPrec@1 85.156 (78.048)\n",
            "Epoch: [78][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8609 (0.8040)\tPrec@1 78.125 (77.713)\n",
            "Epoch: [78][300/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.8190 (0.8168)\tPrec@1 77.344 (77.245)\n",
            "Epoch: [78][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.9874 (0.8255)\tPrec@1 75.000 (76.952)\n",
            "Total time : 12.682\n",
            "Train Loss: 0.8255, Train Accuracy: 0.7695\n",
            "Test Loss : 1.1122, Test Accuracy : 0.6825 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.207 (0.207)\tData 0.146 (0.146)\tLoss 0.6823 (0.6823)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [79][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7181 (0.7636)\tPrec@1 79.688 (78.860)\n",
            "Epoch: [79][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.7485 (0.7797)\tPrec@1 83.594 (78.331)\n",
            "Epoch: [79][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.8134 (0.8031)\tPrec@1 78.906 (77.528)\n",
            "Epoch: [79][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7512 (0.8181)\tPrec@1 80.000 (77.036)\n",
            "Total time : 12.533\n",
            "Train Loss: 0.8181, Train Accuracy: 0.7704\n",
            "Test Loss : 1.0761, Test Accuracy : 0.6911 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.182 (0.182)\tData 0.143 (0.143)\tLoss 0.6799 (0.6799)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [80][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.8542 (0.7845)\tPrec@1 75.000 (78.295)\n",
            "Epoch: [80][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9121 (0.7960)\tPrec@1 71.094 (77.900)\n",
            "Epoch: [80][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 0.8166 (0.8010)\tPrec@1 78.906 (77.577)\n",
            "Epoch: [80][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.9834 (0.8088)\tPrec@1 72.500 (77.392)\n",
            "Total time : 12.348\n",
            "Train Loss: 0.8088, Train Accuracy: 0.7739\n",
            "Test Loss : 1.1054, Test Accuracy : 0.6917 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 0.8086 (0.8086)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [81][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.6715 (0.7675)\tPrec@1 82.031 (79.092)\n",
            "Epoch: [81][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.7956 (0.7714)\tPrec@1 78.125 (78.634)\n",
            "Epoch: [81][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8136 (0.7859)\tPrec@1 75.781 (78.094)\n",
            "Epoch: [81][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.8345 (0.8004)\tPrec@1 70.000 (77.612)\n",
            "Total time : 12.353\n",
            "Train Loss: 0.8004, Train Accuracy: 0.7761\n",
            "Test Loss : 1.1534, Test Accuracy : 0.6731 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.196 (0.196)\tData 0.143 (0.143)\tLoss 0.6488 (0.6488)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [82][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.9188 (0.7737)\tPrec@1 77.344 (78.512)\n",
            "Epoch: [82][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.9705 (0.7820)\tPrec@1 72.656 (78.106)\n",
            "Epoch: [82][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.9182 (0.7932)\tPrec@1 74.219 (77.762)\n",
            "Epoch: [82][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.6587 (0.7993)\tPrec@1 78.750 (77.644)\n",
            "Total time : 12.303\n",
            "Train Loss: 0.7993, Train Accuracy: 0.7764\n",
            "Test Loss : 1.1079, Test Accuracy : 0.6866 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.201 (0.201)\tData 0.147 (0.147)\tLoss 0.6427 (0.6427)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [83][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.7275 (0.7367)\tPrec@1 84.375 (79.688)\n",
            "Epoch: [83][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8081 (0.7670)\tPrec@1 75.781 (78.735)\n",
            "Epoch: [83][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9445 (0.7774)\tPrec@1 75.781 (78.395)\n",
            "Epoch: [83][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.9198 (0.7936)\tPrec@1 76.250 (77.874)\n",
            "Total time : 12.254\n",
            "Train Loss: 0.7936, Train Accuracy: 0.7787\n",
            "Test Loss : 1.0999, Test Accuracy : 0.6843 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.182 (0.182)\tData 0.143 (0.143)\tLoss 0.8182 (0.8182)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [84][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7695 (0.7484)\tPrec@1 78.906 (79.316)\n",
            "Epoch: [84][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.8017 (0.7563)\tPrec@1 76.562 (79.272)\n",
            "Epoch: [84][300/391]\tTime 0.042 (0.032)\tData 0.000 (0.001)\tLoss 0.5867 (0.7709)\tPrec@1 84.375 (78.878)\n",
            "Epoch: [84][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.8010 (0.7812)\tPrec@1 75.000 (78.490)\n",
            "Total time : 12.284\n",
            "Train Loss: 0.7812, Train Accuracy: 0.7849\n",
            "Test Loss : 1.1597, Test Accuracy : 0.6724 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.192 (0.192)\tData 0.147 (0.147)\tLoss 0.6081 (0.6081)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [85][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.6341 (0.7410)\tPrec@1 82.812 (79.517)\n",
            "Epoch: [85][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8147 (0.7563)\tPrec@1 75.000 (79.520)\n",
            "Epoch: [85][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8718 (0.7647)\tPrec@1 75.781 (78.992)\n",
            "Epoch: [85][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.8743 (0.7714)\tPrec@1 77.500 (78.728)\n",
            "Total time : 12.543\n",
            "Train Loss: 0.7714, Train Accuracy: 0.7873\n",
            "Test Loss : 1.1046, Test Accuracy : 0.6876 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.205 (0.205)\tData 0.148 (0.148)\tLoss 0.7050 (0.7050)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [86][100/391]\tTime 0.036 (0.036)\tData 0.000 (0.002)\tLoss 0.7780 (0.7107)\tPrec@1 77.344 (80.670)\n",
            "Epoch: [86][200/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 0.6654 (0.7274)\tPrec@1 83.594 (80.228)\n",
            "Epoch: [86][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8078 (0.7432)\tPrec@1 78.125 (79.604)\n",
            "Epoch: [86][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.9826 (0.7608)\tPrec@1 73.750 (79.128)\n",
            "Total time : 12.828\n",
            "Train Loss: 0.7608, Train Accuracy: 0.7913\n",
            "Test Loss : 1.0695, Test Accuracy : 0.6935 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.192 (0.192)\tData 0.147 (0.147)\tLoss 0.6994 (0.6994)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [87][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.5973 (0.7194)\tPrec@1 82.031 (80.322)\n",
            "Epoch: [87][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8740 (0.7327)\tPrec@1 75.781 (79.897)\n",
            "Epoch: [87][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8789 (0.7422)\tPrec@1 76.562 (79.467)\n",
            "Epoch: [87][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.7523 (0.7569)\tPrec@1 82.500 (79.072)\n",
            "Total time : 12.472\n",
            "Train Loss: 0.7569, Train Accuracy: 0.7907\n",
            "Test Loss : 1.1001, Test Accuracy : 0.6938 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.182 (0.182)\tData 0.137 (0.137)\tLoss 0.7069 (0.7069)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [88][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.6729 (0.6979)\tPrec@1 82.031 (81.258)\n",
            "Epoch: [88][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9221 (0.7090)\tPrec@1 77.344 (80.655)\n",
            "Epoch: [88][300/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 0.8117 (0.7306)\tPrec@1 77.344 (79.960)\n",
            "Epoch: [88][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7371 (0.7477)\tPrec@1 78.750 (79.522)\n",
            "Total time : 12.431\n",
            "Train Loss: 0.7477, Train Accuracy: 0.7952\n",
            "Test Loss : 1.0349, Test Accuracy : 0.7037 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.196 (0.196)\tData 0.145 (0.145)\tLoss 0.6249 (0.6249)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [89][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7289 (0.6959)\tPrec@1 78.125 (80.832)\n",
            "Epoch: [89][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9597 (0.7094)\tPrec@1 73.438 (80.302)\n",
            "Epoch: [89][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 0.6173 (0.7234)\tPrec@1 82.812 (79.906)\n",
            "Epoch: [89][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.8831 (0.7360)\tPrec@1 76.250 (79.568)\n",
            "Total time : 12.227\n",
            "Train Loss: 0.7360, Train Accuracy: 0.7957\n",
            "Test Loss : 1.0291, Test Accuracy : 0.7056 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.182 (0.182)\tData 0.138 (0.138)\tLoss 0.5497 (0.5497)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [90][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 0.7221 (0.7015)\tPrec@1 79.688 (80.894)\n",
            "Epoch: [90][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.7477 (0.7080)\tPrec@1 75.781 (80.601)\n",
            "Epoch: [90][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9878 (0.7194)\tPrec@1 74.219 (80.204)\n",
            "Epoch: [90][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7958 (0.7303)\tPrec@1 76.250 (79.902)\n",
            "Total time : 12.568\n",
            "Train Loss: 0.7303, Train Accuracy: 0.7990\n",
            "Test Loss : 1.0657, Test Accuracy : 0.6951 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.185 (0.185)\tData 0.144 (0.144)\tLoss 0.5719 (0.5719)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [91][100/391]\tTime 0.036 (0.034)\tData 0.000 (0.002)\tLoss 0.6447 (0.6791)\tPrec@1 84.375 (81.420)\n",
            "Epoch: [91][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.7361 (0.6880)\tPrec@1 81.250 (81.067)\n",
            "Epoch: [91][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.8764 (0.7095)\tPrec@1 69.531 (80.396)\n",
            "Epoch: [91][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7280 (0.7198)\tPrec@1 77.500 (80.114)\n",
            "Total time : 12.503\n",
            "Train Loss: 0.7198, Train Accuracy: 0.8011\n",
            "Test Loss : 1.1304, Test Accuracy : 0.6838 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 0.7142 (0.7142)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [92][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.6782 (0.6773)\tPrec@1 77.344 (81.204)\n",
            "Epoch: [92][200/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.7156 (0.6852)\tPrec@1 76.562 (81.180)\n",
            "Epoch: [92][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.6777 (0.6987)\tPrec@1 82.812 (80.746)\n",
            "Epoch: [92][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7825 (0.7151)\tPrec@1 78.750 (80.204)\n",
            "Total time : 12.691\n",
            "Train Loss: 0.7151, Train Accuracy: 0.8020\n",
            "Test Loss : 1.0735, Test Accuracy : 0.6900 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 0.6036 (0.6036)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [93][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.8368 (0.6693)\tPrec@1 77.344 (81.722)\n",
            "Epoch: [93][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5975 (0.6766)\tPrec@1 80.469 (81.437)\n",
            "Epoch: [93][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.6778 (0.6894)\tPrec@1 79.688 (80.868)\n",
            "Epoch: [93][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.8160 (0.7013)\tPrec@1 78.750 (80.502)\n",
            "Total time : 12.348\n",
            "Train Loss: 0.7013, Train Accuracy: 0.8050\n",
            "Test Loss : 1.0185, Test Accuracy : 0.7103 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.182 (0.182)\tData 0.138 (0.138)\tLoss 0.5950 (0.5950)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [94][100/391]\tTime 0.035 (0.034)\tData 0.000 (0.002)\tLoss 0.6940 (0.6660)\tPrec@1 81.250 (81.621)\n",
            "Epoch: [94][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.6854 (0.6831)\tPrec@1 80.469 (81.273)\n",
            "Epoch: [94][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.8240 (0.6968)\tPrec@1 78.906 (80.871)\n",
            "Epoch: [94][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.8036 (0.7030)\tPrec@1 80.000 (80.780)\n",
            "Total time : 12.440\n",
            "Train Loss: 0.7030, Train Accuracy: 0.8078\n",
            "Test Loss : 1.0328, Test Accuracy : 0.7045 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.190 (0.190)\tData 0.142 (0.142)\tLoss 0.5223 (0.5223)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [95][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.6682 (0.6568)\tPrec@1 82.031 (82.217)\n",
            "Epoch: [95][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.6614 (0.6681)\tPrec@1 81.250 (81.860)\n",
            "Epoch: [95][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.9733 (0.6851)\tPrec@1 71.094 (81.136)\n",
            "Epoch: [95][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 1.0374 (0.6917)\tPrec@1 66.250 (80.826)\n",
            "Total time : 12.411\n",
            "Train Loss: 0.6917, Train Accuracy: 0.8083\n",
            "Test Loss : 1.1234, Test Accuracy : 0.6874 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.184 (0.184)\tData 0.144 (0.144)\tLoss 0.6444 (0.6444)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [96][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.6114 (0.6547)\tPrec@1 86.719 (81.745)\n",
            "Epoch: [96][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7096 (0.6621)\tPrec@1 80.469 (81.635)\n",
            "Epoch: [96][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7577 (0.6738)\tPrec@1 77.344 (81.414)\n",
            "Epoch: [96][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.6556 (0.6835)\tPrec@1 85.000 (81.206)\n",
            "Total time : 12.597\n",
            "Train Loss: 0.6835, Train Accuracy: 0.8121\n",
            "Test Loss : 1.0518, Test Accuracy : 0.6988 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.181 (0.181)\tData 0.142 (0.142)\tLoss 0.5456 (0.5456)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [97][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.6176 (0.6246)\tPrec@1 84.375 (83.114)\n",
            "Epoch: [97][200/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 0.6241 (0.6379)\tPrec@1 82.812 (82.731)\n",
            "Epoch: [97][300/391]\tTime 0.034 (0.032)\tData 0.000 (0.001)\tLoss 0.6086 (0.6539)\tPrec@1 79.688 (82.203)\n",
            "Epoch: [97][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7622 (0.6676)\tPrec@1 73.750 (81.706)\n",
            "Total time : 12.427\n",
            "Train Loss: 0.6676, Train Accuracy: 0.8171\n",
            "Test Loss : 1.0644, Test Accuracy : 0.6998 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.188 (0.188)\tData 0.141 (0.141)\tLoss 0.6324 (0.6324)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [98][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.6945 (0.6288)\tPrec@1 84.375 (82.882)\n",
            "Epoch: [98][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7329 (0.6387)\tPrec@1 78.906 (82.548)\n",
            "Epoch: [98][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7733 (0.6517)\tPrec@1 78.125 (82.164)\n",
            "Epoch: [98][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.6842 (0.6599)\tPrec@1 85.000 (81.918)\n",
            "Total time : 12.337\n",
            "Train Loss: 0.6599, Train Accuracy: 0.8192\n",
            "Test Loss : 1.0143, Test Accuracy : 0.7129 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.196 (0.196)\tData 0.138 (0.138)\tLoss 0.5282 (0.5282)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [99][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.7043 (0.6043)\tPrec@1 78.906 (83.818)\n",
            "Epoch: [99][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.6931 (0.6248)\tPrec@1 78.906 (83.166)\n",
            "Epoch: [99][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.8686 (0.6423)\tPrec@1 78.125 (82.579)\n",
            "Epoch: [99][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7126 (0.6500)\tPrec@1 78.750 (82.378)\n",
            "Total time : 12.443\n",
            "Train Loss: 0.6500, Train Accuracy: 0.8238\n",
            "Test Loss : 1.0235, Test Accuracy : 0.7066 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.194 (0.194)\tData 0.137 (0.137)\tLoss 0.5986 (0.5986)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [100][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.6166 (0.6039)\tPrec@1 85.938 (83.872)\n",
            "Epoch: [100][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5664 (0.6133)\tPrec@1 86.719 (83.489)\n",
            "Epoch: [100][300/391]\tTime 0.032 (0.031)\tData 0.000 (0.001)\tLoss 0.5725 (0.6297)\tPrec@1 85.156 (82.903)\n",
            "Epoch: [100][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.6898 (0.6403)\tPrec@1 78.750 (82.554)\n",
            "Total time : 12.196\n",
            "Train Loss: 0.6403, Train Accuracy: 0.8255\n",
            "Test Loss : 1.0851, Test Accuracy : 0.6915 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.186 (0.186)\tData 0.141 (0.141)\tLoss 0.7556 (0.7556)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [101][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.6578 (0.5936)\tPrec@1 81.250 (84.367)\n",
            "Epoch: [101][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5482 (0.6084)\tPrec@1 85.938 (83.555)\n",
            "Epoch: [101][300/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.6434 (0.6250)\tPrec@1 85.156 (83.119)\n",
            "Epoch: [101][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.5810 (0.6360)\tPrec@1 86.250 (82.718)\n",
            "Total time : 12.833\n",
            "Train Loss: 0.6360, Train Accuracy: 0.8272\n",
            "Test Loss : 0.9896, Test Accuracy : 0.7186 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.193 (0.193)\tData 0.137 (0.137)\tLoss 0.5804 (0.5804)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [102][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.7059 (0.5839)\tPrec@1 78.906 (84.847)\n",
            "Epoch: [102][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.6005 (0.5975)\tPrec@1 81.250 (84.153)\n",
            "Epoch: [102][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7860 (0.6151)\tPrec@1 80.469 (83.542)\n",
            "Epoch: [102][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.6185 (0.6253)\tPrec@1 80.000 (83.222)\n",
            "Total time : 12.437\n",
            "Train Loss: 0.6253, Train Accuracy: 0.8322\n",
            "Test Loss : 1.0252, Test Accuracy : 0.7099 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.178 (0.178)\tData 0.139 (0.139)\tLoss 0.5955 (0.5955)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [103][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.5336 (0.5750)\tPrec@1 87.500 (84.808)\n",
            "Epoch: [103][200/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.5781 (0.5923)\tPrec@1 84.375 (84.192)\n",
            "Epoch: [103][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.6600 (0.6116)\tPrec@1 84.375 (83.482)\n",
            "Epoch: [103][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.8401 (0.6169)\tPrec@1 72.500 (83.280)\n",
            "Total time : 12.622\n",
            "Train Loss: 0.6169, Train Accuracy: 0.8328\n",
            "Test Loss : 1.0591, Test Accuracy : 0.6970 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.186 (0.186)\tData 0.141 (0.141)\tLoss 0.4463 (0.4463)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [104][100/391]\tTime 0.035 (0.035)\tData 0.000 (0.002)\tLoss 0.6011 (0.5708)\tPrec@1 84.375 (84.692)\n",
            "Epoch: [104][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.7064 (0.5813)\tPrec@1 79.688 (84.449)\n",
            "Epoch: [104][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.6473 (0.5966)\tPrec@1 82.812 (83.996)\n",
            "Epoch: [104][390/391]\tTime 0.027 (0.035)\tData 0.000 (0.001)\tLoss 0.5904 (0.6051)\tPrec@1 85.000 (83.748)\n",
            "Total time : 13.530\n",
            "Train Loss: 0.6051, Train Accuracy: 0.8375\n",
            "Test Loss : 0.9895, Test Accuracy : 0.7134 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.182 (0.182)\tData 0.141 (0.141)\tLoss 0.5096 (0.5096)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [105][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.4395 (0.5588)\tPrec@1 89.844 (85.589)\n",
            "Epoch: [105][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.4561 (0.5722)\tPrec@1 86.719 (85.024)\n",
            "Epoch: [105][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 0.5879 (0.5817)\tPrec@1 82.031 (84.710)\n",
            "Epoch: [105][390/391]\tTime 0.028 (0.031)\tData 0.000 (0.001)\tLoss 0.7227 (0.5952)\tPrec@1 80.000 (84.168)\n",
            "Total time : 12.259\n",
            "Train Loss: 0.5952, Train Accuracy: 0.8417\n",
            "Test Loss : 1.0746, Test Accuracy : 0.6945 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.190 (0.190)\tData 0.137 (0.137)\tLoss 0.8385 (0.8385)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [106][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.5542 (0.5508)\tPrec@1 82.031 (85.667)\n",
            "Epoch: [106][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.5782 (0.5714)\tPrec@1 84.375 (84.849)\n",
            "Epoch: [106][300/391]\tTime 0.034 (0.032)\tData 0.000 (0.001)\tLoss 0.6318 (0.5846)\tPrec@1 83.594 (84.406)\n",
            "Epoch: [106][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.5690 (0.5931)\tPrec@1 85.000 (84.100)\n",
            "Total time : 12.408\n",
            "Train Loss: 0.5931, Train Accuracy: 0.8410\n",
            "Test Loss : 1.0355, Test Accuracy : 0.7085 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.179 (0.179)\tData 0.140 (0.140)\tLoss 0.6662 (0.6662)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [107][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 0.5363 (0.5380)\tPrec@1 86.719 (85.999)\n",
            "Epoch: [107][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5944 (0.5505)\tPrec@1 85.938 (85.522)\n",
            "Epoch: [107][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 0.6795 (0.5659)\tPrec@1 80.469 (84.868)\n",
            "Epoch: [107][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.6408 (0.5758)\tPrec@1 81.250 (84.562)\n",
            "Total time : 12.312\n",
            "Train Loss: 0.5758, Train Accuracy: 0.8456\n",
            "Test Loss : 0.9837, Test Accuracy : 0.7202 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.175 (0.175)\tData 0.134 (0.134)\tLoss 0.6507 (0.6507)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [108][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.5264 (0.5248)\tPrec@1 85.938 (86.394)\n",
            "Epoch: [108][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5919 (0.5380)\tPrec@1 84.375 (85.778)\n",
            "Epoch: [108][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.5555 (0.5493)\tPrec@1 85.156 (85.385)\n",
            "Epoch: [108][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.4844 (0.5621)\tPrec@1 88.750 (84.894)\n",
            "Total time : 12.445\n",
            "Train Loss: 0.5621, Train Accuracy: 0.8489\n",
            "Test Loss : 1.0401, Test Accuracy : 0.7035 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.195 (0.195)\tData 0.150 (0.150)\tLoss 0.4968 (0.4968)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [109][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.5628 (0.5275)\tPrec@1 85.156 (86.270)\n",
            "Epoch: [109][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.6310 (0.5498)\tPrec@1 84.375 (85.440)\n",
            "Epoch: [109][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.5783 (0.5621)\tPrec@1 83.594 (84.985)\n",
            "Epoch: [109][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.7554 (0.5668)\tPrec@1 81.250 (84.878)\n",
            "Total time : 12.546\n",
            "Train Loss: 0.5668, Train Accuracy: 0.8488\n",
            "Test Loss : 0.9645, Test Accuracy : 0.7261 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.182 (0.182)\tData 0.140 (0.140)\tLoss 0.5908 (0.5908)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [110][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.4795 (0.5308)\tPrec@1 86.719 (86.216)\n",
            "Epoch: [110][200/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 0.5467 (0.5284)\tPrec@1 85.156 (86.089)\n",
            "Epoch: [110][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.7098 (0.5377)\tPrec@1 78.906 (85.774)\n",
            "Epoch: [110][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4115 (0.5433)\tPrec@1 87.500 (85.578)\n",
            "Total time : 12.500\n",
            "Train Loss: 0.5433, Train Accuracy: 0.8558\n",
            "Test Loss : 0.9601, Test Accuracy : 0.7223 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.189 (0.189)\tData 0.137 (0.137)\tLoss 0.4513 (0.4513)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [111][100/391]\tTime 0.036 (0.035)\tData 0.000 (0.002)\tLoss 0.4829 (0.5052)\tPrec@1 89.062 (86.850)\n",
            "Epoch: [111][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.4518 (0.5164)\tPrec@1 85.156 (86.416)\n",
            "Epoch: [111][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.5084 (0.5298)\tPrec@1 89.062 (86.049)\n",
            "Epoch: [111][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.6234 (0.5364)\tPrec@1 82.500 (85.862)\n",
            "Total time : 12.577\n",
            "Train Loss: 0.5364, Train Accuracy: 0.8586\n",
            "Test Loss : 0.9695, Test Accuracy : 0.7253 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.187 (0.187)\tData 0.146 (0.146)\tLoss 0.4465 (0.4465)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [112][100/391]\tTime 0.044 (0.034)\tData 0.000 (0.002)\tLoss 0.5091 (0.5000)\tPrec@1 83.594 (86.873)\n",
            "Epoch: [112][200/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.4349 (0.5094)\tPrec@1 87.500 (86.878)\n",
            "Epoch: [112][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4983 (0.5187)\tPrec@1 88.281 (86.545)\n",
            "Epoch: [112][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.5378 (0.5235)\tPrec@1 81.250 (86.390)\n",
            "Total time : 12.488\n",
            "Train Loss: 0.5235, Train Accuracy: 0.8639\n",
            "Test Loss : 0.9731, Test Accuracy : 0.7221 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.211 (0.211)\tData 0.148 (0.148)\tLoss 0.4726 (0.4726)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [113][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.4541 (0.4851)\tPrec@1 89.062 (87.693)\n",
            "Epoch: [113][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5556 (0.4952)\tPrec@1 88.281 (87.282)\n",
            "Epoch: [113][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.6004 (0.5074)\tPrec@1 82.812 (86.833)\n",
            "Epoch: [113][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.4883 (0.5164)\tPrec@1 83.750 (86.522)\n",
            "Total time : 12.359\n",
            "Train Loss: 0.5164, Train Accuracy: 0.8652\n",
            "Test Loss : 0.9923, Test Accuracy : 0.7120 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.185 (0.185)\tData 0.141 (0.141)\tLoss 0.4804 (0.4804)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [114][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.4529 (0.4773)\tPrec@1 89.062 (87.724)\n",
            "Epoch: [114][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.5391 (0.4899)\tPrec@1 82.812 (87.247)\n",
            "Epoch: [114][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4187 (0.5005)\tPrec@1 89.844 (86.900)\n",
            "Epoch: [114][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.5559 (0.5094)\tPrec@1 82.500 (86.678)\n",
            "Total time : 12.489\n",
            "Train Loss: 0.5094, Train Accuracy: 0.8668\n",
            "Test Loss : 0.9541, Test Accuracy : 0.7287 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.201 (0.201)\tData 0.158 (0.158)\tLoss 0.3372 (0.3372)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [115][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.5053 (0.4762)\tPrec@1 85.938 (87.918)\n",
            "Epoch: [115][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.4906 (0.4850)\tPrec@1 85.938 (87.648)\n",
            "Epoch: [115][300/391]\tTime 0.030 (0.031)\tData 0.000 (0.001)\tLoss 0.4861 (0.4940)\tPrec@1 90.625 (87.368)\n",
            "Epoch: [115][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.4432 (0.5015)\tPrec@1 87.500 (87.130)\n",
            "Total time : 12.371\n",
            "Train Loss: 0.5015, Train Accuracy: 0.8713\n",
            "Test Loss : 0.9557, Test Accuracy : 0.7281 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.177 (0.177)\tData 0.135 (0.135)\tLoss 0.3429 (0.3429)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [116][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.4520 (0.4495)\tPrec@1 85.156 (88.815)\n",
            "Epoch: [116][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3996 (0.4623)\tPrec@1 86.719 (88.336)\n",
            "Epoch: [116][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.5125 (0.4735)\tPrec@1 84.375 (87.985)\n",
            "Epoch: [116][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.4086 (0.4854)\tPrec@1 87.500 (87.580)\n",
            "Total time : 12.786\n",
            "Train Loss: 0.4854, Train Accuracy: 0.8758\n",
            "Test Loss : 0.9665, Test Accuracy : 0.7231 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.192 (0.192)\tData 0.138 (0.138)\tLoss 0.5484 (0.5484)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [117][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.4483 (0.4522)\tPrec@1 90.625 (88.792)\n",
            "Epoch: [117][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4806 (0.4637)\tPrec@1 88.281 (88.262)\n",
            "Epoch: [117][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5651 (0.4718)\tPrec@1 84.375 (87.983)\n",
            "Epoch: [117][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.5621 (0.4794)\tPrec@1 83.750 (87.744)\n",
            "Total time : 12.379\n",
            "Train Loss: 0.4794, Train Accuracy: 0.8774\n",
            "Test Loss : 0.9302, Test Accuracy : 0.7332 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.187 (0.187)\tData 0.142 (0.142)\tLoss 0.3863 (0.3863)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [118][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.4079 (0.4244)\tPrec@1 92.969 (89.689)\n",
            "Epoch: [118][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.3506 (0.4431)\tPrec@1 92.969 (88.981)\n",
            "Epoch: [118][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.4879 (0.4566)\tPrec@1 85.156 (88.468)\n",
            "Epoch: [118][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4597 (0.4679)\tPrec@1 87.500 (88.134)\n",
            "Total time : 12.681\n",
            "Train Loss: 0.4679, Train Accuracy: 0.8813\n",
            "Test Loss : 0.9666, Test Accuracy : 0.7242 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.184 (0.184)\tData 0.141 (0.141)\tLoss 0.4789 (0.4789)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [119][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 0.3813 (0.4230)\tPrec@1 92.188 (89.689)\n",
            "Epoch: [119][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4747 (0.4389)\tPrec@1 89.844 (89.276)\n",
            "Epoch: [119][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 0.3222 (0.4488)\tPrec@1 93.750 (88.891)\n",
            "Epoch: [119][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.6269 (0.4548)\tPrec@1 85.000 (88.580)\n",
            "Total time : 12.678\n",
            "Train Loss: 0.4548, Train Accuracy: 0.8858\n",
            "Test Loss : 0.9559, Test Accuracy : 0.7273 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.205 (0.205)\tData 0.147 (0.147)\tLoss 0.3097 (0.3097)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [120][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.3368 (0.4224)\tPrec@1 92.188 (89.612)\n",
            "Epoch: [120][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5295 (0.4313)\tPrec@1 86.719 (89.370)\n",
            "Epoch: [120][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3952 (0.4424)\tPrec@1 89.062 (88.839)\n",
            "Epoch: [120][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4117 (0.4499)\tPrec@1 90.000 (88.660)\n",
            "Total time : 12.357\n",
            "Train Loss: 0.4499, Train Accuracy: 0.8866\n",
            "Test Loss : 0.9267, Test Accuracy : 0.7370 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.186 (0.186)\tData 0.146 (0.146)\tLoss 0.3784 (0.3784)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [121][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.3796 (0.4153)\tPrec@1 91.406 (89.705)\n",
            "Epoch: [121][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4862 (0.4186)\tPrec@1 90.625 (89.708)\n",
            "Epoch: [121][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.5025 (0.4322)\tPrec@1 86.719 (89.140)\n",
            "Epoch: [121][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.5025 (0.4427)\tPrec@1 88.750 (88.822)\n",
            "Total time : 12.281\n",
            "Train Loss: 0.4427, Train Accuracy: 0.8882\n",
            "Test Loss : 0.9144, Test Accuracy : 0.7414 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.195 (0.195)\tData 0.138 (0.138)\tLoss 0.4039 (0.4039)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [122][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.4428 (0.4113)\tPrec@1 89.062 (90.053)\n",
            "Epoch: [122][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.3928 (0.4170)\tPrec@1 88.281 (89.817)\n",
            "Epoch: [122][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.4264 (0.4278)\tPrec@1 92.188 (89.447)\n",
            "Epoch: [122][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.4354 (0.4337)\tPrec@1 87.500 (89.284)\n",
            "Total time : 12.564\n",
            "Train Loss: 0.4337, Train Accuracy: 0.8928\n",
            "Test Loss : 0.9139, Test Accuracy : 0.7406 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.192 (0.192)\tData 0.151 (0.151)\tLoss 0.3790 (0.3790)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [123][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.3237 (0.3972)\tPrec@1 91.406 (90.463)\n",
            "Epoch: [123][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.3791 (0.4081)\tPrec@1 91.406 (89.953)\n",
            "Epoch: [123][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4398 (0.4158)\tPrec@1 88.281 (89.826)\n",
            "Epoch: [123][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.5973 (0.4246)\tPrec@1 88.750 (89.556)\n",
            "Total time : 12.359\n",
            "Train Loss: 0.4246, Train Accuracy: 0.8956\n",
            "Test Loss : 0.8870, Test Accuracy : 0.7449 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.205 (0.205)\tData 0.160 (0.160)\tLoss 0.2627 (0.2627)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [124][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.4064 (0.3833)\tPrec@1 85.938 (91.081)\n",
            "Epoch: [124][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3489 (0.3921)\tPrec@1 90.625 (90.637)\n",
            "Epoch: [124][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.5213 (0.4000)\tPrec@1 87.500 (90.394)\n",
            "Epoch: [124][390/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.6166 (0.4087)\tPrec@1 80.000 (90.088)\n",
            "Total time : 12.381\n",
            "Train Loss: 0.4087, Train Accuracy: 0.9009\n",
            "Test Loss : 0.8923, Test Accuracy : 0.7455 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.192 (0.192)\tData 0.144 (0.144)\tLoss 0.3096 (0.3096)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [125][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.3642 (0.3621)\tPrec@1 92.188 (91.561)\n",
            "Epoch: [125][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4332 (0.3813)\tPrec@1 89.844 (90.979)\n",
            "Epoch: [125][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 0.4131 (0.3955)\tPrec@1 89.844 (90.555)\n",
            "Epoch: [125][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.4103 (0.4031)\tPrec@1 91.250 (90.238)\n",
            "Total time : 12.283\n",
            "Train Loss: 0.4031, Train Accuracy: 0.9024\n",
            "Test Loss : 0.8865, Test Accuracy : 0.7463 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.179 (0.179)\tData 0.138 (0.138)\tLoss 0.3477 (0.3477)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [126][100/391]\tTime 0.033 (0.033)\tData 0.000 (0.002)\tLoss 0.4425 (0.3601)\tPrec@1 88.281 (91.747)\n",
            "Epoch: [126][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.4195 (0.3668)\tPrec@1 91.406 (91.503)\n",
            "Epoch: [126][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.4266 (0.3814)\tPrec@1 89.844 (90.887)\n",
            "Epoch: [126][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.5208 (0.3861)\tPrec@1 86.250 (90.766)\n",
            "Total time : 12.771\n",
            "Train Loss: 0.3861, Train Accuracy: 0.9077\n",
            "Test Loss : 0.9010, Test Accuracy : 0.7459 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 0.3670 (0.3670)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [127][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.2580 (0.3452)\tPrec@1 95.312 (92.234)\n",
            "Epoch: [127][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.3062 (0.3603)\tPrec@1 92.969 (91.682)\n",
            "Epoch: [127][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4358 (0.3749)\tPrec@1 91.406 (91.209)\n",
            "Epoch: [127][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.5397 (0.3827)\tPrec@1 82.500 (90.918)\n",
            "Total time : 12.428\n",
            "Train Loss: 0.3827, Train Accuracy: 0.9092\n",
            "Test Loss : 0.8778, Test Accuracy : 0.7464 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.186 (0.186)\tData 0.142 (0.142)\tLoss 0.3763 (0.3763)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [128][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.3328 (0.3501)\tPrec@1 92.969 (92.095)\n",
            "Epoch: [128][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3989 (0.3583)\tPrec@1 88.281 (91.698)\n",
            "Epoch: [128][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.4164 (0.3661)\tPrec@1 89.844 (91.385)\n",
            "Epoch: [128][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4217 (0.3724)\tPrec@1 90.000 (91.174)\n",
            "Total time : 12.330\n",
            "Train Loss: 0.3724, Train Accuracy: 0.9117\n",
            "Test Loss : 0.8829, Test Accuracy : 0.7499 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.191 (0.191)\tData 0.136 (0.136)\tLoss 0.2588 (0.2588)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [129][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.4111 (0.3364)\tPrec@1 87.500 (92.458)\n",
            "Epoch: [129][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3362 (0.3449)\tPrec@1 92.188 (92.230)\n",
            "Epoch: [129][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 0.4796 (0.3577)\tPrec@1 86.719 (91.803)\n",
            "Epoch: [129][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.3038 (0.3664)\tPrec@1 91.250 (91.502)\n",
            "Total time : 12.555\n",
            "Train Loss: 0.3664, Train Accuracy: 0.9150\n",
            "Test Loss : 0.8881, Test Accuracy : 0.7467 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.211 (0.211)\tData 0.153 (0.153)\tLoss 0.2878 (0.2878)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [130][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.3202 (0.3479)\tPrec@1 93.750 (91.909)\n",
            "Epoch: [130][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3546 (0.3462)\tPrec@1 92.188 (92.083)\n",
            "Epoch: [130][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3905 (0.3595)\tPrec@1 89.844 (91.642)\n",
            "Epoch: [130][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4380 (0.3641)\tPrec@1 90.000 (91.458)\n",
            "Total time : 12.325\n",
            "Train Loss: 0.3641, Train Accuracy: 0.9146\n",
            "Test Loss : 0.8720, Test Accuracy : 0.7544 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.183 (0.183)\tData 0.143 (0.143)\tLoss 0.2766 (0.2766)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [131][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.2864 (0.3222)\tPrec@1 92.969 (92.644)\n",
            "Epoch: [131][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.3781 (0.3261)\tPrec@1 91.406 (92.697)\n",
            "Epoch: [131][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2818 (0.3342)\tPrec@1 95.312 (92.465)\n",
            "Epoch: [131][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.3875 (0.3412)\tPrec@1 95.000 (92.260)\n",
            "Total time : 12.601\n",
            "Train Loss: 0.3412, Train Accuracy: 0.9226\n",
            "Test Loss : 0.8385, Test Accuracy : 0.7594 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.203 (0.203)\tData 0.141 (0.141)\tLoss 0.2450 (0.2450)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [132][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.3275 (0.3220)\tPrec@1 92.188 (92.860)\n",
            "Epoch: [132][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3375 (0.3248)\tPrec@1 93.750 (92.693)\n",
            "Epoch: [132][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.4513 (0.3311)\tPrec@1 89.062 (92.450)\n",
            "Epoch: [132][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.3742 (0.3380)\tPrec@1 92.500 (92.282)\n",
            "Total time : 12.475\n",
            "Train Loss: 0.3380, Train Accuracy: 0.9228\n",
            "Test Loss : 0.8508, Test Accuracy : 0.7547 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.209 (0.209)\tData 0.147 (0.147)\tLoss 0.3064 (0.3064)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [133][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.3821 (0.3192)\tPrec@1 91.406 (93.232)\n",
            "Epoch: [133][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3218 (0.3181)\tPrec@1 92.188 (93.027)\n",
            "Epoch: [133][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.3097 (0.3232)\tPrec@1 92.969 (92.888)\n",
            "Epoch: [133][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.3489 (0.3280)\tPrec@1 88.750 (92.624)\n",
            "Total time : 12.479\n",
            "Train Loss: 0.3280, Train Accuracy: 0.9262\n",
            "Test Loss : 0.8557, Test Accuracy : 0.7572 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.199 (0.199)\tData 0.139 (0.139)\tLoss 0.2820 (0.2820)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [134][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.3081 (0.2997)\tPrec@1 92.188 (93.758)\n",
            "Epoch: [134][200/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 0.2747 (0.3098)\tPrec@1 95.312 (93.365)\n",
            "Epoch: [134][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.2657 (0.3158)\tPrec@1 96.094 (93.145)\n",
            "Epoch: [134][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.5053 (0.3197)\tPrec@1 85.000 (93.022)\n",
            "Total time : 12.426\n",
            "Train Loss: 0.3197, Train Accuracy: 0.9302\n",
            "Test Loss : 0.8382, Test Accuracy : 0.7621 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.191 (0.191)\tData 0.138 (0.138)\tLoss 0.3060 (0.3060)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [135][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.2845 (0.2810)\tPrec@1 95.312 (94.028)\n",
            "Epoch: [135][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2728 (0.2911)\tPrec@1 94.531 (93.804)\n",
            "Epoch: [135][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2606 (0.2976)\tPrec@1 95.312 (93.618)\n",
            "Epoch: [135][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.4642 (0.3067)\tPrec@1 90.000 (93.336)\n",
            "Total time : 12.326\n",
            "Train Loss: 0.3067, Train Accuracy: 0.9334\n",
            "Test Loss : 0.8743, Test Accuracy : 0.7545 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.179 (0.179)\tData 0.139 (0.139)\tLoss 0.2315 (0.2315)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [136][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.3288 (0.2882)\tPrec@1 95.312 (94.067)\n",
            "Epoch: [136][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2711 (0.2938)\tPrec@1 94.531 (93.843)\n",
            "Epoch: [136][300/391]\tTime 0.039 (0.032)\tData 0.000 (0.001)\tLoss 0.2895 (0.2985)\tPrec@1 92.188 (93.602)\n",
            "Epoch: [136][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4002 (0.3054)\tPrec@1 88.750 (93.364)\n",
            "Total time : 12.456\n",
            "Train Loss: 0.3054, Train Accuracy: 0.9336\n",
            "Test Loss : 0.8520, Test Accuracy : 0.7576 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.186 (0.186)\tData 0.141 (0.141)\tLoss 0.2688 (0.2688)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [137][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.2027 (0.2783)\tPrec@1 96.094 (94.500)\n",
            "Epoch: [137][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.3499 (0.2834)\tPrec@1 89.844 (94.228)\n",
            "Epoch: [137][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 0.4084 (0.2921)\tPrec@1 91.406 (93.851)\n",
            "Epoch: [137][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.4403 (0.2952)\tPrec@1 90.000 (93.730)\n",
            "Total time : 12.531\n",
            "Train Loss: 0.2952, Train Accuracy: 0.9373\n",
            "Test Loss : 0.8180, Test Accuracy : 0.7706 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.177 (0.177)\tData 0.138 (0.138)\tLoss 0.3003 (0.3003)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [138][100/391]\tTime 0.035 (0.034)\tData 0.000 (0.002)\tLoss 0.2603 (0.2701)\tPrec@1 96.094 (94.763)\n",
            "Epoch: [138][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3906 (0.2759)\tPrec@1 90.625 (94.376)\n",
            "Epoch: [138][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.2525 (0.2823)\tPrec@1 95.312 (94.176)\n",
            "Epoch: [138][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.3014 (0.2874)\tPrec@1 91.250 (93.956)\n",
            "Total time : 12.594\n",
            "Train Loss: 0.2874, Train Accuracy: 0.9396\n",
            "Test Loss : 0.8563, Test Accuracy : 0.7610 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.188 (0.188)\tData 0.148 (0.148)\tLoss 0.3182 (0.3182)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [139][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.2848 (0.2547)\tPrec@1 92.969 (94.933)\n",
            "Epoch: [139][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.2510 (0.2611)\tPrec@1 96.094 (94.838)\n",
            "Epoch: [139][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2075 (0.2673)\tPrec@1 96.094 (94.677)\n",
            "Epoch: [139][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.3555 (0.2722)\tPrec@1 88.750 (94.494)\n",
            "Total time : 12.626\n",
            "Train Loss: 0.2722, Train Accuracy: 0.9449\n",
            "Test Loss : 0.8450, Test Accuracy : 0.7593 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.192 (0.192)\tData 0.136 (0.136)\tLoss 0.1739 (0.1739)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [140][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.1887 (0.2499)\tPrec@1 96.094 (95.119)\n",
            "Epoch: [140][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.1451 (0.2537)\tPrec@1 97.656 (94.990)\n",
            "Epoch: [140][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.2330 (0.2623)\tPrec@1 95.312 (94.729)\n",
            "Epoch: [140][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.4517 (0.2701)\tPrec@1 90.000 (94.478)\n",
            "Total time : 12.462\n",
            "Train Loss: 0.2701, Train Accuracy: 0.9448\n",
            "Test Loss : 0.8174, Test Accuracy : 0.7716 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.177 (0.177)\tData 0.138 (0.138)\tLoss 0.2136 (0.2136)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [141][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.2719 (0.2465)\tPrec@1 92.188 (95.235)\n",
            "Epoch: [141][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.2289 (0.2517)\tPrec@1 94.531 (95.141)\n",
            "Epoch: [141][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2843 (0.2557)\tPrec@1 92.969 (94.980)\n",
            "Epoch: [141][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1737 (0.2602)\tPrec@1 98.750 (94.856)\n",
            "Total time : 12.389\n",
            "Train Loss: 0.2602, Train Accuracy: 0.9486\n",
            "Test Loss : 0.8439, Test Accuracy : 0.7586 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.181 (0.181)\tData 0.141 (0.141)\tLoss 0.2755 (0.2755)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [142][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.2349 (0.2406)\tPrec@1 95.312 (95.390)\n",
            "Epoch: [142][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2168 (0.2478)\tPrec@1 93.750 (95.200)\n",
            "Epoch: [142][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1993 (0.2507)\tPrec@1 96.094 (95.159)\n",
            "Epoch: [142][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.2305 (0.2546)\tPrec@1 97.500 (95.050)\n",
            "Total time : 12.554\n",
            "Train Loss: 0.2546, Train Accuracy: 0.9505\n",
            "Test Loss : 0.8139, Test Accuracy : 0.7685 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.181 (0.181)\tData 0.142 (0.142)\tLoss 0.2336 (0.2336)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [143][100/391]\tTime 0.035 (0.034)\tData 0.000 (0.002)\tLoss 0.3190 (0.2308)\tPrec@1 94.531 (95.792)\n",
            "Epoch: [143][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2531 (0.2401)\tPrec@1 96.094 (95.441)\n",
            "Epoch: [143][300/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 0.3042 (0.2453)\tPrec@1 93.750 (95.328)\n",
            "Epoch: [143][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2822 (0.2504)\tPrec@1 93.750 (95.110)\n",
            "Total time : 12.471\n",
            "Train Loss: 0.2504, Train Accuracy: 0.9511\n",
            "Test Loss : 0.7974, Test Accuracy : 0.7711 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.186 (0.186)\tData 0.146 (0.146)\tLoss 0.1644 (0.1644)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [144][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1994 (0.2295)\tPrec@1 98.438 (95.622)\n",
            "Epoch: [144][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2484 (0.2319)\tPrec@1 96.875 (95.662)\n",
            "Epoch: [144][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1751 (0.2351)\tPrec@1 96.875 (95.588)\n",
            "Epoch: [144][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.2262 (0.2387)\tPrec@1 96.250 (95.480)\n",
            "Total time : 12.776\n",
            "Train Loss: 0.2387, Train Accuracy: 0.9548\n",
            "Test Loss : 0.8327, Test Accuracy : 0.7651 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.172 (0.172)\tData 0.133 (0.133)\tLoss 0.2807 (0.2807)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [145][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1993 (0.2188)\tPrec@1 96.875 (95.877)\n",
            "Epoch: [145][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1815 (0.2204)\tPrec@1 95.312 (95.829)\n",
            "Epoch: [145][300/391]\tTime 0.037 (0.033)\tData 0.000 (0.001)\tLoss 0.2220 (0.2262)\tPrec@1 97.656 (95.775)\n",
            "Epoch: [145][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2699 (0.2299)\tPrec@1 96.250 (95.694)\n",
            "Total time : 12.622\n",
            "Train Loss: 0.2299, Train Accuracy: 0.9569\n",
            "Test Loss : 0.8100, Test Accuracy : 0.7711 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.184 (0.184)\tData 0.143 (0.143)\tLoss 0.1641 (0.1641)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [146][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 0.2208 (0.2153)\tPrec@1 96.094 (96.218)\n",
            "Epoch: [146][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1761 (0.2175)\tPrec@1 95.312 (96.160)\n",
            "Epoch: [146][300/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.1889 (0.2228)\tPrec@1 96.875 (95.930)\n",
            "Epoch: [146][390/391]\tTime 0.027 (0.034)\tData 0.000 (0.001)\tLoss 0.2846 (0.2260)\tPrec@1 93.750 (95.810)\n",
            "Total time : 13.312\n",
            "Train Loss: 0.2260, Train Accuracy: 0.9581\n",
            "Test Loss : 0.8068, Test Accuracy : 0.7713 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.185 (0.185)\tData 0.146 (0.146)\tLoss 0.1625 (0.1625)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [147][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.2588 (0.2069)\tPrec@1 95.312 (96.318)\n",
            "Epoch: [147][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2289 (0.2104)\tPrec@1 96.094 (96.249)\n",
            "Epoch: [147][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2294 (0.2153)\tPrec@1 96.094 (96.133)\n",
            "Epoch: [147][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.3455 (0.2173)\tPrec@1 93.750 (96.130)\n",
            "Total time : 12.351\n",
            "Train Loss: 0.2173, Train Accuracy: 0.9613\n",
            "Test Loss : 0.7883, Test Accuracy : 0.7784 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 0.1851 (0.1851)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [148][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.2606 (0.2101)\tPrec@1 95.312 (96.233)\n",
            "Epoch: [148][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1925 (0.2087)\tPrec@1 97.656 (96.327)\n",
            "Epoch: [148][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1701 (0.2105)\tPrec@1 97.656 (96.262)\n",
            "Epoch: [148][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2949 (0.2134)\tPrec@1 95.000 (96.210)\n",
            "Total time : 12.538\n",
            "Train Loss: 0.2134, Train Accuracy: 0.9621\n",
            "Test Loss : 0.7985, Test Accuracy : 0.7748 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.190 (0.190)\tData 0.143 (0.143)\tLoss 0.2144 (0.2144)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [149][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.2568 (0.1930)\tPrec@1 93.750 (96.713)\n",
            "Epoch: [149][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.2924 (0.2005)\tPrec@1 92.969 (96.490)\n",
            "Epoch: [149][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.2891 (0.2055)\tPrec@1 93.750 (96.325)\n",
            "Epoch: [149][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2594 (0.2082)\tPrec@1 96.250 (96.264)\n",
            "Total time : 12.367\n",
            "Train Loss: 0.2082, Train Accuracy: 0.9626\n",
            "Test Loss : 0.8002, Test Accuracy : 0.7760 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.182 (0.182)\tData 0.136 (0.136)\tLoss 0.1514 (0.1514)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [150][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.2122 (0.1911)\tPrec@1 96.094 (96.821)\n",
            "Epoch: [150][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1631 (0.1972)\tPrec@1 96.875 (96.661)\n",
            "Epoch: [150][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1944 (0.1977)\tPrec@1 97.656 (96.665)\n",
            "Epoch: [150][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.2569 (0.1998)\tPrec@1 95.000 (96.600)\n",
            "Total time : 12.302\n",
            "Train Loss: 0.1998, Train Accuracy: 0.9660\n",
            "Test Loss : 0.7819, Test Accuracy : 0.7812 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.185 (0.185)\tData 0.141 (0.141)\tLoss 0.1945 (0.1945)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [151][100/391]\tTime 0.035 (0.035)\tData 0.000 (0.002)\tLoss 0.2187 (0.1877)\tPrec@1 96.875 (96.620)\n",
            "Epoch: [151][200/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.1958 (0.1909)\tPrec@1 96.875 (96.677)\n",
            "Epoch: [151][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.2365 (0.1934)\tPrec@1 95.312 (96.626)\n",
            "Epoch: [151][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.2793 (0.1955)\tPrec@1 92.500 (96.618)\n",
            "Total time : 12.908\n",
            "Train Loss: 0.1955, Train Accuracy: 0.9662\n",
            "Test Loss : 0.7743, Test Accuracy : 0.7807 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.188 (0.188)\tData 0.142 (0.142)\tLoss 0.1738 (0.1738)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [152][100/391]\tTime 0.036 (0.035)\tData 0.000 (0.002)\tLoss 0.1203 (0.1773)\tPrec@1 99.219 (97.192)\n",
            "Epoch: [152][200/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.2324 (0.1843)\tPrec@1 93.750 (96.984)\n",
            "Epoch: [152][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.2616 (0.1876)\tPrec@1 96.094 (96.870)\n",
            "Epoch: [152][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.1967 (0.1891)\tPrec@1 98.750 (96.794)\n",
            "Total time : 12.694\n",
            "Train Loss: 0.1891, Train Accuracy: 0.9679\n",
            "Test Loss : 0.7768, Test Accuracy : 0.7800 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.200 (0.200)\tData 0.144 (0.144)\tLoss 0.1409 (0.1409)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [153][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1814 (0.1737)\tPrec@1 99.219 (97.300)\n",
            "Epoch: [153][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.2053 (0.1741)\tPrec@1 96.875 (97.326)\n",
            "Epoch: [153][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1590 (0.1823)\tPrec@1 97.656 (97.057)\n",
            "Epoch: [153][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2376 (0.1838)\tPrec@1 96.250 (97.042)\n",
            "Total time : 12.585\n",
            "Train Loss: 0.1838, Train Accuracy: 0.9704\n",
            "Test Loss : 0.7670, Test Accuracy : 0.7813 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.175 (0.175)\tData 0.135 (0.135)\tLoss 0.1317 (0.1317)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [154][100/391]\tTime 0.030 (0.032)\tData 0.000 (0.002)\tLoss 0.1879 (0.1662)\tPrec@1 96.875 (97.540)\n",
            "Epoch: [154][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.1602 (0.1745)\tPrec@1 97.656 (97.209)\n",
            "Epoch: [154][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1608 (0.1745)\tPrec@1 99.219 (97.166)\n",
            "Epoch: [154][390/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.1556 (0.1768)\tPrec@1 98.750 (97.084)\n",
            "Total time : 12.318\n",
            "Train Loss: 0.1768, Train Accuracy: 0.9708\n",
            "Test Loss : 0.7783, Test Accuracy : 0.7836 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.187 (0.187)\tData 0.141 (0.141)\tLoss 0.2101 (0.2101)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [155][100/391]\tTime 0.035 (0.034)\tData 0.000 (0.002)\tLoss 0.1606 (0.1684)\tPrec@1 98.438 (97.239)\n",
            "Epoch: [155][200/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.1876 (0.1700)\tPrec@1 96.875 (97.248)\n",
            "Epoch: [155][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1861 (0.1714)\tPrec@1 97.656 (97.241)\n",
            "Epoch: [155][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2299 (0.1737)\tPrec@1 93.750 (97.170)\n",
            "Total time : 12.694\n",
            "Train Loss: 0.1737, Train Accuracy: 0.9717\n",
            "Test Loss : 0.7544, Test Accuracy : 0.7821 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.196 (0.196)\tData 0.143 (0.143)\tLoss 0.2082 (0.2082)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [156][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1214 (0.1614)\tPrec@1 96.875 (97.594)\n",
            "Epoch: [156][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1675 (0.1639)\tPrec@1 97.656 (97.466)\n",
            "Epoch: [156][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1830 (0.1659)\tPrec@1 96.875 (97.389)\n",
            "Epoch: [156][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2428 (0.1680)\tPrec@1 95.000 (97.362)\n",
            "Total time : 12.481\n",
            "Train Loss: 0.1680, Train Accuracy: 0.9736\n",
            "Test Loss : 0.7534, Test Accuracy : 0.7845 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.198 (0.198)\tData 0.138 (0.138)\tLoss 0.1524 (0.1524)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [157][100/391]\tTime 0.035 (0.033)\tData 0.000 (0.002)\tLoss 0.1486 (0.1575)\tPrec@1 99.219 (97.803)\n",
            "Epoch: [157][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1510 (0.1582)\tPrec@1 96.875 (97.610)\n",
            "Epoch: [157][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1309 (0.1588)\tPrec@1 98.438 (97.610)\n",
            "Epoch: [157][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1795 (0.1619)\tPrec@1 97.500 (97.502)\n",
            "Total time : 12.533\n",
            "Train Loss: 0.1619, Train Accuracy: 0.9750\n",
            "Test Loss : 0.7577, Test Accuracy : 0.7838 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.186 (0.186)\tData 0.141 (0.141)\tLoss 0.2198 (0.2198)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [158][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1738 (0.1548)\tPrec@1 98.438 (97.540)\n",
            "Epoch: [158][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1244 (0.1552)\tPrec@1 96.875 (97.602)\n",
            "Epoch: [158][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1453 (0.1597)\tPrec@1 98.438 (97.555)\n",
            "Epoch: [158][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2262 (0.1612)\tPrec@1 96.250 (97.504)\n",
            "Total time : 12.432\n",
            "Train Loss: 0.1612, Train Accuracy: 0.9750\n",
            "Test Loss : 0.7657, Test Accuracy : 0.7841 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.179 (0.179)\tData 0.139 (0.139)\tLoss 0.1521 (0.1521)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [159][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 0.1809 (0.1512)\tPrec@1 97.656 (97.757)\n",
            "Epoch: [159][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.1348 (0.1521)\tPrec@1 99.219 (97.788)\n",
            "Epoch: [159][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1863 (0.1535)\tPrec@1 96.875 (97.765)\n",
            "Epoch: [159][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.2161 (0.1556)\tPrec@1 96.250 (97.696)\n",
            "Total time : 12.580\n",
            "Train Loss: 0.1556, Train Accuracy: 0.9770\n",
            "Test Loss : 0.7369, Test Accuracy : 0.7920 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.188 (0.188)\tData 0.147 (0.147)\tLoss 0.1175 (0.1175)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [160][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.1290 (0.1425)\tPrec@1 98.438 (97.904)\n",
            "Epoch: [160][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1253 (0.1462)\tPrec@1 98.438 (97.897)\n",
            "Epoch: [160][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.0973 (0.1480)\tPrec@1 100.000 (97.869)\n",
            "Epoch: [160][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1294 (0.1504)\tPrec@1 97.500 (97.770)\n",
            "Total time : 12.575\n",
            "Train Loss: 0.1504, Train Accuracy: 0.9777\n",
            "Test Loss : 0.7476, Test Accuracy : 0.7918 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.187 (0.187)\tData 0.146 (0.146)\tLoss 0.1346 (0.1346)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [161][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1465 (0.1423)\tPrec@1 99.219 (98.035)\n",
            "Epoch: [161][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1615 (0.1435)\tPrec@1 96.875 (97.944)\n",
            "Epoch: [161][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.1932 (0.1460)\tPrec@1 94.531 (97.859)\n",
            "Epoch: [161][390/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1623 (0.1454)\tPrec@1 97.500 (97.916)\n",
            "Total time : 12.464\n",
            "Train Loss: 0.1454, Train Accuracy: 0.9792\n",
            "Test Loss : 0.7457, Test Accuracy : 0.7863 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.198 (0.198)\tData 0.151 (0.151)\tLoss 0.1735 (0.1735)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [162][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.1681 (0.1406)\tPrec@1 99.219 (98.012)\n",
            "Epoch: [162][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1261 (0.1439)\tPrec@1 98.438 (97.889)\n",
            "Epoch: [162][300/391]\tTime 0.033 (0.032)\tData 0.000 (0.001)\tLoss 0.1589 (0.1425)\tPrec@1 97.656 (97.944)\n",
            "Epoch: [162][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1444 (0.1437)\tPrec@1 97.500 (97.922)\n",
            "Total time : 12.554\n",
            "Train Loss: 0.1437, Train Accuracy: 0.9792\n",
            "Test Loss : 0.7371, Test Accuracy : 0.7889 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.183 (0.183)\tData 0.140 (0.140)\tLoss 0.1401 (0.1401)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [163][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.0822 (0.1325)\tPrec@1 100.000 (98.252)\n",
            "Epoch: [163][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1512 (0.1336)\tPrec@1 98.438 (98.247)\n",
            "Epoch: [163][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1600 (0.1346)\tPrec@1 97.656 (98.230)\n",
            "Epoch: [163][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1677 (0.1380)\tPrec@1 100.000 (98.124)\n",
            "Total time : 12.340\n",
            "Train Loss: 0.1380, Train Accuracy: 0.9812\n",
            "Test Loss : 0.7364, Test Accuracy : 0.7954 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 0.0787 (0.0787)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [164][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1522 (0.1328)\tPrec@1 96.875 (98.128)\n",
            "Epoch: [164][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1448 (0.1353)\tPrec@1 98.438 (98.130)\n",
            "Epoch: [164][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1245 (0.1354)\tPrec@1 98.438 (98.126)\n",
            "Epoch: [164][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1488 (0.1356)\tPrec@1 97.500 (98.148)\n",
            "Total time : 12.494\n",
            "Train Loss: 0.1356, Train Accuracy: 0.9815\n",
            "Test Loss : 0.7330, Test Accuracy : 0.7959 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.194 (0.194)\tData 0.145 (0.145)\tLoss 0.1269 (0.1269)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [165][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.0829 (0.1252)\tPrec@1 99.219 (98.407)\n",
            "Epoch: [165][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1251 (0.1275)\tPrec@1 100.000 (98.301)\n",
            "Epoch: [165][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0859 (0.1297)\tPrec@1 99.219 (98.217)\n",
            "Epoch: [165][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.0940 (0.1303)\tPrec@1 100.000 (98.236)\n",
            "Total time : 12.421\n",
            "Train Loss: 0.1303, Train Accuracy: 0.9824\n",
            "Test Loss : 0.7304, Test Accuracy : 0.7939 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.189 (0.189)\tData 0.144 (0.144)\tLoss 0.1027 (0.1027)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [166][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1040 (0.1278)\tPrec@1 99.219 (98.275)\n",
            "Epoch: [166][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1114 (0.1285)\tPrec@1 97.656 (98.197)\n",
            "Epoch: [166][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1549 (0.1276)\tPrec@1 97.656 (98.232)\n",
            "Epoch: [166][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1533 (0.1274)\tPrec@1 96.250 (98.242)\n",
            "Total time : 12.494\n",
            "Train Loss: 0.1274, Train Accuracy: 0.9824\n",
            "Test Loss : 0.7238, Test Accuracy : 0.7960 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.185 (0.185)\tData 0.146 (0.146)\tLoss 0.1301 (0.1301)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [167][100/391]\tTime 0.036 (0.033)\tData 0.000 (0.002)\tLoss 0.1099 (0.1296)\tPrec@1 99.219 (98.252)\n",
            "Epoch: [167][200/391]\tTime 0.037 (0.032)\tData 0.000 (0.001)\tLoss 0.1499 (0.1297)\tPrec@1 98.438 (98.263)\n",
            "Epoch: [167][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1283 (0.1286)\tPrec@1 98.438 (98.308)\n",
            "Epoch: [167][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1680 (0.1282)\tPrec@1 97.500 (98.304)\n",
            "Total time : 12.358\n",
            "Train Loss: 0.1282, Train Accuracy: 0.9830\n",
            "Test Loss : 0.7140, Test Accuracy : 0.7966 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.175 (0.175)\tData 0.136 (0.136)\tLoss 0.0998 (0.0998)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [168][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0980 (0.1204)\tPrec@1 99.219 (98.476)\n",
            "Epoch: [168][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0975 (0.1192)\tPrec@1 99.219 (98.488)\n",
            "Epoch: [168][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1110 (0.1193)\tPrec@1 98.438 (98.435)\n",
            "Epoch: [168][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.1190 (0.1207)\tPrec@1 98.750 (98.434)\n",
            "Total time : 12.715\n",
            "Train Loss: 0.1207, Train Accuracy: 0.9843\n",
            "Test Loss : 0.7140, Test Accuracy : 0.7972 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.177 (0.177)\tData 0.137 (0.137)\tLoss 0.0839 (0.0839)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [169][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.1158 (0.1137)\tPrec@1 98.438 (98.584)\n",
            "Epoch: [169][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1168 (0.1164)\tPrec@1 97.656 (98.484)\n",
            "Epoch: [169][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0789 (0.1180)\tPrec@1 100.000 (98.474)\n",
            "Epoch: [169][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.1216 (0.1181)\tPrec@1 98.750 (98.496)\n",
            "Total time : 12.523\n",
            "Train Loss: 0.1181, Train Accuracy: 0.9850\n",
            "Test Loss : 0.7097, Test Accuracy : 0.7989 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.190 (0.190)\tData 0.145 (0.145)\tLoss 0.0831 (0.0831)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [170][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 0.1004 (0.1096)\tPrec@1 99.219 (98.855)\n",
            "Epoch: [170][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1179 (0.1154)\tPrec@1 98.438 (98.624)\n",
            "Epoch: [170][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.0853 (0.1149)\tPrec@1 100.000 (98.622)\n",
            "Epoch: [170][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.1726 (0.1152)\tPrec@1 98.750 (98.604)\n",
            "Total time : 12.290\n",
            "Train Loss: 0.1152, Train Accuracy: 0.9860\n",
            "Test Loss : 0.7168, Test Accuracy : 0.7987 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.188 (0.188)\tData 0.147 (0.147)\tLoss 0.1280 (0.1280)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [171][100/391]\tTime 0.035 (0.033)\tData 0.000 (0.002)\tLoss 0.1050 (0.1134)\tPrec@1 99.219 (98.538)\n",
            "Epoch: [171][200/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.1033 (0.1143)\tPrec@1 98.438 (98.558)\n",
            "Epoch: [171][300/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.0988 (0.1155)\tPrec@1 99.219 (98.479)\n",
            "Epoch: [171][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.1104 (0.1165)\tPrec@1 98.750 (98.454)\n",
            "Total time : 12.877\n",
            "Train Loss: 0.1165, Train Accuracy: 0.9845\n",
            "Test Loss : 0.7054, Test Accuracy : 0.8032 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 0.1109 (0.1109)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [172][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.0595 (0.1130)\tPrec@1 100.000 (98.677)\n",
            "Epoch: [172][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0940 (0.1108)\tPrec@1 99.219 (98.745)\n",
            "Epoch: [172][300/391]\tTime 0.044 (0.032)\tData 0.000 (0.001)\tLoss 0.1002 (0.1135)\tPrec@1 98.438 (98.658)\n",
            "Epoch: [172][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.1233 (0.1135)\tPrec@1 98.750 (98.656)\n",
            "Total time : 12.631\n",
            "Train Loss: 0.1135, Train Accuracy: 0.9866\n",
            "Test Loss : 0.7015, Test Accuracy : 0.8038 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.188 (0.188)\tData 0.149 (0.149)\tLoss 0.1084 (0.1084)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [173][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1312 (0.1078)\tPrec@1 98.438 (98.731)\n",
            "Epoch: [173][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1042 (0.1108)\tPrec@1 99.219 (98.682)\n",
            "Epoch: [173][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1530 (0.1127)\tPrec@1 98.438 (98.640)\n",
            "Epoch: [173][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1324 (0.1130)\tPrec@1 98.750 (98.634)\n",
            "Total time : 12.329\n",
            "Train Loss: 0.1130, Train Accuracy: 0.9863\n",
            "Test Loss : 0.7043, Test Accuracy : 0.8029 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.187 (0.187)\tData 0.140 (0.140)\tLoss 0.0697 (0.0697)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [174][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0835 (0.1025)\tPrec@1 100.000 (98.894)\n",
            "Epoch: [174][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.1203 (0.1065)\tPrec@1 97.656 (98.795)\n",
            "Epoch: [174][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0794 (0.1073)\tPrec@1 99.219 (98.752)\n",
            "Epoch: [174][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1326 (0.1079)\tPrec@1 97.500 (98.708)\n",
            "Total time : 12.658\n",
            "Train Loss: 0.1079, Train Accuracy: 0.9871\n",
            "Test Loss : 0.7059, Test Accuracy : 0.8025 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.183 (0.183)\tData 0.144 (0.144)\tLoss 0.0749 (0.0749)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [175][100/391]\tTime 0.035 (0.034)\tData 0.000 (0.002)\tLoss 0.0934 (0.1074)\tPrec@1 99.219 (98.786)\n",
            "Epoch: [175][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.0922 (0.1063)\tPrec@1 98.438 (98.780)\n",
            "Epoch: [175][300/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.0945 (0.1057)\tPrec@1 98.438 (98.798)\n",
            "Epoch: [175][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.1240 (0.1052)\tPrec@1 100.000 (98.796)\n",
            "Total time : 12.552\n",
            "Train Loss: 0.1052, Train Accuracy: 0.9880\n",
            "Test Loss : 0.7015, Test Accuracy : 0.8023 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.193 (0.193)\tData 0.137 (0.137)\tLoss 0.0843 (0.0843)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [176][100/391]\tTime 0.033 (0.033)\tData 0.000 (0.002)\tLoss 0.1384 (0.1040)\tPrec@1 97.656 (98.677)\n",
            "Epoch: [176][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1176 (0.1044)\tPrec@1 98.438 (98.721)\n",
            "Epoch: [176][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0943 (0.1050)\tPrec@1 99.219 (98.731)\n",
            "Epoch: [176][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1747 (0.1058)\tPrec@1 96.250 (98.708)\n",
            "Total time : 12.405\n",
            "Train Loss: 0.1058, Train Accuracy: 0.9871\n",
            "Test Loss : 0.7031, Test Accuracy : 0.8032 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.191 (0.191)\tData 0.152 (0.152)\tLoss 0.1202 (0.1202)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [177][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1068 (0.1016)\tPrec@1 98.438 (98.832)\n",
            "Epoch: [177][200/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1200 (0.1011)\tPrec@1 98.438 (98.822)\n",
            "Epoch: [177][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.1016 (0.1019)\tPrec@1 98.438 (98.840)\n",
            "Epoch: [177][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.1622 (0.1035)\tPrec@1 97.500 (98.792)\n",
            "Total time : 12.352\n",
            "Train Loss: 0.1035, Train Accuracy: 0.9879\n",
            "Test Loss : 0.6982, Test Accuracy : 0.8039 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 0.1006 (0.1006)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [178][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1118 (0.1024)\tPrec@1 98.438 (98.824)\n",
            "Epoch: [178][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0664 (0.0999)\tPrec@1 100.000 (98.939)\n",
            "Epoch: [178][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0942 (0.1002)\tPrec@1 99.219 (98.905)\n",
            "Epoch: [178][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1275 (0.1005)\tPrec@1 97.500 (98.872)\n",
            "Total time : 12.645\n",
            "Train Loss: 0.1005, Train Accuracy: 0.9887\n",
            "Test Loss : 0.7031, Test Accuracy : 0.8012 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.191 (0.191)\tData 0.146 (0.146)\tLoss 0.0821 (0.0821)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [179][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.0828 (0.0991)\tPrec@1 100.000 (98.979)\n",
            "Epoch: [179][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.0888 (0.0985)\tPrec@1 98.438 (98.951)\n",
            "Epoch: [179][300/391]\tTime 0.039 (0.032)\tData 0.000 (0.001)\tLoss 0.0911 (0.0998)\tPrec@1 99.219 (98.920)\n",
            "Epoch: [179][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.2352 (0.0988)\tPrec@1 93.750 (98.916)\n",
            "Total time : 12.630\n",
            "Train Loss: 0.0988, Train Accuracy: 0.9892\n",
            "Test Loss : 0.6981, Test Accuracy : 0.8044 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.195 (0.195)\tData 0.139 (0.139)\tLoss 0.0636 (0.0636)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [180][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0858 (0.0972)\tPrec@1 99.219 (98.979)\n",
            "Epoch: [180][200/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.0604 (0.0982)\tPrec@1 100.000 (98.923)\n",
            "Epoch: [180][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.0932 (0.0981)\tPrec@1 99.219 (98.912)\n",
            "Epoch: [180][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.0798 (0.0985)\tPrec@1 100.000 (98.896)\n",
            "Total time : 12.642\n",
            "Train Loss: 0.0985, Train Accuracy: 0.9890\n",
            "Test Loss : 0.6933, Test Accuracy : 0.8057 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.185 (0.185)\tData 0.140 (0.140)\tLoss 0.0944 (0.0944)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [181][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.0819 (0.0946)\tPrec@1 98.438 (98.979)\n",
            "Epoch: [181][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0807 (0.0939)\tPrec@1 99.219 (98.997)\n",
            "Epoch: [181][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.1279 (0.0955)\tPrec@1 97.656 (98.962)\n",
            "Epoch: [181][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1044 (0.0951)\tPrec@1 98.750 (98.980)\n",
            "Total time : 12.471\n",
            "Train Loss: 0.0951, Train Accuracy: 0.9898\n",
            "Test Loss : 0.6913, Test Accuracy : 0.8060 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.205 (0.205)\tData 0.144 (0.144)\tLoss 0.0516 (0.0516)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [182][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.0629 (0.0923)\tPrec@1 100.000 (98.979)\n",
            "Epoch: [182][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0728 (0.0944)\tPrec@1 100.000 (98.970)\n",
            "Epoch: [182][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0908 (0.0943)\tPrec@1 100.000 (98.993)\n",
            "Epoch: [182][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1204 (0.0949)\tPrec@1 98.750 (98.970)\n",
            "Total time : 12.689\n",
            "Train Loss: 0.0949, Train Accuracy: 0.9897\n",
            "Test Loss : 0.6914, Test Accuracy : 0.8058 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.195 (0.195)\tData 0.140 (0.140)\tLoss 0.0756 (0.0756)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [183][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.0880 (0.0945)\tPrec@1 99.219 (98.925)\n",
            "Epoch: [183][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1003 (0.0937)\tPrec@1 97.656 (98.904)\n",
            "Epoch: [183][300/391]\tTime 0.035 (0.031)\tData 0.000 (0.001)\tLoss 0.0846 (0.0942)\tPrec@1 99.219 (98.892)\n",
            "Epoch: [183][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.1119 (0.0939)\tPrec@1 98.750 (98.928)\n",
            "Total time : 12.233\n",
            "Train Loss: 0.0939, Train Accuracy: 0.9893\n",
            "Test Loss : 0.6911, Test Accuracy : 0.8085 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.186 (0.186)\tData 0.147 (0.147)\tLoss 0.1282 (0.1282)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [184][100/391]\tTime 0.031 (0.032)\tData 0.000 (0.002)\tLoss 0.0878 (0.0925)\tPrec@1 99.219 (98.940)\n",
            "Epoch: [184][200/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.1182 (0.0912)\tPrec@1 98.438 (98.993)\n",
            "Epoch: [184][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 0.0465 (0.0915)\tPrec@1 100.000 (98.998)\n",
            "Epoch: [184][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.0822 (0.0924)\tPrec@1 100.000 (98.956)\n",
            "Total time : 12.356\n",
            "Train Loss: 0.0924, Train Accuracy: 0.9896\n",
            "Test Loss : 0.6902, Test Accuracy : 0.8070 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.185 (0.185)\tData 0.138 (0.138)\tLoss 0.0812 (0.0812)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [185][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0884 (0.0924)\tPrec@1 98.438 (98.863)\n",
            "Epoch: [185][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.0700 (0.0921)\tPrec@1 100.000 (98.916)\n",
            "Epoch: [185][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1174 (0.0921)\tPrec@1 96.875 (98.936)\n",
            "Epoch: [185][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1545 (0.0921)\tPrec@1 97.500 (98.948)\n",
            "Total time : 12.577\n",
            "Train Loss: 0.0921, Train Accuracy: 0.9895\n",
            "Test Loss : 0.6890, Test Accuracy : 0.8061 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.189 (0.189)\tData 0.142 (0.142)\tLoss 0.1073 (0.1073)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [186][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0698 (0.0941)\tPrec@1 100.000 (98.863)\n",
            "Epoch: [186][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0902 (0.0926)\tPrec@1 99.219 (98.904)\n",
            "Epoch: [186][300/391]\tTime 0.030 (0.032)\tData 0.000 (0.001)\tLoss 0.0728 (0.0923)\tPrec@1 100.000 (98.941)\n",
            "Epoch: [186][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1245 (0.0916)\tPrec@1 97.500 (98.960)\n",
            "Total time : 12.379\n",
            "Train Loss: 0.0916, Train Accuracy: 0.9896\n",
            "Test Loss : 0.6920, Test Accuracy : 0.8048 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.178 (0.178)\tData 0.137 (0.137)\tLoss 0.1091 (0.1091)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [187][100/391]\tTime 0.037 (0.034)\tData 0.000 (0.002)\tLoss 0.0814 (0.0910)\tPrec@1 99.219 (99.056)\n",
            "Epoch: [187][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1033 (0.0915)\tPrec@1 96.875 (98.958)\n",
            "Epoch: [187][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.0901 (0.0912)\tPrec@1 98.438 (98.933)\n",
            "Epoch: [187][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.0894 (0.0909)\tPrec@1 98.750 (98.946)\n",
            "Total time : 13.007\n",
            "Train Loss: 0.0909, Train Accuracy: 0.9895\n",
            "Test Loss : 0.6905, Test Accuracy : 0.8077 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.195 (0.195)\tData 0.151 (0.151)\tLoss 0.0929 (0.0929)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [188][100/391]\tTime 0.030 (0.033)\tData 0.000 (0.002)\tLoss 0.0776 (0.0932)\tPrec@1 99.219 (98.863)\n",
            "Epoch: [188][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1504 (0.0899)\tPrec@1 98.438 (99.009)\n",
            "Epoch: [188][300/391]\tTime 0.031 (0.031)\tData 0.000 (0.001)\tLoss 0.0653 (0.0891)\tPrec@1 100.000 (99.032)\n",
            "Epoch: [188][390/391]\tTime 0.027 (0.031)\tData 0.000 (0.001)\tLoss 0.1089 (0.0888)\tPrec@1 98.750 (99.048)\n",
            "Total time : 12.270\n",
            "Train Loss: 0.0888, Train Accuracy: 0.9905\n",
            "Test Loss : 0.6893, Test Accuracy : 0.8062 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.202 (0.202)\tData 0.141 (0.141)\tLoss 0.0823 (0.0823)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [189][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 0.0913 (0.0901)\tPrec@1 99.219 (99.049)\n",
            "Epoch: [189][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0717 (0.0881)\tPrec@1 99.219 (99.087)\n",
            "Epoch: [189][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0861 (0.0871)\tPrec@1 99.219 (99.084)\n",
            "Epoch: [189][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.0665 (0.0886)\tPrec@1 100.000 (99.056)\n",
            "Total time : 12.414\n",
            "Train Loss: 0.0886, Train Accuracy: 0.9906\n",
            "Test Loss : 0.6886, Test Accuracy : 0.8070 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.197 (0.197)\tData 0.140 (0.140)\tLoss 0.0564 (0.0564)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [190][100/391]\tTime 0.030 (0.034)\tData 0.000 (0.002)\tLoss 0.0765 (0.0908)\tPrec@1 99.219 (98.863)\n",
            "Epoch: [190][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0945 (0.0910)\tPrec@1 100.000 (98.896)\n",
            "Epoch: [190][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.0925 (0.0902)\tPrec@1 100.000 (98.954)\n",
            "Epoch: [190][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.1289 (0.0908)\tPrec@1 97.500 (98.958)\n",
            "Total time : 12.409\n",
            "Train Loss: 0.0908, Train Accuracy: 0.9896\n",
            "Test Loss : 0.6869, Test Accuracy : 0.8077 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.178 (0.178)\tData 0.138 (0.138)\tLoss 0.0878 (0.0878)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [191][100/391]\tTime 0.035 (0.035)\tData 0.000 (0.002)\tLoss 0.1084 (0.0859)\tPrec@1 97.656 (99.141)\n",
            "Epoch: [191][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.0796 (0.0868)\tPrec@1 99.219 (99.098)\n",
            "Epoch: [191][300/391]\tTime 0.039 (0.033)\tData 0.000 (0.001)\tLoss 0.1160 (0.0869)\tPrec@1 98.438 (99.097)\n",
            "Epoch: [191][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.1358 (0.0872)\tPrec@1 96.250 (99.092)\n",
            "Total time : 12.824\n",
            "Train Loss: 0.0872, Train Accuracy: 0.9909\n",
            "Test Loss : 0.6894, Test Accuracy : 0.8065 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.185 (0.185)\tData 0.138 (0.138)\tLoss 0.0634 (0.0634)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [192][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.0672 (0.0868)\tPrec@1 99.219 (99.010)\n",
            "Epoch: [192][200/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 0.1095 (0.0882)\tPrec@1 99.219 (99.040)\n",
            "Epoch: [192][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.1025 (0.0883)\tPrec@1 98.438 (99.032)\n",
            "Epoch: [192][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1120 (0.0885)\tPrec@1 97.500 (99.010)\n",
            "Total time : 12.408\n",
            "Train Loss: 0.0885, Train Accuracy: 0.9901\n",
            "Test Loss : 0.6848, Test Accuracy : 0.8080 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.180 (0.180)\tData 0.141 (0.141)\tLoss 0.0746 (0.0746)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [193][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.0863 (0.0889)\tPrec@1 100.000 (99.141)\n",
            "Epoch: [193][200/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.1009 (0.0882)\tPrec@1 98.438 (99.106)\n",
            "Epoch: [193][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0914 (0.0874)\tPrec@1 99.219 (99.125)\n",
            "Epoch: [193][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.1013 (0.0864)\tPrec@1 100.000 (99.126)\n",
            "Total time : 12.814\n",
            "Train Loss: 0.0864, Train Accuracy: 0.9913\n",
            "Test Loss : 0.6872, Test Accuracy : 0.8090 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 0.1411 (0.1411)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [194][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1230 (0.0853)\tPrec@1 97.656 (99.041)\n",
            "Epoch: [194][200/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.0969 (0.0863)\tPrec@1 98.438 (99.040)\n",
            "Epoch: [194][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0996 (0.0873)\tPrec@1 98.438 (99.011)\n",
            "Epoch: [194][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.0983 (0.0873)\tPrec@1 98.750 (99.028)\n",
            "Total time : 12.494\n",
            "Train Loss: 0.0873, Train Accuracy: 0.9903\n",
            "Test Loss : 0.6866, Test Accuracy : 0.8075 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.180 (0.180)\tData 0.141 (0.141)\tLoss 0.0549 (0.0549)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [195][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0587 (0.0854)\tPrec@1 99.219 (99.072)\n",
            "Epoch: [195][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0634 (0.0839)\tPrec@1 100.000 (99.168)\n",
            "Epoch: [195][300/391]\tTime 0.044 (0.032)\tData 0.000 (0.001)\tLoss 0.0540 (0.0845)\tPrec@1 100.000 (99.136)\n",
            "Epoch: [195][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.0896 (0.0847)\tPrec@1 100.000 (99.122)\n",
            "Total time : 12.371\n",
            "Train Loss: 0.0847, Train Accuracy: 0.9912\n",
            "Test Loss : 0.6850, Test Accuracy : 0.8074 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.201 (0.201)\tData 0.146 (0.146)\tLoss 0.0569 (0.0569)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [196][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1081 (0.0895)\tPrec@1 98.438 (99.049)\n",
            "Epoch: [196][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0927 (0.0887)\tPrec@1 97.656 (99.001)\n",
            "Epoch: [196][300/391]\tTime 0.035 (0.032)\tData 0.000 (0.001)\tLoss 0.1084 (0.0880)\tPrec@1 98.438 (99.055)\n",
            "Epoch: [196][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.0834 (0.0867)\tPrec@1 100.000 (99.090)\n",
            "Total time : 12.452\n",
            "Train Loss: 0.0867, Train Accuracy: 0.9909\n",
            "Test Loss : 0.6857, Test Accuracy : 0.8077 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.437 (0.437)\tData 0.382 (0.382)\tLoss 0.1155 (0.1155)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [197][100/391]\tTime 0.031 (0.039)\tData 0.000 (0.004)\tLoss 0.0769 (0.0858)\tPrec@1 100.000 (99.165)\n",
            "Epoch: [197][200/391]\tTime 0.030 (0.035)\tData 0.000 (0.002)\tLoss 0.0433 (0.0845)\tPrec@1 100.000 (99.145)\n",
            "Epoch: [197][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0777 (0.0860)\tPrec@1 99.219 (99.097)\n",
            "Epoch: [197][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.0624 (0.0861)\tPrec@1 98.750 (99.100)\n",
            "Total time : 12.942\n",
            "Train Loss: 0.0861, Train Accuracy: 0.9910\n",
            "Test Loss : 0.6870, Test Accuracy : 0.8061 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.192 (0.192)\tData 0.146 (0.146)\tLoss 0.0670 (0.0670)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [198][100/391]\tTime 0.037 (0.034)\tData 0.000 (0.002)\tLoss 0.0677 (0.0889)\tPrec@1 100.000 (99.118)\n",
            "Epoch: [198][200/391]\tTime 0.038 (0.033)\tData 0.000 (0.001)\tLoss 0.0834 (0.0867)\tPrec@1 100.000 (99.168)\n",
            "Epoch: [198][300/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.0982 (0.0873)\tPrec@1 99.219 (99.159)\n",
            "Epoch: [198][390/391]\tTime 0.027 (0.033)\tData 0.000 (0.001)\tLoss 0.0795 (0.0872)\tPrec@1 100.000 (99.150)\n",
            "Total time : 12.825\n",
            "Train Loss: 0.0872, Train Accuracy: 0.9915\n",
            "Test Loss : 0.6843, Test Accuracy : 0.8085 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.197 (0.197)\tData 0.139 (0.139)\tLoss 0.0791 (0.0791)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [199][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.0791 (0.0877)\tPrec@1 98.438 (99.049)\n",
            "Epoch: [199][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0954 (0.0877)\tPrec@1 98.438 (99.024)\n",
            "Epoch: [199][300/391]\tTime 0.036 (0.032)\tData 0.000 (0.001)\tLoss 0.0649 (0.0865)\tPrec@1 98.438 (99.029)\n",
            "Epoch: [199][390/391]\tTime 0.027 (0.032)\tData 0.000 (0.001)\tLoss 0.1236 (0.0875)\tPrec@1 98.750 (98.994)\n",
            "Total time : 12.602\n",
            "Train Loss: 0.0875, Train Accuracy: 0.9899\n",
            "Test Loss : 0.6855, Test Accuracy : 0.8075 \n",
            "\n",
            "train loss:  [4.0224, 3.5286, 3.177, 2.8793, 2.5816, 2.3227, 2.1131, 1.9671, 1.8459, 1.7558, 1.6888, 1.6275, 1.5832, 1.5337, 1.492, 1.4614, 1.4313, 1.4113, 1.3845, 1.36, 1.3448, 1.3232, 1.3102, 1.2879, 1.2736, 1.2562, 1.2531, 1.23, 1.2256, 1.2131, 1.203, 1.1868, 1.183, 1.1669, 1.1622, 1.1546, 1.1471, 1.1391, 1.1273, 1.1111, 1.111, 1.1024, 1.0949, 1.0743, 1.0835, 1.0682, 1.0592, 1.0588, 1.0479, 1.041, 1.0391, 1.0254, 1.0117, 1.0114, 1.0034, 1.0006, 0.9958, 0.9831, 0.9684, 0.9748, 0.965, 0.9566, 0.9489, 0.9447, 0.9368, 0.926, 0.9205, 0.9153, 0.9064, 0.8957, 0.8901, 0.8851, 0.8705, 0.8686, 0.8585, 0.854, 0.8435, 0.8369, 0.8255, 0.8181, 0.8088, 0.8004, 0.7993, 0.7936, 0.7812, 0.7714, 0.7608, 0.7569, 0.7477, 0.736, 0.7303, 0.7198, 0.7151, 0.7013, 0.703, 0.6917, 0.6835, 0.6676, 0.6599, 0.65, 0.6403, 0.636, 0.6253, 0.6169, 0.6051, 0.5952, 0.5931, 0.5758, 0.5621, 0.5668, 0.5433, 0.5364, 0.5235, 0.5164, 0.5094, 0.5015, 0.4854, 0.4794, 0.4679, 0.4548, 0.4499, 0.4427, 0.4337, 0.4246, 0.4087, 0.4031, 0.3861, 0.3827, 0.3724, 0.3664, 0.3641, 0.3412, 0.338, 0.328, 0.3197, 0.3067, 0.3054, 0.2952, 0.2874, 0.2722, 0.2701, 0.2602, 0.2546, 0.2504, 0.2387, 0.2299, 0.226, 0.2173, 0.2134, 0.2082, 0.1998, 0.1955, 0.1891, 0.1838, 0.1768, 0.1737, 0.168, 0.1619, 0.1612, 0.1556, 0.1504, 0.1454, 0.1437, 0.138, 0.1356, 0.1303, 0.1274, 0.1282, 0.1207, 0.1181, 0.1152, 0.1165, 0.1135, 0.113, 0.1079, 0.1052, 0.1058, 0.1035, 0.1005, 0.0988, 0.0985, 0.0951, 0.0949, 0.0939, 0.0924, 0.0921, 0.0916, 0.0909, 0.0888, 0.0886, 0.0908, 0.0872, 0.0885, 0.0864, 0.0873, 0.0847, 0.0867, 0.0861, 0.0872, 0.0875]\n",
            "train err:  [0.9239, 0.8485, 0.7845, 0.7308, 0.6714, 0.616, 0.57, 0.5368, 0.5031, 0.4816, 0.4655, 0.4525, 0.4392, 0.4264, 0.4163, 0.4063, 0.4005, 0.3952, 0.3871, 0.3818, 0.3761, 0.3714, 0.3679, 0.3599, 0.3566, 0.3541, 0.3507, 0.3453, 0.343, 0.3387, 0.3374, 0.3322, 0.3317, 0.3289, 0.3275, 0.3238, 0.32, 0.3185, 0.3165, 0.3126, 0.3125, 0.3106, 0.3073, 0.3033, 0.3039, 0.3002, 0.2972, 0.297, 0.2928, 0.2921, 0.2917, 0.2888, 0.284, 0.2844, 0.2816, 0.2818, 0.2788, 0.2749, 0.2721, 0.2742, 0.2719, 0.2696, 0.2663, 0.2635, 0.2615, 0.2584, 0.2584, 0.2587, 0.2529, 0.2519, 0.2504, 0.2489, 0.2441, 0.2442, 0.2394, 0.2374, 0.2364, 0.2329, 0.2305, 0.2296, 0.2261, 0.2239, 0.2236, 0.2213, 0.2151, 0.2127, 0.2087, 0.2093, 0.2048, 0.2043, 0.201, 0.1989, 0.198, 0.195, 0.1922, 0.1917, 0.1879, 0.1829, 0.1808, 0.1762, 0.1745, 0.1728, 0.1678, 0.1672, 0.1625, 0.1583, 0.159, 0.1544, 0.1511, 0.1512, 0.1442, 0.1414, 0.1361, 0.1348, 0.1332, 0.1287, 0.1242, 0.1226, 0.1187, 0.1142, 0.1134, 0.1118, 0.1072, 0.1044, 0.0991, 0.0976, 0.0923, 0.0908, 0.0883, 0.085, 0.0854, 0.0774, 0.0772, 0.0738, 0.0698, 0.0666, 0.0664, 0.0627, 0.0604, 0.0551, 0.0552, 0.0514, 0.0495, 0.0489, 0.0452, 0.0431, 0.0419, 0.0387, 0.0379, 0.0374, 0.034, 0.0338, 0.0321, 0.0296, 0.0292, 0.0283, 0.0264, 0.025, 0.025, 0.023, 0.0223, 0.0208, 0.0208, 0.0188, 0.0185, 0.0176, 0.0176, 0.017, 0.0157, 0.015, 0.014, 0.0155, 0.0134, 0.0137, 0.0129, 0.012, 0.0129, 0.0121, 0.0113, 0.0108, 0.011, 0.0102, 0.0103, 0.0107, 0.0104, 0.0105, 0.0104, 0.0105, 0.0095, 0.0094, 0.0104, 0.0091, 0.0099, 0.0087, 0.0097, 0.0088, 0.0091, 0.009, 0.0085, 0.0101]\n",
            "train acc:  [0.0761, 0.1515, 0.2155, 0.2692, 0.3286, 0.384, 0.43, 0.4632, 0.4969, 0.5184, 0.5345, 0.5475, 0.5608, 0.5736, 0.5837, 0.5937, 0.5995, 0.6048, 0.6129, 0.6182, 0.6239, 0.6286, 0.6321, 0.6401, 0.6434, 0.6459, 0.6493, 0.6547, 0.657, 0.6613, 0.6626, 0.6678, 0.6683, 0.6711, 0.6725, 0.6762, 0.68, 0.6815, 0.6835, 0.6874, 0.6875, 0.6894, 0.6927, 0.6967, 0.6961, 0.6998, 0.7028, 0.703, 0.7072, 0.7079, 0.7083, 0.7112, 0.716, 0.7156, 0.7184, 0.7182, 0.7212, 0.7251, 0.7279, 0.7258, 0.7281, 0.7304, 0.7337, 0.7365, 0.7385, 0.7416, 0.7416, 0.7413, 0.7471, 0.7481, 0.7496, 0.7511, 0.7559, 0.7558, 0.7606, 0.7626, 0.7636, 0.7671, 0.7695, 0.7704, 0.7739, 0.7761, 0.7764, 0.7787, 0.7849, 0.7873, 0.7913, 0.7907, 0.7952, 0.7957, 0.799, 0.8011, 0.802, 0.805, 0.8078, 0.8083, 0.8121, 0.8171, 0.8192, 0.8238, 0.8255, 0.8272, 0.8322, 0.8328, 0.8375, 0.8417, 0.841, 0.8456, 0.8489, 0.8488, 0.8558, 0.8586, 0.8639, 0.8652, 0.8668, 0.8713, 0.8758, 0.8774, 0.8813, 0.8858, 0.8866, 0.8882, 0.8928, 0.8956, 0.9009, 0.9024, 0.9077, 0.9092, 0.9117, 0.915, 0.9146, 0.9226, 0.9228, 0.9262, 0.9302, 0.9334, 0.9336, 0.9373, 0.9396, 0.9449, 0.9448, 0.9486, 0.9505, 0.9511, 0.9548, 0.9569, 0.9581, 0.9613, 0.9621, 0.9626, 0.966, 0.9662, 0.9679, 0.9704, 0.9708, 0.9717, 0.9736, 0.975, 0.975, 0.977, 0.9777, 0.9792, 0.9792, 0.9812, 0.9815, 0.9824, 0.9824, 0.983, 0.9843, 0.985, 0.986, 0.9845, 0.9866, 0.9863, 0.9871, 0.988, 0.9871, 0.9879, 0.9887, 0.9892, 0.989, 0.9898, 0.9897, 0.9893, 0.9896, 0.9895, 0.9896, 0.9895, 0.9905, 0.9906, 0.9896, 0.9909, 0.9901, 0.9913, 0.9903, 0.9912, 0.9909, 0.991, 0.9915, 0.9899]\n",
            "test loss:  [3.6602, 3.2287, 3.0104, 2.7964, 2.3624, 2.2038, 1.9693, 1.9489, 1.8107, 1.76, 1.7217, 1.6866, 1.6943, 1.5934, 1.5907, 1.5614, 1.7824, 1.6032, 1.5565, 1.4678, 1.5594, 1.4965, 1.5363, 1.3506, 1.4754, 1.508, 1.4836, 1.4146, 1.5655, 1.6519, 1.3943, 1.3087, 1.4486, 1.5756, 1.2611, 1.3549, 1.3783, 1.3524, 1.4134, 1.2692, 1.3983, 1.2666, 1.3005, 1.3278, 1.3272, 1.2662, 1.2928, 1.2809, 1.3011, 1.3855, 1.299, 1.2091, 1.2425, 1.2037, 1.2922, 1.2651, 1.2462, 1.1544, 1.2139, 1.1959, 1.2828, 1.2284, 1.2177, 1.1662, 1.2677, 1.1851, 1.3429, 1.1928, 1.2992, 1.1278, 1.1977, 1.1698, 1.1857, 1.1754, 1.1047, 1.145, 1.1391, 1.1104, 1.1122, 1.0761, 1.1054, 1.1534, 1.1079, 1.0999, 1.1597, 1.1046, 1.0695, 1.1001, 1.0349, 1.0291, 1.0657, 1.1304, 1.0735, 1.0185, 1.0328, 1.1234, 1.0518, 1.0644, 1.0143, 1.0235, 1.0851, 0.9896, 1.0252, 1.0591, 0.9895, 1.0746, 1.0355, 0.9837, 1.0401, 0.9645, 0.9601, 0.9695, 0.9731, 0.9923, 0.9541, 0.9557, 0.9665, 0.9302, 0.9666, 0.9559, 0.9267, 0.9144, 0.9139, 0.887, 0.8923, 0.8865, 0.901, 0.8778, 0.8829, 0.8881, 0.872, 0.8385, 0.8508, 0.8557, 0.8382, 0.8743, 0.852, 0.818, 0.8563, 0.845, 0.8174, 0.8439, 0.8139, 0.7974, 0.8327, 0.81, 0.8068, 0.7883, 0.7985, 0.8002, 0.7819, 0.7743, 0.7768, 0.767, 0.7783, 0.7544, 0.7534, 0.7577, 0.7657, 0.7369, 0.7476, 0.7457, 0.7371, 0.7364, 0.733, 0.7304, 0.7238, 0.714, 0.714, 0.7097, 0.7168, 0.7054, 0.7015, 0.7043, 0.7059, 0.7015, 0.7031, 0.6982, 0.7031, 0.6981, 0.6933, 0.6913, 0.6914, 0.6911, 0.6902, 0.689, 0.692, 0.6905, 0.6893, 0.6886, 0.6869, 0.6894, 0.6848, 0.6872, 0.6866, 0.685, 0.6857, 0.687, 0.6843, 0.6855]\n",
            "test err:  [0.8836, 0.7976, 0.7537, 0.7117, 0.6253, 0.5911, 0.5458, 0.5337, 0.5051, 0.4831, 0.484, 0.4705, 0.4632, 0.4415, 0.4445, 0.4399, 0.4811, 0.4466, 0.4362, 0.4095, 0.4333, 0.4219, 0.4309, 0.3829, 0.4168, 0.4114, 0.418, 0.3995, 0.4337, 0.4518, 0.3867, 0.369, 0.4043, 0.4345, 0.3534, 0.3798, 0.3796, 0.3803, 0.3913, 0.3636, 0.3972, 0.3556, 0.3671, 0.3758, 0.3768, 0.3573, 0.3648, 0.364, 0.3697, 0.3779, 0.3654, 0.3391, 0.3545, 0.344, 0.3622, 0.3589, 0.3508, 0.3312, 0.3457, 0.3412, 0.3604, 0.3456, 0.3434, 0.3293, 0.3569, 0.3412, 0.3663, 0.3376, 0.3628, 0.3206, 0.3393, 0.3308, 0.3375, 0.3328, 0.3144, 0.3241, 0.3219, 0.3201, 0.3175, 0.3089, 0.3083, 0.3269, 0.3134, 0.3157, 0.3276, 0.3124, 0.3065, 0.3062, 0.2963, 0.2944, 0.3049, 0.3162, 0.31, 0.2897, 0.2955, 0.3126, 0.3012, 0.3002, 0.2871, 0.2934, 0.3085, 0.2814, 0.2901, 0.303, 0.2866, 0.3055, 0.2915, 0.2798, 0.2965, 0.2739, 0.2777, 0.2747, 0.2779, 0.288, 0.2713, 0.2719, 0.2769, 0.2668, 0.2758, 0.2727, 0.263, 0.2586, 0.2594, 0.2551, 0.2545, 0.2537, 0.2541, 0.2536, 0.2501, 0.2533, 0.2456, 0.2406, 0.2453, 0.2428, 0.2379, 0.2455, 0.2424, 0.2294, 0.239, 0.2407, 0.2284, 0.2414, 0.2315, 0.2289, 0.2349, 0.2289, 0.2287, 0.2216, 0.2252, 0.224, 0.2188, 0.2193, 0.22, 0.2187, 0.2164, 0.2179, 0.2155, 0.2162, 0.2159, 0.208, 0.2082, 0.2137, 0.2111, 0.2046, 0.2041, 0.2061, 0.204, 0.2034, 0.2028, 0.2011, 0.2013, 0.1968, 0.1962, 0.1971, 0.1975, 0.1977, 0.1968, 0.1961, 0.1988, 0.1956, 0.1943, 0.194, 0.1942, 0.1915, 0.193, 0.1939, 0.1952, 0.1923, 0.1938, 0.193, 0.1923, 0.1935, 0.192, 0.191, 0.1925, 0.1926, 0.1923, 0.1939, 0.1915, 0.1925]\n",
            "test acc:  [0.1164, 0.2024, 0.2463, 0.2883, 0.3747, 0.4089, 0.4542, 0.4663, 0.4949, 0.5169, 0.516, 0.5295, 0.5368, 0.5585, 0.5555, 0.5601, 0.5189, 0.5534, 0.5638, 0.5905, 0.5667, 0.5781, 0.5691, 0.6171, 0.5832, 0.5886, 0.582, 0.6005, 0.5663, 0.5482, 0.6133, 0.631, 0.5957, 0.5655, 0.6466, 0.6202, 0.6204, 0.6197, 0.6087, 0.6364, 0.6028, 0.6444, 0.6329, 0.6242, 0.6232, 0.6427, 0.6352, 0.636, 0.6303, 0.6221, 0.6346, 0.6609, 0.6455, 0.656, 0.6378, 0.6411, 0.6492, 0.6688, 0.6543, 0.6588, 0.6396, 0.6544, 0.6566, 0.6707, 0.6431, 0.6588, 0.6337, 0.6624, 0.6372, 0.6794, 0.6607, 0.6692, 0.6625, 0.6672, 0.6856, 0.6759, 0.6781, 0.6799, 0.6825, 0.6911, 0.6917, 0.6731, 0.6866, 0.6843, 0.6724, 0.6876, 0.6935, 0.6938, 0.7037, 0.7056, 0.6951, 0.6838, 0.69, 0.7103, 0.7045, 0.6874, 0.6988, 0.6998, 0.7129, 0.7066, 0.6915, 0.7186, 0.7099, 0.697, 0.7134, 0.6945, 0.7085, 0.7202, 0.7035, 0.7261, 0.7223, 0.7253, 0.7221, 0.712, 0.7287, 0.7281, 0.7231, 0.7332, 0.7242, 0.7273, 0.737, 0.7414, 0.7406, 0.7449, 0.7455, 0.7463, 0.7459, 0.7464, 0.7499, 0.7467, 0.7544, 0.7594, 0.7547, 0.7572, 0.7621, 0.7545, 0.7576, 0.7706, 0.761, 0.7593, 0.7716, 0.7586, 0.7685, 0.7711, 0.7651, 0.7711, 0.7713, 0.7784, 0.7748, 0.776, 0.7812, 0.7807, 0.78, 0.7813, 0.7836, 0.7821, 0.7845, 0.7838, 0.7841, 0.792, 0.7918, 0.7863, 0.7889, 0.7954, 0.7959, 0.7939, 0.796, 0.7966, 0.7972, 0.7989, 0.7987, 0.8032, 0.8038, 0.8029, 0.8025, 0.8023, 0.8032, 0.8039, 0.8012, 0.8044, 0.8057, 0.806, 0.8058, 0.8085, 0.807, 0.8061, 0.8048, 0.8077, 0.8062, 0.807, 0.8077, 0.8065, 0.808, 0.809, 0.8075, 0.8074, 0.8077, 0.8061, 0.8085, 0.8075]\n",
            "ori train loss:  [4.1485, 3.6644, 3.3338, 3.0491, 2.7617, 2.5097, 2.3069, 2.1678, 2.0512, 1.968, 1.9044, 1.8454, 1.8039, 1.7576, 1.7171, 1.6892, 1.6604, 1.6428, 1.6173, 1.5938, 1.5809, 1.5601, 1.5485, 1.5266, 1.5141, 1.4971, 1.4961, 1.4734, 1.4702, 1.4583, 1.448, 1.433, 1.4313, 1.4152, 1.411, 1.4057, 1.3969, 1.3902, 1.379, 1.365, 1.3646, 1.3574, 1.3504, 1.3287, 1.3401, 1.325, 1.3169, 1.3176, 1.3073, 1.3004, 1.3002, 1.2859, 1.2726, 1.2732, 1.266, 1.2651, 1.2608, 1.2475, 1.2317, 1.2421, 1.2316, 1.2232, 1.217, 1.2135, 1.2063, 1.1963, 1.1926, 1.1871, 1.1781, 1.1678, 1.1628, 1.1598, 1.146, 1.1444, 1.1345, 1.1325, 1.1204, 1.1158, 1.1058, 1.0978, 1.0886, 1.0826, 1.0827, 1.0774, 1.0642, 1.0563, 1.0463, 1.0436, 1.0348, 1.0218, 1.0196, 1.01, 1.0053, 0.9932, 0.9954, 0.9845, 0.9752, 0.9616, 0.955, 0.9459, 0.9359, 0.9331, 0.9223, 0.9154, 0.9055, 0.8939, 0.8952, 0.8765, 0.8641, 0.8706, 0.8442, 0.8395, 0.8266, 0.8214, 0.8137, 0.8057, 0.7897, 0.7843, 0.7757, 0.7603, 0.7568, 0.7517, 0.741, 0.7337, 0.7162, 0.7112, 0.6941, 0.6904, 0.6786, 0.674, 0.6734, 0.6467, 0.6452, 0.6347, 0.627, 0.609, 0.6113, 0.5976, 0.5886, 0.5691, 0.5689, 0.5593, 0.5537, 0.5457, 0.5345, 0.5224, 0.5208, 0.509, 0.5045, 0.4997, 0.4858, 0.4799, 0.4699, 0.4618, 0.4543, 0.448, 0.4414, 0.4327, 0.431, 0.4231, 0.4166, 0.4074, 0.4074, 0.3996, 0.3908, 0.3842, 0.3796, 0.3773, 0.3658, 0.3637, 0.358, 0.3619, 0.3543, 0.3538, 0.3435, 0.3391, 0.3407, 0.3356, 0.3293, 0.3276, 0.3267, 0.3205, 0.3193, 0.3165, 0.3144, 0.3104, 0.3098, 0.3095, 0.3069, 0.3062, 0.3083, 0.3024, 0.306, 0.3016, 0.3016, 0.2996, 0.3011, 0.2997, 0.3022, 0.3028]\n",
            "ori train err:  [0.9395, 0.8733, 0.8149, 0.7652, 0.711, 0.656, 0.6158, 0.586, 0.5527, 0.5365, 0.5209, 0.5069, 0.4954, 0.4852, 0.4748, 0.4659, 0.4599, 0.4564, 0.4496, 0.4419, 0.4386, 0.4335, 0.4313, 0.4243, 0.4203, 0.4186, 0.4171, 0.4105, 0.4097, 0.4042, 0.4044, 0.3987, 0.3991, 0.3967, 0.3943, 0.3916, 0.388, 0.3866, 0.3853, 0.3801, 0.3806, 0.38, 0.3776, 0.3741, 0.3725, 0.3705, 0.3682, 0.3669, 0.3647, 0.3644, 0.3648, 0.3618, 0.3583, 0.3573, 0.3536, 0.3532, 0.3535, 0.3498, 0.3461, 0.3494, 0.347, 0.3424, 0.3421, 0.3394, 0.3374, 0.3352, 0.3345, 0.336, 0.3297, 0.3279, 0.3252, 0.3235, 0.3222, 0.3236, 0.3175, 0.3171, 0.3147, 0.3143, 0.3119, 0.3113, 0.3065, 0.3058, 0.3047, 0.3028, 0.2974, 0.2955, 0.2926, 0.2957, 0.2896, 0.2857, 0.2863, 0.2841, 0.2826, 0.2814, 0.2806, 0.2765, 0.2745, 0.2702, 0.269, 0.2648, 0.2629, 0.2618, 0.2547, 0.2571, 0.253, 0.2502, 0.2507, 0.2471, 0.2419, 0.2416, 0.2364, 0.2342, 0.2297, 0.2295, 0.2274, 0.2216, 0.2181, 0.2174, 0.2152, 0.2108, 0.2082, 0.2076, 0.2028, 0.1989, 0.1945, 0.194, 0.1902, 0.1869, 0.1846, 0.1829, 0.1823, 0.1743, 0.1727, 0.1689, 0.1662, 0.1602, 0.1614, 0.1565, 0.1548, 0.1482, 0.148, 0.1438, 0.1434, 0.1396, 0.1359, 0.133, 0.1324, 0.1272, 0.1267, 0.125, 0.1215, 0.1179, 0.1146, 0.1119, 0.1112, 0.1066, 0.1058, 0.1037, 0.1017, 0.0998, 0.0973, 0.0941, 0.0938, 0.092, 0.088, 0.0877, 0.0863, 0.0844, 0.0817, 0.0808, 0.0793, 0.081, 0.0789, 0.078, 0.076, 0.0734, 0.0742, 0.0731, 0.0722, 0.0721, 0.0703, 0.0688, 0.0695, 0.068, 0.0671, 0.0669, 0.0659, 0.066, 0.0657, 0.0659, 0.0647, 0.0638, 0.0654, 0.0643, 0.0636, 0.0644, 0.0644, 0.0637, 0.0647, 0.0637]\n",
            "ori train acc:  [0.0605, 0.1267, 0.1851, 0.2348, 0.289, 0.344, 0.3842, 0.414, 0.4473, 0.4635, 0.4791, 0.4931, 0.5046, 0.5148, 0.5252, 0.5341, 0.5401, 0.5436, 0.5504, 0.5581, 0.5614, 0.5665, 0.5687, 0.5757, 0.5797, 0.5814, 0.5829, 0.5895, 0.5903, 0.5958, 0.5956, 0.6013, 0.6009, 0.6033, 0.6057, 0.6084, 0.612, 0.6134, 0.6147, 0.6199, 0.6194, 0.62, 0.6224, 0.6259, 0.6275, 0.6295, 0.6318, 0.6331, 0.6353, 0.6356, 0.6352, 0.6382, 0.6417, 0.6427, 0.6464, 0.6468, 0.6465, 0.6502, 0.6539, 0.6506, 0.653, 0.6576, 0.6579, 0.6606, 0.6626, 0.6648, 0.6655, 0.664, 0.6703, 0.6721, 0.6748, 0.6765, 0.6778, 0.6764, 0.6825, 0.6829, 0.6853, 0.6857, 0.6881, 0.6887, 0.6935, 0.6942, 0.6953, 0.6972, 0.7026, 0.7045, 0.7074, 0.7043, 0.7104, 0.7143, 0.7137, 0.7159, 0.7174, 0.7186, 0.7194, 0.7235, 0.7255, 0.7298, 0.731, 0.7352, 0.7371, 0.7382, 0.7453, 0.7429, 0.747, 0.7498, 0.7493, 0.7529, 0.7581, 0.7584, 0.7636, 0.7658, 0.7703, 0.7705, 0.7726, 0.7784, 0.7819, 0.7826, 0.7848, 0.7892, 0.7918, 0.7924, 0.7972, 0.8011, 0.8055, 0.806, 0.8098, 0.8131, 0.8154, 0.8171, 0.8177, 0.8257, 0.8273, 0.8311, 0.8338, 0.8398, 0.8386, 0.8435, 0.8452, 0.8518, 0.852, 0.8562, 0.8566, 0.8604, 0.8641, 0.867, 0.8676, 0.8728, 0.8733, 0.875, 0.8785, 0.8821, 0.8854, 0.8881, 0.8888, 0.8934, 0.8942, 0.8963, 0.8983, 0.9002, 0.9027, 0.9059, 0.9062, 0.908, 0.912, 0.9123, 0.9137, 0.9156, 0.9183, 0.9192, 0.9207, 0.919, 0.9211, 0.922, 0.924, 0.9266, 0.9258, 0.9269, 0.9278, 0.9279, 0.9297, 0.9312, 0.9305, 0.932, 0.9329, 0.9331, 0.9341, 0.934, 0.9343, 0.9341, 0.9353, 0.9362, 0.9346, 0.9357, 0.9364, 0.9356, 0.9356, 0.9363, 0.9353, 0.9363]\n",
            "time:  [14.72, 12.29, 12.5, 12.38, 12.44, 12.57, 12.54, 12.62, 12.74, 12.43, 12.57, 12.74, 12.85, 12.48, 12.37, 12.32, 12.4, 12.47, 12.89, 12.43, 12.39, 12.55, 12.92, 12.33, 12.69, 12.7, 12.52, 12.6, 12.41, 12.48, 12.31, 12.34, 12.34, 12.51, 12.74, 13.08, 12.34, 12.29, 12.25, 12.39, 12.62, 12.45, 12.35, 12.84, 12.86, 12.32, 12.33, 12.39, 12.34, 12.64, 12.6, 12.69, 12.25, 12.17, 12.36, 12.28, 12.42, 12.94, 12.56, 12.71, 12.53, 12.76, 12.48, 12.34, 12.6, 12.47, 12.45, 12.19, 12.76, 12.29, 12.31, 12.69, 12.73, 12.3, 12.38, 12.43, 12.36, 12.45, 12.68, 12.53, 12.35, 12.35, 12.3, 12.25, 12.28, 12.54, 12.83, 12.47, 12.43, 12.23, 12.57, 12.5, 12.69, 12.35, 12.44, 12.41, 12.6, 12.43, 12.34, 12.44, 12.2, 12.83, 12.44, 12.62, 13.53, 12.26, 12.41, 12.31, 12.45, 12.55, 12.5, 12.58, 12.49, 12.36, 12.49, 12.37, 12.79, 12.38, 12.68, 12.68, 12.36, 12.28, 12.56, 12.36, 12.38, 12.28, 12.77, 12.43, 12.33, 12.56, 12.32, 12.6, 12.48, 12.48, 12.43, 12.33, 12.46, 12.53, 12.59, 12.63, 12.46, 12.39, 12.55, 12.47, 12.78, 12.62, 13.31, 12.35, 12.54, 12.37, 12.3, 12.91, 12.69, 12.59, 12.32, 12.69, 12.48, 12.53, 12.43, 12.58, 12.57, 12.46, 12.55, 12.34, 12.49, 12.42, 12.49, 12.36, 12.71, 12.52, 12.29, 12.88, 12.63, 12.33, 12.66, 12.55, 12.4, 12.35, 12.65, 12.63, 12.64, 12.47, 12.69, 12.23, 12.36, 12.58, 12.38, 13.01, 12.27, 12.41, 12.41, 12.82, 12.41, 12.81, 12.49, 12.37, 12.45, 12.94, 12.83, 12.6]\n"
          ]
        }
      ]
    }
  ]
}