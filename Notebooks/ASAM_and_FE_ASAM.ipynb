{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNWzes6sqvLIF6TK3JfWwUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Notebooks/ASAM_and_FE_ASAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for Adaptive variants of SAM (ASAM) and our method, FE-SAM (FE-ASAM). Make sure the files are saved in your Google Drive under the folder /content/drive/MyDrive/src before running it."
      ],
      "metadata": {
        "id": "YVPmPVxEycZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ft0km09HzYVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6xxSPnjosjX",
        "outputId": "ac213d7f-700f-46e3-c67c-b10ae19bef0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Adaptive SAM (ASAM)**"
      ],
      "metadata": {
        "id": "NsdktW46IKUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/src/trains.py \\\n",
        "    --optimizer SAM \\\n",
        "    --rho 4 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR100 \\\n",
        "    --arch resnet18 \\\n",
        "    --epochs 200 \\\n",
        "    --adaptive \\\n",
        "    --batch-size 128\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND262bIqqunT",
        "outputId": "4087af38-387e-4a53-f440-bda76a8e3077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: resnet18\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar100 dataset!\n",
            "391\n",
            "50000\n",
            "optimizer: SAM\n",
            "SAM (\n",
            "Parameter Group 0\n",
            "    adaptive: True\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 4.0\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "Epoch: [0][0/391]\tTime 0.953 (0.953)\tData 0.129 (0.129)\tLoss 4.7223 (4.7223)\tPrec@1 0.000 (0.000)\n",
            "Epoch: [0][100/391]\tTime 0.032 (0.043)\tData 0.000 (0.002)\tLoss 4.0779 (4.3885)\tPrec@1 4.688 (4.169)\n",
            "Epoch: [0][200/391]\tTime 0.033 (0.038)\tData 0.000 (0.001)\tLoss 4.0407 (4.2259)\tPrec@1 4.688 (5.391)\n",
            "Epoch: [0][300/391]\tTime 0.033 (0.036)\tData 0.000 (0.001)\tLoss 3.8498 (4.1271)\tPrec@1 12.500 (6.533)\n",
            "Epoch: [0][390/391]\tTime 0.195 (0.036)\tData 0.000 (0.001)\tLoss 3.9054 (4.0604)\tPrec@1 11.250 (7.426)\n",
            "Total time : 14.026\n",
            "Train Loss: 4.0604, Train Accuracy: 0.0743\n",
            "Test Loss : 3.7187, Test Accuracy : 0.1191 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.192 (0.192)\tData 0.140 (0.140)\tLoss 3.8649 (3.8649)\tPrec@1 8.594 (8.594)\n",
            "Epoch: [1][100/391]\tTime 0.034 (0.036)\tData 0.000 (0.002)\tLoss 3.5319 (3.7330)\tPrec@1 14.062 (11.286)\n",
            "Epoch: [1][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 3.5087 (3.6824)\tPrec@1 13.281 (12.243)\n",
            "Epoch: [1][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 3.4189 (3.6437)\tPrec@1 14.844 (12.988)\n",
            "Epoch: [1][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 3.2490 (3.6079)\tPrec@1 21.250 (13.710)\n",
            "Total time : 13.116\n",
            "Train Loss: 3.6079, Train Accuracy: 0.1371\n",
            "Test Loss : 3.4981, Test Accuracy : 0.1646 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.181 (0.181)\tData 0.140 (0.140)\tLoss 3.4696 (3.4696)\tPrec@1 14.844 (14.844)\n",
            "Epoch: [2][100/391]\tTime 0.034 (0.035)\tData 0.000 (0.002)\tLoss 3.3087 (3.3917)\tPrec@1 21.094 (17.520)\n",
            "Epoch: [2][200/391]\tTime 0.037 (0.035)\tData 0.000 (0.001)\tLoss 3.3556 (3.3554)\tPrec@1 19.531 (18.322)\n",
            "Epoch: [2][300/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 3.1487 (3.3127)\tPrec@1 20.312 (19.095)\n",
            "Epoch: [2][390/391]\tTime 0.028 (0.035)\tData 0.000 (0.001)\tLoss 3.1384 (3.2824)\tPrec@1 18.750 (19.730)\n",
            "Total time : 13.523\n",
            "Train Loss: 3.2824, Train Accuracy: 0.1973\n",
            "Test Loss : 3.0427, Test Accuracy : 0.2392 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.190 (0.190)\tData 0.148 (0.148)\tLoss 2.9387 (2.9387)\tPrec@1 22.656 (22.656)\n",
            "Epoch: [3][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 2.7845 (3.0594)\tPrec@1 30.469 (23.391)\n",
            "Epoch: [3][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 3.2587 (3.0520)\tPrec@1 21.875 (23.850)\n",
            "Epoch: [3][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 3.0432 (3.0213)\tPrec@1 21.875 (24.369)\n",
            "Epoch: [3][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 3.0528 (2.9919)\tPrec@1 18.750 (24.952)\n",
            "Total time : 13.002\n",
            "Train Loss: 2.9919, Train Accuracy: 0.2495\n",
            "Test Loss : 2.8326, Test Accuracy : 0.2782 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.183 (0.183)\tData 0.143 (0.143)\tLoss 2.8043 (2.8043)\tPrec@1 26.562 (26.562)\n",
            "Epoch: [4][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 2.7571 (2.7638)\tPrec@1 27.344 (29.301)\n",
            "Epoch: [4][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 2.6937 (2.7474)\tPrec@1 28.125 (29.862)\n",
            "Epoch: [4][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 2.6356 (2.7109)\tPrec@1 36.719 (30.640)\n",
            "Epoch: [4][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 2.9142 (2.6782)\tPrec@1 25.000 (31.232)\n",
            "Total time : 13.060\n",
            "Train Loss: 2.6782, Train Accuracy: 0.3123\n",
            "Test Loss : 2.6018, Test Accuracy : 0.3268 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.203 (0.203)\tData 0.149 (0.149)\tLoss 2.4367 (2.4367)\tPrec@1 38.281 (38.281)\n",
            "Epoch: [5][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 2.2665 (2.4492)\tPrec@1 39.062 (35.907)\n",
            "Epoch: [5][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 2.4690 (2.4412)\tPrec@1 33.594 (36.011)\n",
            "Epoch: [5][300/391]\tTime 0.037 (0.033)\tData 0.000 (0.001)\tLoss 2.1680 (2.4139)\tPrec@1 46.094 (36.737)\n",
            "Epoch: [5][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 2.2040 (2.3911)\tPrec@1 45.000 (37.234)\n",
            "Total time : 13.067\n",
            "Train Loss: 2.3911, Train Accuracy: 0.3723\n",
            "Test Loss : 2.1857, Test Accuracy : 0.4127 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.203 (0.203)\tData 0.140 (0.140)\tLoss 2.3950 (2.3950)\tPrec@1 37.500 (37.500)\n",
            "Epoch: [6][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 2.3687 (2.2181)\tPrec@1 37.500 (41.607)\n",
            "Epoch: [6][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 2.1198 (2.1980)\tPrec@1 43.750 (41.873)\n",
            "Epoch: [6][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 2.3607 (2.1873)\tPrec@1 36.719 (42.019)\n",
            "Epoch: [6][390/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 2.1206 (2.1737)\tPrec@1 43.750 (42.372)\n",
            "Total time : 13.052\n",
            "Train Loss: 2.1737, Train Accuracy: 0.4237\n",
            "Test Loss : 1.9874, Test Accuracy : 0.4595 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.185 (0.185)\tData 0.141 (0.141)\tLoss 1.8137 (1.8137)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [7][100/391]\tTime 0.036 (0.036)\tData 0.000 (0.002)\tLoss 2.0347 (2.0301)\tPrec@1 48.438 (46.419)\n",
            "Epoch: [7][200/391]\tTime 0.036 (0.035)\tData 0.000 (0.001)\tLoss 2.3620 (2.0233)\tPrec@1 32.031 (45.868)\n",
            "Epoch: [7][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 2.0426 (2.0258)\tPrec@1 43.750 (45.775)\n",
            "Epoch: [7][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 1.8904 (2.0164)\tPrec@1 48.750 (45.984)\n",
            "Total time : 13.313\n",
            "Train Loss: 2.0164, Train Accuracy: 0.4598\n",
            "Test Loss : 1.9518, Test Accuracy : 0.4653 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.191 (0.191)\tData 0.150 (0.150)\tLoss 1.9317 (1.9317)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [8][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 2.1101 (1.8991)\tPrec@1 45.312 (49.134)\n",
            "Epoch: [8][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.9291 (1.8996)\tPrec@1 46.875 (48.951)\n",
            "Epoch: [8][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.8722 (1.8980)\tPrec@1 48.438 (49.068)\n",
            "Epoch: [8][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.8489 (1.8926)\tPrec@1 43.750 (49.100)\n",
            "Total time : 12.792\n",
            "Train Loss: 1.8926, Train Accuracy: 0.4910\n",
            "Test Loss : 1.7853, Test Accuracy : 0.5108 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.181 (0.181)\tData 0.142 (0.142)\tLoss 1.6739 (1.6739)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [9][100/391]\tTime 0.035 (0.035)\tData 0.000 (0.002)\tLoss 1.7025 (1.8071)\tPrec@1 52.344 (51.300)\n",
            "Epoch: [9][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.9455 (1.8053)\tPrec@1 41.406 (51.217)\n",
            "Epoch: [9][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.6099 (1.8014)\tPrec@1 56.250 (51.072)\n",
            "Epoch: [9][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.9739 (1.7995)\tPrec@1 41.250 (51.188)\n",
            "Total time : 12.937\n",
            "Train Loss: 1.7995, Train Accuracy: 0.5119\n",
            "Test Loss : 1.7450, Test Accuracy : 0.5162 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.193 (0.193)\tData 0.152 (0.152)\tLoss 1.6652 (1.6652)\tPrec@1 52.344 (52.344)\n",
            "Epoch: [10][100/391]\tTime 0.032 (0.037)\tData 0.000 (0.002)\tLoss 1.8353 (1.7214)\tPrec@1 47.656 (53.543)\n",
            "Epoch: [10][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.7947 (1.7265)\tPrec@1 53.906 (53.463)\n",
            "Epoch: [10][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 1.6797 (1.7239)\tPrec@1 52.344 (53.520)\n",
            "Epoch: [10][390/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.5547 (1.7298)\tPrec@1 62.500 (53.248)\n",
            "Total time : 13.090\n",
            "Train Loss: 1.7298, Train Accuracy: 0.5325\n",
            "Test Loss : 1.6601, Test Accuracy : 0.5362 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 1.8213 (1.8213)\tPrec@1 50.000 (50.000)\n",
            "Epoch: [11][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 1.8017 (1.6354)\tPrec@1 46.875 (55.941)\n",
            "Epoch: [11][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.5722 (1.6543)\tPrec@1 52.344 (55.243)\n",
            "Epoch: [11][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.7590 (1.6658)\tPrec@1 49.219 (54.882)\n",
            "Epoch: [11][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.6263 (1.6704)\tPrec@1 55.000 (54.778)\n",
            "Total time : 13.004\n",
            "Train Loss: 1.6704, Train Accuracy: 0.5478\n",
            "Test Loss : 1.6684, Test Accuracy : 0.5414 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.185 (0.185)\tData 0.139 (0.139)\tLoss 1.7354 (1.7354)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [12][100/391]\tTime 0.034 (0.035)\tData 0.000 (0.002)\tLoss 1.6992 (1.6228)\tPrec@1 50.781 (55.964)\n",
            "Epoch: [12][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 1.5869 (1.6238)\tPrec@1 55.469 (56.130)\n",
            "Epoch: [12][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 1.7916 (1.6220)\tPrec@1 48.438 (55.998)\n",
            "Epoch: [12][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.7855 (1.6241)\tPrec@1 58.750 (55.892)\n",
            "Total time : 13.051\n",
            "Train Loss: 1.6241, Train Accuracy: 0.5589\n",
            "Test Loss : 1.6535, Test Accuracy : 0.5360 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.188 (0.188)\tData 0.147 (0.147)\tLoss 1.4960 (1.4960)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [13][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.2923 (1.5603)\tPrec@1 67.188 (57.658)\n",
            "Epoch: [13][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.5603 (1.5775)\tPrec@1 57.031 (57.171)\n",
            "Epoch: [13][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.6519 (1.5777)\tPrec@1 51.562 (57.132)\n",
            "Epoch: [13][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.5766 (1.5745)\tPrec@1 52.500 (57.208)\n",
            "Total time : 12.957\n",
            "Train Loss: 1.5745, Train Accuracy: 0.5721\n",
            "Test Loss : 1.5621, Test Accuracy : 0.5647 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.192 (0.192)\tData 0.151 (0.151)\tLoss 1.4400 (1.4400)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [14][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 1.4889 (1.5118)\tPrec@1 57.812 (59.073)\n",
            "Epoch: [14][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 1.8106 (1.5211)\tPrec@1 46.875 (58.594)\n",
            "Epoch: [14][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 1.4909 (1.5259)\tPrec@1 57.812 (58.373)\n",
            "Epoch: [14][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.5860 (1.5288)\tPrec@1 58.750 (58.350)\n",
            "Total time : 13.227\n",
            "Train Loss: 1.5288, Train Accuracy: 0.5835\n",
            "Test Loss : 1.5417, Test Accuracy : 0.5703 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 1.4663 (1.4663)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [15][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.3560 (1.4697)\tPrec@1 62.500 (59.893)\n",
            "Epoch: [15][200/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 1.5341 (1.4859)\tPrec@1 53.906 (59.445)\n",
            "Epoch: [15][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.4654 (1.4927)\tPrec@1 60.938 (59.230)\n",
            "Epoch: [15][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.5700 (1.5006)\tPrec@1 57.500 (59.126)\n",
            "Total time : 13.107\n",
            "Train Loss: 1.5006, Train Accuracy: 0.5913\n",
            "Test Loss : 1.5687, Test Accuracy : 0.5515 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.186 (0.186)\tData 0.147 (0.147)\tLoss 1.5111 (1.5111)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [16][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.2648 (1.4653)\tPrec@1 64.062 (60.365)\n",
            "Epoch: [16][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.4586 (1.4715)\tPrec@1 60.156 (60.152)\n",
            "Epoch: [16][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.3973 (1.4763)\tPrec@1 57.031 (60.019)\n",
            "Epoch: [16][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.4902 (1.4718)\tPrec@1 55.000 (60.002)\n",
            "Total time : 12.841\n",
            "Train Loss: 1.4718, Train Accuracy: 0.6000\n",
            "Test Loss : 1.6174, Test Accuracy : 0.5514 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.193 (0.193)\tData 0.152 (0.152)\tLoss 1.4879 (1.4879)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [17][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 1.5011 (1.4255)\tPrec@1 53.906 (61.224)\n",
            "Epoch: [17][200/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 1.5188 (1.4324)\tPrec@1 59.375 (60.864)\n",
            "Epoch: [17][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.5107 (1.4444)\tPrec@1 59.375 (60.481)\n",
            "Epoch: [17][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.3030 (1.4547)\tPrec@1 62.500 (60.100)\n",
            "Total time : 12.992\n",
            "Train Loss: 1.4547, Train Accuracy: 0.6010\n",
            "Test Loss : 1.6261, Test Accuracy : 0.5477 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.188 (0.188)\tData 0.142 (0.142)\tLoss 1.3720 (1.3720)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [18][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.3742 (1.3926)\tPrec@1 57.812 (61.564)\n",
            "Epoch: [18][200/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 1.5189 (1.4201)\tPrec@1 58.594 (61.077)\n",
            "Epoch: [18][300/391]\tTime 0.049 (0.034)\tData 0.000 (0.001)\tLoss 1.5653 (1.4302)\tPrec@1 58.594 (60.828)\n",
            "Epoch: [18][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.6653 (1.4244)\tPrec@1 56.250 (60.952)\n",
            "Total time : 13.118\n",
            "Train Loss: 1.4244, Train Accuracy: 0.6095\n",
            "Test Loss : 1.4932, Test Accuracy : 0.5736 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.186 (0.186)\tData 0.142 (0.142)\tLoss 1.1299 (1.1299)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [19][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.2408 (1.3636)\tPrec@1 71.094 (62.732)\n",
            "Epoch: [19][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.3353 (1.3704)\tPrec@1 67.188 (62.760)\n",
            "Epoch: [19][300/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 1.2743 (1.3899)\tPrec@1 68.750 (62.121)\n",
            "Epoch: [19][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.4726 (1.3976)\tPrec@1 55.000 (61.836)\n",
            "Total time : 13.175\n",
            "Train Loss: 1.3976, Train Accuracy: 0.6184\n",
            "Test Loss : 1.4065, Test Accuracy : 0.6037 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.196 (0.196)\tData 0.153 (0.153)\tLoss 1.6595 (1.6595)\tPrec@1 57.031 (57.031)\n",
            "Epoch: [20][100/391]\tTime 0.033 (0.036)\tData 0.000 (0.002)\tLoss 1.2766 (1.3751)\tPrec@1 70.312 (62.879)\n",
            "Epoch: [20][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 1.3829 (1.3716)\tPrec@1 63.281 (62.679)\n",
            "Epoch: [20][300/391]\tTime 0.037 (0.035)\tData 0.000 (0.001)\tLoss 1.5305 (1.3823)\tPrec@1 57.031 (62.292)\n",
            "Epoch: [20][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.3797 (1.3846)\tPrec@1 58.750 (62.288)\n",
            "Total time : 13.458\n",
            "Train Loss: 1.3846, Train Accuracy: 0.6229\n",
            "Test Loss : 1.5483, Test Accuracy : 0.5601 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.183 (0.183)\tData 0.144 (0.144)\tLoss 1.3956 (1.3956)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [21][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1721 (1.3281)\tPrec@1 71.094 (63.869)\n",
            "Epoch: [21][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.3319 (1.3410)\tPrec@1 60.938 (63.577)\n",
            "Epoch: [21][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.5996 (1.3542)\tPrec@1 59.375 (63.201)\n",
            "Epoch: [21][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 1.7006 (1.3685)\tPrec@1 51.250 (62.850)\n",
            "Total time : 12.597\n",
            "Train Loss: 1.3685, Train Accuracy: 0.6285\n",
            "Test Loss : 1.3833, Test Accuracy : 0.6085 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.192 (0.192)\tData 0.153 (0.153)\tLoss 1.0812 (1.0812)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [22][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 1.1082 (1.3185)\tPrec@1 70.312 (64.596)\n",
            "Epoch: [22][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.3050 (1.3275)\tPrec@1 65.625 (64.047)\n",
            "Epoch: [22][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.4316 (1.3364)\tPrec@1 64.844 (63.660)\n",
            "Epoch: [22][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.3634 (1.3442)\tPrec@1 62.500 (63.474)\n",
            "Total time : 12.954\n",
            "Train Loss: 1.3442, Train Accuracy: 0.6347\n",
            "Test Loss : 1.3797, Test Accuracy : 0.6104 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.195 (0.195)\tData 0.149 (0.149)\tLoss 1.1885 (1.1885)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [23][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 1.2752 (1.2953)\tPrec@1 65.625 (64.728)\n",
            "Epoch: [23][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.3101 (1.3094)\tPrec@1 62.500 (64.288)\n",
            "Epoch: [23][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.1486 (1.3182)\tPrec@1 72.656 (64.156)\n",
            "Epoch: [23][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.4224 (1.3237)\tPrec@1 66.250 (63.962)\n",
            "Total time : 12.915\n",
            "Train Loss: 1.3237, Train Accuracy: 0.6396\n",
            "Test Loss : 1.4266, Test Accuracy : 0.5988 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.211 (0.211)\tData 0.167 (0.167)\tLoss 1.2974 (1.2974)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [24][100/391]\tTime 0.031 (0.037)\tData 0.000 (0.002)\tLoss 1.3073 (1.2757)\tPrec@1 63.281 (65.354)\n",
            "Epoch: [24][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.0965 (1.2881)\tPrec@1 71.875 (64.918)\n",
            "Epoch: [24][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.2909 (1.3009)\tPrec@1 64.844 (64.563)\n",
            "Epoch: [24][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.2836 (1.3113)\tPrec@1 66.250 (64.290)\n",
            "Total time : 13.074\n",
            "Train Loss: 1.3113, Train Accuracy: 0.6429\n",
            "Test Loss : 1.4268, Test Accuracy : 0.5933 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.181 (0.181)\tData 0.140 (0.140)\tLoss 1.1939 (1.1939)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [25][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.2157 (1.2640)\tPrec@1 70.312 (65.447)\n",
            "Epoch: [25][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.2516 (1.2744)\tPrec@1 67.969 (65.108)\n",
            "Epoch: [25][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.2035 (1.2908)\tPrec@1 64.844 (64.776)\n",
            "Epoch: [25][390/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.3971 (1.2961)\tPrec@1 60.000 (64.662)\n",
            "Total time : 12.732\n",
            "Train Loss: 1.2961, Train Accuracy: 0.6466\n",
            "Test Loss : 1.4595, Test Accuracy : 0.5949 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.198 (0.198)\tData 0.142 (0.142)\tLoss 1.4041 (1.4041)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [26][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.2316 (1.2504)\tPrec@1 67.188 (66.569)\n",
            "Epoch: [26][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.2397 (1.2710)\tPrec@1 72.656 (65.652)\n",
            "Epoch: [26][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.3033 (1.2852)\tPrec@1 65.625 (65.184)\n",
            "Epoch: [26][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.4589 (1.2910)\tPrec@1 56.250 (64.926)\n",
            "Total time : 12.902\n",
            "Train Loss: 1.2910, Train Accuracy: 0.6493\n",
            "Test Loss : 1.4002, Test Accuracy : 0.6009 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.182 (0.182)\tData 0.142 (0.142)\tLoss 1.2235 (1.2235)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [27][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 1.2657 (1.2307)\tPrec@1 64.844 (66.592)\n",
            "Epoch: [27][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.2684 (1.2456)\tPrec@1 67.969 (66.010)\n",
            "Epoch: [27][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.4101 (1.2638)\tPrec@1 61.719 (65.461)\n",
            "Epoch: [27][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.3264 (1.2726)\tPrec@1 60.000 (65.308)\n",
            "Total time : 12.820\n",
            "Train Loss: 1.2726, Train Accuracy: 0.6531\n",
            "Test Loss : 1.3624, Test Accuracy : 0.6103 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.189 (0.189)\tData 0.141 (0.141)\tLoss 1.1562 (1.1562)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [28][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.3218 (1.2281)\tPrec@1 61.719 (66.654)\n",
            "Epoch: [28][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.1517 (1.2393)\tPrec@1 73.438 (66.414)\n",
            "Epoch: [28][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.3485 (1.2559)\tPrec@1 62.500 (65.820)\n",
            "Epoch: [28][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.2743 (1.2678)\tPrec@1 61.250 (65.456)\n",
            "Total time : 12.908\n",
            "Train Loss: 1.2678, Train Accuracy: 0.6546\n",
            "Test Loss : 1.5096, Test Accuracy : 0.5785 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.190 (0.190)\tData 0.145 (0.145)\tLoss 1.3377 (1.3377)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [29][100/391]\tTime 0.037 (0.036)\tData 0.000 (0.002)\tLoss 1.2030 (1.2042)\tPrec@1 64.062 (67.427)\n",
            "Epoch: [29][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 1.2245 (1.2298)\tPrec@1 63.281 (66.484)\n",
            "Epoch: [29][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 1.1423 (1.2312)\tPrec@1 70.312 (66.409)\n",
            "Epoch: [29][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.3206 (1.2505)\tPrec@1 60.000 (65.922)\n",
            "Total time : 13.130\n",
            "Train Loss: 1.2505, Train Accuracy: 0.6592\n",
            "Test Loss : 1.3562, Test Accuracy : 0.6230 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.182 (0.182)\tData 0.142 (0.142)\tLoss 0.9569 (0.9569)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [30][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 1.3961 (1.1963)\tPrec@1 52.344 (67.249)\n",
            "Epoch: [30][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.1850 (1.2191)\tPrec@1 66.406 (66.686)\n",
            "Epoch: [30][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.4736 (1.2265)\tPrec@1 57.812 (66.505)\n",
            "Epoch: [30][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.2107 (1.2397)\tPrec@1 66.250 (66.160)\n",
            "Total time : 13.364\n",
            "Train Loss: 1.2397, Train Accuracy: 0.6616\n",
            "Test Loss : 1.3036, Test Accuracy : 0.6317 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.215 (0.215)\tData 0.170 (0.170)\tLoss 1.1613 (1.1613)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [31][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 1.1553 (1.1652)\tPrec@1 70.312 (68.147)\n",
            "Epoch: [31][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.3602 (1.1995)\tPrec@1 59.375 (67.125)\n",
            "Epoch: [31][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 1.3192 (1.2125)\tPrec@1 64.062 (66.679)\n",
            "Epoch: [31][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.1282 (1.2244)\tPrec@1 68.750 (66.278)\n",
            "Total time : 13.353\n",
            "Train Loss: 1.2244, Train Accuracy: 0.6628\n",
            "Test Loss : 1.3065, Test Accuracy : 0.6301 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.197 (0.197)\tData 0.146 (0.146)\tLoss 1.1091 (1.1091)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [32][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.3415 (1.1895)\tPrec@1 59.375 (67.729)\n",
            "Epoch: [32][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.1487 (1.1971)\tPrec@1 65.625 (67.242)\n",
            "Epoch: [32][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.4308 (1.2105)\tPrec@1 63.281 (66.829)\n",
            "Epoch: [32][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.0214 (1.2218)\tPrec@1 76.250 (66.620)\n",
            "Total time : 13.456\n",
            "Train Loss: 1.2218, Train Accuracy: 0.6662\n",
            "Test Loss : 1.3080, Test Accuracy : 0.6244 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.205 (0.205)\tData 0.148 (0.148)\tLoss 1.2872 (1.2872)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [33][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.2696 (1.1803)\tPrec@1 66.406 (68.162)\n",
            "Epoch: [33][200/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 1.1147 (1.1875)\tPrec@1 67.969 (67.615)\n",
            "Epoch: [33][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.2828 (1.1963)\tPrec@1 66.406 (67.361)\n",
            "Epoch: [33][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.5671 (1.2057)\tPrec@1 52.500 (67.158)\n",
            "Total time : 13.299\n",
            "Train Loss: 1.2057, Train Accuracy: 0.6716\n",
            "Test Loss : 1.4744, Test Accuracy : 0.5860 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.191 (0.191)\tData 0.144 (0.144)\tLoss 1.1919 (1.1919)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [34][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 1.0702 (1.1735)\tPrec@1 71.875 (68.510)\n",
            "Epoch: [34][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.2774 (1.1870)\tPrec@1 67.969 (67.899)\n",
            "Epoch: [34][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.3365 (1.1935)\tPrec@1 64.062 (67.434)\n",
            "Epoch: [34][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.2837 (1.2041)\tPrec@1 61.250 (67.120)\n",
            "Total time : 12.754\n",
            "Train Loss: 1.2041, Train Accuracy: 0.6712\n",
            "Test Loss : 1.3083, Test Accuracy : 0.6248 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.196 (0.196)\tData 0.145 (0.145)\tLoss 1.0009 (1.0009)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [35][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.1543 (1.1497)\tPrec@1 64.062 (68.495)\n",
            "Epoch: [35][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.9250 (1.1605)\tPrec@1 78.125 (68.315)\n",
            "Epoch: [35][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.2071 (1.1757)\tPrec@1 69.531 (67.899)\n",
            "Epoch: [35][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 1.3033 (1.1897)\tPrec@1 60.000 (67.588)\n",
            "Total time : 13.032\n",
            "Train Loss: 1.1897, Train Accuracy: 0.6759\n",
            "Test Loss : 1.2476, Test Accuracy : 0.6468 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.197 (0.197)\tData 0.141 (0.141)\tLoss 0.9504 (0.9504)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [36][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 1.1210 (1.1464)\tPrec@1 73.438 (68.619)\n",
            "Epoch: [36][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.3044 (1.1612)\tPrec@1 64.062 (68.501)\n",
            "Epoch: [36][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.1679 (1.1742)\tPrec@1 70.312 (68.270)\n",
            "Epoch: [36][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.2605 (1.1865)\tPrec@1 66.250 (67.850)\n",
            "Total time : 12.859\n",
            "Train Loss: 1.1865, Train Accuracy: 0.6785\n",
            "Test Loss : 1.4291, Test Accuracy : 0.6007 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.200 (0.200)\tData 0.148 (0.148)\tLoss 1.1774 (1.1774)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [37][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 1.0086 (1.1344)\tPrec@1 73.438 (69.647)\n",
            "Epoch: [37][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1667 (1.1425)\tPrec@1 69.531 (69.189)\n",
            "Epoch: [37][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.3677 (1.1653)\tPrec@1 67.969 (68.472)\n",
            "Epoch: [37][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.1290 (1.1765)\tPrec@1 71.250 (68.158)\n",
            "Total time : 13.037\n",
            "Train Loss: 1.1765, Train Accuracy: 0.6816\n",
            "Test Loss : 1.2388, Test Accuracy : 0.6523 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 1.1211 (1.1211)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [38][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1081 (1.1218)\tPrec@1 71.875 (69.361)\n",
            "Epoch: [38][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.3298 (1.1375)\tPrec@1 60.938 (68.956)\n",
            "Epoch: [38][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.1369 (1.1515)\tPrec@1 67.969 (68.607)\n",
            "Epoch: [38][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.1819 (1.1647)\tPrec@1 63.750 (68.178)\n",
            "Total time : 12.849\n",
            "Train Loss: 1.1647, Train Accuracy: 0.6818\n",
            "Test Loss : 1.3140, Test Accuracy : 0.6321 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.184 (0.184)\tData 0.143 (0.143)\tLoss 1.1205 (1.1205)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [39][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 1.2131 (1.1009)\tPrec@1 69.531 (70.227)\n",
            "Epoch: [39][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.3395 (1.1315)\tPrec@1 61.719 (69.376)\n",
            "Epoch: [39][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.2257 (1.1448)\tPrec@1 66.406 (68.924)\n",
            "Epoch: [39][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.1054 (1.1531)\tPrec@1 72.500 (68.702)\n",
            "Total time : 13.013\n",
            "Train Loss: 1.1531, Train Accuracy: 0.6870\n",
            "Test Loss : 1.2517, Test Accuracy : 0.6442 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.184 (0.184)\tData 0.144 (0.144)\tLoss 1.0866 (1.0866)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [40][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 1.0858 (1.0851)\tPrec@1 69.531 (70.862)\n",
            "Epoch: [40][200/391]\tTime 0.038 (0.034)\tData 0.000 (0.001)\tLoss 1.2772 (1.1149)\tPrec@1 66.406 (69.873)\n",
            "Epoch: [40][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 1.2370 (1.1294)\tPrec@1 65.625 (69.409)\n",
            "Epoch: [40][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.3749 (1.1448)\tPrec@1 58.750 (68.986)\n",
            "Total time : 13.416\n",
            "Train Loss: 1.1448, Train Accuracy: 0.6899\n",
            "Test Loss : 1.2905, Test Accuracy : 0.6278 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.203 (0.203)\tData 0.147 (0.147)\tLoss 0.9301 (0.9301)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [41][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 1.0729 (1.1038)\tPrec@1 66.406 (70.019)\n",
            "Epoch: [41][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 1.2268 (1.1191)\tPrec@1 64.844 (69.679)\n",
            "Epoch: [41][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1417 (1.1301)\tPrec@1 67.969 (69.248)\n",
            "Epoch: [41][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.0818 (1.1374)\tPrec@1 72.500 (69.070)\n",
            "Total time : 13.131\n",
            "Train Loss: 1.1374, Train Accuracy: 0.6907\n",
            "Test Loss : 1.2112, Test Accuracy : 0.6537 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.205 (0.205)\tData 0.148 (0.148)\tLoss 1.0981 (1.0981)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [42][100/391]\tTime 0.037 (0.035)\tData 0.000 (0.002)\tLoss 0.9602 (1.0751)\tPrec@1 73.438 (70.653)\n",
            "Epoch: [42][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1945 (1.0947)\tPrec@1 67.188 (70.075)\n",
            "Epoch: [42][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.1931 (1.1192)\tPrec@1 64.844 (69.448)\n",
            "Epoch: [42][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.1706 (1.1324)\tPrec@1 67.500 (69.088)\n",
            "Total time : 13.130\n",
            "Train Loss: 1.1324, Train Accuracy: 0.6909\n",
            "Test Loss : 1.3305, Test Accuracy : 0.6263 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.201 (0.201)\tData 0.162 (0.162)\tLoss 0.9631 (0.9631)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [43][100/391]\tTime 0.036 (0.035)\tData 0.000 (0.002)\tLoss 1.1064 (1.0813)\tPrec@1 71.094 (70.653)\n",
            "Epoch: [43][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.0763 (1.0917)\tPrec@1 75.000 (70.569)\n",
            "Epoch: [43][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.2225 (1.1102)\tPrec@1 65.625 (69.941)\n",
            "Epoch: [43][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.2732 (1.1206)\tPrec@1 65.000 (69.604)\n",
            "Total time : 12.848\n",
            "Train Loss: 1.1206, Train Accuracy: 0.6960\n",
            "Test Loss : 1.2886, Test Accuracy : 0.6341 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.211 (0.211)\tData 0.168 (0.168)\tLoss 1.0724 (1.0724)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [44][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1235 (1.0896)\tPrec@1 71.094 (70.622)\n",
            "Epoch: [44][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.2281 (1.1089)\tPrec@1 64.062 (69.749)\n",
            "Epoch: [44][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.9567 (1.1161)\tPrec@1 75.000 (69.695)\n",
            "Epoch: [44][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.2928 (1.1209)\tPrec@1 68.750 (69.604)\n",
            "Total time : 12.812\n",
            "Train Loss: 1.1209, Train Accuracy: 0.6960\n",
            "Test Loss : 1.3277, Test Accuracy : 0.6225 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.180 (0.180)\tData 0.139 (0.139)\tLoss 0.9981 (0.9981)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [45][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 1.1683 (1.0666)\tPrec@1 63.281 (71.218)\n",
            "Epoch: [45][200/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 1.3187 (1.0811)\tPrec@1 64.844 (70.655)\n",
            "Epoch: [45][300/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 1.2936 (1.0911)\tPrec@1 61.719 (70.320)\n",
            "Epoch: [45][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.1233 (1.1040)\tPrec@1 71.250 (70.056)\n",
            "Total time : 12.747\n",
            "Train Loss: 1.1040, Train Accuracy: 0.7006\n",
            "Test Loss : 1.2241, Test Accuracy : 0.6466 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.198 (0.198)\tData 0.151 (0.151)\tLoss 1.2570 (1.2570)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [46][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 1.1453 (1.0718)\tPrec@1 69.531 (70.893)\n",
            "Epoch: [46][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.0990 (1.0875)\tPrec@1 73.438 (70.503)\n",
            "Epoch: [46][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.2585 (1.0906)\tPrec@1 67.969 (70.328)\n",
            "Epoch: [46][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.2788 (1.0989)\tPrec@1 65.000 (70.160)\n",
            "Total time : 12.810\n",
            "Train Loss: 1.0989, Train Accuracy: 0.7016\n",
            "Test Loss : 1.2859, Test Accuracy : 0.6413 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 1.1183 (1.1183)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [47][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 0.9702 (1.0597)\tPrec@1 75.000 (71.434)\n",
            "Epoch: [47][200/391]\tTime 0.037 (0.033)\tData 0.000 (0.001)\tLoss 1.0201 (1.0782)\tPrec@1 69.531 (70.655)\n",
            "Epoch: [47][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.8937 (1.0944)\tPrec@1 75.000 (70.209)\n",
            "Epoch: [47][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.1631 (1.0976)\tPrec@1 66.250 (70.164)\n",
            "Total time : 12.896\n",
            "Train Loss: 1.0976, Train Accuracy: 0.7016\n",
            "Test Loss : 1.2127, Test Accuracy : 0.6514 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.190 (0.190)\tData 0.150 (0.150)\tLoss 1.1097 (1.1097)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [48][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.1340 (1.0365)\tPrec@1 65.625 (71.968)\n",
            "Epoch: [48][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.2925 (1.0553)\tPrec@1 62.500 (71.455)\n",
            "Epoch: [48][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.1334 (1.0832)\tPrec@1 68.750 (70.710)\n",
            "Epoch: [48][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.1791 (1.0917)\tPrec@1 68.750 (70.478)\n",
            "Total time : 12.976\n",
            "Train Loss: 1.0917, Train Accuracy: 0.7048\n",
            "Test Loss : 1.2351, Test Accuracy : 0.6475 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.195 (0.195)\tData 0.149 (0.149)\tLoss 0.9821 (0.9821)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [49][100/391]\tTime 0.033 (0.036)\tData 0.000 (0.002)\tLoss 0.9586 (1.0327)\tPrec@1 72.656 (72.037)\n",
            "Epoch: [49][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 1.0250 (1.0592)\tPrec@1 74.219 (71.102)\n",
            "Epoch: [49][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1027 (1.0723)\tPrec@1 73.438 (70.876)\n",
            "Epoch: [49][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.3359 (1.0775)\tPrec@1 61.250 (70.704)\n",
            "Total time : 12.928\n",
            "Train Loss: 1.0775, Train Accuracy: 0.7070\n",
            "Test Loss : 1.2867, Test Accuracy : 0.6352 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.186 (0.186)\tData 0.138 (0.138)\tLoss 1.1797 (1.1797)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [50][100/391]\tTime 0.032 (0.037)\tData 0.000 (0.002)\tLoss 1.0865 (1.0666)\tPrec@1 67.188 (70.924)\n",
            "Epoch: [50][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.9890 (1.0665)\tPrec@1 75.000 (70.950)\n",
            "Epoch: [50][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.0491 (1.0753)\tPrec@1 68.750 (70.767)\n",
            "Epoch: [50][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.1478 (1.0798)\tPrec@1 68.750 (70.700)\n",
            "Total time : 12.993\n",
            "Train Loss: 1.0798, Train Accuracy: 0.7070\n",
            "Test Loss : 1.3771, Test Accuracy : 0.6219 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.196 (0.196)\tData 0.151 (0.151)\tLoss 0.8669 (0.8669)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [51][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1178 (1.0218)\tPrec@1 67.188 (72.478)\n",
            "Epoch: [51][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.1120 (1.0388)\tPrec@1 68.750 (71.821)\n",
            "Epoch: [51][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.2912 (1.0563)\tPrec@1 64.062 (71.413)\n",
            "Epoch: [51][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8045 (1.0665)\tPrec@1 81.250 (71.102)\n",
            "Total time : 12.735\n",
            "Train Loss: 1.0665, Train Accuracy: 0.7110\n",
            "Test Loss : 1.2147, Test Accuracy : 0.6631 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.186 (0.186)\tData 0.144 (0.144)\tLoss 1.1213 (1.1213)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [52][100/391]\tTime 0.036 (0.034)\tData 0.000 (0.002)\tLoss 0.9771 (1.0170)\tPrec@1 75.781 (72.625)\n",
            "Epoch: [52][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.0463 (1.0251)\tPrec@1 69.531 (72.229)\n",
            "Epoch: [52][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.2298 (1.0512)\tPrec@1 71.875 (71.447)\n",
            "Epoch: [52][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.9990 (1.0588)\tPrec@1 72.500 (71.260)\n",
            "Total time : 12.929\n",
            "Train Loss: 1.0588, Train Accuracy: 0.7126\n",
            "Test Loss : 1.1749, Test Accuracy : 0.6631 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 0.9464 (0.9464)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [53][100/391]\tTime 0.037 (0.034)\tData 0.000 (0.002)\tLoss 1.0858 (1.0200)\tPrec@1 68.750 (72.416)\n",
            "Epoch: [53][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1500 (1.0336)\tPrec@1 65.625 (71.949)\n",
            "Epoch: [53][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.0300 (1.0480)\tPrec@1 71.875 (71.556)\n",
            "Epoch: [53][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 1.0500 (1.0576)\tPrec@1 71.250 (71.362)\n",
            "Total time : 13.116\n",
            "Train Loss: 1.0576, Train Accuracy: 0.7136\n",
            "Test Loss : 1.2196, Test Accuracy : 0.6501 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.189 (0.189)\tData 0.144 (0.144)\tLoss 1.0797 (1.0797)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [54][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.1632 (1.0034)\tPrec@1 64.062 (72.826)\n",
            "Epoch: [54][200/391]\tTime 0.038 (0.034)\tData 0.000 (0.001)\tLoss 0.9157 (1.0159)\tPrec@1 75.000 (72.396)\n",
            "Epoch: [54][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1189 (1.0297)\tPrec@1 71.094 (71.917)\n",
            "Epoch: [54][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.0137 (1.0414)\tPrec@1 72.500 (71.568)\n",
            "Total time : 12.968\n",
            "Train Loss: 1.0414, Train Accuracy: 0.7157\n",
            "Test Loss : 1.2204, Test Accuracy : 0.6538 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.192 (0.192)\tData 0.145 (0.145)\tLoss 1.0642 (1.0642)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [55][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.9724 (1.0123)\tPrec@1 72.656 (72.672)\n",
            "Epoch: [55][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.9860 (1.0291)\tPrec@1 71.094 (72.178)\n",
            "Epoch: [55][300/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 1.0390 (1.0382)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [55][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.9725 (1.0441)\tPrec@1 75.000 (71.840)\n",
            "Total time : 13.062\n",
            "Train Loss: 1.0441, Train Accuracy: 0.7184\n",
            "Test Loss : 1.2409, Test Accuracy : 0.6507 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.191 (0.191)\tData 0.150 (0.150)\tLoss 0.9526 (0.9526)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [56][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.0421 (0.9858)\tPrec@1 75.781 (73.584)\n",
            "Epoch: [56][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.9735 (1.0054)\tPrec@1 72.656 (73.084)\n",
            "Epoch: [56][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 1.0619 (1.0220)\tPrec@1 67.188 (72.425)\n",
            "Epoch: [56][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.0518 (1.0342)\tPrec@1 70.000 (72.114)\n",
            "Total time : 12.735\n",
            "Train Loss: 1.0342, Train Accuracy: 0.7211\n",
            "Test Loss : 1.2373, Test Accuracy : 0.6438 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.201 (0.201)\tData 0.139 (0.139)\tLoss 0.9101 (0.9101)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [57][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.0315 (0.9706)\tPrec@1 73.438 (74.087)\n",
            "Epoch: [57][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.0863 (1.0022)\tPrec@1 75.781 (72.921)\n",
            "Epoch: [57][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.9789 (1.0175)\tPrec@1 75.781 (72.467)\n",
            "Epoch: [57][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8994 (1.0247)\tPrec@1 81.250 (72.250)\n",
            "Total time : 12.918\n",
            "Train Loss: 1.0247, Train Accuracy: 0.7225\n",
            "Test Loss : 1.1296, Test Accuracy : 0.6767 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.211 (0.211)\tData 0.151 (0.151)\tLoss 0.8721 (0.8721)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [58][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 1.0111 (0.9815)\tPrec@1 67.188 (73.507)\n",
            "Epoch: [58][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.1366 (0.9980)\tPrec@1 66.406 (72.823)\n",
            "Epoch: [58][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 1.0332 (1.0094)\tPrec@1 71.875 (72.630)\n",
            "Epoch: [58][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.0750 (1.0159)\tPrec@1 71.250 (72.446)\n",
            "Total time : 13.031\n",
            "Train Loss: 1.0159, Train Accuracy: 0.7245\n",
            "Test Loss : 1.2496, Test Accuracy : 0.6458 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.199 (0.199)\tData 0.154 (0.154)\tLoss 0.9812 (0.9812)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [59][100/391]\tTime 0.034 (0.035)\tData 0.000 (0.002)\tLoss 0.9128 (0.9920)\tPrec@1 75.781 (73.229)\n",
            "Epoch: [59][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1086 (0.9986)\tPrec@1 71.094 (72.862)\n",
            "Epoch: [59][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.0193 (1.0084)\tPrec@1 72.656 (72.742)\n",
            "Epoch: [59][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.1329 (1.0163)\tPrec@1 67.500 (72.516)\n",
            "Total time : 12.831\n",
            "Train Loss: 1.0163, Train Accuracy: 0.7252\n",
            "Test Loss : 1.2149, Test Accuracy : 0.6531 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.188 (0.188)\tData 0.143 (0.143)\tLoss 0.9815 (0.9815)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [60][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.0292 (0.9884)\tPrec@1 74.219 (73.306)\n",
            "Epoch: [60][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.9756 (0.9878)\tPrec@1 75.781 (73.266)\n",
            "Epoch: [60][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.2007 (0.9973)\tPrec@1 65.625 (73.046)\n",
            "Epoch: [60][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.0624 (1.0042)\tPrec@1 75.000 (72.780)\n",
            "Total time : 12.942\n",
            "Train Loss: 1.0042, Train Accuracy: 0.7278\n",
            "Test Loss : 1.2189, Test Accuracy : 0.6505 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.186 (0.186)\tData 0.146 (0.146)\tLoss 0.9632 (0.9632)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [61][100/391]\tTime 0.038 (0.034)\tData 0.000 (0.002)\tLoss 1.1295 (0.9643)\tPrec@1 73.438 (74.288)\n",
            "Epoch: [61][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.9642 (0.9819)\tPrec@1 74.219 (73.783)\n",
            "Epoch: [61][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.0549 (0.9863)\tPrec@1 69.531 (73.547)\n",
            "Epoch: [61][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.9328 (1.0005)\tPrec@1 75.000 (73.034)\n",
            "Total time : 12.903\n",
            "Train Loss: 1.0005, Train Accuracy: 0.7303\n",
            "Test Loss : 1.1620, Test Accuracy : 0.6668 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.182 (0.182)\tData 0.142 (0.142)\tLoss 0.8955 (0.8955)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [62][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.7991 (0.9658)\tPrec@1 80.469 (73.894)\n",
            "Epoch: [62][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.1353 (0.9739)\tPrec@1 60.156 (73.675)\n",
            "Epoch: [62][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.0159 (0.9901)\tPrec@1 71.875 (73.328)\n",
            "Epoch: [62][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.8089 (0.9963)\tPrec@1 78.750 (73.162)\n",
            "Total time : 12.719\n",
            "Train Loss: 0.9963, Train Accuracy: 0.7316\n",
            "Test Loss : 1.1329, Test Accuracy : 0.6784 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 0.8607 (0.8607)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [63][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 1.0035 (0.9470)\tPrec@1 80.469 (74.869)\n",
            "Epoch: [63][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.0886 (0.9685)\tPrec@1 68.750 (74.052)\n",
            "Epoch: [63][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 1.1168 (0.9814)\tPrec@1 70.312 (73.562)\n",
            "Epoch: [63][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.2204 (0.9893)\tPrec@1 70.000 (73.358)\n",
            "Total time : 12.899\n",
            "Train Loss: 0.9893, Train Accuracy: 0.7336\n",
            "Test Loss : 1.1172, Test Accuracy : 0.6787 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.200 (0.200)\tData 0.158 (0.158)\tLoss 0.8239 (0.8239)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [64][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.1055 (0.9342)\tPrec@1 68.750 (75.224)\n",
            "Epoch: [64][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.9398 (0.9592)\tPrec@1 74.219 (74.433)\n",
            "Epoch: [64][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.0048 (0.9752)\tPrec@1 75.000 (73.957)\n",
            "Epoch: [64][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.9738 (0.9825)\tPrec@1 70.000 (73.582)\n",
            "Total time : 12.947\n",
            "Train Loss: 0.9825, Train Accuracy: 0.7358\n",
            "Test Loss : 1.2076, Test Accuracy : 0.6514 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.201 (0.201)\tData 0.149 (0.149)\tLoss 0.9040 (0.9040)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [65][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 1.0079 (0.9283)\tPrec@1 74.219 (75.371)\n",
            "Epoch: [65][200/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 1.0038 (0.9469)\tPrec@1 74.219 (74.604)\n",
            "Epoch: [65][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.8877 (0.9622)\tPrec@1 79.688 (74.120)\n",
            "Epoch: [65][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.9798 (0.9758)\tPrec@1 73.750 (73.648)\n",
            "Total time : 13.072\n",
            "Train Loss: 0.9758, Train Accuracy: 0.7365\n",
            "Test Loss : 1.1142, Test Accuracy : 0.6764 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 0.9241 (0.9241)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [66][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 1.0023 (0.9422)\tPrec@1 71.875 (74.667)\n",
            "Epoch: [66][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8016 (0.9469)\tPrec@1 80.469 (74.405)\n",
            "Epoch: [66][300/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.9057 (0.9608)\tPrec@1 78.906 (73.985)\n",
            "Epoch: [66][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.0294 (0.9675)\tPrec@1 70.000 (73.878)\n",
            "Total time : 12.908\n",
            "Train Loss: 0.9675, Train Accuracy: 0.7388\n",
            "Test Loss : 1.2268, Test Accuracy : 0.6562 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.182 (0.182)\tData 0.141 (0.141)\tLoss 0.7432 (0.7432)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [67][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.8709 (0.9242)\tPrec@1 80.469 (75.596)\n",
            "Epoch: [67][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.8989 (0.9426)\tPrec@1 76.562 (74.833)\n",
            "Epoch: [67][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9824 (0.9513)\tPrec@1 71.094 (74.541)\n",
            "Epoch: [67][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.9345 (0.9642)\tPrec@1 77.500 (74.108)\n",
            "Total time : 12.717\n",
            "Train Loss: 0.9642, Train Accuracy: 0.7411\n",
            "Test Loss : 1.1095, Test Accuracy : 0.6842 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.211 (0.211)\tData 0.152 (0.152)\tLoss 0.9691 (0.9691)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [68][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 0.8868 (0.9295)\tPrec@1 74.219 (75.054)\n",
            "Epoch: [68][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.8853 (0.9414)\tPrec@1 75.000 (74.720)\n",
            "Epoch: [68][300/391]\tTime 0.034 (0.034)\tData 0.000 (0.001)\tLoss 1.1089 (0.9491)\tPrec@1 69.531 (74.374)\n",
            "Epoch: [68][390/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.8743 (0.9541)\tPrec@1 76.250 (74.188)\n",
            "Total time : 13.252\n",
            "Train Loss: 0.9541, Train Accuracy: 0.7419\n",
            "Test Loss : 1.1151, Test Accuracy : 0.6807 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.204 (0.204)\tData 0.158 (0.158)\tLoss 0.7696 (0.7696)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [69][100/391]\tTime 0.033 (0.037)\tData 0.000 (0.002)\tLoss 0.9980 (0.8976)\tPrec@1 76.562 (75.735)\n",
            "Epoch: [69][200/391]\tTime 0.036 (0.036)\tData 0.000 (0.001)\tLoss 1.0296 (0.9129)\tPrec@1 72.656 (75.587)\n",
            "Epoch: [69][300/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 0.9215 (0.9300)\tPrec@1 75.000 (75.062)\n",
            "Epoch: [69][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.7484 (0.9396)\tPrec@1 86.250 (74.818)\n",
            "Total time : 13.341\n",
            "Train Loss: 0.9396, Train Accuracy: 0.7482\n",
            "Test Loss : 1.2229, Test Accuracy : 0.6505 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.195 (0.195)\tData 0.149 (0.149)\tLoss 0.8850 (0.8850)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [70][100/391]\tTime 0.035 (0.036)\tData 0.000 (0.002)\tLoss 0.9509 (0.9016)\tPrec@1 75.781 (76.176)\n",
            "Epoch: [70][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.0368 (0.9092)\tPrec@1 73.438 (75.781)\n",
            "Epoch: [70][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 1.1206 (0.9230)\tPrec@1 67.969 (75.249)\n",
            "Epoch: [70][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 1.3189 (0.9361)\tPrec@1 63.750 (74.898)\n",
            "Total time : 12.974\n",
            "Train Loss: 0.9361, Train Accuracy: 0.7490\n",
            "Test Loss : 1.2033, Test Accuracy : 0.6640 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.187 (0.187)\tData 0.141 (0.141)\tLoss 0.7931 (0.7931)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [71][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.9869 (0.9073)\tPrec@1 72.656 (75.781)\n",
            "Epoch: [71][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.9876 (0.9155)\tPrec@1 75.000 (75.560)\n",
            "Epoch: [71][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.9171 (0.9317)\tPrec@1 75.000 (74.891)\n",
            "Epoch: [71][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.8032 (0.9361)\tPrec@1 81.250 (74.784)\n",
            "Total time : 13.351\n",
            "Train Loss: 0.9361, Train Accuracy: 0.7478\n",
            "Test Loss : 1.1196, Test Accuracy : 0.6777 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.204 (0.204)\tData 0.159 (0.159)\tLoss 0.8667 (0.8667)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [72][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.9660 (0.8888)\tPrec@1 68.750 (76.222)\n",
            "Epoch: [72][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.8534 (0.9125)\tPrec@1 75.781 (75.711)\n",
            "Epoch: [72][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.7748 (0.9255)\tPrec@1 81.250 (75.153)\n",
            "Epoch: [72][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8543 (0.9305)\tPrec@1 77.500 (75.008)\n",
            "Total time : 13.064\n",
            "Train Loss: 0.9305, Train Accuracy: 0.7501\n",
            "Test Loss : 1.1115, Test Accuracy : 0.6832 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.186 (0.186)\tData 0.146 (0.146)\tLoss 0.7639 (0.7639)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [73][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 1.0431 (0.8622)\tPrec@1 69.531 (76.887)\n",
            "Epoch: [73][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.9347 (0.8783)\tPrec@1 71.094 (76.290)\n",
            "Epoch: [73][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.8772 (0.9034)\tPrec@1 78.125 (75.740)\n",
            "Epoch: [73][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.6759 (0.9230)\tPrec@1 83.750 (75.086)\n",
            "Total time : 13.210\n",
            "Train Loss: 0.9230, Train Accuracy: 0.7509\n",
            "Test Loss : 1.1346, Test Accuracy : 0.6722 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.207 (0.207)\tData 0.146 (0.146)\tLoss 0.8100 (0.8100)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [74][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 0.7691 (0.8920)\tPrec@1 80.469 (76.129)\n",
            "Epoch: [74][200/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 1.0710 (0.9006)\tPrec@1 70.312 (75.801)\n",
            "Epoch: [74][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.8332 (0.9101)\tPrec@1 75.000 (75.519)\n",
            "Epoch: [74][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.9049 (0.9151)\tPrec@1 72.500 (75.370)\n",
            "Total time : 13.220\n",
            "Train Loss: 0.9151, Train Accuracy: 0.7537\n",
            "Test Loss : 1.0386, Test Accuracy : 0.7073 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.186 (0.186)\tData 0.146 (0.146)\tLoss 0.9027 (0.9027)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [75][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.9294 (0.8602)\tPrec@1 81.250 (77.235)\n",
            "Epoch: [75][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.0025 (0.8832)\tPrec@1 70.312 (76.263)\n",
            "Epoch: [75][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.7641 (0.8968)\tPrec@1 78.125 (75.810)\n",
            "Epoch: [75][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.6162 (0.9048)\tPrec@1 91.250 (75.638)\n",
            "Total time : 13.110\n",
            "Train Loss: 0.9048, Train Accuracy: 0.7564\n",
            "Test Loss : 1.1022, Test Accuracy : 0.6876 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.184 (0.184)\tData 0.142 (0.142)\tLoss 0.9686 (0.9686)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [76][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.8593 (0.8564)\tPrec@1 75.781 (77.266)\n",
            "Epoch: [76][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.9681 (0.8742)\tPrec@1 76.562 (76.706)\n",
            "Epoch: [76][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.8487 (0.8780)\tPrec@1 74.219 (76.505)\n",
            "Epoch: [76][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 1.1377 (0.8917)\tPrec@1 67.500 (76.112)\n",
            "Total time : 13.085\n",
            "Train Loss: 0.8917, Train Accuracy: 0.7611\n",
            "Test Loss : 1.0894, Test Accuracy : 0.6926 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.185 (0.185)\tData 0.144 (0.144)\tLoss 0.7819 (0.7819)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [77][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.8242 (0.8453)\tPrec@1 78.125 (77.483)\n",
            "Epoch: [77][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.8726 (0.8606)\tPrec@1 79.688 (76.912)\n",
            "Epoch: [77][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 1.0340 (0.8801)\tPrec@1 70.312 (76.319)\n",
            "Epoch: [77][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.9626 (0.8903)\tPrec@1 73.750 (76.056)\n",
            "Total time : 12.865\n",
            "Train Loss: 0.8903, Train Accuracy: 0.7606\n",
            "Test Loss : 1.0400, Test Accuracy : 0.7048 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.188 (0.188)\tData 0.148 (0.148)\tLoss 0.8661 (0.8661)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [78][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.8421 (0.8438)\tPrec@1 79.688 (77.839)\n",
            "Epoch: [78][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8354 (0.8615)\tPrec@1 79.688 (77.212)\n",
            "Epoch: [78][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9484 (0.8727)\tPrec@1 71.875 (76.864)\n",
            "Epoch: [78][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.9894 (0.8801)\tPrec@1 76.250 (76.588)\n",
            "Total time : 12.766\n",
            "Train Loss: 0.8801, Train Accuracy: 0.7659\n",
            "Test Loss : 1.1529, Test Accuracy : 0.6693 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.196 (0.196)\tData 0.156 (0.156)\tLoss 0.7879 (0.7879)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [79][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.7936 (0.8179)\tPrec@1 79.688 (78.210)\n",
            "Epoch: [79][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.8419 (0.8342)\tPrec@1 74.219 (77.888)\n",
            "Epoch: [79][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.8273 (0.8544)\tPrec@1 78.125 (77.237)\n",
            "Epoch: [79][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8991 (0.8694)\tPrec@1 70.000 (76.726)\n",
            "Total time : 12.947\n",
            "Train Loss: 0.8694, Train Accuracy: 0.7673\n",
            "Test Loss : 1.0479, Test Accuracy : 0.6915 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.185 (0.185)\tData 0.146 (0.146)\tLoss 0.7357 (0.7357)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [80][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.8318 (0.8489)\tPrec@1 78.125 (77.406)\n",
            "Epoch: [80][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 1.0304 (0.8524)\tPrec@1 67.969 (77.433)\n",
            "Epoch: [80][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.9038 (0.8553)\tPrec@1 76.562 (77.287)\n",
            "Epoch: [80][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.9739 (0.8630)\tPrec@1 73.750 (77.052)\n",
            "Total time : 13.236\n",
            "Train Loss: 0.8630, Train Accuracy: 0.7705\n",
            "Test Loss : 1.0361, Test Accuracy : 0.7049 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.193 (0.193)\tData 0.144 (0.144)\tLoss 0.8840 (0.8840)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [81][100/391]\tTime 0.037 (0.036)\tData 0.000 (0.002)\tLoss 0.7508 (0.8317)\tPrec@1 78.125 (77.754)\n",
            "Epoch: [81][200/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 0.7994 (0.8297)\tPrec@1 78.906 (77.973)\n",
            "Epoch: [81][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.8390 (0.8419)\tPrec@1 75.781 (77.515)\n",
            "Epoch: [81][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8458 (0.8552)\tPrec@1 76.250 (77.068)\n",
            "Total time : 13.085\n",
            "Train Loss: 0.8552, Train Accuracy: 0.7707\n",
            "Test Loss : 1.1255, Test Accuracy : 0.6776 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.202 (0.202)\tData 0.144 (0.144)\tLoss 0.6777 (0.6777)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [82][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 1.0032 (0.8276)\tPrec@1 71.875 (78.396)\n",
            "Epoch: [82][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.9920 (0.8345)\tPrec@1 75.781 (77.764)\n",
            "Epoch: [82][300/391]\tTime 0.032 (0.032)\tData 0.000 (0.001)\tLoss 0.9730 (0.8451)\tPrec@1 71.875 (77.497)\n",
            "Epoch: [82][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.7832 (0.8511)\tPrec@1 73.750 (77.320)\n",
            "Total time : 12.538\n",
            "Train Loss: 0.8511, Train Accuracy: 0.7732\n",
            "Test Loss : 1.0619, Test Accuracy : 0.7007 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.182 (0.182)\tData 0.143 (0.143)\tLoss 0.6350 (0.6350)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [83][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.7583 (0.7910)\tPrec@1 79.688 (79.262)\n",
            "Epoch: [83][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.8256 (0.8183)\tPrec@1 78.906 (78.409)\n",
            "Epoch: [83][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.9541 (0.8284)\tPrec@1 72.656 (78.151)\n",
            "Epoch: [83][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8737 (0.8423)\tPrec@1 77.500 (77.692)\n",
            "Total time : 12.992\n",
            "Train Loss: 0.8423, Train Accuracy: 0.7769\n",
            "Test Loss : 1.0243, Test Accuracy : 0.7035 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.196 (0.196)\tData 0.151 (0.151)\tLoss 0.8624 (0.8624)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [84][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.7976 (0.8004)\tPrec@1 82.031 (78.883)\n",
            "Epoch: [84][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9602 (0.8077)\tPrec@1 73.438 (78.595)\n",
            "Epoch: [84][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.6357 (0.8228)\tPrec@1 83.594 (78.239)\n",
            "Epoch: [84][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.8539 (0.8328)\tPrec@1 76.250 (77.918)\n",
            "Total time : 12.725\n",
            "Train Loss: 0.8328, Train Accuracy: 0.7792\n",
            "Test Loss : 1.0288, Test Accuracy : 0.7043 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.208 (0.208)\tData 0.169 (0.169)\tLoss 0.7071 (0.7071)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [85][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.7003 (0.7946)\tPrec@1 83.594 (78.929)\n",
            "Epoch: [85][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8771 (0.8156)\tPrec@1 78.125 (78.467)\n",
            "Epoch: [85][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9089 (0.8244)\tPrec@1 71.875 (78.099)\n",
            "Epoch: [85][390/391]\tTime 0.028 (0.032)\tData 0.000 (0.001)\tLoss 0.8868 (0.8313)\tPrec@1 75.000 (77.886)\n",
            "Total time : 12.695\n",
            "Train Loss: 0.8313, Train Accuracy: 0.7789\n",
            "Test Loss : 1.0386, Test Accuracy : 0.7034 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.186 (0.186)\tData 0.145 (0.145)\tLoss 0.6157 (0.6157)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [86][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.7640 (0.7771)\tPrec@1 79.688 (79.386)\n",
            "Epoch: [86][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.7945 (0.7954)\tPrec@1 79.688 (79.038)\n",
            "Epoch: [86][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.8286 (0.8087)\tPrec@1 78.906 (78.545)\n",
            "Epoch: [86][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 1.0825 (0.8245)\tPrec@1 63.750 (77.990)\n",
            "Total time : 13.155\n",
            "Train Loss: 0.8245, Train Accuracy: 0.7799\n",
            "Test Loss : 1.0690, Test Accuracy : 0.6903 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.202 (0.202)\tData 0.149 (0.149)\tLoss 0.7806 (0.7806)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [87][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.7089 (0.7791)\tPrec@1 80.469 (79.556)\n",
            "Epoch: [87][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.9311 (0.7931)\tPrec@1 72.656 (78.953)\n",
            "Epoch: [87][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8723 (0.8002)\tPrec@1 75.781 (78.644)\n",
            "Epoch: [87][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8016 (0.8127)\tPrec@1 80.000 (78.242)\n",
            "Total time : 12.910\n",
            "Train Loss: 0.8127, Train Accuracy: 0.7824\n",
            "Test Loss : 1.1173, Test Accuracy : 0.6863 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.196 (0.196)\tData 0.143 (0.143)\tLoss 0.6919 (0.6919)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [88][100/391]\tTime 0.041 (0.034)\tData 0.000 (0.002)\tLoss 0.7565 (0.7640)\tPrec@1 78.906 (79.834)\n",
            "Epoch: [88][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.9365 (0.7777)\tPrec@1 72.656 (79.505)\n",
            "Epoch: [88][300/391]\tTime 0.036 (0.035)\tData 0.000 (0.001)\tLoss 0.8810 (0.7976)\tPrec@1 73.438 (78.888)\n",
            "Epoch: [88][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.7946 (0.8095)\tPrec@1 80.000 (78.644)\n",
            "Total time : 13.479\n",
            "Train Loss: 0.8095, Train Accuracy: 0.7864\n",
            "Test Loss : 1.0630, Test Accuracy : 0.6926 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.209 (0.209)\tData 0.151 (0.151)\tLoss 0.6195 (0.6195)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [89][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.7697 (0.7541)\tPrec@1 83.594 (80.461)\n",
            "Epoch: [89][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.9574 (0.7742)\tPrec@1 76.562 (79.699)\n",
            "Epoch: [89][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.6606 (0.7821)\tPrec@1 80.469 (79.498)\n",
            "Epoch: [89][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.9450 (0.7983)\tPrec@1 76.250 (79.012)\n",
            "Total time : 12.978\n",
            "Train Loss: 0.7983, Train Accuracy: 0.7901\n",
            "Test Loss : 1.0155, Test Accuracy : 0.7134 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.200 (0.200)\tData 0.141 (0.141)\tLoss 0.7070 (0.7070)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [90][100/391]\tTime 0.038 (0.036)\tData 0.000 (0.002)\tLoss 0.7918 (0.7782)\tPrec@1 78.906 (79.494)\n",
            "Epoch: [90][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.8753 (0.7820)\tPrec@1 77.344 (79.415)\n",
            "Epoch: [90][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 1.0457 (0.7903)\tPrec@1 75.000 (79.197)\n",
            "Epoch: [90][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.9052 (0.7982)\tPrec@1 75.000 (78.924)\n",
            "Total time : 13.254\n",
            "Train Loss: 0.7982, Train Accuracy: 0.7892\n",
            "Test Loss : 1.0743, Test Accuracy : 0.6871 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.203 (0.203)\tData 0.146 (0.146)\tLoss 0.6321 (0.6321)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [91][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.6632 (0.7412)\tPrec@1 83.594 (80.840)\n",
            "Epoch: [91][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.8056 (0.7556)\tPrec@1 78.906 (80.407)\n",
            "Epoch: [91][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.8582 (0.7733)\tPrec@1 73.438 (79.877)\n",
            "Epoch: [91][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.6650 (0.7798)\tPrec@1 83.750 (79.626)\n",
            "Total time : 12.853\n",
            "Train Loss: 0.7798, Train Accuracy: 0.7963\n",
            "Test Loss : 1.0604, Test Accuracy : 0.6963 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.185 (0.185)\tData 0.146 (0.146)\tLoss 0.7764 (0.7764)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [92][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.7786 (0.7404)\tPrec@1 81.250 (80.972)\n",
            "Epoch: [92][200/391]\tTime 0.041 (0.033)\tData 0.000 (0.001)\tLoss 0.7538 (0.7466)\tPrec@1 77.344 (80.710)\n",
            "Epoch: [92][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.7925 (0.7589)\tPrec@1 79.688 (80.046)\n",
            "Epoch: [92][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.8179 (0.7751)\tPrec@1 76.250 (79.486)\n",
            "Total time : 12.869\n",
            "Train Loss: 0.7751, Train Accuracy: 0.7949\n",
            "Test Loss : 0.9961, Test Accuracy : 0.7156 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.196 (0.196)\tData 0.146 (0.146)\tLoss 0.6987 (0.6987)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [93][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.9359 (0.7321)\tPrec@1 71.094 (80.747)\n",
            "Epoch: [93][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.7047 (0.7426)\tPrec@1 82.031 (80.321)\n",
            "Epoch: [93][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.7340 (0.7552)\tPrec@1 80.469 (79.957)\n",
            "Epoch: [93][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.7967 (0.7652)\tPrec@1 83.750 (79.712)\n",
            "Total time : 12.905\n",
            "Train Loss: 0.7652, Train Accuracy: 0.7971\n",
            "Test Loss : 1.0311, Test Accuracy : 0.7011 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.206 (0.206)\tData 0.147 (0.147)\tLoss 0.6273 (0.6273)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [94][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.6847 (0.7247)\tPrec@1 83.594 (81.281)\n",
            "Epoch: [94][200/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.7110 (0.7388)\tPrec@1 78.125 (80.745)\n",
            "Epoch: [94][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.8360 (0.7520)\tPrec@1 78.125 (80.264)\n",
            "Epoch: [94][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.8030 (0.7605)\tPrec@1 83.750 (80.066)\n",
            "Total time : 13.214\n",
            "Train Loss: 0.7605, Train Accuracy: 0.8007\n",
            "Test Loss : 1.0107, Test Accuracy : 0.7119 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.189 (0.189)\tData 0.146 (0.146)\tLoss 0.5783 (0.5783)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [95][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.7229 (0.7228)\tPrec@1 82.812 (81.227)\n",
            "Epoch: [95][200/391]\tTime 0.037 (0.035)\tData 0.000 (0.001)\tLoss 0.8022 (0.7351)\tPrec@1 82.031 (80.714)\n",
            "Epoch: [95][300/391]\tTime 0.039 (0.034)\tData 0.000 (0.001)\tLoss 1.0252 (0.7523)\tPrec@1 68.750 (80.155)\n",
            "Epoch: [95][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.9522 (0.7581)\tPrec@1 70.000 (79.998)\n",
            "Total time : 13.232\n",
            "Train Loss: 0.7581, Train Accuracy: 0.8000\n",
            "Test Loss : 1.0271, Test Accuracy : 0.7051 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.221 (0.221)\tData 0.169 (0.169)\tLoss 0.6123 (0.6123)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [96][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.7199 (0.7081)\tPrec@1 81.250 (81.335)\n",
            "Epoch: [96][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.7256 (0.7252)\tPrec@1 79.688 (81.098)\n",
            "Epoch: [96][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.9401 (0.7397)\tPrec@1 71.875 (80.554)\n",
            "Epoch: [96][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.7083 (0.7483)\tPrec@1 81.250 (80.278)\n",
            "Total time : 13.163\n",
            "Train Loss: 0.7483, Train Accuracy: 0.8028\n",
            "Test Loss : 0.9983, Test Accuracy : 0.7127 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.195 (0.195)\tData 0.155 (0.155)\tLoss 0.6143 (0.6143)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [97][100/391]\tTime 0.038 (0.036)\tData 0.000 (0.002)\tLoss 0.7395 (0.7014)\tPrec@1 82.031 (81.923)\n",
            "Epoch: [97][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.7138 (0.7051)\tPrec@1 77.344 (81.479)\n",
            "Epoch: [97][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.7171 (0.7208)\tPrec@1 80.469 (81.050)\n",
            "Epoch: [97][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8301 (0.7331)\tPrec@1 78.750 (80.682)\n",
            "Total time : 12.965\n",
            "Train Loss: 0.7331, Train Accuracy: 0.8068\n",
            "Test Loss : 1.0818, Test Accuracy : 0.6922 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.205 (0.205)\tData 0.148 (0.148)\tLoss 0.6514 (0.6514)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [98][100/391]\tTime 0.037 (0.036)\tData 0.000 (0.002)\tLoss 0.7792 (0.6989)\tPrec@1 81.250 (81.877)\n",
            "Epoch: [98][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.8124 (0.7099)\tPrec@1 74.219 (81.402)\n",
            "Epoch: [98][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.8119 (0.7229)\tPrec@1 78.125 (81.050)\n",
            "Epoch: [98][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.7777 (0.7315)\tPrec@1 78.750 (80.814)\n",
            "Total time : 13.209\n",
            "Train Loss: 0.7315, Train Accuracy: 0.8081\n",
            "Test Loss : 1.0456, Test Accuracy : 0.7024 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.218 (0.218)\tData 0.152 (0.152)\tLoss 0.5593 (0.5593)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [99][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.8083 (0.6864)\tPrec@1 73.438 (81.954)\n",
            "Epoch: [99][200/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 0.6573 (0.7018)\tPrec@1 82.812 (81.728)\n",
            "Epoch: [99][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.8796 (0.7120)\tPrec@1 77.344 (81.510)\n",
            "Epoch: [99][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.7050 (0.7185)\tPrec@1 80.000 (81.332)\n",
            "Total time : 13.187\n",
            "Train Loss: 0.7185, Train Accuracy: 0.8133\n",
            "Test Loss : 0.9842, Test Accuracy : 0.7137 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.184 (0.184)\tData 0.144 (0.144)\tLoss 0.7101 (0.7101)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [100][100/391]\tTime 0.034 (0.035)\tData 0.000 (0.002)\tLoss 0.7772 (0.6744)\tPrec@1 82.031 (82.480)\n",
            "Epoch: [100][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.6825 (0.6828)\tPrec@1 81.250 (82.210)\n",
            "Epoch: [100][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.7011 (0.7017)\tPrec@1 81.250 (81.681)\n",
            "Epoch: [100][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.8634 (0.7112)\tPrec@1 80.000 (81.420)\n",
            "Total time : 13.171\n",
            "Train Loss: 0.7112, Train Accuracy: 0.8142\n",
            "Test Loss : 1.0043, Test Accuracy : 0.7093 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.209 (0.209)\tData 0.151 (0.151)\tLoss 0.8120 (0.8120)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [101][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.7181 (0.6682)\tPrec@1 79.688 (83.130)\n",
            "Epoch: [101][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.5806 (0.6794)\tPrec@1 86.719 (82.603)\n",
            "Epoch: [101][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.6796 (0.6986)\tPrec@1 84.375 (81.948)\n",
            "Epoch: [101][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.6819 (0.7081)\tPrec@1 85.000 (81.634)\n",
            "Total time : 13.065\n",
            "Train Loss: 0.7081, Train Accuracy: 0.8163\n",
            "Test Loss : 0.9914, Test Accuracy : 0.7132 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.183 (0.183)\tData 0.143 (0.143)\tLoss 0.6533 (0.6533)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [102][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.7852 (0.6644)\tPrec@1 79.688 (83.091)\n",
            "Epoch: [102][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.6331 (0.6733)\tPrec@1 81.250 (82.583)\n",
            "Epoch: [102][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.8199 (0.6869)\tPrec@1 82.812 (82.140)\n",
            "Epoch: [102][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.7453 (0.6962)\tPrec@1 76.250 (81.838)\n",
            "Total time : 12.881\n",
            "Train Loss: 0.6962, Train Accuracy: 0.8184\n",
            "Test Loss : 1.0506, Test Accuracy : 0.6952 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.202 (0.202)\tData 0.144 (0.144)\tLoss 0.5714 (0.5714)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [103][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.6183 (0.6472)\tPrec@1 85.156 (83.710)\n",
            "Epoch: [103][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.6028 (0.6606)\tPrec@1 84.375 (83.252)\n",
            "Epoch: [103][300/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.7867 (0.6763)\tPrec@1 82.812 (82.626)\n",
            "Epoch: [103][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.9083 (0.6841)\tPrec@1 76.250 (82.282)\n",
            "Total time : 13.154\n",
            "Train Loss: 0.6841, Train Accuracy: 0.8228\n",
            "Test Loss : 0.9396, Test Accuracy : 0.7248 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.201 (0.201)\tData 0.144 (0.144)\tLoss 0.6513 (0.6513)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [104][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 0.7573 (0.6516)\tPrec@1 80.469 (83.462)\n",
            "Epoch: [104][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.6862 (0.6579)\tPrec@1 81.250 (83.186)\n",
            "Epoch: [104][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.7663 (0.6718)\tPrec@1 79.688 (82.774)\n",
            "Epoch: [104][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.6083 (0.6792)\tPrec@1 86.250 (82.446)\n",
            "Total time : 12.908\n",
            "Train Loss: 0.6792, Train Accuracy: 0.8245\n",
            "Test Loss : 0.9734, Test Accuracy : 0.7221 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.209 (0.209)\tData 0.169 (0.169)\tLoss 0.5701 (0.5701)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [105][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.4361 (0.6254)\tPrec@1 91.406 (84.367)\n",
            "Epoch: [105][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.4526 (0.6384)\tPrec@1 89.844 (83.874)\n",
            "Epoch: [105][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.6477 (0.6516)\tPrec@1 83.594 (83.459)\n",
            "Epoch: [105][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.8671 (0.6667)\tPrec@1 73.750 (82.890)\n",
            "Total time : 12.974\n",
            "Train Loss: 0.6667, Train Accuracy: 0.8289\n",
            "Test Loss : 0.9835, Test Accuracy : 0.7174 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.197 (0.197)\tData 0.142 (0.142)\tLoss 0.8423 (0.8423)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [106][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.5889 (0.6200)\tPrec@1 85.938 (84.514)\n",
            "Epoch: [106][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.5887 (0.6349)\tPrec@1 89.062 (83.909)\n",
            "Epoch: [106][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.7391 (0.6476)\tPrec@1 82.812 (83.493)\n",
            "Epoch: [106][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.6340 (0.6579)\tPrec@1 87.500 (83.126)\n",
            "Total time : 12.986\n",
            "Train Loss: 0.6579, Train Accuracy: 0.8313\n",
            "Test Loss : 0.9768, Test Accuracy : 0.7214 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 0.6394 (0.6394)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [107][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.6258 (0.6140)\tPrec@1 85.938 (84.089)\n",
            "Epoch: [107][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.6253 (0.6239)\tPrec@1 86.719 (84.103)\n",
            "Epoch: [107][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.6793 (0.6373)\tPrec@1 82.812 (83.690)\n",
            "Epoch: [107][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.7504 (0.6484)\tPrec@1 82.500 (83.340)\n",
            "Total time : 12.861\n",
            "Train Loss: 0.6484, Train Accuracy: 0.8334\n",
            "Test Loss : 0.9448, Test Accuracy : 0.7271 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.188 (0.188)\tData 0.148 (0.148)\tLoss 0.7410 (0.7410)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [108][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.5652 (0.6044)\tPrec@1 87.500 (84.777)\n",
            "Epoch: [108][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.6395 (0.6221)\tPrec@1 85.156 (84.080)\n",
            "Epoch: [108][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.4946 (0.6323)\tPrec@1 89.062 (83.843)\n",
            "Epoch: [108][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.6324 (0.6403)\tPrec@1 88.750 (83.586)\n",
            "Total time : 12.952\n",
            "Train Loss: 0.6403, Train Accuracy: 0.8359\n",
            "Test Loss : 0.9991, Test Accuracy : 0.7125 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.201 (0.201)\tData 0.154 (0.154)\tLoss 0.5823 (0.5823)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [109][100/391]\tTime 0.036 (0.036)\tData 0.000 (0.002)\tLoss 0.6396 (0.6019)\tPrec@1 82.031 (85.226)\n",
            "Epoch: [109][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.7092 (0.6207)\tPrec@1 80.469 (84.398)\n",
            "Epoch: [109][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.6222 (0.6296)\tPrec@1 84.375 (83.916)\n",
            "Epoch: [109][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.6945 (0.6346)\tPrec@1 81.250 (83.818)\n",
            "Total time : 13.174\n",
            "Train Loss: 0.6346, Train Accuracy: 0.8382\n",
            "Test Loss : 0.9697, Test Accuracy : 0.7212 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.186 (0.186)\tData 0.147 (0.147)\tLoss 0.6753 (0.6753)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [110][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.5769 (0.6074)\tPrec@1 84.375 (84.793)\n",
            "Epoch: [110][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.5696 (0.6066)\tPrec@1 87.500 (84.674)\n",
            "Epoch: [110][300/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.7148 (0.6130)\tPrec@1 82.031 (84.411)\n",
            "Epoch: [110][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.5292 (0.6181)\tPrec@1 83.750 (84.160)\n",
            "Total time : 12.992\n",
            "Train Loss: 0.6181, Train Accuracy: 0.8416\n",
            "Test Loss : 0.9256, Test Accuracy : 0.7305 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.209 (0.209)\tData 0.151 (0.151)\tLoss 0.5986 (0.5986)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [111][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.5690 (0.5894)\tPrec@1 88.281 (85.497)\n",
            "Epoch: [111][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.4701 (0.5923)\tPrec@1 86.719 (85.234)\n",
            "Epoch: [111][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.5652 (0.6061)\tPrec@1 88.281 (84.738)\n",
            "Epoch: [111][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.7610 (0.6121)\tPrec@1 78.750 (84.602)\n",
            "Total time : 13.250\n",
            "Train Loss: 0.6121, Train Accuracy: 0.8460\n",
            "Test Loss : 0.9041, Test Accuracy : 0.7412 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.200 (0.200)\tData 0.143 (0.143)\tLoss 0.4935 (0.4935)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [112][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.5114 (0.5814)\tPrec@1 89.062 (85.659)\n",
            "Epoch: [112][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.5551 (0.5884)\tPrec@1 82.812 (85.370)\n",
            "Epoch: [112][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.6057 (0.5975)\tPrec@1 82.812 (84.962)\n",
            "Epoch: [112][390/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.6050 (0.6028)\tPrec@1 85.000 (84.794)\n",
            "Total time : 13.097\n",
            "Train Loss: 0.6028, Train Accuracy: 0.8479\n",
            "Test Loss : 0.9031, Test Accuracy : 0.7380 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.199 (0.199)\tData 0.159 (0.159)\tLoss 0.5166 (0.5166)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [113][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.5101 (0.5603)\tPrec@1 88.281 (86.262)\n",
            "Epoch: [113][200/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.6398 (0.5685)\tPrec@1 86.719 (85.984)\n",
            "Epoch: [113][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.6360 (0.5799)\tPrec@1 86.719 (85.616)\n",
            "Epoch: [113][390/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.6045 (0.5892)\tPrec@1 85.000 (85.238)\n",
            "Total time : 13.014\n",
            "Train Loss: 0.5892, Train Accuracy: 0.8524\n",
            "Test Loss : 0.9795, Test Accuracy : 0.7187 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.207 (0.207)\tData 0.152 (0.152)\tLoss 0.6045 (0.6045)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [114][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.5283 (0.5493)\tPrec@1 88.281 (86.696)\n",
            "Epoch: [114][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.6762 (0.5638)\tPrec@1 79.688 (86.050)\n",
            "Epoch: [114][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.5633 (0.5737)\tPrec@1 82.812 (85.642)\n",
            "Epoch: [114][390/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.6227 (0.5842)\tPrec@1 81.250 (85.306)\n",
            "Total time : 13.056\n",
            "Train Loss: 0.5842, Train Accuracy: 0.8531\n",
            "Test Loss : 0.9476, Test Accuracy : 0.7292 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.193 (0.193)\tData 0.151 (0.151)\tLoss 0.4269 (0.4269)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [115][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.5314 (0.5445)\tPrec@1 85.156 (86.734)\n",
            "Epoch: [115][200/391]\tTime 0.036 (0.035)\tData 0.000 (0.001)\tLoss 0.5452 (0.5548)\tPrec@1 84.375 (86.373)\n",
            "Epoch: [115][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.5040 (0.5656)\tPrec@1 87.500 (85.997)\n",
            "Epoch: [115][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.4519 (0.5762)\tPrec@1 86.250 (85.586)\n",
            "Total time : 13.118\n",
            "Train Loss: 0.5762, Train Accuracy: 0.8559\n",
            "Test Loss : 0.9131, Test Accuracy : 0.7355 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.209 (0.209)\tData 0.152 (0.152)\tLoss 0.3907 (0.3907)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [116][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 0.4823 (0.5298)\tPrec@1 83.594 (87.167)\n",
            "Epoch: [116][200/391]\tTime 0.034 (0.034)\tData 0.000 (0.001)\tLoss 0.4511 (0.5438)\tPrec@1 90.625 (86.765)\n",
            "Epoch: [116][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.5290 (0.5547)\tPrec@1 87.500 (86.498)\n",
            "Epoch: [116][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.4500 (0.5634)\tPrec@1 90.000 (86.144)\n",
            "Total time : 13.061\n",
            "Train Loss: 0.5634, Train Accuracy: 0.8614\n",
            "Test Loss : 0.9211, Test Accuracy : 0.7314 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.183 (0.183)\tData 0.143 (0.143)\tLoss 0.6078 (0.6078)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [117][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.6434 (0.5368)\tPrec@1 84.375 (87.384)\n",
            "Epoch: [117][200/391]\tTime 0.040 (0.035)\tData 0.000 (0.001)\tLoss 0.6039 (0.5440)\tPrec@1 85.156 (86.800)\n",
            "Epoch: [117][300/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 0.6458 (0.5544)\tPrec@1 77.344 (86.402)\n",
            "Epoch: [117][390/391]\tTime 0.028 (0.035)\tData 0.000 (0.001)\tLoss 0.5812 (0.5623)\tPrec@1 88.750 (86.128)\n",
            "Total time : 13.608\n",
            "Train Loss: 0.5623, Train Accuracy: 0.8613\n",
            "Test Loss : 0.8709, Test Accuracy : 0.7483 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.201 (0.201)\tData 0.153 (0.153)\tLoss 0.4706 (0.4706)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [118][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.4672 (0.5021)\tPrec@1 89.062 (87.995)\n",
            "Epoch: [118][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.4874 (0.5176)\tPrec@1 87.500 (87.508)\n",
            "Epoch: [118][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.6261 (0.5315)\tPrec@1 83.594 (87.025)\n",
            "Epoch: [118][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.5494 (0.5440)\tPrec@1 90.000 (86.688)\n",
            "Total time : 12.872\n",
            "Train Loss: 0.5440, Train Accuracy: 0.8669\n",
            "Test Loss : 0.9818, Test Accuracy : 0.7171 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.197 (0.197)\tData 0.157 (0.157)\tLoss 0.4721 (0.4721)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [119][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.5079 (0.5114)\tPrec@1 85.156 (87.624)\n",
            "Epoch: [119][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.5575 (0.5249)\tPrec@1 88.281 (87.115)\n",
            "Epoch: [119][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.4461 (0.5321)\tPrec@1 90.625 (86.971)\n",
            "Epoch: [119][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.6689 (0.5381)\tPrec@1 83.750 (86.748)\n",
            "Total time : 13.080\n",
            "Train Loss: 0.5381, Train Accuracy: 0.8675\n",
            "Test Loss : 0.9100, Test Accuracy : 0.7397 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.188 (0.188)\tData 0.146 (0.146)\tLoss 0.3951 (0.3951)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [120][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.4079 (0.4996)\tPrec@1 92.188 (87.956)\n",
            "Epoch: [120][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.6015 (0.5109)\tPrec@1 85.156 (87.562)\n",
            "Epoch: [120][300/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.5194 (0.5208)\tPrec@1 87.500 (87.222)\n",
            "Epoch: [120][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.4762 (0.5274)\tPrec@1 87.500 (87.116)\n",
            "Total time : 12.731\n",
            "Train Loss: 0.5274, Train Accuracy: 0.8712\n",
            "Test Loss : 0.9029, Test Accuracy : 0.7405 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.197 (0.197)\tData 0.152 (0.152)\tLoss 0.4640 (0.4640)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [121][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.3971 (0.4897)\tPrec@1 92.188 (88.281)\n",
            "Epoch: [121][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.6087 (0.4981)\tPrec@1 86.719 (88.056)\n",
            "Epoch: [121][300/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.6981 (0.5097)\tPrec@1 84.375 (87.658)\n",
            "Epoch: [121][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.5472 (0.5219)\tPrec@1 87.500 (87.374)\n",
            "Total time : 13.236\n",
            "Train Loss: 0.5219, Train Accuracy: 0.8737\n",
            "Test Loss : 0.8970, Test Accuracy : 0.7430 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.210 (0.210)\tData 0.147 (0.147)\tLoss 0.4894 (0.4894)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [122][100/391]\tTime 0.037 (0.034)\tData 0.000 (0.002)\tLoss 0.5043 (0.4849)\tPrec@1 89.062 (88.769)\n",
            "Epoch: [122][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.4861 (0.4903)\tPrec@1 86.719 (88.569)\n",
            "Epoch: [122][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.4402 (0.5008)\tPrec@1 88.281 (88.198)\n",
            "Epoch: [122][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.4968 (0.5085)\tPrec@1 90.000 (87.940)\n",
            "Total time : 12.923\n",
            "Train Loss: 0.5085, Train Accuracy: 0.8794\n",
            "Test Loss : 0.8829, Test Accuracy : 0.7461 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.202 (0.202)\tData 0.145 (0.145)\tLoss 0.4548 (0.4548)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [123][100/391]\tTime 0.038 (0.034)\tData 0.000 (0.002)\tLoss 0.4351 (0.4676)\tPrec@1 90.625 (89.233)\n",
            "Epoch: [123][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.4955 (0.4796)\tPrec@1 89.062 (88.787)\n",
            "Epoch: [123][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.4958 (0.4889)\tPrec@1 85.156 (88.507)\n",
            "Epoch: [123][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.7279 (0.4966)\tPrec@1 80.000 (88.274)\n",
            "Total time : 12.784\n",
            "Train Loss: 0.4966, Train Accuracy: 0.8827\n",
            "Test Loss : 0.9022, Test Accuracy : 0.7416 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.206 (0.206)\tData 0.147 (0.147)\tLoss 0.3657 (0.3657)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [124][100/391]\tTime 0.048 (0.034)\tData 0.000 (0.002)\tLoss 0.5467 (0.4649)\tPrec@1 85.156 (89.202)\n",
            "Epoch: [124][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.4747 (0.4727)\tPrec@1 85.156 (88.837)\n",
            "Epoch: [124][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.6673 (0.4782)\tPrec@1 85.938 (88.639)\n",
            "Epoch: [124][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.7469 (0.4864)\tPrec@1 81.250 (88.352)\n",
            "Total time : 12.716\n",
            "Train Loss: 0.4864, Train Accuracy: 0.8835\n",
            "Test Loss : 0.8257, Test Accuracy : 0.7594 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.203 (0.203)\tData 0.158 (0.158)\tLoss 0.4368 (0.4368)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [125][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.4309 (0.4434)\tPrec@1 91.406 (89.998)\n",
            "Epoch: [125][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.4716 (0.4613)\tPrec@1 91.406 (89.327)\n",
            "Epoch: [125][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.5945 (0.4759)\tPrec@1 84.375 (88.756)\n",
            "Epoch: [125][390/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.5518 (0.4842)\tPrec@1 81.250 (88.456)\n",
            "Total time : 13.236\n",
            "Train Loss: 0.4842, Train Accuracy: 0.8846\n",
            "Test Loss : 0.8653, Test Accuracy : 0.7447 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.197 (0.197)\tData 0.151 (0.151)\tLoss 0.3845 (0.3845)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [126][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.5849 (0.4366)\tPrec@1 82.812 (90.200)\n",
            "Epoch: [126][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.4850 (0.4487)\tPrec@1 89.062 (89.770)\n",
            "Epoch: [126][300/391]\tTime 0.038 (0.033)\tData 0.000 (0.001)\tLoss 0.5584 (0.4608)\tPrec@1 84.375 (89.371)\n",
            "Epoch: [126][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.7158 (0.4677)\tPrec@1 82.500 (89.164)\n",
            "Total time : 13.032\n",
            "Train Loss: 0.4677, Train Accuracy: 0.8916\n",
            "Test Loss : 0.8818, Test Accuracy : 0.7468 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.193 (0.193)\tData 0.153 (0.153)\tLoss 0.4012 (0.4012)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [127][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.3013 (0.4220)\tPrec@1 95.312 (90.749)\n",
            "Epoch: [127][200/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.3748 (0.4360)\tPrec@1 91.406 (90.096)\n",
            "Epoch: [127][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.5721 (0.4498)\tPrec@1 83.594 (89.636)\n",
            "Epoch: [127][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.5873 (0.4576)\tPrec@1 86.250 (89.418)\n",
            "Total time : 13.218\n",
            "Train Loss: 0.4576, Train Accuracy: 0.8942\n",
            "Test Loss : 0.8625, Test Accuracy : 0.7527 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.201 (0.201)\tData 0.143 (0.143)\tLoss 0.4622 (0.4622)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [128][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.4088 (0.4220)\tPrec@1 89.062 (90.633)\n",
            "Epoch: [128][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.4988 (0.4347)\tPrec@1 88.281 (90.197)\n",
            "Epoch: [128][300/391]\tTime 0.034 (0.034)\tData 0.000 (0.001)\tLoss 0.4506 (0.4417)\tPrec@1 90.625 (89.955)\n",
            "Epoch: [128][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.5264 (0.4500)\tPrec@1 83.750 (89.678)\n",
            "Total time : 13.268\n",
            "Train Loss: 0.4500, Train Accuracy: 0.8968\n",
            "Test Loss : 0.8614, Test Accuracy : 0.7527 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.187 (0.187)\tData 0.146 (0.146)\tLoss 0.3090 (0.3090)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [129][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.4211 (0.4061)\tPrec@1 89.062 (91.136)\n",
            "Epoch: [129][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.3994 (0.4185)\tPrec@1 92.969 (90.598)\n",
            "Epoch: [129][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.5021 (0.4322)\tPrec@1 85.938 (90.132)\n",
            "Epoch: [129][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.4110 (0.4424)\tPrec@1 87.500 (89.770)\n",
            "Total time : 13.064\n",
            "Train Loss: 0.4424, Train Accuracy: 0.8977\n",
            "Test Loss : 0.8548, Test Accuracy : 0.7559 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.183 (0.183)\tData 0.143 (0.143)\tLoss 0.3946 (0.3946)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [130][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.4219 (0.4130)\tPrec@1 89.062 (90.617)\n",
            "Epoch: [130][200/391]\tTime 0.038 (0.034)\tData 0.000 (0.001)\tLoss 0.4311 (0.4134)\tPrec@1 89.062 (90.687)\n",
            "Epoch: [130][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.4511 (0.4277)\tPrec@1 89.062 (90.259)\n",
            "Epoch: [130][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.4174 (0.4341)\tPrec@1 87.500 (89.984)\n",
            "Total time : 13.472\n",
            "Train Loss: 0.4341, Train Accuracy: 0.8998\n",
            "Test Loss : 0.8176, Test Accuracy : 0.7646 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.187 (0.187)\tData 0.146 (0.146)\tLoss 0.3147 (0.3147)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [131][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.4017 (0.3949)\tPrec@1 91.406 (91.182)\n",
            "Epoch: [131][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.4307 (0.4003)\tPrec@1 88.281 (91.115)\n",
            "Epoch: [131][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.3299 (0.4088)\tPrec@1 95.312 (90.776)\n",
            "Epoch: [131][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.4272 (0.4157)\tPrec@1 88.750 (90.552)\n",
            "Total time : 12.924\n",
            "Train Loss: 0.4157, Train Accuracy: 0.9055\n",
            "Test Loss : 0.8257, Test Accuracy : 0.7632 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.202 (0.202)\tData 0.161 (0.161)\tLoss 0.3513 (0.3513)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [132][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.3832 (0.3919)\tPrec@1 88.281 (91.700)\n",
            "Epoch: [132][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.4133 (0.3982)\tPrec@1 92.188 (91.301)\n",
            "Epoch: [132][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.5107 (0.4030)\tPrec@1 85.938 (90.994)\n",
            "Epoch: [132][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.3997 (0.4104)\tPrec@1 92.500 (90.724)\n",
            "Total time : 13.201\n",
            "Train Loss: 0.4104, Train Accuracy: 0.9072\n",
            "Test Loss : 0.8283, Test Accuracy : 0.7584 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.195 (0.195)\tData 0.156 (0.156)\tLoss 0.3662 (0.3662)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [133][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.4514 (0.3928)\tPrec@1 89.062 (91.476)\n",
            "Epoch: [133][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3795 (0.3941)\tPrec@1 90.625 (91.356)\n",
            "Epoch: [133][300/391]\tTime 0.038 (0.033)\tData 0.000 (0.001)\tLoss 0.4548 (0.3975)\tPrec@1 90.625 (91.245)\n",
            "Epoch: [133][390/391]\tTime 0.030 (0.033)\tData 0.000 (0.001)\tLoss 0.3812 (0.4017)\tPrec@1 87.500 (91.006)\n",
            "Total time : 12.887\n",
            "Train Loss: 0.4017, Train Accuracy: 0.9101\n",
            "Test Loss : 0.8617, Test Accuracy : 0.7540 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.204 (0.204)\tData 0.142 (0.142)\tLoss 0.3137 (0.3137)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [134][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.2879 (0.3618)\tPrec@1 96.094 (92.443)\n",
            "Epoch: [134][200/391]\tTime 0.038 (0.035)\tData 0.000 (0.001)\tLoss 0.3502 (0.3770)\tPrec@1 92.188 (91.915)\n",
            "Epoch: [134][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.3362 (0.3857)\tPrec@1 92.969 (91.606)\n",
            "Epoch: [134][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.6170 (0.3921)\tPrec@1 83.750 (91.330)\n",
            "Total time : 13.200\n",
            "Train Loss: 0.3921, Train Accuracy: 0.9133\n",
            "Test Loss : 0.8260, Test Accuracy : 0.7627 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.205 (0.205)\tData 0.145 (0.145)\tLoss 0.3391 (0.3391)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [135][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.3433 (0.3492)\tPrec@1 93.750 (92.845)\n",
            "Epoch: [135][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.3373 (0.3587)\tPrec@1 92.969 (92.545)\n",
            "Epoch: [135][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.3365 (0.3656)\tPrec@1 92.188 (92.286)\n",
            "Epoch: [135][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.6032 (0.3756)\tPrec@1 87.500 (91.962)\n",
            "Total time : 13.028\n",
            "Train Loss: 0.3756, Train Accuracy: 0.9196\n",
            "Test Loss : 0.8411, Test Accuracy : 0.7599 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.185 (0.185)\tData 0.140 (0.140)\tLoss 0.3219 (0.3219)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [136][100/391]\tTime 0.034 (0.034)\tData 0.000 (0.002)\tLoss 0.3566 (0.3507)\tPrec@1 92.188 (92.922)\n",
            "Epoch: [136][200/391]\tTime 0.034 (0.033)\tData 0.000 (0.001)\tLoss 0.3514 (0.3600)\tPrec@1 92.188 (92.432)\n",
            "Epoch: [136][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.3632 (0.3631)\tPrec@1 92.969 (92.276)\n",
            "Epoch: [136][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.4971 (0.3711)\tPrec@1 87.500 (91.990)\n",
            "Total time : 12.874\n",
            "Train Loss: 0.3711, Train Accuracy: 0.9199\n",
            "Test Loss : 0.8193, Test Accuracy : 0.7611 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.204 (0.204)\tData 0.143 (0.143)\tLoss 0.3086 (0.3086)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [137][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.2522 (0.3454)\tPrec@1 96.875 (93.015)\n",
            "Epoch: [137][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.3910 (0.3485)\tPrec@1 89.062 (92.809)\n",
            "Epoch: [137][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.4883 (0.3579)\tPrec@1 83.594 (92.528)\n",
            "Epoch: [137][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.5097 (0.3632)\tPrec@1 86.250 (92.354)\n",
            "Total time : 13.076\n",
            "Train Loss: 0.3632, Train Accuracy: 0.9235\n",
            "Test Loss : 0.7955, Test Accuracy : 0.7724 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.188 (0.188)\tData 0.149 (0.149)\tLoss 0.3976 (0.3976)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [138][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.3722 (0.3327)\tPrec@1 92.969 (93.348)\n",
            "Epoch: [138][200/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.5087 (0.3413)\tPrec@1 87.500 (92.914)\n",
            "Epoch: [138][300/391]\tTime 0.039 (0.034)\tData 0.000 (0.001)\tLoss 0.3712 (0.3496)\tPrec@1 92.188 (92.668)\n",
            "Epoch: [138][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.3250 (0.3548)\tPrec@1 95.000 (92.514)\n",
            "Total time : 13.006\n",
            "Train Loss: 0.3548, Train Accuracy: 0.9251\n",
            "Test Loss : 0.7982, Test Accuracy : 0.7717 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.195 (0.195)\tData 0.150 (0.150)\tLoss 0.3918 (0.3918)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [139][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.3520 (0.3205)\tPrec@1 90.625 (93.765)\n",
            "Epoch: [139][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.3324 (0.3256)\tPrec@1 93.750 (93.420)\n",
            "Epoch: [139][300/391]\tTime 0.037 (0.033)\tData 0.000 (0.001)\tLoss 0.3301 (0.3319)\tPrec@1 89.844 (93.252)\n",
            "Epoch: [139][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.4335 (0.3393)\tPrec@1 90.000 (92.968)\n",
            "Total time : 12.922\n",
            "Train Loss: 0.3393, Train Accuracy: 0.9297\n",
            "Test Loss : 0.8311, Test Accuracy : 0.7630 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.183 (0.183)\tData 0.143 (0.143)\tLoss 0.2287 (0.2287)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [140][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.2310 (0.3045)\tPrec@1 97.656 (94.230)\n",
            "Epoch: [140][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.2450 (0.3169)\tPrec@1 96.875 (93.614)\n",
            "Epoch: [140][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3744 (0.3258)\tPrec@1 92.969 (93.350)\n",
            "Epoch: [140][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.4497 (0.3357)\tPrec@1 91.250 (93.080)\n",
            "Total time : 13.087\n",
            "Train Loss: 0.3357, Train Accuracy: 0.9308\n",
            "Test Loss : 0.7998, Test Accuracy : 0.7699 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.183 (0.183)\tData 0.144 (0.144)\tLoss 0.2964 (0.2964)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [141][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.3073 (0.3061)\tPrec@1 95.312 (94.144)\n",
            "Epoch: [141][200/391]\tTime 0.037 (0.033)\tData 0.000 (0.001)\tLoss 0.2990 (0.3130)\tPrec@1 94.531 (93.874)\n",
            "Epoch: [141][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.3385 (0.3178)\tPrec@1 90.625 (93.657)\n",
            "Epoch: [141][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.2576 (0.3249)\tPrec@1 95.000 (93.402)\n",
            "Total time : 12.886\n",
            "Train Loss: 0.3249, Train Accuracy: 0.9340\n",
            "Test Loss : 0.7926, Test Accuracy : 0.7745 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.190 (0.190)\tData 0.144 (0.144)\tLoss 0.3438 (0.3438)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [142][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.3476 (0.2940)\tPrec@1 91.406 (94.299)\n",
            "Epoch: [142][200/391]\tTime 0.035 (0.035)\tData 0.000 (0.001)\tLoss 0.2943 (0.3065)\tPrec@1 91.406 (93.878)\n",
            "Epoch: [142][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.2866 (0.3099)\tPrec@1 94.531 (93.716)\n",
            "Epoch: [142][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.3179 (0.3155)\tPrec@1 96.250 (93.544)\n",
            "Total time : 13.183\n",
            "Train Loss: 0.3155, Train Accuracy: 0.9354\n",
            "Test Loss : 0.7811, Test Accuracy : 0.7751 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.206 (0.206)\tData 0.143 (0.143)\tLoss 0.2880 (0.2880)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [143][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.3412 (0.2853)\tPrec@1 92.188 (94.663)\n",
            "Epoch: [143][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.3034 (0.2957)\tPrec@1 93.750 (94.197)\n",
            "Epoch: [143][300/391]\tTime 0.040 (0.033)\tData 0.000 (0.001)\tLoss 0.3753 (0.3050)\tPrec@1 91.406 (93.849)\n",
            "Epoch: [143][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.3186 (0.3111)\tPrec@1 92.500 (93.710)\n",
            "Total time : 12.912\n",
            "Train Loss: 0.3111, Train Accuracy: 0.9371\n",
            "Test Loss : 0.7705, Test Accuracy : 0.7817 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.202 (0.202)\tData 0.143 (0.143)\tLoss 0.2152 (0.2152)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [144][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.2785 (0.2835)\tPrec@1 92.969 (94.431)\n",
            "Epoch: [144][200/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.3697 (0.2884)\tPrec@1 93.750 (94.349)\n",
            "Epoch: [144][300/391]\tTime 0.031 (0.035)\tData 0.000 (0.001)\tLoss 0.2280 (0.2935)\tPrec@1 97.656 (94.285)\n",
            "Epoch: [144][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.2317 (0.2973)\tPrec@1 97.500 (94.276)\n",
            "Total time : 13.359\n",
            "Train Loss: 0.2973, Train Accuracy: 0.9428\n",
            "Test Loss : 0.7822, Test Accuracy : 0.7719 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.206 (0.206)\tData 0.148 (0.148)\tLoss 0.3250 (0.3250)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [145][100/391]\tTime 0.037 (0.035)\tData 0.000 (0.002)\tLoss 0.2504 (0.2672)\tPrec@1 96.094 (95.003)\n",
            "Epoch: [145][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.2254 (0.2742)\tPrec@1 96.094 (94.749)\n",
            "Epoch: [145][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.2277 (0.2813)\tPrec@1 96.875 (94.627)\n",
            "Epoch: [145][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.3380 (0.2849)\tPrec@1 93.750 (94.524)\n",
            "Total time : 13.207\n",
            "Train Loss: 0.2849, Train Accuracy: 0.9452\n",
            "Test Loss : 0.7793, Test Accuracy : 0.7725 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.191 (0.191)\tData 0.146 (0.146)\tLoss 0.2365 (0.2365)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [146][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.2636 (0.2658)\tPrec@1 95.312 (95.135)\n",
            "Epoch: [146][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2208 (0.2698)\tPrec@1 95.312 (94.932)\n",
            "Epoch: [146][300/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.2430 (0.2784)\tPrec@1 96.094 (94.625)\n",
            "Epoch: [146][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.3509 (0.2826)\tPrec@1 91.250 (94.456)\n",
            "Total time : 12.935\n",
            "Train Loss: 0.2826, Train Accuracy: 0.9446\n",
            "Test Loss : 0.7717, Test Accuracy : 0.7769 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.202 (0.202)\tData 0.143 (0.143)\tLoss 0.2133 (0.2133)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [147][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.3462 (0.2596)\tPrec@1 91.406 (95.289)\n",
            "Epoch: [147][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.3290 (0.2655)\tPrec@1 92.188 (95.091)\n",
            "Epoch: [147][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.2919 (0.2709)\tPrec@1 96.094 (94.998)\n",
            "Epoch: [147][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.3833 (0.2737)\tPrec@1 91.250 (94.894)\n",
            "Total time : 12.908\n",
            "Train Loss: 0.2737, Train Accuracy: 0.9489\n",
            "Test Loss : 0.7616, Test Accuracy : 0.7822 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.195 (0.195)\tData 0.154 (0.154)\tLoss 0.2113 (0.2113)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [148][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.3147 (0.2642)\tPrec@1 93.750 (95.212)\n",
            "Epoch: [148][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.2394 (0.2596)\tPrec@1 96.094 (95.340)\n",
            "Epoch: [148][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.1891 (0.2621)\tPrec@1 97.656 (95.172)\n",
            "Epoch: [148][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.3349 (0.2652)\tPrec@1 91.250 (95.056)\n",
            "Total time : 13.298\n",
            "Train Loss: 0.2652, Train Accuracy: 0.9506\n",
            "Test Loss : 0.7605, Test Accuracy : 0.7838 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.201 (0.201)\tData 0.144 (0.144)\tLoss 0.2435 (0.2435)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [149][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.2623 (0.2395)\tPrec@1 95.312 (95.846)\n",
            "Epoch: [149][200/391]\tTime 0.037 (0.035)\tData 0.000 (0.001)\tLoss 0.3339 (0.2495)\tPrec@1 93.750 (95.534)\n",
            "Epoch: [149][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.3205 (0.2538)\tPrec@1 93.750 (95.333)\n",
            "Epoch: [149][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.2825 (0.2583)\tPrec@1 92.500 (95.224)\n",
            "Total time : 13.363\n",
            "Train Loss: 0.2583, Train Accuracy: 0.9522\n",
            "Test Loss : 0.7498, Test Accuracy : 0.7844 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 0.1695 (0.1695)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [150][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.2750 (0.2308)\tPrec@1 95.312 (96.233)\n",
            "Epoch: [150][200/391]\tTime 0.034 (0.034)\tData 0.000 (0.001)\tLoss 0.2405 (0.2391)\tPrec@1 96.875 (95.857)\n",
            "Epoch: [150][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2647 (0.2412)\tPrec@1 94.531 (95.826)\n",
            "Epoch: [150][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.2657 (0.2453)\tPrec@1 95.000 (95.678)\n",
            "Total time : 12.886\n",
            "Train Loss: 0.2453, Train Accuracy: 0.9568\n",
            "Test Loss : 0.7561, Test Accuracy : 0.7840 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.208 (0.208)\tData 0.148 (0.148)\tLoss 0.2609 (0.2609)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [151][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.2423 (0.2240)\tPrec@1 96.094 (96.210)\n",
            "Epoch: [151][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.2800 (0.2293)\tPrec@1 96.094 (96.105)\n",
            "Epoch: [151][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.3186 (0.2349)\tPrec@1 92.969 (95.858)\n",
            "Epoch: [151][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.3158 (0.2382)\tPrec@1 93.750 (95.792)\n",
            "Total time : 12.941\n",
            "Train Loss: 0.2382, Train Accuracy: 0.9579\n",
            "Test Loss : 0.7660, Test Accuracy : 0.7770 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.205 (0.205)\tData 0.163 (0.163)\tLoss 0.2066 (0.2066)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [152][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.1510 (0.2187)\tPrec@1 98.438 (96.248)\n",
            "Epoch: [152][200/391]\tTime 0.036 (0.035)\tData 0.000 (0.001)\tLoss 0.2327 (0.2229)\tPrec@1 95.312 (96.257)\n",
            "Epoch: [152][300/391]\tTime 0.036 (0.035)\tData 0.000 (0.001)\tLoss 0.2807 (0.2289)\tPrec@1 95.312 (96.055)\n",
            "Epoch: [152][390/391]\tTime 0.028 (0.035)\tData 0.000 (0.001)\tLoss 0.2391 (0.2310)\tPrec@1 96.250 (96.004)\n",
            "Total time : 13.590\n",
            "Train Loss: 0.2310, Train Accuracy: 0.9600\n",
            "Test Loss : 0.7340, Test Accuracy : 0.7870 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.196 (0.196)\tData 0.152 (0.152)\tLoss 0.1888 (0.1888)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [153][100/391]\tTime 0.035 (0.036)\tData 0.000 (0.002)\tLoss 0.2496 (0.2070)\tPrec@1 92.969 (96.597)\n",
            "Epoch: [153][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.2422 (0.2107)\tPrec@1 96.875 (96.580)\n",
            "Epoch: [153][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.1842 (0.2198)\tPrec@1 98.438 (96.335)\n",
            "Epoch: [153][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.3101 (0.2222)\tPrec@1 95.000 (96.266)\n",
            "Total time : 13.103\n",
            "Train Loss: 0.2222, Train Accuracy: 0.9627\n",
            "Test Loss : 0.7342, Test Accuracy : 0.7857 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.201 (0.201)\tData 0.155 (0.155)\tLoss 0.1778 (0.1778)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [154][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1699 (0.1983)\tPrec@1 98.438 (96.759)\n",
            "Epoch: [154][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1759 (0.2095)\tPrec@1 97.656 (96.490)\n",
            "Epoch: [154][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.2408 (0.2107)\tPrec@1 99.219 (96.455)\n",
            "Epoch: [154][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.1845 (0.2138)\tPrec@1 98.750 (96.434)\n",
            "Total time : 12.815\n",
            "Train Loss: 0.2138, Train Accuracy: 0.9643\n",
            "Test Loss : 0.7518, Test Accuracy : 0.7884 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.199 (0.199)\tData 0.140 (0.140)\tLoss 0.2138 (0.2138)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [155][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.1965 (0.2001)\tPrec@1 97.656 (96.836)\n",
            "Epoch: [155][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.2368 (0.2044)\tPrec@1 96.875 (96.665)\n",
            "Epoch: [155][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1822 (0.2049)\tPrec@1 96.875 (96.657)\n",
            "Epoch: [155][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.3006 (0.2080)\tPrec@1 96.250 (96.568)\n",
            "Total time : 13.099\n",
            "Train Loss: 0.2080, Train Accuracy: 0.9657\n",
            "Test Loss : 0.7335, Test Accuracy : 0.7917 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.191 (0.191)\tData 0.152 (0.152)\tLoss 0.2463 (0.2463)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [156][100/391]\tTime 0.048 (0.035)\tData 0.000 (0.002)\tLoss 0.1711 (0.1919)\tPrec@1 98.438 (97.061)\n",
            "Epoch: [156][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1877 (0.1952)\tPrec@1 98.438 (96.875)\n",
            "Epoch: [156][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.2495 (0.1997)\tPrec@1 95.312 (96.795)\n",
            "Epoch: [156][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.2294 (0.2033)\tPrec@1 96.250 (96.722)\n",
            "Total time : 13.042\n",
            "Train Loss: 0.2033, Train Accuracy: 0.9672\n",
            "Test Loss : 0.7415, Test Accuracy : 0.7874 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.213 (0.213)\tData 0.171 (0.171)\tLoss 0.1593 (0.1593)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [157][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.1886 (0.1871)\tPrec@1 98.438 (97.115)\n",
            "Epoch: [157][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1781 (0.1888)\tPrec@1 96.875 (97.038)\n",
            "Epoch: [157][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1270 (0.1900)\tPrec@1 98.438 (96.992)\n",
            "Epoch: [157][390/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1675 (0.1952)\tPrec@1 100.000 (96.886)\n",
            "Total time : 12.915\n",
            "Train Loss: 0.1952, Train Accuracy: 0.9689\n",
            "Test Loss : 0.7314, Test Accuracy : 0.7869 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 0.2630 (0.2630)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [158][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1889 (0.1831)\tPrec@1 98.438 (97.223)\n",
            "Epoch: [158][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1525 (0.1832)\tPrec@1 95.312 (97.198)\n",
            "Epoch: [158][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1374 (0.1894)\tPrec@1 99.219 (97.059)\n",
            "Epoch: [158][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.2038 (0.1916)\tPrec@1 95.000 (97.028)\n",
            "Total time : 12.798\n",
            "Train Loss: 0.1916, Train Accuracy: 0.9703\n",
            "Test Loss : 0.7295, Test Accuracy : 0.7887 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.181 (0.181)\tData 0.142 (0.142)\tLoss 0.1713 (0.1713)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [159][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.2286 (0.1767)\tPrec@1 96.875 (97.424)\n",
            "Epoch: [159][200/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.2008 (0.1770)\tPrec@1 96.094 (97.458)\n",
            "Epoch: [159][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.2057 (0.1803)\tPrec@1 97.656 (97.298)\n",
            "Epoch: [159][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.2476 (0.1821)\tPrec@1 95.000 (97.228)\n",
            "Total time : 12.866\n",
            "Train Loss: 0.1821, Train Accuracy: 0.9723\n",
            "Test Loss : 0.7139, Test Accuracy : 0.7971 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.206 (0.206)\tData 0.148 (0.148)\tLoss 0.1295 (0.1295)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [160][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1563 (0.1623)\tPrec@1 96.094 (97.726)\n",
            "Epoch: [160][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1584 (0.1684)\tPrec@1 98.438 (97.586)\n",
            "Epoch: [160][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.1354 (0.1712)\tPrec@1 98.438 (97.524)\n",
            "Epoch: [160][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.1286 (0.1741)\tPrec@1 98.750 (97.390)\n",
            "Total time : 13.184\n",
            "Train Loss: 0.1741, Train Accuracy: 0.9739\n",
            "Test Loss : 0.7143, Test Accuracy : 0.7958 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.196 (0.196)\tData 0.144 (0.144)\tLoss 0.1606 (0.1606)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [161][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.1745 (0.1663)\tPrec@1 97.656 (97.525)\n",
            "Epoch: [161][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1737 (0.1672)\tPrec@1 97.656 (97.509)\n",
            "Epoch: [161][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1839 (0.1691)\tPrec@1 95.312 (97.449)\n",
            "Epoch: [161][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.2010 (0.1691)\tPrec@1 96.250 (97.496)\n",
            "Total time : 12.972\n",
            "Train Loss: 0.1691, Train Accuracy: 0.9750\n",
            "Test Loss : 0.7150, Test Accuracy : 0.7972 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.205 (0.205)\tData 0.148 (0.148)\tLoss 0.1685 (0.1685)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [162][100/391]\tTime 0.039 (0.034)\tData 0.000 (0.002)\tLoss 0.2001 (0.1619)\tPrec@1 97.656 (97.749)\n",
            "Epoch: [162][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.1297 (0.1632)\tPrec@1 99.219 (97.621)\n",
            "Epoch: [162][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1491 (0.1641)\tPrec@1 99.219 (97.581)\n",
            "Epoch: [162][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.1461 (0.1655)\tPrec@1 96.250 (97.556)\n",
            "Total time : 12.786\n",
            "Train Loss: 0.1655, Train Accuracy: 0.9756\n",
            "Test Loss : 0.7146, Test Accuracy : 0.7972 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.181 (0.181)\tData 0.141 (0.141)\tLoss 0.1347 (0.1347)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [163][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.1176 (0.1499)\tPrec@1 100.000 (97.919)\n",
            "Epoch: [163][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.1415 (0.1518)\tPrec@1 99.219 (97.851)\n",
            "Epoch: [163][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1674 (0.1540)\tPrec@1 97.656 (97.879)\n",
            "Epoch: [163][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.2210 (0.1572)\tPrec@1 96.250 (97.798)\n",
            "Total time : 12.848\n",
            "Train Loss: 0.1572, Train Accuracy: 0.9780\n",
            "Test Loss : 0.6999, Test Accuracy : 0.8015 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.193 (0.193)\tData 0.147 (0.147)\tLoss 0.0996 (0.0996)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [164][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.1862 (0.1481)\tPrec@1 97.656 (97.896)\n",
            "Epoch: [164][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.1864 (0.1503)\tPrec@1 95.312 (97.870)\n",
            "Epoch: [164][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1212 (0.1520)\tPrec@1 98.438 (97.846)\n",
            "Epoch: [164][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.2028 (0.1527)\tPrec@1 96.250 (97.826)\n",
            "Total time : 13.101\n",
            "Train Loss: 0.1527, Train Accuracy: 0.9783\n",
            "Test Loss : 0.7030, Test Accuracy : 0.7991 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.220 (0.220)\tData 0.148 (0.148)\tLoss 0.1308 (0.1308)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [165][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.0905 (0.1384)\tPrec@1 97.656 (98.105)\n",
            "Epoch: [165][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.1450 (0.1420)\tPrec@1 98.438 (98.092)\n",
            "Epoch: [165][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.0975 (0.1442)\tPrec@1 98.438 (97.983)\n",
            "Epoch: [165][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.0883 (0.1456)\tPrec@1 98.750 (97.952)\n",
            "Total time : 12.981\n",
            "Train Loss: 0.1456, Train Accuracy: 0.9795\n",
            "Test Loss : 0.7020, Test Accuracy : 0.7988 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 0.1067 (0.1067)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [166][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.1092 (0.1412)\tPrec@1 99.219 (98.105)\n",
            "Epoch: [166][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1404 (0.1414)\tPrec@1 97.656 (98.099)\n",
            "Epoch: [166][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.1983 (0.1422)\tPrec@1 95.312 (98.014)\n",
            "Epoch: [166][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.1772 (0.1420)\tPrec@1 97.500 (98.046)\n",
            "Total time : 12.997\n",
            "Train Loss: 0.1420, Train Accuracy: 0.9805\n",
            "Test Loss : 0.6978, Test Accuracy : 0.7980 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.188 (0.188)\tData 0.147 (0.147)\tLoss 0.1469 (0.1469)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [167][100/391]\tTime 0.040 (0.034)\tData 0.000 (0.002)\tLoss 0.1326 (0.1386)\tPrec@1 98.438 (98.136)\n",
            "Epoch: [167][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1568 (0.1402)\tPrec@1 98.438 (98.099)\n",
            "Epoch: [167][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1455 (0.1405)\tPrec@1 96.875 (98.090)\n",
            "Epoch: [167][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.1304 (0.1397)\tPrec@1 98.750 (98.104)\n",
            "Total time : 13.226\n",
            "Train Loss: 0.1397, Train Accuracy: 0.9810\n",
            "Test Loss : 0.6866, Test Accuracy : 0.8035 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.202 (0.202)\tData 0.158 (0.158)\tLoss 0.0992 (0.0992)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [168][100/391]\tTime 0.036 (0.037)\tData 0.000 (0.002)\tLoss 0.0915 (0.1276)\tPrec@1 99.219 (98.414)\n",
            "Epoch: [168][200/391]\tTime 0.037 (0.036)\tData 0.000 (0.001)\tLoss 0.0922 (0.1270)\tPrec@1 98.438 (98.391)\n",
            "Epoch: [168][300/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.0935 (0.1281)\tPrec@1 99.219 (98.310)\n",
            "Epoch: [168][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.1820 (0.1302)\tPrec@1 97.500 (98.288)\n",
            "Total time : 13.465\n",
            "Train Loss: 0.1302, Train Accuracy: 0.9829\n",
            "Test Loss : 0.6860, Test Accuracy : 0.8038 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.185 (0.185)\tData 0.139 (0.139)\tLoss 0.1050 (0.1050)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [169][100/391]\tTime 0.033 (0.036)\tData 0.000 (0.002)\tLoss 0.0939 (0.1186)\tPrec@1 99.219 (98.716)\n",
            "Epoch: [169][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.1480 (0.1219)\tPrec@1 96.875 (98.542)\n",
            "Epoch: [169][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.1153 (0.1233)\tPrec@1 99.219 (98.521)\n",
            "Epoch: [169][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.1063 (0.1241)\tPrec@1 100.000 (98.486)\n",
            "Total time : 13.115\n",
            "Train Loss: 0.1241, Train Accuracy: 0.9849\n",
            "Test Loss : 0.6784, Test Accuracy : 0.8043 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.199 (0.199)\tData 0.141 (0.141)\tLoss 0.0763 (0.0763)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [170][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.1085 (0.1133)\tPrec@1 99.219 (98.700)\n",
            "Epoch: [170][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1335 (0.1209)\tPrec@1 99.219 (98.488)\n",
            "Epoch: [170][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1020 (0.1212)\tPrec@1 99.219 (98.489)\n",
            "Epoch: [170][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.1975 (0.1212)\tPrec@1 97.500 (98.490)\n",
            "Total time : 12.786\n",
            "Train Loss: 0.1212, Train Accuracy: 0.9849\n",
            "Test Loss : 0.6791, Test Accuracy : 0.8063 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.188 (0.188)\tData 0.142 (0.142)\tLoss 0.0969 (0.0969)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [171][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.1203 (0.1151)\tPrec@1 99.219 (98.631)\n",
            "Epoch: [171][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1183 (0.1177)\tPrec@1 97.656 (98.554)\n",
            "Epoch: [171][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.0907 (0.1195)\tPrec@1 99.219 (98.471)\n",
            "Epoch: [171][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.1213 (0.1199)\tPrec@1 98.750 (98.436)\n",
            "Total time : 12.848\n",
            "Train Loss: 0.1199, Train Accuracy: 0.9844\n",
            "Test Loss : 0.6758, Test Accuracy : 0.8073 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.204 (0.204)\tData 0.145 (0.145)\tLoss 0.1226 (0.1226)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [172][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.0802 (0.1161)\tPrec@1 99.219 (98.631)\n",
            "Epoch: [172][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1108 (0.1143)\tPrec@1 98.438 (98.601)\n",
            "Epoch: [172][300/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1006 (0.1166)\tPrec@1 98.438 (98.534)\n",
            "Epoch: [172][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.0965 (0.1170)\tPrec@1 100.000 (98.528)\n",
            "Total time : 12.879\n",
            "Train Loss: 0.1170, Train Accuracy: 0.9853\n",
            "Test Loss : 0.6679, Test Accuracy : 0.8100 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.198 (0.198)\tData 0.147 (0.147)\tLoss 0.1258 (0.1258)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [173][100/391]\tTime 0.032 (0.036)\tData 0.000 (0.002)\tLoss 0.1479 (0.1128)\tPrec@1 97.656 (98.608)\n",
            "Epoch: [173][200/391]\tTime 0.036 (0.035)\tData 0.000 (0.001)\tLoss 0.1338 (0.1143)\tPrec@1 98.438 (98.577)\n",
            "Epoch: [173][300/391]\tTime 0.037 (0.035)\tData 0.000 (0.001)\tLoss 0.1402 (0.1160)\tPrec@1 97.656 (98.552)\n",
            "Epoch: [173][390/391]\tTime 0.030 (0.034)\tData 0.000 (0.001)\tLoss 0.1705 (0.1160)\tPrec@1 97.500 (98.582)\n",
            "Total time : 13.442\n",
            "Train Loss: 0.1160, Train Accuracy: 0.9858\n",
            "Test Loss : 0.6697, Test Accuracy : 0.8081 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.189 (0.189)\tData 0.145 (0.145)\tLoss 0.0594 (0.0594)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [174][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.0874 (0.1042)\tPrec@1 99.219 (98.817)\n",
            "Epoch: [174][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.1362 (0.1073)\tPrec@1 96.875 (98.713)\n",
            "Epoch: [174][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.0761 (0.1091)\tPrec@1 99.219 (98.650)\n",
            "Epoch: [174][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.1312 (0.1092)\tPrec@1 97.500 (98.656)\n",
            "Total time : 13.025\n",
            "Train Loss: 0.1092, Train Accuracy: 0.9866\n",
            "Test Loss : 0.6685, Test Accuracy : 0.8090 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.190 (0.190)\tData 0.150 (0.150)\tLoss 0.0602 (0.0602)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [175][100/391]\tTime 0.038 (0.034)\tData 0.000 (0.002)\tLoss 0.1039 (0.1082)\tPrec@1 99.219 (98.724)\n",
            "Epoch: [175][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0780 (0.1080)\tPrec@1 99.219 (98.632)\n",
            "Epoch: [175][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1144 (0.1071)\tPrec@1 98.438 (98.640)\n",
            "Epoch: [175][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.1385 (0.1064)\tPrec@1 100.000 (98.672)\n",
            "Total time : 12.964\n",
            "Train Loss: 0.1064, Train Accuracy: 0.9867\n",
            "Test Loss : 0.6640, Test Accuracy : 0.8096 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 0.0876 (0.0876)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [176][100/391]\tTime 0.031 (0.033)\tData 0.000 (0.002)\tLoss 0.1252 (0.1042)\tPrec@1 97.656 (98.739)\n",
            "Epoch: [176][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1199 (0.1039)\tPrec@1 97.656 (98.811)\n",
            "Epoch: [176][300/391]\tTime 0.031 (0.032)\tData 0.000 (0.001)\tLoss 0.0892 (0.1050)\tPrec@1 99.219 (98.780)\n",
            "Epoch: [176][390/391]\tTime 0.029 (0.032)\tData 0.000 (0.001)\tLoss 0.1711 (0.1055)\tPrec@1 97.500 (98.750)\n",
            "Total time : 12.628\n",
            "Train Loss: 0.1055, Train Accuracy: 0.9875\n",
            "Test Loss : 0.6570, Test Accuracy : 0.8108 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.188 (0.188)\tData 0.143 (0.143)\tLoss 0.1230 (0.1230)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [177][100/391]\tTime 0.037 (0.037)\tData 0.000 (0.002)\tLoss 0.1150 (0.1000)\tPrec@1 98.438 (98.886)\n",
            "Epoch: [177][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 0.1310 (0.1002)\tPrec@1 98.438 (98.853)\n",
            "Epoch: [177][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0917 (0.1012)\tPrec@1 99.219 (98.822)\n",
            "Epoch: [177][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.1637 (0.1029)\tPrec@1 98.750 (98.774)\n",
            "Total time : 13.138\n",
            "Train Loss: 0.1029, Train Accuracy: 0.9877\n",
            "Test Loss : 0.6607, Test Accuracy : 0.8102 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.190 (0.190)\tData 0.149 (0.149)\tLoss 0.0870 (0.0870)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [178][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.1031 (0.0995)\tPrec@1 99.219 (98.956)\n",
            "Epoch: [178][200/391]\tTime 0.038 (0.035)\tData 0.000 (0.001)\tLoss 0.0683 (0.0975)\tPrec@1 100.000 (98.943)\n",
            "Epoch: [178][300/391]\tTime 0.038 (0.035)\tData 0.000 (0.001)\tLoss 0.1071 (0.0980)\tPrec@1 98.438 (98.910)\n",
            "Epoch: [178][390/391]\tTime 0.029 (0.035)\tData 0.000 (0.001)\tLoss 0.0743 (0.0978)\tPrec@1 98.750 (98.904)\n",
            "Total time : 13.670\n",
            "Train Loss: 0.0978, Train Accuracy: 0.9890\n",
            "Test Loss : 0.6605, Test Accuracy : 0.8128 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.188 (0.188)\tData 0.147 (0.147)\tLoss 0.0793 (0.0793)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [179][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.1020 (0.0968)\tPrec@1 99.219 (98.971)\n",
            "Epoch: [179][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.0793 (0.0956)\tPrec@1 99.219 (98.974)\n",
            "Epoch: [179][300/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.0848 (0.0968)\tPrec@1 100.000 (98.970)\n",
            "Epoch: [179][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.2095 (0.0957)\tPrec@1 95.000 (98.944)\n",
            "Total time : 13.092\n",
            "Train Loss: 0.0957, Train Accuracy: 0.9894\n",
            "Test Loss : 0.6563, Test Accuracy : 0.8131 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.208 (0.208)\tData 0.147 (0.147)\tLoss 0.0684 (0.0684)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [180][100/391]\tTime 0.036 (0.036)\tData 0.000 (0.002)\tLoss 0.0793 (0.0932)\tPrec@1 99.219 (98.971)\n",
            "Epoch: [180][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.0437 (0.0944)\tPrec@1 100.000 (98.939)\n",
            "Epoch: [180][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0925 (0.0942)\tPrec@1 100.000 (98.959)\n",
            "Epoch: [180][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.0788 (0.0946)\tPrec@1 100.000 (98.938)\n",
            "Total time : 13.069\n",
            "Train Loss: 0.0946, Train Accuracy: 0.9894\n",
            "Test Loss : 0.6509, Test Accuracy : 0.8158 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.181 (0.181)\tData 0.142 (0.142)\tLoss 0.0775 (0.0775)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [181][100/391]\tTime 0.032 (0.033)\tData 0.000 (0.002)\tLoss 0.0815 (0.0882)\tPrec@1 100.000 (99.056)\n",
            "Epoch: [181][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.0894 (0.0886)\tPrec@1 100.000 (99.028)\n",
            "Epoch: [181][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1067 (0.0904)\tPrec@1 99.219 (98.996)\n",
            "Epoch: [181][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.0778 (0.0899)\tPrec@1 100.000 (99.016)\n",
            "Total time : 12.759\n",
            "Train Loss: 0.0899, Train Accuracy: 0.9902\n",
            "Test Loss : 0.6498, Test Accuracy : 0.8154 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.186 (0.186)\tData 0.143 (0.143)\tLoss 0.0364 (0.0364)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [182][100/391]\tTime 0.038 (0.035)\tData 0.000 (0.002)\tLoss 0.0666 (0.0855)\tPrec@1 99.219 (99.002)\n",
            "Epoch: [182][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0606 (0.0879)\tPrec@1 100.000 (98.982)\n",
            "Epoch: [182][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.0929 (0.0886)\tPrec@1 99.219 (98.990)\n",
            "Epoch: [182][390/391]\tTime 0.029 (0.033)\tData 0.000 (0.001)\tLoss 0.0853 (0.0895)\tPrec@1 100.000 (99.004)\n",
            "Total time : 13.090\n",
            "Train Loss: 0.0895, Train Accuracy: 0.9900\n",
            "Test Loss : 0.6482, Test Accuracy : 0.8149 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.184 (0.184)\tData 0.145 (0.145)\tLoss 0.0840 (0.0840)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [183][100/391]\tTime 0.036 (0.036)\tData 0.000 (0.002)\tLoss 0.0950 (0.0904)\tPrec@1 98.438 (99.033)\n",
            "Epoch: [183][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0968 (0.0875)\tPrec@1 97.656 (99.079)\n",
            "Epoch: [183][300/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.0866 (0.0885)\tPrec@1 99.219 (99.001)\n",
            "Epoch: [183][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.1356 (0.0881)\tPrec@1 96.250 (99.008)\n",
            "Total time : 13.187\n",
            "Train Loss: 0.0881, Train Accuracy: 0.9901\n",
            "Test Loss : 0.6492, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.190 (0.190)\tData 0.150 (0.150)\tLoss 0.1154 (0.1154)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [184][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.0727 (0.0850)\tPrec@1 99.219 (99.180)\n",
            "Epoch: [184][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.0962 (0.0842)\tPrec@1 99.219 (99.192)\n",
            "Epoch: [184][300/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.0551 (0.0851)\tPrec@1 100.000 (99.143)\n",
            "Epoch: [184][390/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1068 (0.0859)\tPrec@1 98.750 (99.124)\n",
            "Total time : 13.009\n",
            "Train Loss: 0.0859, Train Accuracy: 0.9912\n",
            "Test Loss : 0.6449, Test Accuracy : 0.8151 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.193 (0.193)\tData 0.154 (0.154)\tLoss 0.0718 (0.0718)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [185][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0675 (0.0848)\tPrec@1 100.000 (99.126)\n",
            "Epoch: [185][200/391]\tTime 0.033 (0.033)\tData 0.000 (0.001)\tLoss 0.0718 (0.0843)\tPrec@1 99.219 (99.094)\n",
            "Epoch: [185][300/391]\tTime 0.036 (0.033)\tData 0.000 (0.001)\tLoss 0.1198 (0.0842)\tPrec@1 97.656 (99.068)\n",
            "Epoch: [185][390/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.1185 (0.0841)\tPrec@1 98.750 (99.088)\n",
            "Total time : 12.942\n",
            "Train Loss: 0.0841, Train Accuracy: 0.9909\n",
            "Test Loss : 0.6438, Test Accuracy : 0.8149 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.206 (0.206)\tData 0.148 (0.148)\tLoss 0.1018 (0.1018)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [186][100/391]\tTime 0.037 (0.036)\tData 0.000 (0.002)\tLoss 0.0725 (0.0846)\tPrec@1 99.219 (99.064)\n",
            "Epoch: [186][200/391]\tTime 0.033 (0.035)\tData 0.000 (0.001)\tLoss 0.0742 (0.0840)\tPrec@1 100.000 (99.122)\n",
            "Epoch: [186][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.0965 (0.0841)\tPrec@1 99.219 (99.092)\n",
            "Epoch: [186][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.1037 (0.0839)\tPrec@1 97.500 (99.096)\n",
            "Total time : 13.438\n",
            "Train Loss: 0.0839, Train Accuracy: 0.9910\n",
            "Test Loss : 0.6429, Test Accuracy : 0.8150 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.194 (0.194)\tData 0.151 (0.151)\tLoss 0.1092 (0.1092)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [187][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.0731 (0.0826)\tPrec@1 99.219 (99.080)\n",
            "Epoch: [187][200/391]\tTime 0.035 (0.034)\tData 0.000 (0.001)\tLoss 0.1074 (0.0836)\tPrec@1 98.438 (99.071)\n",
            "Epoch: [187][300/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.0879 (0.0829)\tPrec@1 100.000 (99.060)\n",
            "Epoch: [187][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.0955 (0.0828)\tPrec@1 100.000 (99.082)\n",
            "Total time : 13.236\n",
            "Train Loss: 0.0828, Train Accuracy: 0.9908\n",
            "Test Loss : 0.6423, Test Accuracy : 0.8167 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.199 (0.199)\tData 0.153 (0.153)\tLoss 0.0733 (0.0733)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [188][100/391]\tTime 0.031 (0.034)\tData 0.000 (0.002)\tLoss 0.0796 (0.0856)\tPrec@1 99.219 (99.010)\n",
            "Epoch: [188][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1262 (0.0818)\tPrec@1 98.438 (99.157)\n",
            "Epoch: [188][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0604 (0.0812)\tPrec@1 100.000 (99.159)\n",
            "Epoch: [188][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.0853 (0.0806)\tPrec@1 100.000 (99.174)\n",
            "Total time : 12.941\n",
            "Train Loss: 0.0806, Train Accuracy: 0.9917\n",
            "Test Loss : 0.6394, Test Accuracy : 0.8174 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.185 (0.185)\tData 0.146 (0.146)\tLoss 0.0810 (0.0810)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [189][100/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.1098 (0.0814)\tPrec@1 97.656 (99.064)\n",
            "Epoch: [189][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0653 (0.0802)\tPrec@1 99.219 (99.098)\n",
            "Epoch: [189][300/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.0568 (0.0788)\tPrec@1 100.000 (99.138)\n",
            "Epoch: [189][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.0538 (0.0801)\tPrec@1 100.000 (99.154)\n",
            "Total time : 13.224\n",
            "Train Loss: 0.0801, Train Accuracy: 0.9915\n",
            "Test Loss : 0.6405, Test Accuracy : 0.8175 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.215 (0.215)\tData 0.153 (0.153)\tLoss 0.0521 (0.0521)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [190][100/391]\tTime 0.032 (0.037)\tData 0.000 (0.002)\tLoss 0.0603 (0.0805)\tPrec@1 100.000 (99.149)\n",
            "Epoch: [190][200/391]\tTime 0.032 (0.035)\tData 0.000 (0.001)\tLoss 0.0858 (0.0816)\tPrec@1 99.219 (99.118)\n",
            "Epoch: [190][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.0836 (0.0805)\tPrec@1 99.219 (99.141)\n",
            "Epoch: [190][390/391]\tTime 0.028 (0.034)\tData 0.000 (0.001)\tLoss 0.1178 (0.0807)\tPrec@1 98.750 (99.138)\n",
            "Total time : 13.183\n",
            "Train Loss: 0.0807, Train Accuracy: 0.9914\n",
            "Test Loss : 0.6385, Test Accuracy : 0.8183 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.216 (0.216)\tData 0.153 (0.153)\tLoss 0.0850 (0.0850)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [191][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.0943 (0.0773)\tPrec@1 99.219 (99.203)\n",
            "Epoch: [191][200/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.0766 (0.0776)\tPrec@1 99.219 (99.180)\n",
            "Epoch: [191][300/391]\tTime 0.033 (0.034)\tData 0.000 (0.001)\tLoss 0.0958 (0.0781)\tPrec@1 99.219 (99.138)\n",
            "Epoch: [191][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.1053 (0.0781)\tPrec@1 97.500 (99.162)\n",
            "Total time : 13.137\n",
            "Train Loss: 0.0781, Train Accuracy: 0.9916\n",
            "Test Loss : 0.6408, Test Accuracy : 0.8172 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.181 (0.181)\tData 0.141 (0.141)\tLoss 0.0506 (0.0506)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [192][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.0471 (0.0782)\tPrec@1 100.000 (99.304)\n",
            "Epoch: [192][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.1034 (0.0785)\tPrec@1 99.219 (99.223)\n",
            "Epoch: [192][300/391]\tTime 0.039 (0.033)\tData 0.000 (0.001)\tLoss 0.0987 (0.0784)\tPrec@1 98.438 (99.211)\n",
            "Epoch: [192][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.0934 (0.0787)\tPrec@1 97.500 (99.190)\n",
            "Total time : 12.841\n",
            "Train Loss: 0.0787, Train Accuracy: 0.9919\n",
            "Test Loss : 0.6374, Test Accuracy : 0.8157 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.188 (0.188)\tData 0.146 (0.146)\tLoss 0.0668 (0.0668)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [193][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.0791 (0.0800)\tPrec@1 98.438 (99.141)\n",
            "Epoch: [193][200/391]\tTime 0.035 (0.033)\tData 0.000 (0.001)\tLoss 0.0854 (0.0795)\tPrec@1 100.000 (99.207)\n",
            "Epoch: [193][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.0644 (0.0781)\tPrec@1 100.000 (99.221)\n",
            "Epoch: [193][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.1221 (0.0771)\tPrec@1 96.250 (99.220)\n",
            "Total time : 13.054\n",
            "Train Loss: 0.0771, Train Accuracy: 0.9922\n",
            "Test Loss : 0.6383, Test Accuracy : 0.8165 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.203 (0.203)\tData 0.147 (0.147)\tLoss 0.1122 (0.1122)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [194][100/391]\tTime 0.033 (0.034)\tData 0.000 (0.002)\tLoss 0.0919 (0.0748)\tPrec@1 99.219 (99.242)\n",
            "Epoch: [194][200/391]\tTime 0.036 (0.034)\tData 0.000 (0.001)\tLoss 0.0945 (0.0754)\tPrec@1 98.438 (99.211)\n",
            "Epoch: [194][300/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.1052 (0.0762)\tPrec@1 99.219 (99.216)\n",
            "Epoch: [194][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.0921 (0.0764)\tPrec@1 100.000 (99.214)\n",
            "Total time : 13.107\n",
            "Train Loss: 0.0764, Train Accuracy: 0.9921\n",
            "Test Loss : 0.6376, Test Accuracy : 0.8145 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.213 (0.213)\tData 0.144 (0.144)\tLoss 0.0625 (0.0625)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [195][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.002)\tLoss 0.0533 (0.0741)\tPrec@1 100.000 (99.381)\n",
            "Epoch: [195][200/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0415 (0.0727)\tPrec@1 100.000 (99.429)\n",
            "Epoch: [195][300/391]\tTime 0.037 (0.034)\tData 0.000 (0.001)\tLoss 0.0504 (0.0739)\tPrec@1 100.000 (99.325)\n",
            "Epoch: [195][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.0912 (0.0739)\tPrec@1 100.000 (99.298)\n",
            "Total time : 13.237\n",
            "Train Loss: 0.0739, Train Accuracy: 0.9930\n",
            "Test Loss : 0.6361, Test Accuracy : 0.8168 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.201 (0.201)\tData 0.142 (0.142)\tLoss 0.0573 (0.0573)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [196][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.0715 (0.0772)\tPrec@1 99.219 (99.296)\n",
            "Epoch: [196][200/391]\tTime 0.031 (0.034)\tData 0.000 (0.001)\tLoss 0.0707 (0.0783)\tPrec@1 99.219 (99.184)\n",
            "Epoch: [196][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1060 (0.0778)\tPrec@1 98.438 (99.169)\n",
            "Epoch: [196][390/391]\tTime 0.028 (0.033)\tData 0.000 (0.001)\tLoss 0.0879 (0.0767)\tPrec@1 100.000 (99.218)\n",
            "Total time : 12.789\n",
            "Train Loss: 0.0767, Train Accuracy: 0.9922\n",
            "Test Loss : 0.6364, Test Accuracy : 0.8166 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.182 (0.182)\tData 0.143 (0.143)\tLoss 0.0777 (0.0777)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [197][100/391]\tTime 0.032 (0.034)\tData 0.000 (0.002)\tLoss 0.0583 (0.0747)\tPrec@1 99.219 (99.327)\n",
            "Epoch: [197][200/391]\tTime 0.032 (0.033)\tData 0.000 (0.001)\tLoss 0.0393 (0.0743)\tPrec@1 100.000 (99.304)\n",
            "Epoch: [197][300/391]\tTime 0.032 (0.034)\tData 0.000 (0.001)\tLoss 0.0832 (0.0757)\tPrec@1 100.000 (99.273)\n",
            "Epoch: [197][390/391]\tTime 0.034 (0.034)\tData 0.000 (0.001)\tLoss 0.0467 (0.0757)\tPrec@1 100.000 (99.262)\n",
            "Total time : 13.261\n",
            "Train Loss: 0.0757, Train Accuracy: 0.9926\n",
            "Test Loss : 0.6381, Test Accuracy : 0.8155 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 0.0606 (0.0606)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [198][100/391]\tTime 0.031 (0.035)\tData 0.000 (0.002)\tLoss 0.0572 (0.0764)\tPrec@1 100.000 (99.281)\n",
            "Epoch: [198][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0781 (0.0755)\tPrec@1 98.438 (99.285)\n",
            "Epoch: [198][300/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.0999 (0.0761)\tPrec@1 99.219 (99.260)\n",
            "Epoch: [198][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.0857 (0.0760)\tPrec@1 100.000 (99.270)\n",
            "Total time : 13.140\n",
            "Train Loss: 0.0760, Train Accuracy: 0.9927\n",
            "Test Loss : 0.6360, Test Accuracy : 0.8166 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.199 (0.199)\tData 0.142 (0.142)\tLoss 0.1098 (0.1098)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [199][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.002)\tLoss 0.0591 (0.0771)\tPrec@1 100.000 (99.242)\n",
            "Epoch: [199][200/391]\tTime 0.031 (0.033)\tData 0.000 (0.001)\tLoss 0.1163 (0.0774)\tPrec@1 98.438 (99.164)\n",
            "Epoch: [199][300/391]\tTime 0.038 (0.034)\tData 0.000 (0.001)\tLoss 0.0448 (0.0762)\tPrec@1 99.219 (99.211)\n",
            "Epoch: [199][390/391]\tTime 0.029 (0.034)\tData 0.000 (0.001)\tLoss 0.0837 (0.0769)\tPrec@1 100.000 (99.188)\n",
            "Total time : 13.306\n",
            "Train Loss: 0.0769, Train Accuracy: 0.9919\n",
            "Test Loss : 0.6365, Test Accuracy : 0.8168 \n",
            "\n",
            "train loss:  [4.0604, 3.6079, 3.2824, 2.9919, 2.6782, 2.3911, 2.1737, 2.0164, 1.8926, 1.7995, 1.7298, 1.6704, 1.6241, 1.5745, 1.5288, 1.5006, 1.4718, 1.4547, 1.4244, 1.3976, 1.3846, 1.3685, 1.3442, 1.3237, 1.3113, 1.2961, 1.291, 1.2726, 1.2678, 1.2505, 1.2397, 1.2244, 1.2218, 1.2057, 1.2041, 1.1897, 1.1865, 1.1765, 1.1647, 1.1531, 1.1448, 1.1374, 1.1324, 1.1206, 1.1209, 1.104, 1.0989, 1.0976, 1.0917, 1.0775, 1.0798, 1.0665, 1.0588, 1.0576, 1.0414, 1.0441, 1.0342, 1.0247, 1.0159, 1.0163, 1.0042, 1.0005, 0.9963, 0.9893, 0.9825, 0.9758, 0.9675, 0.9642, 0.9541, 0.9396, 0.9361, 0.9361, 0.9305, 0.923, 0.9151, 0.9048, 0.8917, 0.8903, 0.8801, 0.8694, 0.863, 0.8552, 0.8511, 0.8423, 0.8328, 0.8313, 0.8245, 0.8127, 0.8095, 0.7983, 0.7982, 0.7798, 0.7751, 0.7652, 0.7605, 0.7581, 0.7483, 0.7331, 0.7315, 0.7185, 0.7112, 0.7081, 0.6962, 0.6841, 0.6792, 0.6667, 0.6579, 0.6484, 0.6403, 0.6346, 0.6181, 0.6121, 0.6028, 0.5892, 0.5842, 0.5762, 0.5634, 0.5623, 0.544, 0.5381, 0.5274, 0.5219, 0.5085, 0.4966, 0.4864, 0.4842, 0.4677, 0.4576, 0.45, 0.4424, 0.4341, 0.4157, 0.4104, 0.4017, 0.3921, 0.3756, 0.3711, 0.3632, 0.3548, 0.3393, 0.3357, 0.3249, 0.3155, 0.3111, 0.2973, 0.2849, 0.2826, 0.2737, 0.2652, 0.2583, 0.2453, 0.2382, 0.231, 0.2222, 0.2138, 0.208, 0.2033, 0.1952, 0.1916, 0.1821, 0.1741, 0.1691, 0.1655, 0.1572, 0.1527, 0.1456, 0.142, 0.1397, 0.1302, 0.1241, 0.1212, 0.1199, 0.117, 0.116, 0.1092, 0.1064, 0.1055, 0.1029, 0.0978, 0.0957, 0.0946, 0.0899, 0.0895, 0.0881, 0.0859, 0.0841, 0.0839, 0.0828, 0.0806, 0.0801, 0.0807, 0.0781, 0.0787, 0.0771, 0.0764, 0.0739, 0.0767, 0.0757, 0.076, 0.0769]\n",
            "train err:  [0.9257, 0.8629, 0.8027, 0.7505, 0.6877, 0.6277, 0.5763, 0.5402, 0.509, 0.4881, 0.4675, 0.4522, 0.4411, 0.4279, 0.4165, 0.4087, 0.4, 0.399, 0.3905, 0.3816, 0.3771, 0.3715, 0.3653, 0.3604, 0.3571, 0.3534, 0.3507, 0.3469, 0.3454, 0.3408, 0.3384, 0.3372, 0.3338, 0.3284, 0.3288, 0.3241, 0.3215, 0.3184, 0.3182, 0.313, 0.3101, 0.3093, 0.3091, 0.304, 0.304, 0.2994, 0.2984, 0.2984, 0.2952, 0.293, 0.293, 0.289, 0.2874, 0.2864, 0.2843, 0.2816, 0.2789, 0.2775, 0.2755, 0.2748, 0.2722, 0.2697, 0.2684, 0.2664, 0.2642, 0.2635, 0.2612, 0.2589, 0.2581, 0.2518, 0.251, 0.2522, 0.2499, 0.2491, 0.2463, 0.2436, 0.2389, 0.2394, 0.2341, 0.2327, 0.2295, 0.2293, 0.2268, 0.2231, 0.2208, 0.2211, 0.2201, 0.2176, 0.2136, 0.2099, 0.2108, 0.2037, 0.2051, 0.2029, 0.1993, 0.2, 0.1972, 0.1932, 0.1919, 0.1867, 0.1858, 0.1837, 0.1816, 0.1772, 0.1755, 0.1711, 0.1687, 0.1666, 0.1641, 0.1618, 0.1584, 0.154, 0.1521, 0.1476, 0.1469, 0.1441, 0.1386, 0.1387, 0.1331, 0.1325, 0.1288, 0.1263, 0.1206, 0.1173, 0.1165, 0.1154, 0.1084, 0.1058, 0.1032, 0.1023, 0.1002, 0.0945, 0.0928, 0.0899, 0.0867, 0.0804, 0.0801, 0.0765, 0.0749, 0.0703, 0.0692, 0.066, 0.0646, 0.0629, 0.0572, 0.0548, 0.0554, 0.0511, 0.0494, 0.0478, 0.0432, 0.0421, 0.04, 0.0373, 0.0357, 0.0343, 0.0328, 0.0311, 0.0297, 0.0277, 0.0261, 0.025, 0.0244, 0.022, 0.0217, 0.0205, 0.0195, 0.019, 0.0171, 0.0151, 0.0151, 0.0156, 0.0147, 0.0142, 0.0134, 0.0133, 0.0125, 0.0123, 0.011, 0.0106, 0.0106, 0.0098, 0.01, 0.0099, 0.0088, 0.0091, 0.009, 0.0092, 0.0083, 0.0085, 0.0086, 0.0084, 0.0081, 0.0078, 0.0079, 0.007, 0.0078, 0.0074, 0.0073, 0.0081]\n",
            "train acc:  [0.0743, 0.1371, 0.1973, 0.2495, 0.3123, 0.3723, 0.4237, 0.4598, 0.491, 0.5119, 0.5325, 0.5478, 0.5589, 0.5721, 0.5835, 0.5913, 0.6, 0.601, 0.6095, 0.6184, 0.6229, 0.6285, 0.6347, 0.6396, 0.6429, 0.6466, 0.6493, 0.6531, 0.6546, 0.6592, 0.6616, 0.6628, 0.6662, 0.6716, 0.6712, 0.6759, 0.6785, 0.6816, 0.6818, 0.687, 0.6899, 0.6907, 0.6909, 0.696, 0.696, 0.7006, 0.7016, 0.7016, 0.7048, 0.707, 0.707, 0.711, 0.7126, 0.7136, 0.7157, 0.7184, 0.7211, 0.7225, 0.7245, 0.7252, 0.7278, 0.7303, 0.7316, 0.7336, 0.7358, 0.7365, 0.7388, 0.7411, 0.7419, 0.7482, 0.749, 0.7478, 0.7501, 0.7509, 0.7537, 0.7564, 0.7611, 0.7606, 0.7659, 0.7673, 0.7705, 0.7707, 0.7732, 0.7769, 0.7792, 0.7789, 0.7799, 0.7824, 0.7864, 0.7901, 0.7892, 0.7963, 0.7949, 0.7971, 0.8007, 0.8, 0.8028, 0.8068, 0.8081, 0.8133, 0.8142, 0.8163, 0.8184, 0.8228, 0.8245, 0.8289, 0.8313, 0.8334, 0.8359, 0.8382, 0.8416, 0.846, 0.8479, 0.8524, 0.8531, 0.8559, 0.8614, 0.8613, 0.8669, 0.8675, 0.8712, 0.8737, 0.8794, 0.8827, 0.8835, 0.8846, 0.8916, 0.8942, 0.8968, 0.8977, 0.8998, 0.9055, 0.9072, 0.9101, 0.9133, 0.9196, 0.9199, 0.9235, 0.9251, 0.9297, 0.9308, 0.934, 0.9354, 0.9371, 0.9428, 0.9452, 0.9446, 0.9489, 0.9506, 0.9522, 0.9568, 0.9579, 0.96, 0.9627, 0.9643, 0.9657, 0.9672, 0.9689, 0.9703, 0.9723, 0.9739, 0.975, 0.9756, 0.978, 0.9783, 0.9795, 0.9805, 0.981, 0.9829, 0.9849, 0.9849, 0.9844, 0.9853, 0.9858, 0.9866, 0.9867, 0.9875, 0.9877, 0.989, 0.9894, 0.9894, 0.9902, 0.99, 0.9901, 0.9912, 0.9909, 0.991, 0.9908, 0.9917, 0.9915, 0.9914, 0.9916, 0.9919, 0.9922, 0.9921, 0.993, 0.9922, 0.9926, 0.9927, 0.9919]\n",
            "test loss:  [3.7187, 3.4981, 3.0427, 2.8326, 2.6018, 2.1857, 1.9874, 1.9518, 1.7853, 1.745, 1.6601, 1.6684, 1.6535, 1.5621, 1.5417, 1.5687, 1.6174, 1.6261, 1.4932, 1.4065, 1.5483, 1.3833, 1.3797, 1.4266, 1.4268, 1.4595, 1.4002, 1.3624, 1.5096, 1.3562, 1.3036, 1.3065, 1.308, 1.4744, 1.3083, 1.2476, 1.4291, 1.2388, 1.314, 1.2517, 1.2905, 1.2112, 1.3305, 1.2886, 1.3277, 1.2241, 1.2859, 1.2127, 1.2351, 1.2867, 1.3771, 1.2147, 1.1749, 1.2196, 1.2204, 1.2409, 1.2373, 1.1296, 1.2496, 1.2149, 1.2189, 1.162, 1.1329, 1.1172, 1.2076, 1.1142, 1.2268, 1.1095, 1.1151, 1.2229, 1.2033, 1.1196, 1.1115, 1.1346, 1.0386, 1.1022, 1.0894, 1.04, 1.1529, 1.0479, 1.0361, 1.1255, 1.0619, 1.0243, 1.0288, 1.0386, 1.069, 1.1173, 1.063, 1.0155, 1.0743, 1.0604, 0.9961, 1.0311, 1.0107, 1.0271, 0.9983, 1.0818, 1.0456, 0.9842, 1.0043, 0.9914, 1.0506, 0.9396, 0.9734, 0.9835, 0.9768, 0.9448, 0.9991, 0.9697, 0.9256, 0.9041, 0.9031, 0.9795, 0.9476, 0.9131, 0.9211, 0.8709, 0.9818, 0.91, 0.9029, 0.897, 0.8829, 0.9022, 0.8257, 0.8653, 0.8818, 0.8625, 0.8614, 0.8548, 0.8176, 0.8257, 0.8283, 0.8617, 0.826, 0.8411, 0.8193, 0.7955, 0.7982, 0.8311, 0.7998, 0.7926, 0.7811, 0.7705, 0.7822, 0.7793, 0.7717, 0.7616, 0.7605, 0.7498, 0.7561, 0.766, 0.734, 0.7342, 0.7518, 0.7335, 0.7415, 0.7314, 0.7295, 0.7139, 0.7143, 0.715, 0.7146, 0.6999, 0.703, 0.702, 0.6978, 0.6866, 0.686, 0.6784, 0.6791, 0.6758, 0.6679, 0.6697, 0.6685, 0.664, 0.657, 0.6607, 0.6605, 0.6563, 0.6509, 0.6498, 0.6482, 0.6492, 0.6449, 0.6438, 0.6429, 0.6423, 0.6394, 0.6405, 0.6385, 0.6408, 0.6374, 0.6383, 0.6376, 0.6361, 0.6364, 0.6381, 0.636, 0.6365]\n",
            "test err:  [0.8809, 0.8354, 0.7608, 0.7218, 0.6732, 0.5873, 0.5405, 0.5347, 0.4892, 0.4838, 0.4638, 0.4586, 0.464, 0.4353, 0.4297, 0.4485, 0.4486, 0.4523, 0.4264, 0.3963, 0.4399, 0.3915, 0.3896, 0.4012, 0.4067, 0.4051, 0.3991, 0.3897, 0.4215, 0.377, 0.3683, 0.3699, 0.3756, 0.414, 0.3752, 0.3532, 0.3993, 0.3477, 0.3679, 0.3558, 0.3722, 0.3463, 0.3737, 0.3659, 0.3775, 0.3534, 0.3587, 0.3486, 0.3525, 0.3648, 0.3781, 0.3369, 0.3369, 0.3499, 0.3462, 0.3493, 0.3562, 0.3233, 0.3542, 0.3469, 0.3495, 0.3332, 0.3216, 0.3213, 0.3486, 0.3236, 0.3438, 0.3158, 0.3193, 0.3495, 0.336, 0.3223, 0.3168, 0.3278, 0.2927, 0.3124, 0.3074, 0.2952, 0.3307, 0.3085, 0.2951, 0.3224, 0.2993, 0.2965, 0.2957, 0.2966, 0.3097, 0.3137, 0.3074, 0.2866, 0.3129, 0.3037, 0.2844, 0.2989, 0.2881, 0.2949, 0.2873, 0.3078, 0.2976, 0.2863, 0.2907, 0.2868, 0.3048, 0.2752, 0.2779, 0.2826, 0.2786, 0.2729, 0.2875, 0.2788, 0.2695, 0.2588, 0.262, 0.2813, 0.2708, 0.2645, 0.2686, 0.2517, 0.2829, 0.2603, 0.2595, 0.257, 0.2539, 0.2584, 0.2406, 0.2553, 0.2532, 0.2473, 0.2473, 0.2441, 0.2354, 0.2368, 0.2416, 0.246, 0.2373, 0.2401, 0.2389, 0.2276, 0.2283, 0.237, 0.2301, 0.2255, 0.2249, 0.2183, 0.2281, 0.2275, 0.2231, 0.2178, 0.2162, 0.2156, 0.216, 0.223, 0.213, 0.2143, 0.2116, 0.2083, 0.2126, 0.2131, 0.2113, 0.2029, 0.2042, 0.2028, 0.2028, 0.1985, 0.2009, 0.2012, 0.202, 0.1965, 0.1962, 0.1957, 0.1937, 0.1927, 0.19, 0.1919, 0.191, 0.1904, 0.1892, 0.1898, 0.1872, 0.1869, 0.1842, 0.1846, 0.1851, 0.1861, 0.1849, 0.1851, 0.185, 0.1833, 0.1826, 0.1825, 0.1817, 0.1828, 0.1843, 0.1835, 0.1855, 0.1832, 0.1834, 0.1845, 0.1834, 0.1832]\n",
            "test acc:  [0.1191, 0.1646, 0.2392, 0.2782, 0.3268, 0.4127, 0.4595, 0.4653, 0.5108, 0.5162, 0.5362, 0.5414, 0.536, 0.5647, 0.5703, 0.5515, 0.5514, 0.5477, 0.5736, 0.6037, 0.5601, 0.6085, 0.6104, 0.5988, 0.5933, 0.5949, 0.6009, 0.6103, 0.5785, 0.623, 0.6317, 0.6301, 0.6244, 0.586, 0.6248, 0.6468, 0.6007, 0.6523, 0.6321, 0.6442, 0.6278, 0.6537, 0.6263, 0.6341, 0.6225, 0.6466, 0.6413, 0.6514, 0.6475, 0.6352, 0.6219, 0.6631, 0.6631, 0.6501, 0.6538, 0.6507, 0.6438, 0.6767, 0.6458, 0.6531, 0.6505, 0.6668, 0.6784, 0.6787, 0.6514, 0.6764, 0.6562, 0.6842, 0.6807, 0.6505, 0.664, 0.6777, 0.6832, 0.6722, 0.7073, 0.6876, 0.6926, 0.7048, 0.6693, 0.6915, 0.7049, 0.6776, 0.7007, 0.7035, 0.7043, 0.7034, 0.6903, 0.6863, 0.6926, 0.7134, 0.6871, 0.6963, 0.7156, 0.7011, 0.7119, 0.7051, 0.7127, 0.6922, 0.7024, 0.7137, 0.7093, 0.7132, 0.6952, 0.7248, 0.7221, 0.7174, 0.7214, 0.7271, 0.7125, 0.7212, 0.7305, 0.7412, 0.738, 0.7187, 0.7292, 0.7355, 0.7314, 0.7483, 0.7171, 0.7397, 0.7405, 0.743, 0.7461, 0.7416, 0.7594, 0.7447, 0.7468, 0.7527, 0.7527, 0.7559, 0.7646, 0.7632, 0.7584, 0.754, 0.7627, 0.7599, 0.7611, 0.7724, 0.7717, 0.763, 0.7699, 0.7745, 0.7751, 0.7817, 0.7719, 0.7725, 0.7769, 0.7822, 0.7838, 0.7844, 0.784, 0.777, 0.787, 0.7857, 0.7884, 0.7917, 0.7874, 0.7869, 0.7887, 0.7971, 0.7958, 0.7972, 0.7972, 0.8015, 0.7991, 0.7988, 0.798, 0.8035, 0.8038, 0.8043, 0.8063, 0.8073, 0.81, 0.8081, 0.809, 0.8096, 0.8108, 0.8102, 0.8128, 0.8131, 0.8158, 0.8154, 0.8149, 0.8139, 0.8151, 0.8149, 0.815, 0.8167, 0.8174, 0.8175, 0.8183, 0.8172, 0.8157, 0.8165, 0.8145, 0.8168, 0.8166, 0.8155, 0.8166, 0.8168]\n",
            "ori train loss:  [4.2712, 3.8572, 3.5844, 3.3408, 3.0624, 2.804, 2.6088, 2.4694, 2.3562, 2.2735, 2.2119, 2.158, 2.1188, 2.0748, 2.0312, 2.0078, 1.9812, 1.9682, 1.9398, 1.9154, 1.907, 1.8902, 1.8674, 1.8479, 1.8399, 1.8215, 1.821, 1.804, 1.8, 1.784, 1.7721, 1.7579, 1.7606, 1.7413, 1.7442, 1.7268, 1.7258, 1.7176, 1.7043, 1.696, 1.6858, 1.6813, 1.6755, 1.6617, 1.6659, 1.6472, 1.6431, 1.6438, 1.6368, 1.6251, 1.6291, 1.6124, 1.6073, 1.6035, 1.5872, 1.5925, 1.5811, 1.5727, 1.5643, 1.5659, 1.5536, 1.5503, 1.5473, 1.5387, 1.5336, 1.5276, 1.5197, 1.5148, 1.5033, 1.4874, 1.484, 1.4852, 1.4799, 1.4757, 1.4621, 1.453, 1.4431, 1.4392, 1.4321, 1.4178, 1.4106, 1.4047, 1.4031, 1.3899, 1.3812, 1.3818, 1.3744, 1.3583, 1.3568, 1.344, 1.347, 1.3253, 1.3219, 1.3092, 1.3079, 1.3037, 1.2924, 1.2767, 1.2788, 1.2604, 1.2544, 1.2532, 1.2362, 1.2241, 1.2213, 1.2072, 1.1966, 1.187, 1.1809, 1.1724, 1.1504, 1.1454, 1.1363, 1.1202, 1.1134, 1.1063, 1.0934, 1.0907, 1.0695, 1.0609, 1.0501, 1.0432, 1.0257, 1.0129, 1.0042, 1.0001, 0.9799, 0.9652, 0.9551, 0.9504, 0.9386, 0.9159, 0.9123, 0.898, 0.8859, 0.8616, 0.8559, 0.8467, 0.8333, 0.8113, 0.8068, 0.7912, 0.7768, 0.7727, 0.7498, 0.7331, 0.7312, 0.7163, 0.7019, 0.6921, 0.6692, 0.6623, 0.6443, 0.6286, 0.6191, 0.604, 0.5982, 0.5818, 0.5731, 0.5565, 0.5418, 0.531, 0.523, 0.5063, 0.4932, 0.4802, 0.4736, 0.4663, 0.4463, 0.4371, 0.4281, 0.422, 0.4142, 0.4098, 0.3983, 0.3889, 0.385, 0.3799, 0.3674, 0.3645, 0.3596, 0.3492, 0.3474, 0.3421, 0.3379, 0.3301, 0.3289, 0.3276, 0.3241, 0.3208, 0.319, 0.3156, 0.3185, 0.3142, 0.3105, 0.3101, 0.313, 0.3102, 0.3119, 0.3136]\n",
            "ori train err:  [0.9528, 0.9067, 0.8621, 0.8223, 0.7746, 0.7238, 0.6846, 0.6509, 0.6248, 0.6086, 0.5911, 0.5765, 0.5662, 0.5557, 0.5451, 0.5372, 0.5303, 0.5282, 0.5231, 0.5135, 0.5129, 0.5086, 0.4995, 0.4979, 0.4965, 0.4888, 0.4879, 0.4847, 0.4829, 0.4797, 0.4783, 0.475, 0.4728, 0.4685, 0.469, 0.4649, 0.4634, 0.4599, 0.4588, 0.4559, 0.4521, 0.4534, 0.4507, 0.4485, 0.4483, 0.4411, 0.4438, 0.4429, 0.439, 0.438, 0.4379, 0.4326, 0.4355, 0.432, 0.4276, 0.4279, 0.4237, 0.4238, 0.4215, 0.4223, 0.4185, 0.4166, 0.4153, 0.4177, 0.414, 0.4106, 0.4078, 0.4075, 0.4073, 0.3998, 0.3998, 0.4015, 0.4, 0.3958, 0.3923, 0.3917, 0.3902, 0.3887, 0.3868, 0.3848, 0.3821, 0.3794, 0.3781, 0.3739, 0.3728, 0.3705, 0.3689, 0.3691, 0.3664, 0.3616, 0.3635, 0.3575, 0.3567, 0.3509, 0.3525, 0.352, 0.3483, 0.344, 0.3433, 0.3382, 0.3387, 0.3376, 0.3311, 0.3288, 0.326, 0.3249, 0.3231, 0.3198, 0.3178, 0.3161, 0.3087, 0.3079, 0.3049, 0.2994, 0.2966, 0.2976, 0.2933, 0.2932, 0.285, 0.2834, 0.2834, 0.2787, 0.2738, 0.2686, 0.2669, 0.2673, 0.2598, 0.2572, 0.2533, 0.2498, 0.2471, 0.2419, 0.2399, 0.2359, 0.2307, 0.2255, 0.2226, 0.22, 0.2164, 0.2112, 0.2081, 0.2056, 0.2001, 0.1995, 0.192, 0.1866, 0.1881, 0.1826, 0.1781, 0.176, 0.1684, 0.1677, 0.1609, 0.1558, 0.1529, 0.1478, 0.1461, 0.1415, 0.1386, 0.1351, 0.1313, 0.1273, 0.1233, 0.1191, 0.1168, 0.1126, 0.1094, 0.1064, 0.1026, 0.0991, 0.098, 0.0949, 0.0938, 0.0915, 0.0885, 0.0842, 0.0847, 0.0833, 0.0808, 0.0797, 0.077, 0.075, 0.0764, 0.0731, 0.0729, 0.0705, 0.0689, 0.0705, 0.0701, 0.0682, 0.0661, 0.0661, 0.0679, 0.0663, 0.0657, 0.0658, 0.0667, 0.0657, 0.0665, 0.0664]\n",
            "ori train acc:  [0.0472, 0.0933, 0.1379, 0.1777, 0.2254, 0.2762, 0.3154, 0.3491, 0.3752, 0.3914, 0.4089, 0.4235, 0.4338, 0.4443, 0.4549, 0.4628, 0.4697, 0.4718, 0.4769, 0.4865, 0.4871, 0.4914, 0.5005, 0.5021, 0.5035, 0.5112, 0.5121, 0.5153, 0.5171, 0.5203, 0.5217, 0.525, 0.5272, 0.5315, 0.531, 0.5351, 0.5366, 0.5401, 0.5412, 0.5441, 0.5479, 0.5466, 0.5493, 0.5515, 0.5517, 0.5589, 0.5562, 0.5571, 0.561, 0.562, 0.5621, 0.5674, 0.5645, 0.568, 0.5724, 0.5721, 0.5763, 0.5762, 0.5785, 0.5777, 0.5815, 0.5834, 0.5847, 0.5823, 0.586, 0.5894, 0.5922, 0.5925, 0.5927, 0.6002, 0.6002, 0.5985, 0.6, 0.6042, 0.6077, 0.6083, 0.6098, 0.6113, 0.6132, 0.6152, 0.6179, 0.6206, 0.6219, 0.6261, 0.6272, 0.6295, 0.6311, 0.6309, 0.6336, 0.6384, 0.6365, 0.6425, 0.6433, 0.6491, 0.6475, 0.648, 0.6517, 0.656, 0.6567, 0.6618, 0.6613, 0.6624, 0.6689, 0.6712, 0.674, 0.6751, 0.6769, 0.6802, 0.6822, 0.6839, 0.6913, 0.6921, 0.6951, 0.7006, 0.7034, 0.7024, 0.7067, 0.7068, 0.715, 0.7166, 0.7166, 0.7213, 0.7262, 0.7314, 0.7331, 0.7327, 0.7402, 0.7428, 0.7467, 0.7502, 0.7529, 0.7581, 0.7601, 0.7641, 0.7693, 0.7745, 0.7774, 0.78, 0.7836, 0.7888, 0.7919, 0.7944, 0.7999, 0.8005, 0.808, 0.8134, 0.8119, 0.8174, 0.8219, 0.824, 0.8316, 0.8323, 0.8391, 0.8442, 0.8471, 0.8522, 0.8539, 0.8585, 0.8614, 0.8649, 0.8687, 0.8727, 0.8767, 0.8809, 0.8832, 0.8874, 0.8906, 0.8936, 0.8974, 0.9009, 0.902, 0.9051, 0.9062, 0.9085, 0.9115, 0.9158, 0.9153, 0.9167, 0.9192, 0.9203, 0.923, 0.925, 0.9236, 0.9269, 0.9271, 0.9295, 0.9311, 0.9295, 0.9299, 0.9318, 0.9339, 0.9339, 0.9321, 0.9337, 0.9343, 0.9342, 0.9333, 0.9343, 0.9335, 0.9336]\n",
            "time:  [14.03, 13.12, 13.52, 13.0, 13.06, 13.07, 13.05, 13.31, 12.79, 12.94, 13.09, 13.0, 13.05, 12.96, 13.23, 13.11, 12.84, 12.99, 13.12, 13.17, 13.46, 12.6, 12.95, 12.92, 13.07, 12.73, 12.9, 12.82, 12.91, 13.13, 13.36, 13.35, 13.46, 13.3, 12.75, 13.03, 12.86, 13.04, 12.85, 13.01, 13.42, 13.13, 13.13, 12.85, 12.81, 12.75, 12.81, 12.9, 12.98, 12.93, 12.99, 12.73, 12.93, 13.12, 12.97, 13.06, 12.73, 12.92, 13.03, 12.83, 12.94, 12.9, 12.72, 12.9, 12.95, 13.07, 12.91, 12.72, 13.25, 13.34, 12.97, 13.35, 13.06, 13.21, 13.22, 13.11, 13.09, 12.87, 12.77, 12.95, 13.24, 13.09, 12.54, 12.99, 12.73, 12.69, 13.15, 12.91, 13.48, 12.98, 13.25, 12.85, 12.87, 12.9, 13.21, 13.23, 13.16, 12.97, 13.21, 13.19, 13.17, 13.06, 12.88, 13.15, 12.91, 12.97, 12.99, 12.86, 12.95, 13.17, 12.99, 13.25, 13.1, 13.01, 13.06, 13.12, 13.06, 13.61, 12.87, 13.08, 12.73, 13.24, 12.92, 12.78, 12.72, 13.24, 13.03, 13.22, 13.27, 13.06, 13.47, 12.92, 13.2, 12.89, 13.2, 13.03, 12.87, 13.08, 13.01, 12.92, 13.09, 12.89, 13.18, 12.91, 13.36, 13.21, 12.94, 12.91, 13.3, 13.36, 12.89, 12.94, 13.59, 13.1, 12.82, 13.1, 13.04, 12.92, 12.8, 12.87, 13.18, 12.97, 12.79, 12.85, 13.1, 12.98, 13.0, 13.23, 13.46, 13.11, 12.79, 12.85, 12.88, 13.44, 13.03, 12.96, 12.63, 13.14, 13.67, 13.09, 13.07, 12.76, 13.09, 13.19, 13.01, 12.94, 13.44, 13.24, 12.94, 13.22, 13.18, 13.14, 12.84, 13.05, 13.11, 13.24, 12.79, 13.26, 13.14, 13.31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Adaptive FE-SAM (FE-ASAM)**"
      ],
      "metadata": {
        "id": "LNeUk0WpIeY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/src/trains.py \\\n",
        "    --optimizer FESAM \\\n",
        "    --rho 6 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --T 0.2 \\\n",
        "    --cutout \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR100 \\\n",
        "    --arch resnet18 \\\n",
        "    --epochs 200 \\\n",
        "    --adaptive \\\n",
        "    --batch-size 128\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PNw_bkabgIX",
        "outputId": "17ee1294-bdd7-4b25-f6ce-8c27a2e4c1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: resnet18\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar100 dataset!\n",
            "391\n",
            "50000\n",
            "optimizer: FESAM\n",
            "FESAM (\n",
            "Parameter Group 0\n",
            "    T: 0.2\n",
            "    adaptive: True\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 6.0\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "Epoch: [0][0/391]\tTime 1.279 (1.279)\tData 0.123 (0.123)\tLoss 4.7223 (4.7223)\tPrec@1 8.594 (8.594)\n",
            "Epoch: [0][100/391]\tTime 0.103 (0.113)\tData 0.000 (0.001)\tLoss 4.0443 (4.3848)\tPrec@1 3.125 (4.927)\n",
            "Epoch: [0][200/391]\tTime 0.104 (0.108)\tData 0.000 (0.001)\tLoss 4.0721 (4.2306)\tPrec@1 5.469 (6.172)\n",
            "Epoch: [0][300/391]\tTime 0.104 (0.106)\tData 0.000 (0.001)\tLoss 3.8648 (4.1371)\tPrec@1 10.938 (7.195)\n",
            "Epoch: [0][390/391]\tTime 0.405 (0.106)\tData 0.000 (0.001)\tLoss 3.9268 (4.0770)\tPrec@1 11.250 (7.980)\n",
            "Total time : 41.550\n",
            "Train Loss: 4.0770, Train Accuracy: 0.0798\n",
            "Test Loss : 3.7513, Test Accuracy : 0.1171 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.243 (0.243)\tData 0.136 (0.136)\tLoss 3.8736 (3.8736)\tPrec@1 11.719 (11.719)\n",
            "Epoch: [1][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 3.5434 (3.7824)\tPrec@1 13.281 (11.471)\n",
            "Epoch: [1][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 3.6098 (3.7344)\tPrec@1 12.500 (12.725)\n",
            "Epoch: [1][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 3.4290 (3.6927)\tPrec@1 17.188 (13.530)\n",
            "Epoch: [1][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 3.2703 (3.6577)\tPrec@1 21.250 (14.330)\n",
            "Total time : 39.852\n",
            "Train Loss: 3.6577, Train Accuracy: 0.1433\n",
            "Test Loss : 3.3958, Test Accuracy : 0.1717 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.243 (0.243)\tData 0.141 (0.141)\tLoss 3.5928 (3.5928)\tPrec@1 11.719 (11.719)\n",
            "Epoch: [2][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 3.3732 (3.4469)\tPrec@1 21.094 (17.582)\n",
            "Epoch: [2][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 3.4563 (3.4089)\tPrec@1 22.656 (18.769)\n",
            "Epoch: [2][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 3.2096 (3.3675)\tPrec@1 18.750 (19.625)\n",
            "Epoch: [2][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 3.1980 (3.3381)\tPrec@1 18.750 (20.272)\n",
            "Total time : 39.999\n",
            "Train Loss: 3.3381, Train Accuracy: 0.2027\n",
            "Test Loss : 3.0672, Test Accuracy : 0.2348 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.240 (0.240)\tData 0.140 (0.140)\tLoss 3.0196 (3.0196)\tPrec@1 26.562 (26.562)\n",
            "Epoch: [3][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 2.8898 (3.1300)\tPrec@1 33.594 (24.404)\n",
            "Epoch: [3][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 3.3498 (3.1254)\tPrec@1 19.531 (24.716)\n",
            "Epoch: [3][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 3.1178 (3.0971)\tPrec@1 25.000 (25.234)\n",
            "Epoch: [3][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 3.0913 (3.0684)\tPrec@1 21.250 (25.898)\n",
            "Total time : 40.019\n",
            "Train Loss: 3.0684, Train Accuracy: 0.2590\n",
            "Test Loss : 2.8260, Test Accuracy : 0.2844 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.245 (0.245)\tData 0.141 (0.141)\tLoss 2.8853 (2.8853)\tPrec@1 28.906 (28.906)\n",
            "Epoch: [4][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 2.8640 (2.8535)\tPrec@1 34.375 (30.221)\n",
            "Epoch: [4][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 2.7885 (2.8333)\tPrec@1 26.562 (30.881)\n",
            "Epoch: [4][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 2.7638 (2.7950)\tPrec@1 35.156 (31.715)\n",
            "Epoch: [4][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 2.9657 (2.7631)\tPrec@1 28.750 (32.276)\n",
            "Total time : 40.050\n",
            "Train Loss: 2.7631, Train Accuracy: 0.3228\n",
            "Test Loss : 2.5129, Test Accuracy : 0.3387 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.242 (0.242)\tData 0.143 (0.143)\tLoss 2.5281 (2.5281)\tPrec@1 40.625 (40.625)\n",
            "Epoch: [5][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 2.3789 (2.5360)\tPrec@1 43.750 (37.794)\n",
            "Epoch: [5][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 2.5867 (2.5258)\tPrec@1 35.938 (37.869)\n",
            "Epoch: [5][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 2.2789 (2.4977)\tPrec@1 43.750 (38.715)\n",
            "Epoch: [5][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 2.2479 (2.4757)\tPrec@1 48.750 (39.186)\n",
            "Total time : 40.046\n",
            "Train Loss: 2.4757, Train Accuracy: 0.3919\n",
            "Test Loss : 2.1940, Test Accuracy : 0.4109 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.234 (0.234)\tData 0.136 (0.136)\tLoss 2.4751 (2.4751)\tPrec@1 41.406 (41.406)\n",
            "Epoch: [6][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 2.4378 (2.3069)\tPrec@1 40.625 (43.742)\n",
            "Epoch: [6][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 2.1746 (2.2806)\tPrec@1 46.094 (43.975)\n",
            "Epoch: [6][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 2.4307 (2.2694)\tPrec@1 39.062 (44.318)\n",
            "Epoch: [6][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 2.1757 (2.2545)\tPrec@1 47.500 (44.644)\n",
            "Total time : 40.017\n",
            "Train Loss: 2.2545, Train Accuracy: 0.4464\n",
            "Test Loss : 2.0131, Test Accuracy : 0.4516 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.248 (0.248)\tData 0.146 (0.146)\tLoss 1.9392 (1.9392)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [7][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 2.0925 (2.1116)\tPrec@1 52.344 (48.577)\n",
            "Epoch: [7][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 2.4090 (2.1009)\tPrec@1 35.938 (48.422)\n",
            "Epoch: [7][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 2.1744 (2.1032)\tPrec@1 46.094 (48.453)\n",
            "Epoch: [7][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.9209 (2.0945)\tPrec@1 53.750 (48.638)\n",
            "Total time : 40.059\n",
            "Train Loss: 2.0945, Train Accuracy: 0.4864\n",
            "Test Loss : 1.9081, Test Accuracy : 0.4846 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.256 (0.256)\tData 0.157 (0.157)\tLoss 2.0659 (2.0659)\tPrec@1 50.000 (50.000)\n",
            "Epoch: [8][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 2.2091 (1.9850)\tPrec@1 46.875 (51.702)\n",
            "Epoch: [8][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 2.0566 (1.9785)\tPrec@1 49.219 (51.831)\n",
            "Epoch: [8][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.9816 (1.9733)\tPrec@1 53.906 (52.082)\n",
            "Epoch: [8][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.9203 (1.9673)\tPrec@1 52.500 (52.192)\n",
            "Total time : 40.049\n",
            "Train Loss: 1.9673, Train Accuracy: 0.5219\n",
            "Test Loss : 1.8126, Test Accuracy : 0.5068 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 1.7820 (1.7820)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [9][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.7816 (1.8875)\tPrec@1 59.375 (54.672)\n",
            "Epoch: [9][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.9817 (1.8799)\tPrec@1 46.875 (54.695)\n",
            "Epoch: [9][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.7130 (1.8719)\tPrec@1 57.031 (54.752)\n",
            "Epoch: [9][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 2.0161 (1.8685)\tPrec@1 55.000 (54.754)\n",
            "Total time : 40.216\n",
            "Train Loss: 1.8685, Train Accuracy: 0.5475\n",
            "Test Loss : 1.7442, Test Accuracy : 0.5143 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 1.7319 (1.7319)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [10][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.9421 (1.7977)\tPrec@1 57.031 (56.784)\n",
            "Epoch: [10][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.8691 (1.7989)\tPrec@1 52.344 (56.748)\n",
            "Epoch: [10][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.6925 (1.7920)\tPrec@1 55.469 (56.894)\n",
            "Epoch: [10][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.6901 (1.7989)\tPrec@1 63.750 (56.680)\n",
            "Total time : 40.149\n",
            "Train Loss: 1.7989, Train Accuracy: 0.5668\n",
            "Test Loss : 1.6547, Test Accuracy : 0.5353 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.238 (0.238)\tData 0.141 (0.141)\tLoss 1.9639 (1.9639)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [11][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.8168 (1.7020)\tPrec@1 53.125 (59.244)\n",
            "Epoch: [11][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.6408 (1.7219)\tPrec@1 58.594 (58.703)\n",
            "Epoch: [11][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.7605 (1.7313)\tPrec@1 53.906 (58.386)\n",
            "Epoch: [11][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 1.7300 (1.7359)\tPrec@1 61.250 (58.274)\n",
            "Total time : 40.003\n",
            "Train Loss: 1.7359, Train Accuracy: 0.5827\n",
            "Test Loss : 1.6034, Test Accuracy : 0.5538 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.235 (0.235)\tData 0.137 (0.137)\tLoss 1.7822 (1.7822)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [12][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.7799 (1.6924)\tPrec@1 56.250 (60.087)\n",
            "Epoch: [12][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.6193 (1.6883)\tPrec@1 58.594 (60.230)\n",
            "Epoch: [12][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.8439 (1.6894)\tPrec@1 56.250 (59.956)\n",
            "Epoch: [12][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.8901 (1.6892)\tPrec@1 63.750 (59.886)\n",
            "Total time : 40.063\n",
            "Train Loss: 1.6892, Train Accuracy: 0.5989\n",
            "Test Loss : 1.6347, Test Accuracy : 0.5433 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.240 (0.240)\tData 0.142 (0.142)\tLoss 1.5395 (1.5395)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [13][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.4079 (1.6342)\tPrec@1 68.750 (61.711)\n",
            "Epoch: [13][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.6042 (1.6446)\tPrec@1 66.406 (61.338)\n",
            "Epoch: [13][300/391]\tTime 0.100 (0.102)\tData 0.000 (0.001)\tLoss 1.7912 (1.6441)\tPrec@1 53.906 (61.228)\n",
            "Epoch: [13][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.6247 (1.6378)\tPrec@1 62.500 (61.434)\n",
            "Total time : 39.970\n",
            "Train Loss: 1.6378, Train Accuracy: 0.6143\n",
            "Test Loss : 1.5425, Test Accuracy : 0.5734 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.244 (0.244)\tData 0.141 (0.141)\tLoss 1.5505 (1.5505)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [14][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 1.5406 (1.5754)\tPrec@1 61.719 (62.802)\n",
            "Epoch: [14][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.8862 (1.5857)\tPrec@1 53.125 (62.741)\n",
            "Epoch: [14][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.5402 (1.5899)\tPrec@1 61.719 (62.643)\n",
            "Epoch: [14][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.7010 (1.5920)\tPrec@1 67.500 (62.634)\n",
            "Total time : 40.181\n",
            "Train Loss: 1.5920, Train Accuracy: 0.6263\n",
            "Test Loss : 1.5094, Test Accuracy : 0.5804 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.242 (0.242)\tData 0.140 (0.140)\tLoss 1.5705 (1.5705)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [15][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.4356 (1.5366)\tPrec@1 66.406 (63.900)\n",
            "Epoch: [15][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.5510 (1.5492)\tPrec@1 58.594 (63.880)\n",
            "Epoch: [15][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.5067 (1.5555)\tPrec@1 69.531 (63.697)\n",
            "Epoch: [15][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.6102 (1.5603)\tPrec@1 66.250 (63.586)\n",
            "Total time : 40.189\n",
            "Train Loss: 1.5603, Train Accuracy: 0.6359\n",
            "Test Loss : 1.4900, Test Accuracy : 0.5810 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.248 (0.248)\tData 0.146 (0.146)\tLoss 1.6352 (1.6352)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [16][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.4007 (1.5287)\tPrec@1 68.750 (64.565)\n",
            "Epoch: [16][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.5774 (1.5365)\tPrec@1 68.750 (64.366)\n",
            "Epoch: [16][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.4465 (1.5375)\tPrec@1 66.406 (64.452)\n",
            "Epoch: [16][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.5579 (1.5333)\tPrec@1 60.000 (64.536)\n",
            "Total time : 40.017\n",
            "Train Loss: 1.5333, Train Accuracy: 0.6454\n",
            "Test Loss : 1.5029, Test Accuracy : 0.5792 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 1.5002 (1.5002)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [17][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.5560 (1.4882)\tPrec@1 66.406 (65.795)\n",
            "Epoch: [17][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.5658 (1.4914)\tPrec@1 64.062 (65.695)\n",
            "Epoch: [17][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.5958 (1.5017)\tPrec@1 65.625 (65.474)\n",
            "Epoch: [17][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.3898 (1.5121)\tPrec@1 67.500 (65.090)\n",
            "Total time : 39.994\n",
            "Train Loss: 1.5121, Train Accuracy: 0.6509\n",
            "Test Loss : 1.4488, Test Accuracy : 0.5982 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 1.4409 (1.4409)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [18][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.4374 (1.4494)\tPrec@1 62.500 (66.731)\n",
            "Epoch: [18][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.5613 (1.4746)\tPrec@1 63.281 (66.056)\n",
            "Epoch: [18][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.6129 (1.4846)\tPrec@1 59.375 (65.737)\n",
            "Epoch: [18][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.6882 (1.4825)\tPrec@1 58.750 (65.790)\n",
            "Total time : 40.044\n",
            "Train Loss: 1.4825, Train Accuracy: 0.6579\n",
            "Test Loss : 1.4253, Test Accuracy : 0.5971 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.240 (0.240)\tData 0.142 (0.142)\tLoss 1.2092 (1.2092)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [19][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.1932 (1.4211)\tPrec@1 74.219 (67.860)\n",
            "Epoch: [19][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.4460 (1.4238)\tPrec@1 67.969 (67.794)\n",
            "Epoch: [19][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.3622 (1.4465)\tPrec@1 71.094 (66.998)\n",
            "Epoch: [19][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 1.4466 (1.4531)\tPrec@1 66.250 (66.794)\n",
            "Total time : 40.180\n",
            "Train Loss: 1.4531, Train Accuracy: 0.6679\n",
            "Test Loss : 1.4268, Test Accuracy : 0.5999 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.244 (0.244)\tData 0.146 (0.146)\tLoss 1.7162 (1.7162)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [20][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.3178 (1.4277)\tPrec@1 75.000 (67.969)\n",
            "Epoch: [20][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.4289 (1.4258)\tPrec@1 64.844 (67.821)\n",
            "Epoch: [20][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.5693 (1.4369)\tPrec@1 65.625 (67.421)\n",
            "Epoch: [20][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.4391 (1.4381)\tPrec@1 70.000 (67.468)\n",
            "Total time : 40.148\n",
            "Train Loss: 1.4381, Train Accuracy: 0.6747\n",
            "Test Loss : 1.4370, Test Accuracy : 0.5886 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.238 (0.238)\tData 0.140 (0.140)\tLoss 1.5005 (1.5005)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [21][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.1637 (1.3875)\tPrec@1 72.656 (68.448)\n",
            "Epoch: [21][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3778 (1.3956)\tPrec@1 69.531 (68.493)\n",
            "Epoch: [21][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.6413 (1.4071)\tPrec@1 66.406 (68.093)\n",
            "Epoch: [21][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.9115 (1.4205)\tPrec@1 56.250 (67.722)\n",
            "Total time : 40.164\n",
            "Train Loss: 1.4205, Train Accuracy: 0.6772\n",
            "Test Loss : 1.3713, Test Accuracy : 0.6105 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.246 (0.246)\tData 0.140 (0.140)\tLoss 1.2121 (1.2121)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [22][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.1308 (1.3911)\tPrec@1 75.000 (68.394)\n",
            "Epoch: [22][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.3955 (1.3921)\tPrec@1 69.531 (68.571)\n",
            "Epoch: [22][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.5169 (1.3981)\tPrec@1 66.406 (68.324)\n",
            "Epoch: [22][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 1.3623 (1.4051)\tPrec@1 68.750 (68.126)\n",
            "Total time : 40.171\n",
            "Train Loss: 1.4051, Train Accuracy: 0.6813\n",
            "Test Loss : 1.4000, Test Accuracy : 0.6064 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.246 (0.246)\tData 0.146 (0.146)\tLoss 1.2755 (1.2755)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [23][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.3364 (1.3568)\tPrec@1 71.875 (69.361)\n",
            "Epoch: [23][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.3450 (1.3646)\tPrec@1 67.188 (69.119)\n",
            "Epoch: [23][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.2420 (1.3753)\tPrec@1 73.438 (68.869)\n",
            "Epoch: [23][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.5001 (1.3825)\tPrec@1 72.500 (68.606)\n",
            "Total time : 40.197\n",
            "Train Loss: 1.3825, Train Accuracy: 0.6861\n",
            "Test Loss : 1.3373, Test Accuracy : 0.6194 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.241 (0.241)\tData 0.138 (0.138)\tLoss 1.3683 (1.3683)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [24][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 1.3154 (1.3425)\tPrec@1 69.531 (69.972)\n",
            "Epoch: [24][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.1451 (1.3490)\tPrec@1 79.688 (69.928)\n",
            "Epoch: [24][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 1.3834 (1.3587)\tPrec@1 69.531 (69.555)\n",
            "Epoch: [24][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.3856 (1.3685)\tPrec@1 71.250 (69.132)\n",
            "Total time : 39.975\n",
            "Train Loss: 1.3685, Train Accuracy: 0.6913\n",
            "Test Loss : 1.3260, Test Accuracy : 0.6246 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.249 (0.249)\tData 0.146 (0.146)\tLoss 1.2759 (1.2759)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [25][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.2914 (1.3272)\tPrec@1 69.531 (69.964)\n",
            "Epoch: [25][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.2893 (1.3311)\tPrec@1 74.219 (69.935)\n",
            "Epoch: [25][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 1.2984 (1.3460)\tPrec@1 69.531 (69.825)\n",
            "Epoch: [25][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.3836 (1.3503)\tPrec@1 67.500 (69.854)\n",
            "Total time : 40.028\n",
            "Train Loss: 1.3503, Train Accuracy: 0.6985\n",
            "Test Loss : 1.3873, Test Accuracy : 0.6138 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.254 (0.254)\tData 0.157 (0.157)\tLoss 1.4318 (1.4318)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [26][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 1.3110 (1.3202)\tPrec@1 71.094 (70.947)\n",
            "Epoch: [26][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.2393 (1.3309)\tPrec@1 77.344 (70.573)\n",
            "Epoch: [26][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 1.4248 (1.3411)\tPrec@1 67.969 (70.263)\n",
            "Epoch: [26][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 1.4375 (1.3471)\tPrec@1 71.250 (70.020)\n",
            "Total time : 39.965\n",
            "Train Loss: 1.3471, Train Accuracy: 0.7002\n",
            "Test Loss : 1.3389, Test Accuracy : 0.6179 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 1.3043 (1.3043)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [27][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 1.2501 (1.2825)\tPrec@1 71.094 (71.836)\n",
            "Epoch: [27][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.3427 (1.2999)\tPrec@1 75.000 (71.051)\n",
            "Epoch: [27][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.4279 (1.3164)\tPrec@1 66.406 (70.665)\n",
            "Epoch: [27][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 1.2896 (1.3250)\tPrec@1 71.250 (70.458)\n",
            "Total time : 39.978\n",
            "Train Loss: 1.3250, Train Accuracy: 0.7046\n",
            "Test Loss : 1.3112, Test Accuracy : 0.6347 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.250 (0.250)\tData 0.142 (0.142)\tLoss 1.1967 (1.1967)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [28][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.3870 (1.2872)\tPrec@1 70.312 (71.581)\n",
            "Epoch: [28][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.2041 (1.2926)\tPrec@1 74.219 (71.552)\n",
            "Epoch: [28][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.3170 (1.3079)\tPrec@1 72.656 (71.135)\n",
            "Epoch: [28][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.2735 (1.3204)\tPrec@1 77.500 (70.770)\n",
            "Total time : 40.005\n",
            "Train Loss: 1.3204, Train Accuracy: 0.7077\n",
            "Test Loss : 1.3669, Test Accuracy : 0.6110 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.237 (0.237)\tData 0.140 (0.140)\tLoss 1.3432 (1.3432)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [29][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.2627 (1.2679)\tPrec@1 72.656 (72.355)\n",
            "Epoch: [29][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.3135 (1.2874)\tPrec@1 72.656 (71.782)\n",
            "Epoch: [29][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.2031 (1.2872)\tPrec@1 71.094 (71.769)\n",
            "Epoch: [29][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.4040 (1.3047)\tPrec@1 67.500 (71.300)\n",
            "Total time : 40.010\n",
            "Train Loss: 1.3047, Train Accuracy: 0.7130\n",
            "Test Loss : 1.2898, Test Accuracy : 0.6375 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.241 (0.241)\tData 0.140 (0.140)\tLoss 1.0164 (1.0164)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [30][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.5278 (1.2567)\tPrec@1 57.812 (72.494)\n",
            "Epoch: [30][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2893 (1.2772)\tPrec@1 73.438 (72.139)\n",
            "Epoch: [30][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.5706 (1.2847)\tPrec@1 63.281 (71.963)\n",
            "Epoch: [30][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.2550 (1.2968)\tPrec@1 73.750 (71.514)\n",
            "Total time : 40.153\n",
            "Train Loss: 1.2968, Train Accuracy: 0.7151\n",
            "Test Loss : 1.2393, Test Accuracy : 0.6499 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 1.1991 (1.1991)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [31][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.1958 (1.2156)\tPrec@1 72.656 (73.383)\n",
            "Epoch: [31][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.4509 (1.2521)\tPrec@1 66.406 (72.435)\n",
            "Epoch: [31][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3918 (1.2654)\tPrec@1 69.531 (71.989)\n",
            "Epoch: [31][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.2260 (1.2762)\tPrec@1 75.000 (71.682)\n",
            "Total time : 40.133\n",
            "Train Loss: 1.2762, Train Accuracy: 0.7168\n",
            "Test Loss : 1.2502, Test Accuracy : 0.6442 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.239 (0.239)\tData 0.141 (0.141)\tLoss 1.2377 (1.2377)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [32][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.3427 (1.2575)\tPrec@1 73.438 (72.308)\n",
            "Epoch: [32][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.2330 (1.2595)\tPrec@1 72.656 (72.314)\n",
            "Epoch: [32][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.4063 (1.2712)\tPrec@1 74.219 (71.854)\n",
            "Epoch: [32][390/391]\tTime 0.064 (0.102)\tData 0.000 (0.001)\tLoss 1.2093 (1.2813)\tPrec@1 82.500 (71.602)\n",
            "Total time : 39.952\n",
            "Train Loss: 1.2813, Train Accuracy: 0.7160\n",
            "Test Loss : 1.2947, Test Accuracy : 0.6312 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.242 (0.242)\tData 0.140 (0.140)\tLoss 1.3353 (1.3353)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [33][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.3893 (1.2443)\tPrec@1 71.094 (73.213)\n",
            "Epoch: [33][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2087 (1.2485)\tPrec@1 72.656 (72.831)\n",
            "Epoch: [33][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.3988 (1.2525)\tPrec@1 65.625 (72.711)\n",
            "Epoch: [33][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.5632 (1.2619)\tPrec@1 65.000 (72.378)\n",
            "Total time : 39.963\n",
            "Train Loss: 1.2619, Train Accuracy: 0.7238\n",
            "Test Loss : 1.3140, Test Accuracy : 0.6225 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.240 (0.240)\tData 0.139 (0.139)\tLoss 1.2310 (1.2310)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [34][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.1440 (1.2271)\tPrec@1 75.781 (73.631)\n",
            "Epoch: [34][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.3160 (1.2419)\tPrec@1 75.000 (73.025)\n",
            "Epoch: [34][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.3894 (1.2500)\tPrec@1 68.750 (72.651)\n",
            "Epoch: [34][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 1.2480 (1.2587)\tPrec@1 71.250 (72.504)\n",
            "Total time : 40.135\n",
            "Train Loss: 1.2587, Train Accuracy: 0.7250\n",
            "Test Loss : 1.2589, Test Accuracy : 0.6474 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.251 (0.251)\tData 0.146 (0.146)\tLoss 1.0086 (1.0086)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [35][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.1806 (1.2049)\tPrec@1 71.094 (73.631)\n",
            "Epoch: [35][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.9622 (1.2193)\tPrec@1 78.125 (73.368)\n",
            "Epoch: [35][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.2155 (1.2333)\tPrec@1 73.438 (72.929)\n",
            "Epoch: [35][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.2720 (1.2442)\tPrec@1 71.250 (72.678)\n",
            "Total time : 40.010\n",
            "Train Loss: 1.2442, Train Accuracy: 0.7268\n",
            "Test Loss : 1.2599, Test Accuracy : 0.6427 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.234 (0.234)\tData 0.137 (0.137)\tLoss 0.9566 (0.9566)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [36][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.1880 (1.2046)\tPrec@1 77.344 (74.172)\n",
            "Epoch: [36][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3535 (1.2157)\tPrec@1 71.875 (73.904)\n",
            "Epoch: [36][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.2629 (1.2272)\tPrec@1 69.531 (73.536)\n",
            "Epoch: [36][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.3783 (1.2386)\tPrec@1 67.500 (73.202)\n",
            "Total time : 40.030\n",
            "Train Loss: 1.2386, Train Accuracy: 0.7320\n",
            "Test Loss : 1.2983, Test Accuracy : 0.6359 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 1.1914 (1.1914)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [37][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.0176 (1.1851)\tPrec@1 81.250 (74.830)\n",
            "Epoch: [37][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.2246 (1.1995)\tPrec@1 73.438 (74.153)\n",
            "Epoch: [37][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3572 (1.2193)\tPrec@1 75.781 (73.739)\n",
            "Epoch: [37][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.2537 (1.2327)\tPrec@1 77.500 (73.316)\n",
            "Total time : 40.134\n",
            "Train Loss: 1.2327, Train Accuracy: 0.7332\n",
            "Test Loss : 1.2173, Test Accuracy : 0.6564 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.239 (0.239)\tData 0.137 (0.137)\tLoss 1.1581 (1.1581)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [38][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 1.1792 (1.1846)\tPrec@1 77.344 (74.226)\n",
            "Epoch: [38][200/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.3453 (1.1957)\tPrec@1 64.844 (74.013)\n",
            "Epoch: [38][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.1851 (1.2090)\tPrec@1 72.656 (73.798)\n",
            "Epoch: [38][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.2866 (1.2202)\tPrec@1 75.000 (73.544)\n",
            "Total time : 39.949\n",
            "Train Loss: 1.2202, Train Accuracy: 0.7354\n",
            "Test Loss : 1.3029, Test Accuracy : 0.6341 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.241 (0.241)\tData 0.141 (0.141)\tLoss 1.1888 (1.1888)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [39][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.2356 (1.1639)\tPrec@1 75.000 (75.263)\n",
            "Epoch: [39][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.2907 (1.1916)\tPrec@1 72.656 (74.584)\n",
            "Epoch: [39][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2473 (1.2026)\tPrec@1 71.875 (74.268)\n",
            "Epoch: [39][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.1654 (1.2082)\tPrec@1 77.500 (74.036)\n",
            "Total time : 40.070\n",
            "Train Loss: 1.2082, Train Accuracy: 0.7404\n",
            "Test Loss : 1.2039, Test Accuracy : 0.6527 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.238 (0.238)\tData 0.138 (0.138)\tLoss 1.2062 (1.2062)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [40][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.1158 (1.1445)\tPrec@1 74.219 (75.549)\n",
            "Epoch: [40][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.2669 (1.1738)\tPrec@1 76.562 (74.953)\n",
            "Epoch: [40][300/391]\tTime 0.100 (0.102)\tData 0.000 (0.001)\tLoss 1.2446 (1.1894)\tPrec@1 67.969 (74.554)\n",
            "Epoch: [40][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 1.3981 (1.2024)\tPrec@1 70.000 (74.276)\n",
            "Total time : 39.934\n",
            "Train Loss: 1.2024, Train Accuracy: 0.7428\n",
            "Test Loss : 1.2218, Test Accuracy : 0.6508 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.243 (0.243)\tData 0.138 (0.138)\tLoss 0.9657 (0.9657)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [41][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.1438 (1.1634)\tPrec@1 75.000 (74.869)\n",
            "Epoch: [41][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.2429 (1.1811)\tPrec@1 77.344 (74.405)\n",
            "Epoch: [41][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.1921 (1.1937)\tPrec@1 78.125 (74.123)\n",
            "Epoch: [41][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 1.1397 (1.1960)\tPrec@1 80.000 (74.190)\n",
            "Total time : 39.959\n",
            "Train Loss: 1.1960, Train Accuracy: 0.7419\n",
            "Test Loss : 1.1842, Test Accuracy : 0.6627 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 1.1361 (1.1361)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [42][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.9831 (1.1423)\tPrec@1 83.594 (75.804)\n",
            "Epoch: [42][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2734 (1.1568)\tPrec@1 71.875 (75.707)\n",
            "Epoch: [42][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2506 (1.1794)\tPrec@1 76.562 (74.992)\n",
            "Epoch: [42][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.2465 (1.1917)\tPrec@1 73.750 (74.492)\n",
            "Total time : 40.124\n",
            "Train Loss: 1.1917, Train Accuracy: 0.7449\n",
            "Test Loss : 1.2087, Test Accuracy : 0.6590 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.238 (0.238)\tData 0.140 (0.140)\tLoss 1.0244 (1.0244)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [43][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 1.1888 (1.1440)\tPrec@1 74.219 (75.642)\n",
            "Epoch: [43][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.1590 (1.1540)\tPrec@1 77.344 (75.548)\n",
            "Epoch: [43][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.2674 (1.1691)\tPrec@1 67.969 (75.078)\n",
            "Epoch: [43][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.4237 (1.1770)\tPrec@1 72.500 (74.822)\n",
            "Total time : 40.110\n",
            "Train Loss: 1.1770, Train Accuracy: 0.7482\n",
            "Test Loss : 1.1723, Test Accuracy : 0.6707 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.235 (0.235)\tData 0.136 (0.136)\tLoss 1.1462 (1.1462)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [44][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.1846 (1.1558)\tPrec@1 73.438 (75.464)\n",
            "Epoch: [44][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.2658 (1.1704)\tPrec@1 74.219 (74.899)\n",
            "Epoch: [44][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0161 (1.1763)\tPrec@1 78.906 (74.860)\n",
            "Epoch: [44][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.3522 (1.1818)\tPrec@1 71.250 (74.740)\n",
            "Total time : 40.149\n",
            "Train Loss: 1.1818, Train Accuracy: 0.7474\n",
            "Test Loss : 1.2095, Test Accuracy : 0.6536 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 1.1110 (1.1110)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [45][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.2156 (1.1324)\tPrec@1 73.438 (76.153)\n",
            "Epoch: [45][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3716 (1.1418)\tPrec@1 70.312 (75.948)\n",
            "Epoch: [45][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.4172 (1.1500)\tPrec@1 67.188 (75.711)\n",
            "Epoch: [45][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.1887 (1.1601)\tPrec@1 77.500 (75.444)\n",
            "Total time : 40.120\n",
            "Train Loss: 1.1601, Train Accuracy: 0.7544\n",
            "Test Loss : 1.1546, Test Accuracy : 0.6703 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.239 (0.239)\tData 0.141 (0.141)\tLoss 1.2952 (1.2952)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [46][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.1656 (1.1239)\tPrec@1 78.906 (76.214)\n",
            "Epoch: [46][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0895 (1.1455)\tPrec@1 77.344 (75.676)\n",
            "Epoch: [46][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.3204 (1.1487)\tPrec@1 73.438 (75.633)\n",
            "Epoch: [46][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.2712 (1.1545)\tPrec@1 78.750 (75.560)\n",
            "Total time : 40.174\n",
            "Train Loss: 1.1545, Train Accuracy: 0.7556\n",
            "Test Loss : 1.1926, Test Accuracy : 0.6642 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 1.1464 (1.1464)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [47][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.0999 (1.1288)\tPrec@1 75.000 (76.323)\n",
            "Epoch: [47][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0823 (1.1418)\tPrec@1 76.562 (75.933)\n",
            "Epoch: [47][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.9806 (1.1549)\tPrec@1 81.250 (75.576)\n",
            "Epoch: [47][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 1.2036 (1.1571)\tPrec@1 73.750 (75.540)\n",
            "Total time : 40.184\n",
            "Train Loss: 1.1571, Train Accuracy: 0.7554\n",
            "Test Loss : 1.1659, Test Accuracy : 0.6756 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.243 (0.243)\tData 0.139 (0.139)\tLoss 1.2086 (1.2086)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [48][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 1.2029 (1.0946)\tPrec@1 71.875 (76.880)\n",
            "Epoch: [48][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3067 (1.1153)\tPrec@1 65.625 (76.543)\n",
            "Epoch: [48][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.1222 (1.1431)\tPrec@1 76.562 (75.937)\n",
            "Epoch: [48][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.2323 (1.1487)\tPrec@1 75.000 (75.706)\n",
            "Total time : 40.122\n",
            "Train Loss: 1.1487, Train Accuracy: 0.7571\n",
            "Test Loss : 1.1703, Test Accuracy : 0.6639 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.243 (0.243)\tData 0.141 (0.141)\tLoss 1.0459 (1.0459)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [49][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.9580 (1.0937)\tPrec@1 78.125 (76.764)\n",
            "Epoch: [49][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.1177 (1.1201)\tPrec@1 78.125 (76.116)\n",
            "Epoch: [49][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1084 (1.1317)\tPrec@1 77.344 (76.046)\n",
            "Epoch: [49][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.4197 (1.1379)\tPrec@1 73.750 (75.904)\n",
            "Total time : 40.130\n",
            "Train Loss: 1.1379, Train Accuracy: 0.7590\n",
            "Test Loss : 1.1795, Test Accuracy : 0.6648 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.235 (0.235)\tData 0.137 (0.137)\tLoss 1.2877 (1.2877)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [50][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.1458 (1.1343)\tPrec@1 72.656 (76.222)\n",
            "Epoch: [50][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 1.0381 (1.1275)\tPrec@1 79.688 (76.353)\n",
            "Epoch: [50][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.1481 (1.1339)\tPrec@1 75.781 (76.077)\n",
            "Epoch: [50][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.2127 (1.1360)\tPrec@1 72.500 (75.978)\n",
            "Total time : 40.095\n",
            "Train Loss: 1.1360, Train Accuracy: 0.7598\n",
            "Test Loss : 1.2035, Test Accuracy : 0.6620 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.235 (0.235)\tData 0.138 (0.138)\tLoss 0.8821 (0.8821)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [51][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.1561 (1.0863)\tPrec@1 77.344 (77.166)\n",
            "Epoch: [51][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.2032 (1.1014)\tPrec@1 71.094 (76.695)\n",
            "Epoch: [51][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.3918 (1.1193)\tPrec@1 70.312 (76.396)\n",
            "Epoch: [51][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.9781 (1.1265)\tPrec@1 90.000 (76.192)\n",
            "Total time : 40.146\n",
            "Train Loss: 1.1265, Train Accuracy: 0.7619\n",
            "Test Loss : 1.1812, Test Accuracy : 0.6701 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.253 (0.253)\tData 0.152 (0.152)\tLoss 1.1993 (1.1993)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [52][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.0673 (1.0829)\tPrec@1 81.250 (77.769)\n",
            "Epoch: [52][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.1023 (1.0863)\tPrec@1 75.781 (77.472)\n",
            "Epoch: [52][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2875 (1.1093)\tPrec@1 75.000 (76.762)\n",
            "Epoch: [52][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.9951 (1.1125)\tPrec@1 83.750 (76.652)\n",
            "Total time : 40.170\n",
            "Train Loss: 1.1125, Train Accuracy: 0.7665\n",
            "Test Loss : 1.1639, Test Accuracy : 0.6693 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 1.0076 (1.0076)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [53][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 1.1243 (1.0869)\tPrec@1 76.562 (77.475)\n",
            "Epoch: [53][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.2420 (1.1002)\tPrec@1 72.656 (76.959)\n",
            "Epoch: [53][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.0843 (1.1103)\tPrec@1 79.688 (76.627)\n",
            "Epoch: [53][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.0681 (1.1172)\tPrec@1 75.000 (76.412)\n",
            "Total time : 40.139\n",
            "Train Loss: 1.1172, Train Accuracy: 0.7641\n",
            "Test Loss : 1.1339, Test Accuracy : 0.6766 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.235 (0.235)\tData 0.136 (0.136)\tLoss 1.1102 (1.1102)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [54][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.2341 (1.0650)\tPrec@1 71.875 (77.607)\n",
            "Epoch: [54][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.9726 (1.0777)\tPrec@1 78.906 (77.449)\n",
            "Epoch: [54][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.1046 (1.0877)\tPrec@1 76.562 (77.224)\n",
            "Epoch: [54][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.0025 (1.0996)\tPrec@1 85.000 (76.896)\n",
            "Total time : 39.954\n",
            "Train Loss: 1.0996, Train Accuracy: 0.7690\n",
            "Test Loss : 1.1536, Test Accuracy : 0.6728 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.239 (0.239)\tData 0.140 (0.140)\tLoss 1.1243 (1.1243)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [55][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.9838 (1.0679)\tPrec@1 78.906 (77.723)\n",
            "Epoch: [55][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.0495 (1.0860)\tPrec@1 75.000 (77.433)\n",
            "Epoch: [55][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 1.0971 (1.0935)\tPrec@1 75.000 (77.025)\n",
            "Epoch: [55][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 0.9822 (1.0987)\tPrec@1 83.750 (76.968)\n",
            "Total time : 39.930\n",
            "Train Loss: 1.0987, Train Accuracy: 0.7697\n",
            "Test Loss : 1.1696, Test Accuracy : 0.6654 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.242 (0.242)\tData 0.141 (0.141)\tLoss 1.0086 (1.0086)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [56][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 1.0742 (1.0488)\tPrec@1 79.688 (78.403)\n",
            "Epoch: [56][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1072 (1.0685)\tPrec@1 78.906 (78.082)\n",
            "Epoch: [56][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1836 (1.0788)\tPrec@1 71.875 (77.679)\n",
            "Epoch: [56][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.0853 (1.0929)\tPrec@1 78.750 (77.318)\n",
            "Total time : 40.117\n",
            "Train Loss: 1.0929, Train Accuracy: 0.7732\n",
            "Test Loss : 1.1282, Test Accuracy : 0.6755 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.244 (0.244)\tData 0.141 (0.141)\tLoss 1.0173 (1.0173)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [57][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.1292 (1.0316)\tPrec@1 79.688 (78.906)\n",
            "Epoch: [57][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1088 (1.0617)\tPrec@1 82.031 (77.833)\n",
            "Epoch: [57][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.0788 (1.0769)\tPrec@1 78.125 (77.450)\n",
            "Epoch: [57][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.0013 (1.0839)\tPrec@1 80.000 (77.292)\n",
            "Total time : 40.021\n",
            "Train Loss: 1.0839, Train Accuracy: 0.7729\n",
            "Test Loss : 1.1197, Test Accuracy : 0.6818 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.244 (0.244)\tData 0.146 (0.146)\tLoss 0.8723 (0.8723)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [58][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.0719 (1.0360)\tPrec@1 74.219 (78.527)\n",
            "Epoch: [58][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.1909 (1.0513)\tPrec@1 78.125 (78.300)\n",
            "Epoch: [58][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.0129 (1.0638)\tPrec@1 78.906 (78.024)\n",
            "Epoch: [58][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 1.2115 (1.0701)\tPrec@1 78.750 (77.750)\n",
            "Total time : 39.926\n",
            "Train Loss: 1.0701, Train Accuracy: 0.7775\n",
            "Test Loss : 1.1690, Test Accuracy : 0.6661 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 1.0575 (1.0575)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [59][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 1.0073 (1.0538)\tPrec@1 77.344 (78.040)\n",
            "Epoch: [59][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1194 (1.0606)\tPrec@1 75.781 (77.779)\n",
            "Epoch: [59][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 1.1659 (1.0675)\tPrec@1 78.125 (77.663)\n",
            "Epoch: [59][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 1.2546 (1.0747)\tPrec@1 72.500 (77.508)\n",
            "Total time : 39.941\n",
            "Train Loss: 1.0747, Train Accuracy: 0.7751\n",
            "Test Loss : 1.1453, Test Accuracy : 0.6703 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.9502 (0.9502)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [60][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.0245 (1.0474)\tPrec@1 78.906 (78.226)\n",
            "Epoch: [60][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0568 (1.0517)\tPrec@1 79.688 (78.113)\n",
            "Epoch: [60][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2449 (1.0575)\tPrec@1 73.438 (77.982)\n",
            "Epoch: [60][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.0782 (1.0627)\tPrec@1 85.000 (77.852)\n",
            "Total time : 40.128\n",
            "Train Loss: 1.0627, Train Accuracy: 0.7785\n",
            "Test Loss : 1.1589, Test Accuracy : 0.6717 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.237 (0.237)\tData 0.137 (0.137)\tLoss 0.9570 (0.9570)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [61][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.2365 (1.0258)\tPrec@1 74.219 (79.146)\n",
            "Epoch: [61][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0349 (1.0433)\tPrec@1 77.344 (78.354)\n",
            "Epoch: [61][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1188 (1.0487)\tPrec@1 69.531 (78.169)\n",
            "Epoch: [61][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.0397 (1.0621)\tPrec@1 77.500 (77.832)\n",
            "Total time : 40.154\n",
            "Train Loss: 1.0621, Train Accuracy: 0.7783\n",
            "Test Loss : 1.1400, Test Accuracy : 0.6777 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.244 (0.244)\tData 0.141 (0.141)\tLoss 0.9513 (0.9513)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [62][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.7792 (1.0313)\tPrec@1 84.375 (78.636)\n",
            "Epoch: [62][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.2218 (1.0345)\tPrec@1 71.094 (78.584)\n",
            "Epoch: [62][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9810 (1.0470)\tPrec@1 79.688 (78.392)\n",
            "Epoch: [62][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.8754 (1.0537)\tPrec@1 86.250 (78.238)\n",
            "Total time : 40.110\n",
            "Train Loss: 1.0537, Train Accuracy: 0.7824\n",
            "Test Loss : 1.0961, Test Accuracy : 0.6898 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.236 (0.236)\tData 0.137 (0.137)\tLoss 0.9744 (0.9744)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [63][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.1152 (1.0147)\tPrec@1 78.906 (79.548)\n",
            "Epoch: [63][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0950 (1.0297)\tPrec@1 75.000 (78.844)\n",
            "Epoch: [63][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.1484 (1.0442)\tPrec@1 78.125 (78.439)\n",
            "Epoch: [63][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 1.2039 (1.0505)\tPrec@1 78.750 (78.270)\n",
            "Total time : 40.158\n",
            "Train Loss: 1.0505, Train Accuracy: 0.7827\n",
            "Test Loss : 1.0837, Test Accuracy : 0.6926 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.236 (0.236)\tData 0.139 (0.139)\tLoss 0.8943 (0.8943)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [64][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 1.1150 (0.9943)\tPrec@1 74.219 (79.920)\n",
            "Epoch: [64][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.9816 (1.0176)\tPrec@1 79.688 (79.551)\n",
            "Epoch: [64][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.9786 (1.0290)\tPrec@1 83.594 (79.205)\n",
            "Epoch: [64][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.0105 (1.0356)\tPrec@1 78.750 (78.932)\n",
            "Total time : 39.951\n",
            "Train Loss: 1.0356, Train Accuracy: 0.7893\n",
            "Test Loss : 1.1009, Test Accuracy : 0.6826 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.240 (0.240)\tData 0.137 (0.137)\tLoss 0.9783 (0.9783)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [65][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 1.1235 (0.9917)\tPrec@1 74.219 (80.005)\n",
            "Epoch: [65][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 1.0665 (1.0108)\tPrec@1 80.469 (79.307)\n",
            "Epoch: [65][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.9304 (1.0248)\tPrec@1 82.812 (78.948)\n",
            "Epoch: [65][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.0175 (1.0364)\tPrec@1 82.500 (78.480)\n",
            "Total time : 39.935\n",
            "Train Loss: 1.0364, Train Accuracy: 0.7848\n",
            "Test Loss : 1.1007, Test Accuracy : 0.6871 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.9957 (0.9957)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [66][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 1.1052 (1.0029)\tPrec@1 73.438 (79.680)\n",
            "Epoch: [66][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9002 (1.0125)\tPrec@1 82.812 (79.404)\n",
            "Epoch: [66][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9744 (1.0247)\tPrec@1 79.688 (78.917)\n",
            "Epoch: [66][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.1414 (1.0311)\tPrec@1 78.750 (78.778)\n",
            "Total time : 40.145\n",
            "Train Loss: 1.0311, Train Accuracy: 0.7878\n",
            "Test Loss : 1.0994, Test Accuracy : 0.6886 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.247 (0.247)\tData 0.147 (0.147)\tLoss 0.8414 (0.8414)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [67][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.8895 (0.9906)\tPrec@1 81.250 (80.059)\n",
            "Epoch: [67][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.0365 (1.0067)\tPrec@1 78.125 (79.450)\n",
            "Epoch: [67][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.9526 (1.0107)\tPrec@1 81.250 (79.373)\n",
            "Epoch: [67][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.9394 (1.0208)\tPrec@1 86.250 (79.082)\n",
            "Total time : 39.950\n",
            "Train Loss: 1.0208, Train Accuracy: 0.7908\n",
            "Test Loss : 1.0820, Test Accuracy : 0.6924 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 1.0075 (1.0075)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [68][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.9329 (0.9900)\tPrec@1 82.812 (79.827)\n",
            "Epoch: [68][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.9390 (1.0011)\tPrec@1 78.906 (79.594)\n",
            "Epoch: [68][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.1842 (1.0105)\tPrec@1 71.875 (79.324)\n",
            "Epoch: [68][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.8979 (1.0139)\tPrec@1 82.500 (79.190)\n",
            "Total time : 39.994\n",
            "Train Loss: 1.0139, Train Accuracy: 0.7919\n",
            "Test Loss : 1.0632, Test Accuracy : 0.6969 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 0.7955 (0.7955)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [69][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.0936 (0.9521)\tPrec@1 79.688 (80.832)\n",
            "Epoch: [69][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.1288 (0.9699)\tPrec@1 82.031 (80.337)\n",
            "Epoch: [69][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.0340 (0.9903)\tPrec@1 78.125 (79.833)\n",
            "Epoch: [69][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.8474 (0.9997)\tPrec@1 88.750 (79.552)\n",
            "Total time : 40.122\n",
            "Train Loss: 0.9997, Train Accuracy: 0.7955\n",
            "Test Loss : 1.0493, Test Accuracy : 0.7018 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.9677 (0.9677)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [70][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 1.0017 (0.9600)\tPrec@1 81.250 (80.585)\n",
            "Epoch: [70][200/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.1371 (0.9726)\tPrec@1 75.781 (80.372)\n",
            "Epoch: [70][300/391]\tTime 0.100 (0.102)\tData 0.000 (0.001)\tLoss 1.1447 (0.9851)\tPrec@1 71.875 (79.963)\n",
            "Epoch: [70][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.3876 (0.9975)\tPrec@1 66.250 (79.670)\n",
            "Total time : 39.820\n",
            "Train Loss: 0.9975, Train Accuracy: 0.7967\n",
            "Test Loss : 1.0911, Test Accuracy : 0.6891 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.236 (0.236)\tData 0.137 (0.137)\tLoss 0.9066 (0.9066)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [71][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 1.0550 (0.9775)\tPrec@1 75.781 (80.229)\n",
            "Epoch: [71][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 1.0464 (0.9823)\tPrec@1 76.562 (79.901)\n",
            "Epoch: [71][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.9759 (0.9924)\tPrec@1 78.125 (79.643)\n",
            "Epoch: [71][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.8333 (0.9962)\tPrec@1 88.750 (79.586)\n",
            "Total time : 39.977\n",
            "Train Loss: 0.9962, Train Accuracy: 0.7959\n",
            "Test Loss : 1.0783, Test Accuracy : 0.6880 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.247 (0.247)\tData 0.148 (0.148)\tLoss 0.9695 (0.9695)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [72][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 1.0464 (0.9528)\tPrec@1 80.469 (80.608)\n",
            "Epoch: [72][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.8943 (0.9745)\tPrec@1 82.812 (80.282)\n",
            "Epoch: [72][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.8684 (0.9841)\tPrec@1 85.156 (80.116)\n",
            "Epoch: [72][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.9886 (0.9876)\tPrec@1 83.750 (79.962)\n",
            "Total time : 39.969\n",
            "Train Loss: 0.9876, Train Accuracy: 0.7996\n",
            "Test Loss : 1.0340, Test Accuracy : 0.6998 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.234 (0.234)\tData 0.136 (0.136)\tLoss 0.8024 (0.8024)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [73][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 1.0482 (0.9232)\tPrec@1 78.906 (81.683)\n",
            "Epoch: [73][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0244 (0.9444)\tPrec@1 79.688 (80.955)\n",
            "Epoch: [73][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 1.0008 (0.9720)\tPrec@1 78.906 (80.243)\n",
            "Epoch: [73][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.7085 (0.9886)\tPrec@1 87.500 (79.816)\n",
            "Total time : 39.947\n",
            "Train Loss: 0.9886, Train Accuracy: 0.7982\n",
            "Test Loss : 1.1285, Test Accuracy : 0.6755 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.241 (0.241)\tData 0.138 (0.138)\tLoss 0.8809 (0.8809)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [74][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.8126 (0.9580)\tPrec@1 82.812 (80.763)\n",
            "Epoch: [74][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.1208 (0.9665)\tPrec@1 75.000 (80.562)\n",
            "Epoch: [74][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.8905 (0.9759)\tPrec@1 80.469 (80.259)\n",
            "Epoch: [74][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.8890 (0.9792)\tPrec@1 86.250 (80.112)\n",
            "Total time : 39.958\n",
            "Train Loss: 0.9792, Train Accuracy: 0.8011\n",
            "Test Loss : 1.0484, Test Accuracy : 0.7014 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.239 (0.239)\tData 0.138 (0.138)\tLoss 0.9979 (0.9979)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [75][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 1.0668 (0.9296)\tPrec@1 76.562 (81.505)\n",
            "Epoch: [75][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.0307 (0.9502)\tPrec@1 76.562 (80.877)\n",
            "Epoch: [75][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.8723 (0.9631)\tPrec@1 83.594 (80.557)\n",
            "Epoch: [75][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.6795 (0.9721)\tPrec@1 90.000 (80.356)\n",
            "Total time : 40.102\n",
            "Train Loss: 0.9721, Train Accuracy: 0.8036\n",
            "Test Loss : 1.0635, Test Accuracy : 0.7007 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.241 (0.241)\tData 0.139 (0.139)\tLoss 1.0776 (1.0776)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [76][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.9432 (0.9259)\tPrec@1 82.031 (82.008)\n",
            "Epoch: [76][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.0376 (0.9427)\tPrec@1 78.906 (81.227)\n",
            "Epoch: [76][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9206 (0.9465)\tPrec@1 83.594 (80.962)\n",
            "Epoch: [76][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.1763 (0.9566)\tPrec@1 77.500 (80.678)\n",
            "Total time : 40.165\n",
            "Train Loss: 0.9566, Train Accuracy: 0.8068\n",
            "Test Loss : 1.0473, Test Accuracy : 0.6983 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.241 (0.241)\tData 0.140 (0.140)\tLoss 0.8651 (0.8651)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [77][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.8474 (0.9149)\tPrec@1 85.156 (81.652)\n",
            "Epoch: [77][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.8986 (0.9251)\tPrec@1 83.594 (81.336)\n",
            "Epoch: [77][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.1218 (0.9413)\tPrec@1 78.906 (80.915)\n",
            "Epoch: [77][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.9841 (0.9527)\tPrec@1 83.750 (80.674)\n",
            "Total time : 39.983\n",
            "Train Loss: 0.9527, Train Accuracy: 0.8067\n",
            "Test Loss : 1.0282, Test Accuracy : 0.7060 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.9399 (0.9399)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [78][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.8680 (0.9044)\tPrec@1 82.812 (81.969)\n",
            "Epoch: [78][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.9192 (0.9282)\tPrec@1 82.031 (81.580)\n",
            "Epoch: [78][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.9952 (0.9398)\tPrec@1 73.438 (81.253)\n",
            "Epoch: [78][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 1.0871 (0.9459)\tPrec@1 78.750 (80.992)\n",
            "Total time : 39.949\n",
            "Train Loss: 0.9459, Train Accuracy: 0.8099\n",
            "Test Loss : 1.0503, Test Accuracy : 0.7005 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.234 (0.234)\tData 0.137 (0.137)\tLoss 0.8705 (0.8705)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [79][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.8530 (0.8908)\tPrec@1 84.375 (82.186)\n",
            "Epoch: [79][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.9261 (0.9056)\tPrec@1 82.812 (82.023)\n",
            "Epoch: [79][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.9142 (0.9230)\tPrec@1 81.250 (81.541)\n",
            "Epoch: [79][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 0.9255 (0.9355)\tPrec@1 78.750 (81.162)\n",
            "Total time : 39.919\n",
            "Train Loss: 0.9355, Train Accuracy: 0.8116\n",
            "Test Loss : 1.0425, Test Accuracy : 0.6993 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.239 (0.239)\tData 0.139 (0.139)\tLoss 0.7958 (0.7958)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [80][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.9143 (0.9154)\tPrec@1 80.469 (81.737)\n",
            "Epoch: [80][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0736 (0.9215)\tPrec@1 75.000 (81.503)\n",
            "Epoch: [80][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9005 (0.9248)\tPrec@1 80.469 (81.388)\n",
            "Epoch: [80][390/391]\tTime 0.060 (0.103)\tData 0.000 (0.001)\tLoss 0.9556 (0.9305)\tPrec@1 82.500 (81.206)\n",
            "Total time : 40.118\n",
            "Train Loss: 0.9305, Train Accuracy: 0.8121\n",
            "Test Loss : 1.0484, Test Accuracy : 0.7012 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.242 (0.242)\tData 0.140 (0.140)\tLoss 0.9373 (0.9373)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [81][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.7718 (0.8969)\tPrec@1 84.375 (82.000)\n",
            "Epoch: [81][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.9266 (0.9005)\tPrec@1 80.469 (82.066)\n",
            "Epoch: [81][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.8575 (0.9083)\tPrec@1 81.250 (81.914)\n",
            "Epoch: [81][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.8898 (0.9191)\tPrec@1 80.000 (81.540)\n",
            "Total time : 39.955\n",
            "Train Loss: 0.9191, Train Accuracy: 0.8154\n",
            "Test Loss : 1.0391, Test Accuracy : 0.7024 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.240 (0.240)\tData 0.141 (0.141)\tLoss 0.7417 (0.7417)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [82][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 1.0315 (0.8992)\tPrec@1 79.688 (82.240)\n",
            "Epoch: [82][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 1.0412 (0.9041)\tPrec@1 81.250 (82.020)\n",
            "Epoch: [82][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.0741 (0.9149)\tPrec@1 75.000 (81.800)\n",
            "Epoch: [82][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.7943 (0.9168)\tPrec@1 83.750 (81.814)\n",
            "Total time : 39.940\n",
            "Train Loss: 0.9168, Train Accuracy: 0.8181\n",
            "Test Loss : 1.0026, Test Accuracy : 0.7120 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.241 (0.241)\tData 0.143 (0.143)\tLoss 0.7377 (0.7377)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [83][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.9033 (0.8586)\tPrec@1 82.812 (83.369)\n",
            "Epoch: [83][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.8789 (0.8872)\tPrec@1 79.688 (82.416)\n",
            "Epoch: [83][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.9939 (0.8990)\tPrec@1 79.688 (82.161)\n",
            "Epoch: [83][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 1.0301 (0.9103)\tPrec@1 85.000 (81.846)\n",
            "Total time : 40.002\n",
            "Train Loss: 0.9103, Train Accuracy: 0.8185\n",
            "Test Loss : 1.0291, Test Accuracy : 0.7058 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.242 (0.242)\tData 0.142 (0.142)\tLoss 0.9379 (0.9379)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [84][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.8774 (0.8664)\tPrec@1 85.156 (83.199)\n",
            "Epoch: [84][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.9550 (0.8759)\tPrec@1 78.906 (82.863)\n",
            "Epoch: [84][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7045 (0.8908)\tPrec@1 86.719 (82.447)\n",
            "Epoch: [84][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.8801 (0.8976)\tPrec@1 81.250 (82.226)\n",
            "Total time : 40.162\n",
            "Train Loss: 0.8976, Train Accuracy: 0.8223\n",
            "Test Loss : 0.9970, Test Accuracy : 0.7131 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.235 (0.235)\tData 0.138 (0.138)\tLoss 0.7689 (0.7689)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [85][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.7256 (0.8676)\tPrec@1 87.500 (82.782)\n",
            "Epoch: [85][200/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.9622 (0.8887)\tPrec@1 81.250 (82.583)\n",
            "Epoch: [85][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.9634 (0.8958)\tPrec@1 80.469 (82.379)\n",
            "Epoch: [85][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.9731 (0.8987)\tPrec@1 76.250 (82.274)\n",
            "Total time : 39.893\n",
            "Train Loss: 0.8987, Train Accuracy: 0.8227\n",
            "Test Loss : 1.0233, Test Accuracy : 0.7074 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.240 (0.240)\tData 0.141 (0.141)\tLoss 0.7063 (0.7063)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [86][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.8461 (0.8417)\tPrec@1 85.938 (83.841)\n",
            "Epoch: [86][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.8629 (0.8624)\tPrec@1 82.031 (83.248)\n",
            "Epoch: [86][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.9265 (0.8756)\tPrec@1 81.250 (82.836)\n",
            "Epoch: [86][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 1.1170 (0.8903)\tPrec@1 78.750 (82.452)\n",
            "Total time : 39.989\n",
            "Train Loss: 0.8903, Train Accuracy: 0.8245\n",
            "Test Loss : 1.0222, Test Accuracy : 0.7043 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.247 (0.247)\tData 0.150 (0.150)\tLoss 0.8206 (0.8206)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [87][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.7357 (0.8457)\tPrec@1 82.812 (83.377)\n",
            "Epoch: [87][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.9710 (0.8583)\tPrec@1 82.812 (82.991)\n",
            "Epoch: [87][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.8606 (0.8648)\tPrec@1 82.031 (82.831)\n",
            "Epoch: [87][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 0.8896 (0.8747)\tPrec@1 86.250 (82.584)\n",
            "Total time : 39.973\n",
            "Train Loss: 0.8747, Train Accuracy: 0.8258\n",
            "Test Loss : 1.0344, Test Accuracy : 0.7071 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.242 (0.242)\tData 0.138 (0.138)\tLoss 0.7267 (0.7267)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [88][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.7483 (0.8378)\tPrec@1 88.281 (83.841)\n",
            "Epoch: [88][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.9641 (0.8456)\tPrec@1 78.125 (83.609)\n",
            "Epoch: [88][300/391]\tTime 0.105 (0.102)\tData 0.000 (0.001)\tLoss 0.8905 (0.8602)\tPrec@1 79.688 (83.116)\n",
            "Epoch: [88][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.8395 (0.8721)\tPrec@1 88.750 (82.872)\n",
            "Total time : 39.944\n",
            "Train Loss: 0.8721, Train Accuracy: 0.8287\n",
            "Test Loss : 0.9895, Test Accuracy : 0.7182 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.6863 (0.6863)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [89][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.8171 (0.8303)\tPrec@1 83.594 (83.485)\n",
            "Epoch: [89][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 1.0897 (0.8408)\tPrec@1 72.656 (83.419)\n",
            "Epoch: [89][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.7028 (0.8481)\tPrec@1 85.938 (83.376)\n",
            "Epoch: [89][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.9955 (0.8623)\tPrec@1 82.500 (83.006)\n",
            "Total time : 39.948\n",
            "Train Loss: 0.8623, Train Accuracy: 0.8301\n",
            "Test Loss : 0.9725, Test Accuracy : 0.7245 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.240 (0.240)\tData 0.138 (0.138)\tLoss 0.7311 (0.7311)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [90][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.8809 (0.8485)\tPrec@1 83.594 (83.354)\n",
            "Epoch: [90][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.9230 (0.8480)\tPrec@1 85.156 (83.419)\n",
            "Epoch: [90][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 1.1076 (0.8535)\tPrec@1 78.125 (83.360)\n",
            "Epoch: [90][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.8573 (0.8601)\tPrec@1 88.750 (83.078)\n",
            "Total time : 39.991\n",
            "Train Loss: 0.8601, Train Accuracy: 0.8308\n",
            "Test Loss : 1.0245, Test Accuracy : 0.6995 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.7043 (0.7043)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [91][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.7313 (0.8104)\tPrec@1 88.281 (84.839)\n",
            "Epoch: [91][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.8641 (0.8247)\tPrec@1 83.594 (84.422)\n",
            "Epoch: [91][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.9978 (0.8422)\tPrec@1 77.344 (83.765)\n",
            "Epoch: [91][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.7508 (0.8488)\tPrec@1 87.500 (83.510)\n",
            "Total time : 39.963\n",
            "Train Loss: 0.8488, Train Accuracy: 0.8351\n",
            "Test Loss : 1.0101, Test Accuracy : 0.7115 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.244 (0.244)\tData 0.145 (0.145)\tLoss 0.8500 (0.8500)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [92][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.8399 (0.8109)\tPrec@1 85.156 (84.646)\n",
            "Epoch: [92][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.8586 (0.8179)\tPrec@1 80.469 (84.414)\n",
            "Epoch: [92][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.8638 (0.8299)\tPrec@1 84.375 (83.949)\n",
            "Epoch: [92][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.8776 (0.8442)\tPrec@1 80.000 (83.412)\n",
            "Total time : 40.111\n",
            "Train Loss: 0.8442, Train Accuracy: 0.8341\n",
            "Test Loss : 0.9883, Test Accuracy : 0.7198 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.239 (0.239)\tData 0.136 (0.136)\tLoss 0.7387 (0.7387)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [93][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.9360 (0.7998)\tPrec@1 80.469 (84.615)\n",
            "Epoch: [93][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.7375 (0.8067)\tPrec@1 88.281 (84.492)\n",
            "Epoch: [93][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.7546 (0.8201)\tPrec@1 88.281 (84.069)\n",
            "Epoch: [93][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.8411 (0.8311)\tPrec@1 86.250 (83.806)\n",
            "Total time : 40.132\n",
            "Train Loss: 0.8311, Train Accuracy: 0.8381\n",
            "Test Loss : 0.9881, Test Accuracy : 0.7125 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.237 (0.237)\tData 0.137 (0.137)\tLoss 0.6227 (0.6227)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [94][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 0.7908 (0.8028)\tPrec@1 85.156 (84.623)\n",
            "Epoch: [94][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.8310 (0.8109)\tPrec@1 80.469 (84.499)\n",
            "Epoch: [94][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9245 (0.8224)\tPrec@1 82.031 (84.170)\n",
            "Epoch: [94][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 1.0158 (0.8295)\tPrec@1 83.750 (84.020)\n",
            "Total time : 40.111\n",
            "Train Loss: 0.8295, Train Accuracy: 0.8402\n",
            "Test Loss : 0.9710, Test Accuracy : 0.7184 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.243 (0.243)\tData 0.143 (0.143)\tLoss 0.7074 (0.7074)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [95][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.8022 (0.7997)\tPrec@1 83.594 (84.824)\n",
            "Epoch: [95][200/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.8544 (0.8073)\tPrec@1 82.812 (84.515)\n",
            "Epoch: [95][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 1.0893 (0.8218)\tPrec@1 78.125 (84.084)\n",
            "Epoch: [95][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.9966 (0.8262)\tPrec@1 77.500 (83.976)\n",
            "Total time : 39.941\n",
            "Train Loss: 0.8262, Train Accuracy: 0.8398\n",
            "Test Loss : 0.9416, Test Accuracy : 0.7293 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.240 (0.240)\tData 0.141 (0.141)\tLoss 0.6570 (0.6570)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [96][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.8606 (0.7797)\tPrec@1 81.250 (84.785)\n",
            "Epoch: [96][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.8167 (0.7969)\tPrec@1 85.156 (84.690)\n",
            "Epoch: [96][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.9802 (0.8103)\tPrec@1 78.906 (84.341)\n",
            "Epoch: [96][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.7939 (0.8171)\tPrec@1 86.250 (84.116)\n",
            "Total time : 40.059\n",
            "Train Loss: 0.8171, Train Accuracy: 0.8412\n",
            "Test Loss : 0.9606, Test Accuracy : 0.7221 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.6833 (0.6833)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [97][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.8004 (0.7686)\tPrec@1 83.594 (85.334)\n",
            "Epoch: [97][200/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.7365 (0.7793)\tPrec@1 85.156 (85.024)\n",
            "Epoch: [97][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.7471 (0.7948)\tPrec@1 86.719 (84.668)\n",
            "Epoch: [97][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.8167 (0.8034)\tPrec@1 87.500 (84.512)\n",
            "Total time : 39.917\n",
            "Train Loss: 0.8034, Train Accuracy: 0.8451\n",
            "Test Loss : 0.9826, Test Accuracy : 0.7125 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.239 (0.239)\tData 0.139 (0.139)\tLoss 0.6632 (0.6632)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [98][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.8061 (0.7613)\tPrec@1 85.156 (85.675)\n",
            "Epoch: [98][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.8498 (0.7764)\tPrec@1 82.812 (85.265)\n",
            "Epoch: [98][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.8772 (0.7904)\tPrec@1 85.156 (84.910)\n",
            "Epoch: [98][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.9340 (0.7979)\tPrec@1 82.500 (84.762)\n",
            "Total time : 39.944\n",
            "Train Loss: 0.7979, Train Accuracy: 0.8476\n",
            "Test Loss : 0.9871, Test Accuracy : 0.7137 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.245 (0.245)\tData 0.142 (0.142)\tLoss 0.6739 (0.6739)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [99][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.8764 (0.7550)\tPrec@1 80.469 (85.682)\n",
            "Epoch: [99][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.8606 (0.7724)\tPrec@1 80.469 (85.405)\n",
            "Epoch: [99][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.9778 (0.7839)\tPrec@1 78.906 (85.213)\n",
            "Epoch: [99][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.8157 (0.7882)\tPrec@1 86.250 (84.988)\n",
            "Total time : 39.941\n",
            "Train Loss: 0.7882, Train Accuracy: 0.8499\n",
            "Test Loss : 0.9335, Test Accuracy : 0.7281 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.237 (0.237)\tData 0.137 (0.137)\tLoss 0.8207 (0.8207)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [100][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.8523 (0.7459)\tPrec@1 83.594 (85.883)\n",
            "Epoch: [100][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7215 (0.7526)\tPrec@1 89.062 (85.646)\n",
            "Epoch: [100][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.7489 (0.7716)\tPrec@1 86.719 (85.221)\n",
            "Epoch: [100][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.8497 (0.7801)\tPrec@1 86.250 (85.000)\n",
            "Total time : 39.948\n",
            "Train Loss: 0.7801, Train Accuracy: 0.8500\n",
            "Test Loss : 0.9704, Test Accuracy : 0.7223 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.245 (0.245)\tData 0.143 (0.143)\tLoss 0.9085 (0.9085)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [101][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.8314 (0.7414)\tPrec@1 81.250 (86.309)\n",
            "Epoch: [101][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6507 (0.7480)\tPrec@1 87.500 (86.105)\n",
            "Epoch: [101][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7743 (0.7687)\tPrec@1 82.812 (85.564)\n",
            "Epoch: [101][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.7387 (0.7754)\tPrec@1 87.500 (85.330)\n",
            "Total time : 40.129\n",
            "Train Loss: 0.7754, Train Accuracy: 0.8533\n",
            "Test Loss : 0.9472, Test Accuracy : 0.7290 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.7141 (0.7141)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [102][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.8652 (0.7388)\tPrec@1 82.812 (86.270)\n",
            "Epoch: [102][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.6507 (0.7436)\tPrec@1 89.062 (86.221)\n",
            "Epoch: [102][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.8977 (0.7580)\tPrec@1 83.594 (85.743)\n",
            "Epoch: [102][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.7390 (0.7663)\tPrec@1 87.500 (85.472)\n",
            "Total time : 40.143\n",
            "Train Loss: 0.7663, Train Accuracy: 0.8547\n",
            "Test Loss : 0.9331, Test Accuracy : 0.7299 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.239 (0.239)\tData 0.139 (0.139)\tLoss 0.6355 (0.6355)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [103][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.7169 (0.7205)\tPrec@1 89.062 (86.974)\n",
            "Epoch: [103][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.6783 (0.7345)\tPrec@1 85.156 (86.509)\n",
            "Epoch: [103][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.8806 (0.7494)\tPrec@1 84.375 (85.917)\n",
            "Epoch: [103][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.9889 (0.7559)\tPrec@1 81.250 (85.710)\n",
            "Total time : 40.150\n",
            "Train Loss: 0.7559, Train Accuracy: 0.8571\n",
            "Test Loss : 0.9075, Test Accuracy : 0.7364 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.243 (0.243)\tData 0.140 (0.140)\tLoss 0.6930 (0.6930)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [104][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.8737 (0.7302)\tPrec@1 81.250 (86.541)\n",
            "Epoch: [104][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7893 (0.7405)\tPrec@1 86.719 (86.326)\n",
            "Epoch: [104][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.8153 (0.7495)\tPrec@1 82.812 (86.080)\n",
            "Epoch: [104][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.7139 (0.7539)\tPrec@1 92.500 (85.912)\n",
            "Total time : 40.138\n",
            "Train Loss: 0.7539, Train Accuracy: 0.8591\n",
            "Test Loss : 0.9174, Test Accuracy : 0.7299 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.6273 (0.6273)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [105][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.5418 (0.7071)\tPrec@1 90.625 (86.989)\n",
            "Epoch: [105][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.5476 (0.7189)\tPrec@1 88.281 (86.781)\n",
            "Epoch: [105][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.7849 (0.7276)\tPrec@1 82.031 (86.599)\n",
            "Epoch: [105][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.9039 (0.7410)\tPrec@1 81.250 (86.170)\n",
            "Total time : 40.129\n",
            "Train Loss: 0.7410, Train Accuracy: 0.8617\n",
            "Test Loss : 0.9437, Test Accuracy : 0.7215 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.239 (0.239)\tData 0.140 (0.140)\tLoss 0.9827 (0.9827)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [106][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6829 (0.6955)\tPrec@1 89.062 (87.662)\n",
            "Epoch: [106][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6960 (0.7119)\tPrec@1 90.625 (87.092)\n",
            "Epoch: [106][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.7994 (0.7237)\tPrec@1 89.062 (86.649)\n",
            "Epoch: [106][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.7296 (0.7330)\tPrec@1 92.500 (86.330)\n",
            "Total time : 40.089\n",
            "Train Loss: 0.7330, Train Accuracy: 0.8633\n",
            "Test Loss : 0.9117, Test Accuracy : 0.7397 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.7098 (0.7098)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [107][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.6922 (0.6911)\tPrec@1 87.500 (87.198)\n",
            "Epoch: [107][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7601 (0.7023)\tPrec@1 85.938 (87.049)\n",
            "Epoch: [107][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.8203 (0.7146)\tPrec@1 84.375 (86.755)\n",
            "Epoch: [107][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.8163 (0.7241)\tPrec@1 90.000 (86.474)\n",
            "Total time : 40.143\n",
            "Train Loss: 0.7241, Train Accuracy: 0.8647\n",
            "Test Loss : 0.9013, Test Accuracy : 0.7380 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.236 (0.236)\tData 0.137 (0.137)\tLoss 0.7898 (0.7898)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [108][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 0.6488 (0.6752)\tPrec@1 89.844 (87.469)\n",
            "Epoch: [108][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.6930 (0.6942)\tPrec@1 90.625 (87.069)\n",
            "Epoch: [108][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.5736 (0.7053)\tPrec@1 92.969 (86.874)\n",
            "Epoch: [108][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.7223 (0.7134)\tPrec@1 92.500 (86.780)\n",
            "Total time : 40.090\n",
            "Train Loss: 0.7134, Train Accuracy: 0.8678\n",
            "Test Loss : 0.9161, Test Accuracy : 0.7374 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.239 (0.239)\tData 0.140 (0.140)\tLoss 0.7080 (0.7080)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [109][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.7128 (0.6812)\tPrec@1 90.625 (88.080)\n",
            "Epoch: [109][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6940 (0.6983)\tPrec@1 85.156 (87.496)\n",
            "Epoch: [109][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7328 (0.7080)\tPrec@1 89.844 (87.051)\n",
            "Epoch: [109][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.7483 (0.7097)\tPrec@1 86.250 (87.036)\n",
            "Total time : 40.152\n",
            "Train Loss: 0.7097, Train Accuracy: 0.8704\n",
            "Test Loss : 0.9142, Test Accuracy : 0.7329 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.7340 (0.7340)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [110][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6404 (0.6792)\tPrec@1 89.062 (87.423)\n",
            "Epoch: [110][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.6553 (0.6810)\tPrec@1 90.625 (87.484)\n",
            "Epoch: [110][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.8365 (0.6866)\tPrec@1 86.719 (87.412)\n",
            "Epoch: [110][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.6191 (0.6929)\tPrec@1 87.500 (87.248)\n",
            "Total time : 39.998\n",
            "Train Loss: 0.6929, Train Accuracy: 0.8725\n",
            "Test Loss : 0.8992, Test Accuracy : 0.7373 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 0.6886 (0.6886)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [111][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6543 (0.6588)\tPrec@1 89.844 (88.088)\n",
            "Epoch: [111][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.5732 (0.6684)\tPrec@1 90.625 (87.951)\n",
            "Epoch: [111][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.6168 (0.6819)\tPrec@1 91.406 (87.547)\n",
            "Epoch: [111][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.8698 (0.6864)\tPrec@1 85.000 (87.438)\n",
            "Total time : 39.950\n",
            "Train Loss: 0.6864, Train Accuracy: 0.8744\n",
            "Test Loss : 0.9085, Test Accuracy : 0.7392 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.241 (0.241)\tData 0.138 (0.138)\tLoss 0.5736 (0.5736)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [112][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.6374 (0.6568)\tPrec@1 91.406 (88.003)\n",
            "Epoch: [112][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6241 (0.6641)\tPrec@1 88.281 (88.044)\n",
            "Epoch: [112][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.6885 (0.6724)\tPrec@1 85.938 (87.918)\n",
            "Epoch: [112][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.6948 (0.6781)\tPrec@1 91.250 (87.744)\n",
            "Total time : 39.984\n",
            "Train Loss: 0.6781, Train Accuracy: 0.8774\n",
            "Test Loss : 0.8839, Test Accuracy : 0.7420 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.239 (0.239)\tData 0.140 (0.140)\tLoss 0.6028 (0.6028)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [113][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6284 (0.6384)\tPrec@1 90.625 (88.691)\n",
            "Epoch: [113][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.7057 (0.6459)\tPrec@1 86.719 (88.483)\n",
            "Epoch: [113][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.7001 (0.6570)\tPrec@1 91.406 (88.338)\n",
            "Epoch: [113][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.6639 (0.6639)\tPrec@1 87.500 (88.070)\n",
            "Total time : 39.972\n",
            "Train Loss: 0.6639, Train Accuracy: 0.8807\n",
            "Test Loss : 0.8990, Test Accuracy : 0.7370 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.245 (0.245)\tData 0.144 (0.144)\tLoss 0.6875 (0.6875)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [114][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 0.5759 (0.6311)\tPrec@1 88.281 (88.954)\n",
            "Epoch: [114][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.7514 (0.6433)\tPrec@1 87.500 (88.437)\n",
            "Epoch: [114][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.6202 (0.6546)\tPrec@1 85.156 (88.222)\n",
            "Epoch: [114][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.6640 (0.6654)\tPrec@1 88.750 (87.934)\n",
            "Total time : 40.036\n",
            "Train Loss: 0.6654, Train Accuracy: 0.8793\n",
            "Test Loss : 0.8948, Test Accuracy : 0.7423 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.245 (0.245)\tData 0.143 (0.143)\tLoss 0.5059 (0.5059)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [115][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.5735 (0.6235)\tPrec@1 89.844 (89.132)\n",
            "Epoch: [115][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.6175 (0.6321)\tPrec@1 87.500 (88.880)\n",
            "Epoch: [115][300/391]\tTime 0.105 (0.102)\tData 0.000 (0.001)\tLoss 0.6006 (0.6416)\tPrec@1 90.625 (88.598)\n",
            "Epoch: [115][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.5017 (0.6501)\tPrec@1 92.500 (88.314)\n",
            "Total time : 39.942\n",
            "Train Loss: 0.6501, Train Accuracy: 0.8831\n",
            "Test Loss : 0.8620, Test Accuracy : 0.7503 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.235 (0.235)\tData 0.137 (0.137)\tLoss 0.4945 (0.4945)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [116][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.5966 (0.6096)\tPrec@1 89.844 (89.395)\n",
            "Epoch: [116][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.5347 (0.6200)\tPrec@1 90.625 (89.125)\n",
            "Epoch: [116][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.6335 (0.6295)\tPrec@1 83.594 (88.889)\n",
            "Epoch: [116][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.5391 (0.6385)\tPrec@1 93.750 (88.580)\n",
            "Total time : 39.947\n",
            "Train Loss: 0.6385, Train Accuracy: 0.8858\n",
            "Test Loss : 0.8723, Test Accuracy : 0.7456 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.236 (0.236)\tData 0.139 (0.139)\tLoss 0.7780 (0.7780)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [117][100/391]\tTime 0.105 (0.103)\tData 0.000 (0.002)\tLoss 0.6999 (0.6128)\tPrec@1 86.719 (89.457)\n",
            "Epoch: [117][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.6408 (0.6205)\tPrec@1 87.500 (89.144)\n",
            "Epoch: [117][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.7012 (0.6312)\tPrec@1 85.938 (88.839)\n",
            "Epoch: [117][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.7672 (0.6386)\tPrec@1 90.000 (88.740)\n",
            "Total time : 40.001\n",
            "Train Loss: 0.6386, Train Accuracy: 0.8874\n",
            "Test Loss : 0.8623, Test Accuracy : 0.7489 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 0.6115 (0.6115)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [118][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.5440 (0.5829)\tPrec@1 90.625 (90.254)\n",
            "Epoch: [118][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.4908 (0.5977)\tPrec@1 92.188 (89.820)\n",
            "Epoch: [118][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.6096 (0.6118)\tPrec@1 88.281 (89.478)\n",
            "Epoch: [118][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.6245 (0.6237)\tPrec@1 93.750 (89.144)\n",
            "Total time : 39.964\n",
            "Train Loss: 0.6237, Train Accuracy: 0.8914\n",
            "Test Loss : 0.8811, Test Accuracy : 0.7459 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.247 (0.247)\tData 0.145 (0.145)\tLoss 0.5900 (0.5900)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [119][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.5751 (0.5864)\tPrec@1 89.062 (90.076)\n",
            "Epoch: [119][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.7452 (0.5999)\tPrec@1 85.156 (89.692)\n",
            "Epoch: [119][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.5299 (0.6073)\tPrec@1 92.188 (89.512)\n",
            "Epoch: [119][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.7404 (0.6134)\tPrec@1 87.500 (89.234)\n",
            "Total time : 40.134\n",
            "Train Loss: 0.6134, Train Accuracy: 0.8923\n",
            "Test Loss : 0.8710, Test Accuracy : 0.7464 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.5001 (0.5001)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [120][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.5204 (0.5816)\tPrec@1 94.531 (90.145)\n",
            "Epoch: [120][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7171 (0.5862)\tPrec@1 82.812 (90.007)\n",
            "Epoch: [120][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6230 (0.5963)\tPrec@1 85.938 (89.665)\n",
            "Epoch: [120][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.5107 (0.6038)\tPrec@1 96.250 (89.598)\n",
            "Total time : 40.149\n",
            "Train Loss: 0.6038, Train Accuracy: 0.8960\n",
            "Test Loss : 0.8574, Test Accuracy : 0.7530 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.235 (0.235)\tData 0.137 (0.137)\tLoss 0.5317 (0.5317)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [121][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.4881 (0.5643)\tPrec@1 93.750 (90.610)\n",
            "Epoch: [121][200/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.6618 (0.5723)\tPrec@1 92.188 (90.462)\n",
            "Epoch: [121][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.7209 (0.5854)\tPrec@1 88.281 (90.038)\n",
            "Epoch: [121][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.5776 (0.5986)\tPrec@1 91.250 (89.706)\n",
            "Total time : 39.923\n",
            "Train Loss: 0.5986, Train Accuracy: 0.8971\n",
            "Test Loss : 0.8645, Test Accuracy : 0.7479 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.5766 (0.5766)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [122][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.5983 (0.5635)\tPrec@1 89.844 (90.780)\n",
            "Epoch: [122][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.5555 (0.5699)\tPrec@1 89.062 (90.606)\n",
            "Epoch: [122][300/391]\tTime 0.100 (0.102)\tData 0.000 (0.001)\tLoss 0.5441 (0.5805)\tPrec@1 90.625 (90.199)\n",
            "Epoch: [122][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.6274 (0.5877)\tPrec@1 95.000 (89.980)\n",
            "Total time : 39.948\n",
            "Train Loss: 0.5877, Train Accuracy: 0.8998\n",
            "Test Loss : 0.8517, Test Accuracy : 0.7540 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.236 (0.236)\tData 0.137 (0.137)\tLoss 0.5246 (0.5246)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [123][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.5166 (0.5469)\tPrec@1 90.625 (90.857)\n",
            "Epoch: [123][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.5770 (0.5604)\tPrec@1 92.188 (90.419)\n",
            "Epoch: [123][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.5938 (0.5681)\tPrec@1 89.062 (90.269)\n",
            "Epoch: [123][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.7853 (0.5788)\tPrec@1 85.000 (90.090)\n",
            "Total time : 40.003\n",
            "Train Loss: 0.5788, Train Accuracy: 0.9009\n",
            "Test Loss : 0.8423, Test Accuracy : 0.7580 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.243 (0.243)\tData 0.141 (0.141)\tLoss 0.4426 (0.4426)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [124][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5503 (0.5371)\tPrec@1 88.281 (91.027)\n",
            "Epoch: [124][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.5561 (0.5499)\tPrec@1 87.500 (90.819)\n",
            "Epoch: [124][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.7326 (0.5558)\tPrec@1 92.188 (90.664)\n",
            "Epoch: [124][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.7132 (0.5641)\tPrec@1 86.250 (90.450)\n",
            "Total time : 40.009\n",
            "Train Loss: 0.5641, Train Accuracy: 0.9045\n",
            "Test Loss : 0.8336, Test Accuracy : 0.7555 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.4758 (0.4758)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [125][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.4763 (0.5287)\tPrec@1 93.750 (91.252)\n",
            "Epoch: [125][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.5223 (0.5442)\tPrec@1 92.969 (91.080)\n",
            "Epoch: [125][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.6516 (0.5547)\tPrec@1 85.156 (90.750)\n",
            "Epoch: [125][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.5294 (0.5612)\tPrec@1 90.000 (90.562)\n",
            "Total time : 39.967\n",
            "Train Loss: 0.5612, Train Accuracy: 0.9056\n",
            "Test Loss : 0.8410, Test Accuracy : 0.7524 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.242 (0.242)\tData 0.138 (0.138)\tLoss 0.4494 (0.4494)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [126][100/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.6532 (0.5169)\tPrec@1 90.625 (91.940)\n",
            "Epoch: [126][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.5755 (0.5274)\tPrec@1 90.625 (91.437)\n",
            "Epoch: [126][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.6003 (0.5388)\tPrec@1 86.719 (91.144)\n",
            "Epoch: [126][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.7862 (0.5457)\tPrec@1 87.500 (90.972)\n",
            "Total time : 40.154\n",
            "Train Loss: 0.5457, Train Accuracy: 0.9097\n",
            "Test Loss : 0.8328, Test Accuracy : 0.7581 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.4836 (0.4836)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [127][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.3599 (0.5032)\tPrec@1 93.750 (92.102)\n",
            "Epoch: [127][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.4548 (0.5170)\tPrec@1 90.625 (91.562)\n",
            "Epoch: [127][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6483 (0.5300)\tPrec@1 86.719 (91.321)\n",
            "Epoch: [127][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.6539 (0.5378)\tPrec@1 92.500 (91.132)\n",
            "Total time : 40.146\n",
            "Train Loss: 0.5378, Train Accuracy: 0.9113\n",
            "Test Loss : 0.8198, Test Accuracy : 0.7596 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.239 (0.239)\tData 0.141 (0.141)\tLoss 0.5537 (0.5537)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [128][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4697 (0.5008)\tPrec@1 92.188 (92.242)\n",
            "Epoch: [128][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.5539 (0.5140)\tPrec@1 92.188 (91.857)\n",
            "Epoch: [128][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.5795 (0.5213)\tPrec@1 88.281 (91.598)\n",
            "Epoch: [128][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.5671 (0.5312)\tPrec@1 90.000 (91.374)\n",
            "Total time : 40.182\n",
            "Train Loss: 0.5312, Train Accuracy: 0.9137\n",
            "Test Loss : 0.8214, Test Accuracy : 0.7639 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.255 (0.255)\tData 0.158 (0.158)\tLoss 0.4684 (0.4684)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [129][100/391]\tTime 0.104 (0.104)\tData 0.000 (0.002)\tLoss 0.5345 (0.4872)\tPrec@1 89.062 (92.443)\n",
            "Epoch: [129][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.5193 (0.5006)\tPrec@1 92.969 (92.055)\n",
            "Epoch: [129][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.5592 (0.5119)\tPrec@1 87.500 (91.725)\n",
            "Epoch: [129][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.4947 (0.5232)\tPrec@1 91.250 (91.382)\n",
            "Total time : 40.127\n",
            "Train Loss: 0.5232, Train Accuracy: 0.9138\n",
            "Test Loss : 0.8266, Test Accuracy : 0.7591 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.238 (0.238)\tData 0.138 (0.138)\tLoss 0.4596 (0.4596)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [130][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.4451 (0.4852)\tPrec@1 94.531 (92.365)\n",
            "Epoch: [130][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.4268 (0.4887)\tPrec@1 94.531 (92.242)\n",
            "Epoch: [130][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.5078 (0.5049)\tPrec@1 90.625 (91.879)\n",
            "Epoch: [130][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.5403 (0.5136)\tPrec@1 92.500 (91.614)\n",
            "Total time : 40.130\n",
            "Train Loss: 0.5136, Train Accuracy: 0.9161\n",
            "Test Loss : 0.8114, Test Accuracy : 0.7627 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.239 (0.239)\tData 0.142 (0.142)\tLoss 0.3706 (0.3706)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [131][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.4131 (0.4717)\tPrec@1 95.312 (92.752)\n",
            "Epoch: [131][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.5410 (0.4763)\tPrec@1 92.969 (92.596)\n",
            "Epoch: [131][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.4357 (0.4852)\tPrec@1 96.094 (92.320)\n",
            "Epoch: [131][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.4677 (0.4932)\tPrec@1 96.250 (92.148)\n",
            "Total time : 40.112\n",
            "Train Loss: 0.4932, Train Accuracy: 0.9215\n",
            "Test Loss : 0.8060, Test Accuracy : 0.7635 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.241 (0.241)\tData 0.142 (0.142)\tLoss 0.4451 (0.4451)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [132][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.4859 (0.4719)\tPrec@1 92.969 (92.860)\n",
            "Epoch: [132][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.5175 (0.4776)\tPrec@1 91.406 (92.681)\n",
            "Epoch: [132][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.6597 (0.4832)\tPrec@1 84.375 (92.442)\n",
            "Epoch: [132][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.5252 (0.4898)\tPrec@1 92.500 (92.280)\n",
            "Total time : 40.137\n",
            "Train Loss: 0.4898, Train Accuracy: 0.9228\n",
            "Test Loss : 0.8054, Test Accuracy : 0.7640 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.238 (0.238)\tData 0.140 (0.140)\tLoss 0.4336 (0.4336)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [133][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.5454 (0.4664)\tPrec@1 90.625 (92.876)\n",
            "Epoch: [133][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.4647 (0.4681)\tPrec@1 92.188 (92.798)\n",
            "Epoch: [133][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.4717 (0.4760)\tPrec@1 94.531 (92.564)\n",
            "Epoch: [133][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.4822 (0.4806)\tPrec@1 91.250 (92.382)\n",
            "Total time : 40.078\n",
            "Train Loss: 0.4806, Train Accuracy: 0.9238\n",
            "Test Loss : 0.8201, Test Accuracy : 0.7620 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.240 (0.240)\tData 0.140 (0.140)\tLoss 0.3724 (0.3724)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [134][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.3457 (0.4406)\tPrec@1 95.312 (93.325)\n",
            "Epoch: [134][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.4826 (0.4554)\tPrec@1 90.625 (92.907)\n",
            "Epoch: [134][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.4060 (0.4629)\tPrec@1 93.750 (92.714)\n",
            "Epoch: [134][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.7406 (0.4681)\tPrec@1 86.250 (92.592)\n",
            "Total time : 39.985\n",
            "Train Loss: 0.4681, Train Accuracy: 0.9259\n",
            "Test Loss : 0.8041, Test Accuracy : 0.7653 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.236 (0.236)\tData 0.137 (0.137)\tLoss 0.4369 (0.4369)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [135][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4410 (0.4254)\tPrec@1 96.094 (93.665)\n",
            "Epoch: [135][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.4395 (0.4380)\tPrec@1 93.750 (93.610)\n",
            "Epoch: [135][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.4390 (0.4464)\tPrec@1 93.750 (93.322)\n",
            "Epoch: [135][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.5933 (0.4563)\tPrec@1 92.500 (93.094)\n",
            "Total time : 39.965\n",
            "Train Loss: 0.4563, Train Accuracy: 0.9309\n",
            "Test Loss : 0.7891, Test Accuracy : 0.7684 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.242 (0.242)\tData 0.142 (0.142)\tLoss 0.4010 (0.4010)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [136][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5048 (0.4254)\tPrec@1 90.625 (93.881)\n",
            "Epoch: [136][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.3684 (0.4340)\tPrec@1 95.312 (93.606)\n",
            "Epoch: [136][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.4571 (0.4378)\tPrec@1 91.406 (93.444)\n",
            "Epoch: [136][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.5712 (0.4464)\tPrec@1 95.000 (93.200)\n",
            "Total time : 40.019\n",
            "Train Loss: 0.4464, Train Accuracy: 0.9320\n",
            "Test Loss : 0.7828, Test Accuracy : 0.7708 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.235 (0.235)\tData 0.136 (0.136)\tLoss 0.3438 (0.3438)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [137][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.3589 (0.4169)\tPrec@1 93.750 (94.075)\n",
            "Epoch: [137][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.5026 (0.4209)\tPrec@1 90.625 (93.863)\n",
            "Epoch: [137][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.5152 (0.4332)\tPrec@1 90.625 (93.522)\n",
            "Epoch: [137][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.5361 (0.4386)\tPrec@1 91.250 (93.374)\n",
            "Total time : 40.026\n",
            "Train Loss: 0.4386, Train Accuracy: 0.9337\n",
            "Test Loss : 0.7768, Test Accuracy : 0.7724 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.241 (0.241)\tData 0.142 (0.142)\tLoss 0.4484 (0.4484)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [138][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.4120 (0.4053)\tPrec@1 96.094 (94.214)\n",
            "Epoch: [138][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.5684 (0.4164)\tPrec@1 89.844 (93.921)\n",
            "Epoch: [138][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.4607 (0.4242)\tPrec@1 91.406 (93.701)\n",
            "Epoch: [138][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.4243 (0.4298)\tPrec@1 93.750 (93.520)\n",
            "Total time : 39.996\n",
            "Train Loss: 0.4298, Train Accuracy: 0.9352\n",
            "Test Loss : 0.7812, Test Accuracy : 0.7721 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.239 (0.239)\tData 0.139 (0.139)\tLoss 0.4354 (0.4354)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [139][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.3986 (0.3942)\tPrec@1 92.188 (94.477)\n",
            "Epoch: [139][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.3981 (0.4019)\tPrec@1 93.750 (94.251)\n",
            "Epoch: [139][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.3891 (0.4106)\tPrec@1 91.406 (94.002)\n",
            "Epoch: [139][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.4431 (0.4174)\tPrec@1 92.500 (93.828)\n",
            "Total time : 39.996\n",
            "Train Loss: 0.4174, Train Accuracy: 0.9383\n",
            "Test Loss : 0.7817, Test Accuracy : 0.7738 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.238 (0.238)\tData 0.140 (0.140)\tLoss 0.3335 (0.3335)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [140][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.2858 (0.3834)\tPrec@1 97.656 (94.640)\n",
            "Epoch: [140][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.2963 (0.3889)\tPrec@1 96.875 (94.391)\n",
            "Epoch: [140][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.4087 (0.3986)\tPrec@1 95.312 (94.103)\n",
            "Epoch: [140][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.5790 (0.4080)\tPrec@1 93.750 (93.862)\n",
            "Total time : 39.986\n",
            "Train Loss: 0.4080, Train Accuracy: 0.9386\n",
            "Test Loss : 0.7654, Test Accuracy : 0.7785 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.251 (0.251)\tData 0.149 (0.149)\tLoss 0.3545 (0.3545)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [141][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.3776 (0.3755)\tPrec@1 97.656 (95.034)\n",
            "Epoch: [141][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.3720 (0.3838)\tPrec@1 96.094 (94.617)\n",
            "Epoch: [141][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.4036 (0.3880)\tPrec@1 93.750 (94.510)\n",
            "Epoch: [141][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.2566 (0.3953)\tPrec@1 100.000 (94.274)\n",
            "Total time : 40.121\n",
            "Train Loss: 0.3953, Train Accuracy: 0.9427\n",
            "Test Loss : 0.7574, Test Accuracy : 0.7792 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 0.3901 (0.3901)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [142][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.3821 (0.3664)\tPrec@1 92.188 (95.042)\n",
            "Epoch: [142][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.3141 (0.3762)\tPrec@1 92.188 (94.780)\n",
            "Epoch: [142][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.3736 (0.3808)\tPrec@1 95.312 (94.591)\n",
            "Epoch: [142][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.3765 (0.3881)\tPrec@1 96.250 (94.416)\n",
            "Total time : 40.122\n",
            "Train Loss: 0.3881, Train Accuracy: 0.9442\n",
            "Test Loss : 0.7529, Test Accuracy : 0.7793 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.3533 (0.3533)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [143][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4114 (0.3498)\tPrec@1 95.312 (95.421)\n",
            "Epoch: [143][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.3685 (0.3623)\tPrec@1 94.531 (95.068)\n",
            "Epoch: [143][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.4464 (0.3709)\tPrec@1 92.969 (94.765)\n",
            "Epoch: [143][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.3520 (0.3787)\tPrec@1 93.750 (94.568)\n",
            "Total time : 40.141\n",
            "Train Loss: 0.3787, Train Accuracy: 0.9457\n",
            "Test Loss : 0.7436, Test Accuracy : 0.7800 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.2811 (0.2811)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [144][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.3441 (0.3544)\tPrec@1 95.312 (94.957)\n",
            "Epoch: [144][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.4080 (0.3572)\tPrec@1 92.969 (94.998)\n",
            "Epoch: [144][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.2668 (0.3638)\tPrec@1 96.875 (94.804)\n",
            "Epoch: [144][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.2717 (0.3696)\tPrec@1 96.250 (94.724)\n",
            "Total time : 39.969\n",
            "Train Loss: 0.3696, Train Accuracy: 0.9472\n",
            "Test Loss : 0.7516, Test Accuracy : 0.7807 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.242 (0.242)\tData 0.141 (0.141)\tLoss 0.3884 (0.3884)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [145][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.3430 (0.3358)\tPrec@1 95.312 (95.405)\n",
            "Epoch: [145][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.3115 (0.3435)\tPrec@1 94.531 (95.281)\n",
            "Epoch: [145][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.2783 (0.3502)\tPrec@1 98.438 (95.222)\n",
            "Epoch: [145][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.4513 (0.3552)\tPrec@1 92.500 (95.064)\n",
            "Total time : 40.178\n",
            "Train Loss: 0.3552, Train Accuracy: 0.9506\n",
            "Test Loss : 0.7431, Test Accuracy : 0.7821 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.243 (0.243)\tData 0.140 (0.140)\tLoss 0.2808 (0.2808)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [146][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.3161 (0.3298)\tPrec@1 97.656 (95.808)\n",
            "Epoch: [146][200/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.2842 (0.3358)\tPrec@1 96.875 (95.569)\n",
            "Epoch: [146][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.2674 (0.3450)\tPrec@1 97.656 (95.302)\n",
            "Epoch: [146][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.3691 (0.3493)\tPrec@1 98.750 (95.228)\n",
            "Total time : 39.869\n",
            "Train Loss: 0.3493, Train Accuracy: 0.9523\n",
            "Test Loss : 0.7624, Test Accuracy : 0.7764 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.234 (0.234)\tData 0.136 (0.136)\tLoss 0.2822 (0.2822)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [147][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.3935 (0.3212)\tPrec@1 93.750 (95.962)\n",
            "Epoch: [147][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.3751 (0.3281)\tPrec@1 94.531 (95.651)\n",
            "Epoch: [147][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.4075 (0.3355)\tPrec@1 93.750 (95.484)\n",
            "Epoch: [147][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.5117 (0.3386)\tPrec@1 92.500 (95.448)\n",
            "Total time : 39.931\n",
            "Train Loss: 0.3386, Train Accuracy: 0.9545\n",
            "Test Loss : 0.7366, Test Accuracy : 0.7858 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.243 (0.243)\tData 0.141 (0.141)\tLoss 0.2605 (0.2605)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [148][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.4030 (0.3213)\tPrec@1 92.188 (95.908)\n",
            "Epoch: [148][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.3043 (0.3211)\tPrec@1 96.094 (95.861)\n",
            "Epoch: [148][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.2964 (0.3249)\tPrec@1 95.312 (95.728)\n",
            "Epoch: [148][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.3561 (0.3304)\tPrec@1 96.250 (95.606)\n",
            "Total time : 40.153\n",
            "Train Loss: 0.3304, Train Accuracy: 0.9561\n",
            "Test Loss : 0.7372, Test Accuracy : 0.7849 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 0.2812 (0.2812)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [149][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.3527 (0.2957)\tPrec@1 94.531 (96.241)\n",
            "Epoch: [149][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.3869 (0.3088)\tPrec@1 92.969 (95.993)\n",
            "Epoch: [149][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.3622 (0.3143)\tPrec@1 93.750 (95.858)\n",
            "Epoch: [149][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.3408 (0.3191)\tPrec@1 96.250 (95.802)\n",
            "Total time : 40.151\n",
            "Train Loss: 0.3191, Train Accuracy: 0.9580\n",
            "Test Loss : 0.7412, Test Accuracy : 0.7834 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.240 (0.240)\tData 0.140 (0.140)\tLoss 0.2314 (0.2314)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [150][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.3352 (0.2911)\tPrec@1 93.750 (96.279)\n",
            "Epoch: [150][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.3094 (0.3021)\tPrec@1 95.312 (95.969)\n",
            "Epoch: [150][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.3537 (0.3048)\tPrec@1 95.312 (95.993)\n",
            "Epoch: [150][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.2917 (0.3088)\tPrec@1 97.500 (95.938)\n",
            "Total time : 40.150\n",
            "Train Loss: 0.3088, Train Accuracy: 0.9594\n",
            "Test Loss : 0.7376, Test Accuracy : 0.7865 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.3075 (0.3075)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [151][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2955 (0.2832)\tPrec@1 96.094 (96.542)\n",
            "Epoch: [151][200/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.3057 (0.2887)\tPrec@1 96.875 (96.432)\n",
            "Epoch: [151][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.3590 (0.2924)\tPrec@1 94.531 (96.330)\n",
            "Epoch: [151][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.3854 (0.2972)\tPrec@1 96.250 (96.224)\n",
            "Total time : 39.916\n",
            "Train Loss: 0.2972, Train Accuracy: 0.9622\n",
            "Test Loss : 0.7296, Test Accuracy : 0.7865 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.238 (0.238)\tData 0.138 (0.138)\tLoss 0.3061 (0.3061)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [152][100/391]\tTime 0.105 (0.103)\tData 0.000 (0.002)\tLoss 0.1932 (0.2791)\tPrec@1 99.219 (96.542)\n",
            "Epoch: [152][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.3003 (0.2814)\tPrec@1 93.750 (96.440)\n",
            "Epoch: [152][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.3509 (0.2886)\tPrec@1 96.875 (96.252)\n",
            "Epoch: [152][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.3110 (0.2903)\tPrec@1 97.500 (96.270)\n",
            "Total time : 40.007\n",
            "Train Loss: 0.2903, Train Accuracy: 0.9627\n",
            "Test Loss : 0.7230, Test Accuracy : 0.7848 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.2089 (0.2089)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [153][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.2797 (0.2619)\tPrec@1 96.875 (96.921)\n",
            "Epoch: [153][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.3463 (0.2682)\tPrec@1 95.312 (96.755)\n",
            "Epoch: [153][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.2388 (0.2790)\tPrec@1 99.219 (96.499)\n",
            "Epoch: [153][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.3283 (0.2808)\tPrec@1 96.250 (96.434)\n",
            "Total time : 40.128\n",
            "Train Loss: 0.2808, Train Accuracy: 0.9643\n",
            "Test Loss : 0.7179, Test Accuracy : 0.7893 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 0.2573 (0.2573)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [154][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.2480 (0.2550)\tPrec@1 98.438 (97.068)\n",
            "Epoch: [154][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.2513 (0.2636)\tPrec@1 99.219 (96.743)\n",
            "Epoch: [154][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.3211 (0.2672)\tPrec@1 92.188 (96.657)\n",
            "Epoch: [154][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.2577 (0.2721)\tPrec@1 97.500 (96.592)\n",
            "Total time : 40.144\n",
            "Train Loss: 0.2721, Train Accuracy: 0.9659\n",
            "Test Loss : 0.7325, Test Accuracy : 0.7885 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.241 (0.241)\tData 0.139 (0.139)\tLoss 0.3139 (0.3139)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [155][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.2382 (0.2525)\tPrec@1 96.094 (97.084)\n",
            "Epoch: [155][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.3020 (0.2570)\tPrec@1 97.656 (96.797)\n",
            "Epoch: [155][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.2800 (0.2575)\tPrec@1 96.875 (96.750)\n",
            "Epoch: [155][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.3339 (0.2627)\tPrec@1 96.250 (96.674)\n",
            "Total time : 40.011\n",
            "Train Loss: 0.2627, Train Accuracy: 0.9667\n",
            "Test Loss : 0.7155, Test Accuracy : 0.7927 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.240 (0.240)\tData 0.140 (0.140)\tLoss 0.3287 (0.3287)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [156][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1963 (0.2434)\tPrec@1 97.656 (97.076)\n",
            "Epoch: [156][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.2517 (0.2499)\tPrec@1 94.531 (96.964)\n",
            "Epoch: [156][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.2988 (0.2531)\tPrec@1 96.094 (96.968)\n",
            "Epoch: [156][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.3219 (0.2563)\tPrec@1 95.000 (96.894)\n",
            "Total time : 39.964\n",
            "Train Loss: 0.2563, Train Accuracy: 0.9689\n",
            "Test Loss : 0.7156, Test Accuracy : 0.7913 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.240 (0.240)\tData 0.139 (0.139)\tLoss 0.1926 (0.1926)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [157][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.2420 (0.2346)\tPrec@1 99.219 (97.277)\n",
            "Epoch: [157][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.3128 (0.2411)\tPrec@1 95.312 (97.054)\n",
            "Epoch: [157][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.2060 (0.2436)\tPrec@1 98.438 (97.036)\n",
            "Epoch: [157][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.2745 (0.2484)\tPrec@1 95.000 (96.954)\n",
            "Total time : 39.987\n",
            "Train Loss: 0.2484, Train Accuracy: 0.9695\n",
            "Test Loss : 0.7059, Test Accuracy : 0.7944 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.242 (0.242)\tData 0.139 (0.139)\tLoss 0.3130 (0.3130)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [158][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.2688 (0.2333)\tPrec@1 96.875 (97.347)\n",
            "Epoch: [158][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.2082 (0.2331)\tPrec@1 97.656 (97.299)\n",
            "Epoch: [158][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.1981 (0.2401)\tPrec@1 98.438 (97.129)\n",
            "Epoch: [158][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.2636 (0.2421)\tPrec@1 96.250 (97.124)\n",
            "Total time : 39.961\n",
            "Train Loss: 0.2421, Train Accuracy: 0.9712\n",
            "Test Loss : 0.7147, Test Accuracy : 0.7912 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 0.2167 (0.2167)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [159][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.2284 (0.2191)\tPrec@1 96.875 (97.486)\n",
            "Epoch: [159][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.2589 (0.2221)\tPrec@1 96.875 (97.419)\n",
            "Epoch: [159][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.2492 (0.2255)\tPrec@1 96.875 (97.350)\n",
            "Epoch: [159][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.2709 (0.2281)\tPrec@1 96.250 (97.276)\n",
            "Total time : 39.972\n",
            "Train Loss: 0.2281, Train Accuracy: 0.9728\n",
            "Test Loss : 0.7052, Test Accuracy : 0.7915 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.243 (0.243)\tData 0.139 (0.139)\tLoss 0.1621 (0.1621)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [160][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.2374 (0.2092)\tPrec@1 96.094 (97.618)\n",
            "Epoch: [160][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.2086 (0.2141)\tPrec@1 98.438 (97.485)\n",
            "Epoch: [160][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.1874 (0.2166)\tPrec@1 96.875 (97.511)\n",
            "Epoch: [160][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.2066 (0.2205)\tPrec@1 98.750 (97.398)\n",
            "Total time : 39.997\n",
            "Train Loss: 0.2205, Train Accuracy: 0.9740\n",
            "Test Loss : 0.7034, Test Accuracy : 0.7927 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.243 (0.243)\tData 0.145 (0.145)\tLoss 0.2223 (0.2223)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [161][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2104 (0.2078)\tPrec@1 96.094 (97.633)\n",
            "Epoch: [161][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.2062 (0.2092)\tPrec@1 99.219 (97.571)\n",
            "Epoch: [161][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.2262 (0.2111)\tPrec@1 97.656 (97.537)\n",
            "Epoch: [161][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.2087 (0.2114)\tPrec@1 98.750 (97.550)\n",
            "Total time : 39.972\n",
            "Train Loss: 0.2114, Train Accuracy: 0.9755\n",
            "Test Loss : 0.6927, Test Accuracy : 0.7963 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.242 (0.242)\tData 0.140 (0.140)\tLoss 0.2074 (0.2074)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [162][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.2639 (0.2029)\tPrec@1 96.875 (97.679)\n",
            "Epoch: [162][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1918 (0.2045)\tPrec@1 98.438 (97.683)\n",
            "Epoch: [162][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.1875 (0.2051)\tPrec@1 99.219 (97.682)\n",
            "Epoch: [162][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.1838 (0.2065)\tPrec@1 98.750 (97.644)\n",
            "Total time : 39.973\n",
            "Train Loss: 0.2065, Train Accuracy: 0.9764\n",
            "Test Loss : 0.7005, Test Accuracy : 0.7955 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.235 (0.235)\tData 0.137 (0.137)\tLoss 0.1433 (0.1433)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [163][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1594 (0.1889)\tPrec@1 98.438 (97.942)\n",
            "Epoch: [163][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.2077 (0.1902)\tPrec@1 97.656 (97.948)\n",
            "Epoch: [163][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.2098 (0.1929)\tPrec@1 97.656 (97.835)\n",
            "Epoch: [163][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.2739 (0.1973)\tPrec@1 96.250 (97.748)\n",
            "Total time : 39.950\n",
            "Train Loss: 0.1973, Train Accuracy: 0.9775\n",
            "Test Loss : 0.7001, Test Accuracy : 0.7903 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 0.1378 (0.1378)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [164][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.2264 (0.1836)\tPrec@1 96.875 (97.873)\n",
            "Epoch: [164][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.2324 (0.1872)\tPrec@1 96.875 (97.854)\n",
            "Epoch: [164][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1430 (0.1896)\tPrec@1 98.438 (97.843)\n",
            "Epoch: [164][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.2162 (0.1901)\tPrec@1 97.500 (97.820)\n",
            "Total time : 40.154\n",
            "Train Loss: 0.1901, Train Accuracy: 0.9782\n",
            "Test Loss : 0.6959, Test Accuracy : 0.7981 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.1988 (0.1988)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [165][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.1171 (0.1734)\tPrec@1 100.000 (98.066)\n",
            "Epoch: [165][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1821 (0.1757)\tPrec@1 98.438 (98.064)\n",
            "Epoch: [165][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1217 (0.1791)\tPrec@1 98.438 (98.017)\n",
            "Epoch: [165][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.1339 (0.1811)\tPrec@1 100.000 (97.972)\n",
            "Total time : 40.139\n",
            "Train Loss: 0.1811, Train Accuracy: 0.9797\n",
            "Test Loss : 0.6865, Test Accuracy : 0.8002 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.248 (0.248)\tData 0.146 (0.146)\tLoss 0.1194 (0.1194)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [166][100/391]\tTime 0.105 (0.104)\tData 0.000 (0.002)\tLoss 0.1402 (0.1721)\tPrec@1 99.219 (98.089)\n",
            "Epoch: [166][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1785 (0.1730)\tPrec@1 97.656 (98.022)\n",
            "Epoch: [166][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1923 (0.1740)\tPrec@1 97.656 (98.048)\n",
            "Epoch: [166][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.2149 (0.1754)\tPrec@1 97.500 (98.020)\n",
            "Total time : 40.136\n",
            "Train Loss: 0.1754, Train Accuracy: 0.9802\n",
            "Test Loss : 0.6816, Test Accuracy : 0.8014 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.241 (0.241)\tData 0.143 (0.143)\tLoss 0.1725 (0.1725)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [167][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1551 (0.1722)\tPrec@1 98.438 (98.066)\n",
            "Epoch: [167][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1961 (0.1737)\tPrec@1 97.656 (98.037)\n",
            "Epoch: [167][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.2035 (0.1741)\tPrec@1 98.438 (98.035)\n",
            "Epoch: [167][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.1653 (0.1738)\tPrec@1 97.500 (98.024)\n",
            "Total time : 40.179\n",
            "Train Loss: 0.1738, Train Accuracy: 0.9802\n",
            "Test Loss : 0.6730, Test Accuracy : 0.8034 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.245 (0.245)\tData 0.148 (0.148)\tLoss 0.1377 (0.1377)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [168][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.1022 (0.1587)\tPrec@1 100.000 (98.182)\n",
            "Epoch: [168][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1181 (0.1586)\tPrec@1 99.219 (98.228)\n",
            "Epoch: [168][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1407 (0.1600)\tPrec@1 99.219 (98.178)\n",
            "Epoch: [168][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.2049 (0.1621)\tPrec@1 95.000 (98.162)\n",
            "Total time : 40.169\n",
            "Train Loss: 0.1621, Train Accuracy: 0.9816\n",
            "Test Loss : 0.6758, Test Accuracy : 0.8044 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.243 (0.243)\tData 0.140 (0.140)\tLoss 0.1389 (0.1389)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [169][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.1473 (0.1471)\tPrec@1 98.438 (98.538)\n",
            "Epoch: [169][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1542 (0.1519)\tPrec@1 98.438 (98.434)\n",
            "Epoch: [169][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1426 (0.1533)\tPrec@1 99.219 (98.386)\n",
            "Epoch: [169][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.1505 (0.1546)\tPrec@1 97.500 (98.348)\n",
            "Total time : 40.015\n",
            "Train Loss: 0.1546, Train Accuracy: 0.9835\n",
            "Test Loss : 0.6700, Test Accuracy : 0.8026 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.1045 (0.1045)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [170][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1428 (0.1414)\tPrec@1 98.438 (98.662)\n",
            "Epoch: [170][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.1485 (0.1495)\tPrec@1 97.656 (98.410)\n",
            "Epoch: [170][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.1204 (0.1499)\tPrec@1 99.219 (98.391)\n",
            "Epoch: [170][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.2311 (0.1502)\tPrec@1 97.500 (98.370)\n",
            "Total time : 39.981\n",
            "Train Loss: 0.1502, Train Accuracy: 0.9837\n",
            "Test Loss : 0.6685, Test Accuracy : 0.8067 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.239 (0.239)\tData 0.140 (0.140)\tLoss 0.1427 (0.1427)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [171][100/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.1194 (0.1428)\tPrec@1 98.438 (98.414)\n",
            "Epoch: [171][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1527 (0.1438)\tPrec@1 96.875 (98.476)\n",
            "Epoch: [171][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.1130 (0.1455)\tPrec@1 98.438 (98.419)\n",
            "Epoch: [171][390/391]\tTime 0.064 (0.102)\tData 0.000 (0.001)\tLoss 0.1330 (0.1472)\tPrec@1 98.750 (98.364)\n",
            "Total time : 39.981\n",
            "Train Loss: 0.1472, Train Accuracy: 0.9836\n",
            "Test Loss : 0.6694, Test Accuracy : 0.8054 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.236 (0.236)\tData 0.138 (0.138)\tLoss 0.1361 (0.1361)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [172][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.0970 (0.1377)\tPrec@1 99.219 (98.461)\n",
            "Epoch: [172][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1365 (0.1377)\tPrec@1 97.656 (98.472)\n",
            "Epoch: [172][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1087 (0.1402)\tPrec@1 96.875 (98.438)\n",
            "Epoch: [172][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.1002 (0.1409)\tPrec@1 100.000 (98.436)\n",
            "Total time : 40.146\n",
            "Train Loss: 0.1409, Train Accuracy: 0.9844\n",
            "Test Loss : 0.6543, Test Accuracy : 0.8076 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.235 (0.235)\tData 0.137 (0.137)\tLoss 0.1419 (0.1419)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [173][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1492 (0.1343)\tPrec@1 98.438 (98.461)\n",
            "Epoch: [173][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1585 (0.1385)\tPrec@1 98.438 (98.368)\n",
            "Epoch: [173][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1478 (0.1407)\tPrec@1 96.875 (98.373)\n",
            "Epoch: [173][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.1699 (0.1409)\tPrec@1 98.750 (98.380)\n",
            "Total time : 40.164\n",
            "Train Loss: 0.1409, Train Accuracy: 0.9838\n",
            "Test Loss : 0.6599, Test Accuracy : 0.8070 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.241 (0.241)\tData 0.143 (0.143)\tLoss 0.0756 (0.0756)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [174][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1337 (0.1266)\tPrec@1 98.438 (98.577)\n",
            "Epoch: [174][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1699 (0.1304)\tPrec@1 96.875 (98.554)\n",
            "Epoch: [174][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0929 (0.1313)\tPrec@1 100.000 (98.547)\n",
            "Epoch: [174][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.1393 (0.1324)\tPrec@1 98.750 (98.536)\n",
            "Total time : 40.170\n",
            "Train Loss: 0.1324, Train Accuracy: 0.9854\n",
            "Test Loss : 0.6668, Test Accuracy : 0.8053 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.249 (0.249)\tData 0.152 (0.152)\tLoss 0.0810 (0.0810)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [175][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1131 (0.1287)\tPrec@1 99.219 (98.608)\n",
            "Epoch: [175][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1157 (0.1291)\tPrec@1 98.438 (98.570)\n",
            "Epoch: [175][300/391]\tTime 0.100 (0.102)\tData 0.000 (0.001)\tLoss 0.1386 (0.1281)\tPrec@1 98.438 (98.614)\n",
            "Epoch: [175][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.1837 (0.1271)\tPrec@1 97.500 (98.646)\n",
            "Total time : 39.979\n",
            "Train Loss: 0.1271, Train Accuracy: 0.9865\n",
            "Test Loss : 0.6566, Test Accuracy : 0.8115 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.241 (0.241)\tData 0.144 (0.144)\tLoss 0.1065 (0.1065)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [176][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1445 (0.1221)\tPrec@1 98.438 (98.608)\n",
            "Epoch: [176][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1346 (0.1231)\tPrec@1 98.438 (98.620)\n",
            "Epoch: [176][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1296 (0.1243)\tPrec@1 99.219 (98.585)\n",
            "Epoch: [176][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.1806 (0.1246)\tPrec@1 97.500 (98.582)\n",
            "Total time : 40.025\n",
            "Train Loss: 0.1246, Train Accuracy: 0.9858\n",
            "Test Loss : 0.6536, Test Accuracy : 0.8108 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.240 (0.240)\tData 0.141 (0.141)\tLoss 0.1270 (0.1270)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [177][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.1287 (0.1191)\tPrec@1 97.656 (98.809)\n",
            "Epoch: [177][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1371 (0.1175)\tPrec@1 97.656 (98.737)\n",
            "Epoch: [177][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.1257 (0.1191)\tPrec@1 100.000 (98.720)\n",
            "Epoch: [177][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.1580 (0.1203)\tPrec@1 96.250 (98.688)\n",
            "Total time : 39.999\n",
            "Train Loss: 0.1203, Train Accuracy: 0.9869\n",
            "Test Loss : 0.6522, Test Accuracy : 0.8090 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.246 (0.246)\tData 0.143 (0.143)\tLoss 0.1043 (0.1043)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [178][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1296 (0.1151)\tPrec@1 98.438 (98.755)\n",
            "Epoch: [178][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.0856 (0.1141)\tPrec@1 99.219 (98.787)\n",
            "Epoch: [178][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.1138 (0.1152)\tPrec@1 99.219 (98.749)\n",
            "Epoch: [178][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.0948 (0.1152)\tPrec@1 98.750 (98.746)\n",
            "Total time : 39.995\n",
            "Train Loss: 0.1152, Train Accuracy: 0.9875\n",
            "Test Loss : 0.6560, Test Accuracy : 0.8098 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.235 (0.235)\tData 0.138 (0.138)\tLoss 0.0816 (0.0816)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [179][100/391]\tTime 0.105 (0.103)\tData 0.000 (0.002)\tLoss 0.1113 (0.1156)\tPrec@1 99.219 (98.747)\n",
            "Epoch: [179][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.1059 (0.1132)\tPrec@1 99.219 (98.780)\n",
            "Epoch: [179][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.1164 (0.1145)\tPrec@1 98.438 (98.694)\n",
            "Epoch: [179][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.2177 (0.1131)\tPrec@1 97.500 (98.730)\n",
            "Total time : 39.970\n",
            "Train Loss: 0.1131, Train Accuracy: 0.9873\n",
            "Test Loss : 0.6449, Test Accuracy : 0.8127 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.239 (0.239)\tData 0.141 (0.141)\tLoss 0.0981 (0.0981)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [180][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.0876 (0.1114)\tPrec@1 100.000 (98.762)\n",
            "Epoch: [180][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.0620 (0.1118)\tPrec@1 99.219 (98.706)\n",
            "Epoch: [180][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.1221 (0.1114)\tPrec@1 99.219 (98.741)\n",
            "Epoch: [180][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.0752 (0.1116)\tPrec@1 100.000 (98.748)\n",
            "Total time : 40.158\n",
            "Train Loss: 0.1116, Train Accuracy: 0.9875\n",
            "Test Loss : 0.6476, Test Accuracy : 0.8114 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.234 (0.234)\tData 0.135 (0.135)\tLoss 0.0875 (0.0875)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [181][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.0902 (0.1023)\tPrec@1 99.219 (98.956)\n",
            "Epoch: [181][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1096 (0.1034)\tPrec@1 99.219 (98.927)\n",
            "Epoch: [181][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1253 (0.1065)\tPrec@1 97.656 (98.845)\n",
            "Epoch: [181][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.0984 (0.1060)\tPrec@1 100.000 (98.854)\n",
            "Total time : 40.149\n",
            "Train Loss: 0.1060, Train Accuracy: 0.9885\n",
            "Test Loss : 0.6441, Test Accuracy : 0.8136 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.248 (0.248)\tData 0.145 (0.145)\tLoss 0.0522 (0.0522)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [182][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.0655 (0.0993)\tPrec@1 99.219 (98.871)\n",
            "Epoch: [182][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0685 (0.1020)\tPrec@1 100.000 (98.842)\n",
            "Epoch: [182][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1071 (0.1038)\tPrec@1 99.219 (98.803)\n",
            "Epoch: [182][390/391]\tTime 0.063 (0.103)\tData 0.000 (0.001)\tLoss 0.1099 (0.1043)\tPrec@1 98.750 (98.798)\n",
            "Total time : 40.195\n",
            "Train Loss: 0.1043, Train Accuracy: 0.9880\n",
            "Test Loss : 0.6400, Test Accuracy : 0.8129 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.242 (0.242)\tData 0.141 (0.141)\tLoss 0.0897 (0.0897)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [183][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1137 (0.1044)\tPrec@1 97.656 (98.762)\n",
            "Epoch: [183][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.0910 (0.1012)\tPrec@1 99.219 (98.873)\n",
            "Epoch: [183][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.0839 (0.1023)\tPrec@1 99.219 (98.798)\n",
            "Epoch: [183][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.1542 (0.1023)\tPrec@1 98.750 (98.820)\n",
            "Total time : 40.166\n",
            "Train Loss: 0.1023, Train Accuracy: 0.9882\n",
            "Test Loss : 0.6452, Test Accuracy : 0.8143 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.1235 (0.1235)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [184][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.0985 (0.0969)\tPrec@1 98.438 (98.933)\n",
            "Epoch: [184][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1026 (0.0973)\tPrec@1 99.219 (98.954)\n",
            "Epoch: [184][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0749 (0.0986)\tPrec@1 99.219 (98.946)\n",
            "Epoch: [184][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.0954 (0.0988)\tPrec@1 98.750 (98.920)\n",
            "Total time : 40.175\n",
            "Train Loss: 0.0988, Train Accuracy: 0.9892\n",
            "Test Loss : 0.6422, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.240 (0.240)\tData 0.139 (0.139)\tLoss 0.0966 (0.0966)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [185][100/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.0915 (0.0985)\tPrec@1 98.438 (98.909)\n",
            "Epoch: [185][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.1046 (0.0977)\tPrec@1 98.438 (98.908)\n",
            "Epoch: [185][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1485 (0.0980)\tPrec@1 97.656 (98.874)\n",
            "Epoch: [185][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.1477 (0.0977)\tPrec@1 98.750 (98.882)\n",
            "Total time : 40.180\n",
            "Train Loss: 0.0977, Train Accuracy: 0.9888\n",
            "Test Loss : 0.6401, Test Accuracy : 0.8151 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.236 (0.236)\tData 0.136 (0.136)\tLoss 0.1056 (0.1056)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [186][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.0856 (0.0988)\tPrec@1 99.219 (98.755)\n",
            "Epoch: [186][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.0966 (0.0965)\tPrec@1 99.219 (98.900)\n",
            "Epoch: [186][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1048 (0.0958)\tPrec@1 99.219 (98.910)\n",
            "Epoch: [186][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.1152 (0.0955)\tPrec@1 100.000 (98.932)\n",
            "Total time : 40.121\n",
            "Train Loss: 0.0955, Train Accuracy: 0.9893\n",
            "Test Loss : 0.6401, Test Accuracy : 0.8164 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.238 (0.238)\tData 0.141 (0.141)\tLoss 0.1025 (0.1025)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [187][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.0590 (0.0945)\tPrec@1 100.000 (98.940)\n",
            "Epoch: [187][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0981 (0.0955)\tPrec@1 98.438 (98.873)\n",
            "Epoch: [187][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0887 (0.0950)\tPrec@1 100.000 (98.858)\n",
            "Epoch: [187][390/391]\tTime 0.061 (0.103)\tData 0.000 (0.001)\tLoss 0.0740 (0.0951)\tPrec@1 100.000 (98.832)\n",
            "Total time : 40.168\n",
            "Train Loss: 0.0951, Train Accuracy: 0.9883\n",
            "Test Loss : 0.6406, Test Accuracy : 0.8157 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.238 (0.238)\tData 0.139 (0.139)\tLoss 0.0832 (0.0832)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [188][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.0717 (0.0976)\tPrec@1 99.219 (98.693)\n",
            "Epoch: [188][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1237 (0.0940)\tPrec@1 99.219 (98.869)\n",
            "Epoch: [188][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.0779 (0.0935)\tPrec@1 100.000 (98.900)\n",
            "Epoch: [188][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.1088 (0.0930)\tPrec@1 98.750 (98.918)\n",
            "Total time : 40.174\n",
            "Train Loss: 0.0930, Train Accuracy: 0.9892\n",
            "Test Loss : 0.6374, Test Accuracy : 0.8156 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.236 (0.236)\tData 0.137 (0.137)\tLoss 0.0807 (0.0807)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [189][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.1326 (0.0939)\tPrec@1 96.094 (98.778)\n",
            "Epoch: [189][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.001)\tLoss 0.0823 (0.0925)\tPrec@1 99.219 (98.857)\n",
            "Epoch: [189][300/391]\tTime 0.102 (0.102)\tData 0.000 (0.001)\tLoss 0.0823 (0.0907)\tPrec@1 99.219 (98.884)\n",
            "Epoch: [189][390/391]\tTime 0.060 (0.102)\tData 0.000 (0.001)\tLoss 0.0821 (0.0919)\tPrec@1 98.750 (98.882)\n",
            "Total time : 39.966\n",
            "Train Loss: 0.0919, Train Accuracy: 0.9888\n",
            "Test Loss : 0.6415, Test Accuracy : 0.8153 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.241 (0.241)\tData 0.141 (0.141)\tLoss 0.0703 (0.0703)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [190][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.0923 (0.0923)\tPrec@1 100.000 (98.987)\n",
            "Epoch: [190][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.1017 (0.0927)\tPrec@1 100.000 (98.954)\n",
            "Epoch: [190][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0979 (0.0918)\tPrec@1 98.438 (98.951)\n",
            "Epoch: [190][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.1034 (0.0925)\tPrec@1 98.750 (98.926)\n",
            "Total time : 40.034\n",
            "Train Loss: 0.0925, Train Accuracy: 0.9893\n",
            "Test Loss : 0.6375, Test Accuracy : 0.8156 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.0865 (0.0865)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [191][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.0831 (0.0892)\tPrec@1 100.000 (99.103)\n",
            "Epoch: [191][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.0777 (0.0895)\tPrec@1 99.219 (99.056)\n",
            "Epoch: [191][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1097 (0.0901)\tPrec@1 98.438 (98.998)\n",
            "Epoch: [191][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.1045 (0.0900)\tPrec@1 97.500 (98.996)\n",
            "Total time : 40.000\n",
            "Train Loss: 0.0900, Train Accuracy: 0.9900\n",
            "Test Loss : 0.6396, Test Accuracy : 0.8157 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.243 (0.243)\tData 0.142 (0.142)\tLoss 0.0698 (0.0698)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [192][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.0600 (0.0897)\tPrec@1 100.000 (99.041)\n",
            "Epoch: [192][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1095 (0.0902)\tPrec@1 99.219 (98.966)\n",
            "Epoch: [192][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1025 (0.0894)\tPrec@1 97.656 (98.985)\n",
            "Epoch: [192][390/391]\tTime 0.063 (0.102)\tData 0.000 (0.001)\tLoss 0.1106 (0.0896)\tPrec@1 97.500 (98.962)\n",
            "Total time : 40.005\n",
            "Train Loss: 0.0896, Train Accuracy: 0.9896\n",
            "Test Loss : 0.6368, Test Accuracy : 0.8152 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.0789 (0.0789)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [193][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.0911 (0.0894)\tPrec@1 99.219 (99.064)\n",
            "Epoch: [193][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.0996 (0.0899)\tPrec@1 98.438 (99.052)\n",
            "Epoch: [193][300/391]\tTime 0.103 (0.102)\tData 0.000 (0.001)\tLoss 0.0702 (0.0886)\tPrec@1 99.219 (99.034)\n",
            "Epoch: [193][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.1224 (0.0877)\tPrec@1 100.000 (99.040)\n",
            "Total time : 39.974\n",
            "Train Loss: 0.0877, Train Accuracy: 0.9904\n",
            "Test Loss : 0.6373, Test Accuracy : 0.8179 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.243 (0.243)\tData 0.144 (0.144)\tLoss 0.1505 (0.1505)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [194][100/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.1180 (0.0872)\tPrec@1 97.656 (98.948)\n",
            "Epoch: [194][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0884 (0.0869)\tPrec@1 99.219 (98.997)\n",
            "Epoch: [194][300/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1146 (0.0877)\tPrec@1 96.875 (98.959)\n",
            "Epoch: [194][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.1173 (0.0876)\tPrec@1 98.750 (98.972)\n",
            "Total time : 40.050\n",
            "Train Loss: 0.0876, Train Accuracy: 0.9897\n",
            "Test Loss : 0.6372, Test Accuracy : 0.8148 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.237 (0.237)\tData 0.138 (0.138)\tLoss 0.0771 (0.0771)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [195][100/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.0469 (0.0841)\tPrec@1 100.000 (99.118)\n",
            "Epoch: [195][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0586 (0.0826)\tPrec@1 100.000 (99.149)\n",
            "Epoch: [195][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0517 (0.0837)\tPrec@1 100.000 (99.102)\n",
            "Epoch: [195][390/391]\tTime 0.062 (0.103)\tData 0.000 (0.001)\tLoss 0.0902 (0.0839)\tPrec@1 98.750 (99.094)\n",
            "Total time : 40.153\n",
            "Train Loss: 0.0839, Train Accuracy: 0.9909\n",
            "Test Loss : 0.6363, Test Accuracy : 0.8178 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.0668 (0.0668)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [196][100/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.0854 (0.0890)\tPrec@1 98.438 (99.064)\n",
            "Epoch: [196][200/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.0884 (0.0897)\tPrec@1 97.656 (98.947)\n",
            "Epoch: [196][300/391]\tTime 0.101 (0.102)\tData 0.000 (0.001)\tLoss 0.1179 (0.0884)\tPrec@1 98.438 (98.996)\n",
            "Epoch: [196][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.0848 (0.0876)\tPrec@1 100.000 (99.014)\n",
            "Total time : 39.843\n",
            "Train Loss: 0.0876, Train Accuracy: 0.9901\n",
            "Test Loss : 0.6354, Test Accuracy : 0.8160 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.0920 (0.0920)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [197][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.0631 (0.0849)\tPrec@1 100.000 (99.149)\n",
            "Epoch: [197][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.001)\tLoss 0.0461 (0.0847)\tPrec@1 100.000 (99.125)\n",
            "Epoch: [197][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0897 (0.0865)\tPrec@1 98.438 (99.029)\n",
            "Epoch: [197][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.0502 (0.0867)\tPrec@1 98.750 (98.984)\n",
            "Total time : 40.037\n",
            "Train Loss: 0.0867, Train Accuracy: 0.9898\n",
            "Test Loss : 0.6386, Test Accuracy : 0.8162 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.237 (0.237)\tData 0.139 (0.139)\tLoss 0.0703 (0.0703)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [198][100/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.0703 (0.0862)\tPrec@1 99.219 (98.956)\n",
            "Epoch: [198][200/391]\tTime 0.103 (0.103)\tData 0.000 (0.001)\tLoss 0.1007 (0.0855)\tPrec@1 98.438 (99.028)\n",
            "Epoch: [198][300/391]\tTime 0.104 (0.102)\tData 0.000 (0.001)\tLoss 0.0938 (0.0867)\tPrec@1 100.000 (99.053)\n",
            "Epoch: [198][390/391]\tTime 0.062 (0.102)\tData 0.000 (0.001)\tLoss 0.0802 (0.0866)\tPrec@1 100.000 (99.054)\n",
            "Total time : 39.988\n",
            "Train Loss: 0.0866, Train Accuracy: 0.9905\n",
            "Test Loss : 0.6351, Test Accuracy : 0.8187 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.244 (0.244)\tData 0.141 (0.141)\tLoss 0.1201 (0.1201)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [199][100/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.0668 (0.0877)\tPrec@1 100.000 (98.963)\n",
            "Epoch: [199][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.001)\tLoss 0.1249 (0.0884)\tPrec@1 96.875 (98.954)\n",
            "Epoch: [199][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.001)\tLoss 0.0574 (0.0874)\tPrec@1 99.219 (98.975)\n",
            "Epoch: [199][390/391]\tTime 0.061 (0.102)\tData 0.000 (0.001)\tLoss 0.0893 (0.0881)\tPrec@1 100.000 (98.948)\n",
            "Total time : 40.021\n",
            "Train Loss: 0.0881, Train Accuracy: 0.9895\n",
            "Test Loss : 0.6354, Test Accuracy : 0.8177 \n",
            "\n",
            "train loss:  [4.077, 3.6577, 3.3381, 3.0684, 2.7631, 2.4757, 2.2545, 2.0945, 1.9673, 1.8685, 1.7989, 1.7359, 1.6892, 1.6378, 1.592, 1.5603, 1.5333, 1.5121, 1.4825, 1.4531, 1.4381, 1.4205, 1.4051, 1.3825, 1.3685, 1.3503, 1.3471, 1.325, 1.3204, 1.3047, 1.2968, 1.2762, 1.2813, 1.2619, 1.2587, 1.2442, 1.2386, 1.2327, 1.2202, 1.2082, 1.2024, 1.196, 1.1917, 1.177, 1.1818, 1.1601, 1.1545, 1.1571, 1.1487, 1.1379, 1.136, 1.1265, 1.1125, 1.1172, 1.0996, 1.0987, 1.0929, 1.0839, 1.0701, 1.0747, 1.0627, 1.0621, 1.0537, 1.0505, 1.0356, 1.0364, 1.0311, 1.0208, 1.0139, 0.9997, 0.9975, 0.9962, 0.9876, 0.9886, 0.9792, 0.9721, 0.9566, 0.9527, 0.9459, 0.9355, 0.9305, 0.9191, 0.9168, 0.9103, 0.8976, 0.8987, 0.8903, 0.8747, 0.8721, 0.8623, 0.8601, 0.8488, 0.8442, 0.8311, 0.8295, 0.8262, 0.8171, 0.8034, 0.7979, 0.7882, 0.7801, 0.7754, 0.7663, 0.7559, 0.7539, 0.741, 0.733, 0.7241, 0.7134, 0.7097, 0.6929, 0.6864, 0.6781, 0.6639, 0.6654, 0.6501, 0.6385, 0.6386, 0.6237, 0.6134, 0.6038, 0.5986, 0.5877, 0.5788, 0.5641, 0.5612, 0.5457, 0.5378, 0.5312, 0.5232, 0.5136, 0.4932, 0.4898, 0.4806, 0.4681, 0.4563, 0.4464, 0.4386, 0.4298, 0.4174, 0.408, 0.3953, 0.3881, 0.3787, 0.3696, 0.3552, 0.3493, 0.3386, 0.3304, 0.3191, 0.3088, 0.2972, 0.2903, 0.2808, 0.2721, 0.2627, 0.2563, 0.2484, 0.2421, 0.2281, 0.2205, 0.2114, 0.2065, 0.1973, 0.1901, 0.1811, 0.1754, 0.1738, 0.1621, 0.1546, 0.1502, 0.1472, 0.1409, 0.1409, 0.1324, 0.1271, 0.1246, 0.1203, 0.1152, 0.1131, 0.1116, 0.106, 0.1043, 0.1023, 0.0988, 0.0977, 0.0955, 0.0951, 0.093, 0.0919, 0.0925, 0.09, 0.0896, 0.0877, 0.0876, 0.0839, 0.0876, 0.0867, 0.0866, 0.0881]\n",
            "train err:  [0.9202, 0.8567, 0.7973, 0.741, 0.6772, 0.6081, 0.5536, 0.5136, 0.4781, 0.4525, 0.4332, 0.4173, 0.4011, 0.3857, 0.3737, 0.3641, 0.3546, 0.3491, 0.3421, 0.3321, 0.3253, 0.3228, 0.3187, 0.3139, 0.3087, 0.3015, 0.2998, 0.2954, 0.2923, 0.287, 0.2849, 0.2832, 0.284, 0.2762, 0.275, 0.2732, 0.268, 0.2668, 0.2646, 0.2596, 0.2572, 0.2581, 0.2551, 0.2518, 0.2526, 0.2456, 0.2444, 0.2446, 0.2429, 0.241, 0.2402, 0.2381, 0.2335, 0.2359, 0.231, 0.2303, 0.2268, 0.2271, 0.2225, 0.2249, 0.2215, 0.2217, 0.2176, 0.2173, 0.2107, 0.2152, 0.2122, 0.2092, 0.2081, 0.2045, 0.2033, 0.2041, 0.2004, 0.2018, 0.1989, 0.1964, 0.1932, 0.1933, 0.1901, 0.1884, 0.1879, 0.1846, 0.1819, 0.1815, 0.1777, 0.1773, 0.1755, 0.1742, 0.1713, 0.1699, 0.1692, 0.1649, 0.1659, 0.1619, 0.1598, 0.1602, 0.1588, 0.1549, 0.1524, 0.1501, 0.15, 0.1467, 0.1453, 0.1429, 0.1409, 0.1383, 0.1367, 0.1353, 0.1322, 0.1296, 0.1275, 0.1256, 0.1226, 0.1193, 0.1207, 0.1169, 0.1142, 0.1126, 0.1086, 0.1077, 0.104, 0.1029, 0.1002, 0.0991, 0.0955, 0.0944, 0.0903, 0.0887, 0.0863, 0.0862, 0.0839, 0.0785, 0.0772, 0.0762, 0.0741, 0.0691, 0.068, 0.0663, 0.0648, 0.0617, 0.0614, 0.0573, 0.0558, 0.0543, 0.0528, 0.0494, 0.0477, 0.0455, 0.0439, 0.042, 0.0406, 0.0378, 0.0373, 0.0357, 0.0341, 0.0333, 0.0311, 0.0305, 0.0288, 0.0272, 0.026, 0.0245, 0.0236, 0.0225, 0.0218, 0.0203, 0.0198, 0.0198, 0.0184, 0.0165, 0.0163, 0.0164, 0.0156, 0.0162, 0.0146, 0.0135, 0.0142, 0.0131, 0.0125, 0.0127, 0.0125, 0.0115, 0.012, 0.0118, 0.0108, 0.0112, 0.0107, 0.0117, 0.0108, 0.0112, 0.0107, 0.01, 0.0104, 0.0096, 0.0103, 0.0091, 0.0099, 0.0102, 0.0095, 0.0105]\n",
            "train acc:  [0.0798, 0.1433, 0.2027, 0.259, 0.3228, 0.3919, 0.4464, 0.4864, 0.5219, 0.5475, 0.5668, 0.5827, 0.5989, 0.6143, 0.6263, 0.6359, 0.6454, 0.6509, 0.6579, 0.6679, 0.6747, 0.6772, 0.6813, 0.6861, 0.6913, 0.6985, 0.7002, 0.7046, 0.7077, 0.713, 0.7151, 0.7168, 0.716, 0.7238, 0.725, 0.7268, 0.732, 0.7332, 0.7354, 0.7404, 0.7428, 0.7419, 0.7449, 0.7482, 0.7474, 0.7544, 0.7556, 0.7554, 0.7571, 0.759, 0.7598, 0.7619, 0.7665, 0.7641, 0.769, 0.7697, 0.7732, 0.7729, 0.7775, 0.7751, 0.7785, 0.7783, 0.7824, 0.7827, 0.7893, 0.7848, 0.7878, 0.7908, 0.7919, 0.7955, 0.7967, 0.7959, 0.7996, 0.7982, 0.8011, 0.8036, 0.8068, 0.8067, 0.8099, 0.8116, 0.8121, 0.8154, 0.8181, 0.8185, 0.8223, 0.8227, 0.8245, 0.8258, 0.8287, 0.8301, 0.8308, 0.8351, 0.8341, 0.8381, 0.8402, 0.8398, 0.8412, 0.8451, 0.8476, 0.8499, 0.85, 0.8533, 0.8547, 0.8571, 0.8591, 0.8617, 0.8633, 0.8647, 0.8678, 0.8704, 0.8725, 0.8744, 0.8774, 0.8807, 0.8793, 0.8831, 0.8858, 0.8874, 0.8914, 0.8923, 0.896, 0.8971, 0.8998, 0.9009, 0.9045, 0.9056, 0.9097, 0.9113, 0.9137, 0.9138, 0.9161, 0.9215, 0.9228, 0.9238, 0.9259, 0.9309, 0.932, 0.9337, 0.9352, 0.9383, 0.9386, 0.9427, 0.9442, 0.9457, 0.9472, 0.9506, 0.9523, 0.9545, 0.9561, 0.958, 0.9594, 0.9622, 0.9627, 0.9643, 0.9659, 0.9667, 0.9689, 0.9695, 0.9712, 0.9728, 0.974, 0.9755, 0.9764, 0.9775, 0.9782, 0.9797, 0.9802, 0.9802, 0.9816, 0.9835, 0.9837, 0.9836, 0.9844, 0.9838, 0.9854, 0.9865, 0.9858, 0.9869, 0.9875, 0.9873, 0.9875, 0.9885, 0.988, 0.9882, 0.9892, 0.9888, 0.9893, 0.9883, 0.9892, 0.9888, 0.9893, 0.99, 0.9896, 0.9904, 0.9897, 0.9909, 0.9901, 0.9898, 0.9905, 0.9895]\n",
            "test loss:  [3.7513, 3.3958, 3.0672, 2.826, 2.5129, 2.194, 2.0131, 1.9081, 1.8126, 1.7442, 1.6547, 1.6034, 1.6347, 1.5425, 1.5094, 1.49, 1.5029, 1.4488, 1.4253, 1.4268, 1.437, 1.3713, 1.4, 1.3373, 1.326, 1.3873, 1.3389, 1.3112, 1.3669, 1.2898, 1.2393, 1.2502, 1.2947, 1.314, 1.2589, 1.2599, 1.2983, 1.2173, 1.3029, 1.2039, 1.2218, 1.1842, 1.2087, 1.1723, 1.2095, 1.1546, 1.1926, 1.1659, 1.1703, 1.1795, 1.2035, 1.1812, 1.1639, 1.1339, 1.1536, 1.1696, 1.1282, 1.1197, 1.169, 1.1453, 1.1589, 1.14, 1.0961, 1.0837, 1.1009, 1.1007, 1.0994, 1.082, 1.0632, 1.0493, 1.0911, 1.0783, 1.034, 1.1285, 1.0484, 1.0635, 1.0473, 1.0282, 1.0503, 1.0425, 1.0484, 1.0391, 1.0026, 1.0291, 0.997, 1.0233, 1.0222, 1.0344, 0.9895, 0.9725, 1.0245, 1.0101, 0.9883, 0.9881, 0.971, 0.9416, 0.9606, 0.9826, 0.9871, 0.9335, 0.9704, 0.9472, 0.9331, 0.9075, 0.9174, 0.9437, 0.9117, 0.9013, 0.9161, 0.9142, 0.8992, 0.9085, 0.8839, 0.899, 0.8948, 0.862, 0.8723, 0.8623, 0.8811, 0.871, 0.8574, 0.8645, 0.8517, 0.8423, 0.8336, 0.841, 0.8328, 0.8198, 0.8214, 0.8266, 0.8114, 0.806, 0.8054, 0.8201, 0.8041, 0.7891, 0.7828, 0.7768, 0.7812, 0.7817, 0.7654, 0.7574, 0.7529, 0.7436, 0.7516, 0.7431, 0.7624, 0.7366, 0.7372, 0.7412, 0.7376, 0.7296, 0.723, 0.7179, 0.7325, 0.7155, 0.7156, 0.7059, 0.7147, 0.7052, 0.7034, 0.6927, 0.7005, 0.7001, 0.6959, 0.6865, 0.6816, 0.673, 0.6758, 0.67, 0.6685, 0.6694, 0.6543, 0.6599, 0.6668, 0.6566, 0.6536, 0.6522, 0.656, 0.6449, 0.6476, 0.6441, 0.64, 0.6452, 0.6422, 0.6401, 0.6401, 0.6406, 0.6374, 0.6415, 0.6375, 0.6396, 0.6368, 0.6373, 0.6372, 0.6363, 0.6354, 0.6386, 0.6351, 0.6354]\n",
            "test err:  [0.8829, 0.8283, 0.7652, 0.7156, 0.6613, 0.5891, 0.5484, 0.5154, 0.4932, 0.4857, 0.4647, 0.4462, 0.4567, 0.4266, 0.4196, 0.419, 0.4208, 0.4018, 0.4029, 0.4001, 0.4114, 0.3895, 0.3936, 0.3806, 0.3754, 0.3862, 0.3821, 0.3653, 0.389, 0.3625, 0.3501, 0.3558, 0.3688, 0.3775, 0.3526, 0.3573, 0.3641, 0.3436, 0.3659, 0.3473, 0.3492, 0.3373, 0.341, 0.3293, 0.3464, 0.3297, 0.3358, 0.3244, 0.3361, 0.3352, 0.338, 0.3299, 0.3307, 0.3234, 0.3272, 0.3346, 0.3245, 0.3182, 0.3339, 0.3297, 0.3283, 0.3223, 0.3102, 0.3074, 0.3174, 0.3129, 0.3114, 0.3076, 0.3031, 0.2982, 0.3109, 0.312, 0.3002, 0.3245, 0.2986, 0.2993, 0.3017, 0.294, 0.2995, 0.3007, 0.2988, 0.2976, 0.288, 0.2942, 0.2869, 0.2926, 0.2957, 0.2929, 0.2818, 0.2755, 0.3005, 0.2885, 0.2802, 0.2875, 0.2816, 0.2707, 0.2779, 0.2875, 0.2863, 0.2719, 0.2777, 0.271, 0.2701, 0.2636, 0.2701, 0.2785, 0.2603, 0.262, 0.2626, 0.2671, 0.2627, 0.2608, 0.258, 0.263, 0.2577, 0.2497, 0.2544, 0.2511, 0.2541, 0.2536, 0.247, 0.2521, 0.246, 0.242, 0.2445, 0.2476, 0.2419, 0.2404, 0.2361, 0.2409, 0.2373, 0.2365, 0.236, 0.238, 0.2347, 0.2316, 0.2292, 0.2276, 0.2279, 0.2262, 0.2215, 0.2208, 0.2207, 0.22, 0.2193, 0.2179, 0.2236, 0.2142, 0.2151, 0.2166, 0.2135, 0.2135, 0.2152, 0.2107, 0.2115, 0.2073, 0.2087, 0.2056, 0.2088, 0.2085, 0.2073, 0.2037, 0.2045, 0.2097, 0.2019, 0.1998, 0.1986, 0.1966, 0.1956, 0.1974, 0.1933, 0.1946, 0.1924, 0.193, 0.1947, 0.1885, 0.1892, 0.191, 0.1902, 0.1873, 0.1886, 0.1864, 0.1871, 0.1857, 0.1861, 0.1849, 0.1836, 0.1843, 0.1844, 0.1847, 0.1844, 0.1843, 0.1848, 0.1821, 0.1852, 0.1822, 0.184, 0.1838, 0.1813, 0.1823]\n",
            "test acc:  [0.1171, 0.1717, 0.2348, 0.2844, 0.3387, 0.4109, 0.4516, 0.4846, 0.5068, 0.5143, 0.5353, 0.5538, 0.5433, 0.5734, 0.5804, 0.581, 0.5792, 0.5982, 0.5971, 0.5999, 0.5886, 0.6105, 0.6064, 0.6194, 0.6246, 0.6138, 0.6179, 0.6347, 0.611, 0.6375, 0.6499, 0.6442, 0.6312, 0.6225, 0.6474, 0.6427, 0.6359, 0.6564, 0.6341, 0.6527, 0.6508, 0.6627, 0.659, 0.6707, 0.6536, 0.6703, 0.6642, 0.6756, 0.6639, 0.6648, 0.662, 0.6701, 0.6693, 0.6766, 0.6728, 0.6654, 0.6755, 0.6818, 0.6661, 0.6703, 0.6717, 0.6777, 0.6898, 0.6926, 0.6826, 0.6871, 0.6886, 0.6924, 0.6969, 0.7018, 0.6891, 0.688, 0.6998, 0.6755, 0.7014, 0.7007, 0.6983, 0.706, 0.7005, 0.6993, 0.7012, 0.7024, 0.712, 0.7058, 0.7131, 0.7074, 0.7043, 0.7071, 0.7182, 0.7245, 0.6995, 0.7115, 0.7198, 0.7125, 0.7184, 0.7293, 0.7221, 0.7125, 0.7137, 0.7281, 0.7223, 0.729, 0.7299, 0.7364, 0.7299, 0.7215, 0.7397, 0.738, 0.7374, 0.7329, 0.7373, 0.7392, 0.742, 0.737, 0.7423, 0.7503, 0.7456, 0.7489, 0.7459, 0.7464, 0.753, 0.7479, 0.754, 0.758, 0.7555, 0.7524, 0.7581, 0.7596, 0.7639, 0.7591, 0.7627, 0.7635, 0.764, 0.762, 0.7653, 0.7684, 0.7708, 0.7724, 0.7721, 0.7738, 0.7785, 0.7792, 0.7793, 0.78, 0.7807, 0.7821, 0.7764, 0.7858, 0.7849, 0.7834, 0.7865, 0.7865, 0.7848, 0.7893, 0.7885, 0.7927, 0.7913, 0.7944, 0.7912, 0.7915, 0.7927, 0.7963, 0.7955, 0.7903, 0.7981, 0.8002, 0.8014, 0.8034, 0.8044, 0.8026, 0.8067, 0.8054, 0.8076, 0.807, 0.8053, 0.8115, 0.8108, 0.809, 0.8098, 0.8127, 0.8114, 0.8136, 0.8129, 0.8143, 0.8139, 0.8151, 0.8164, 0.8157, 0.8156, 0.8153, 0.8156, 0.8157, 0.8152, 0.8179, 0.8148, 0.8178, 0.816, 0.8162, 0.8187, 0.8177]\n",
            "ori train loss:  [4.077, 3.6577, 3.3381, 3.0684, 2.7631, 2.4757, 2.2545, 2.0945, 1.9673, 1.8685, 1.7989, 1.7359, 1.6892, 1.6378, 1.592, 1.5603, 1.5333, 1.5121, 1.4825, 1.4531, 1.4381, 1.4205, 1.4051, 1.3825, 1.3685, 1.3503, 1.3471, 1.325, 1.3204, 1.3047, 1.2968, 1.2762, 1.2813, 1.2619, 1.2587, 1.2442, 1.2386, 1.2327, 1.2202, 1.2082, 1.2024, 1.196, 1.1917, 1.177, 1.1818, 1.1601, 1.1545, 1.1571, 1.1487, 1.1379, 1.136, 1.1265, 1.1125, 1.1172, 1.0996, 1.0987, 1.0929, 1.0839, 1.0701, 1.0747, 1.0627, 1.0621, 1.0537, 1.0505, 1.0356, 1.0364, 1.0311, 1.0208, 1.0139, 0.9997, 0.9975, 0.9962, 0.9876, 0.9886, 0.9792, 0.9721, 0.9566, 0.9527, 0.9459, 0.9355, 0.9305, 0.9191, 0.9168, 0.9103, 0.8976, 0.8987, 0.8903, 0.8747, 0.8721, 0.8623, 0.8601, 0.8488, 0.8442, 0.8311, 0.8295, 0.8262, 0.8171, 0.8034, 0.7979, 0.7882, 0.7801, 0.7754, 0.7663, 0.7559, 0.7539, 0.741, 0.733, 0.7241, 0.7134, 0.7097, 0.6929, 0.6864, 0.6781, 0.6639, 0.6654, 0.6501, 0.6385, 0.6386, 0.6237, 0.6134, 0.6038, 0.5986, 0.5877, 0.5788, 0.5641, 0.5612, 0.5457, 0.5378, 0.5312, 0.5232, 0.5136, 0.4932, 0.4898, 0.4806, 0.4681, 0.4563, 0.4464, 0.4386, 0.4298, 0.4174, 0.408, 0.3953, 0.3881, 0.3787, 0.3696, 0.3552, 0.3493, 0.3386, 0.3304, 0.3191, 0.3088, 0.2972, 0.2903, 0.2808, 0.2721, 0.2627, 0.2563, 0.2484, 0.2421, 0.2281, 0.2205, 0.2114, 0.2065, 0.1973, 0.1901, 0.1811, 0.1754, 0.1738, 0.1621, 0.1546, 0.1502, 0.1472, 0.1409, 0.1409, 0.1324, 0.1271, 0.1246, 0.1203, 0.1152, 0.1131, 0.1116, 0.106, 0.1043, 0.1023, 0.0988, 0.0977, 0.0955, 0.0951, 0.093, 0.0919, 0.0925, 0.09, 0.0896, 0.0877, 0.0876, 0.0839, 0.0876, 0.0867, 0.0866, 0.0881]\n",
            "ori train err:  [0.9202, 0.8567, 0.7973, 0.741, 0.6772, 0.6081, 0.5536, 0.5136, 0.4781, 0.4525, 0.4332, 0.4173, 0.4011, 0.3857, 0.3737, 0.3641, 0.3546, 0.3491, 0.3421, 0.3321, 0.3253, 0.3228, 0.3187, 0.3139, 0.3087, 0.3015, 0.2998, 0.2954, 0.2923, 0.287, 0.2849, 0.2832, 0.284, 0.2762, 0.275, 0.2732, 0.268, 0.2668, 0.2646, 0.2596, 0.2572, 0.2581, 0.2551, 0.2518, 0.2526, 0.2456, 0.2444, 0.2446, 0.2429, 0.241, 0.2402, 0.2381, 0.2335, 0.2359, 0.231, 0.2303, 0.2268, 0.2271, 0.2225, 0.2249, 0.2215, 0.2217, 0.2176, 0.2173, 0.2107, 0.2152, 0.2122, 0.2092, 0.2081, 0.2045, 0.2033, 0.2041, 0.2004, 0.2018, 0.1989, 0.1964, 0.1932, 0.1933, 0.1901, 0.1884, 0.1879, 0.1846, 0.1819, 0.1815, 0.1777, 0.1773, 0.1755, 0.1742, 0.1713, 0.1699, 0.1692, 0.1649, 0.1659, 0.1619, 0.1598, 0.1602, 0.1588, 0.1549, 0.1524, 0.1501, 0.15, 0.1467, 0.1453, 0.1429, 0.1409, 0.1383, 0.1367, 0.1353, 0.1322, 0.1296, 0.1275, 0.1256, 0.1226, 0.1193, 0.1207, 0.1169, 0.1142, 0.1126, 0.1086, 0.1077, 0.104, 0.1029, 0.1002, 0.0991, 0.0955, 0.0944, 0.0903, 0.0887, 0.0863, 0.0862, 0.0839, 0.0785, 0.0772, 0.0762, 0.0741, 0.0691, 0.068, 0.0663, 0.0648, 0.0617, 0.0614, 0.0573, 0.0558, 0.0543, 0.0528, 0.0494, 0.0477, 0.0455, 0.0439, 0.042, 0.0406, 0.0378, 0.0373, 0.0357, 0.0341, 0.0333, 0.0311, 0.0305, 0.0288, 0.0272, 0.026, 0.0245, 0.0236, 0.0225, 0.0218, 0.0203, 0.0198, 0.0198, 0.0184, 0.0165, 0.0163, 0.0164, 0.0156, 0.0162, 0.0146, 0.0135, 0.0142, 0.0131, 0.0125, 0.0127, 0.0125, 0.0115, 0.012, 0.0118, 0.0108, 0.0112, 0.0107, 0.0117, 0.0108, 0.0112, 0.0107, 0.01, 0.0104, 0.0096, 0.0103, 0.0091, 0.0099, 0.0102, 0.0095, 0.0105]\n",
            "ori train acc:  [0.0798, 0.1433, 0.2027, 0.259, 0.3228, 0.3919, 0.4464, 0.4864, 0.5219, 0.5475, 0.5668, 0.5827, 0.5989, 0.6143, 0.6263, 0.6359, 0.6454, 0.6509, 0.6579, 0.6679, 0.6747, 0.6772, 0.6813, 0.6861, 0.6913, 0.6985, 0.7002, 0.7046, 0.7077, 0.713, 0.7151, 0.7168, 0.716, 0.7238, 0.725, 0.7268, 0.732, 0.7332, 0.7354, 0.7404, 0.7428, 0.7419, 0.7449, 0.7482, 0.7474, 0.7544, 0.7556, 0.7554, 0.7571, 0.759, 0.7598, 0.7619, 0.7665, 0.7641, 0.769, 0.7697, 0.7732, 0.7729, 0.7775, 0.7751, 0.7785, 0.7783, 0.7824, 0.7827, 0.7893, 0.7848, 0.7878, 0.7908, 0.7919, 0.7955, 0.7967, 0.7959, 0.7996, 0.7982, 0.8011, 0.8036, 0.8068, 0.8067, 0.8099, 0.8116, 0.8121, 0.8154, 0.8181, 0.8185, 0.8223, 0.8227, 0.8245, 0.8258, 0.8287, 0.8301, 0.8308, 0.8351, 0.8341, 0.8381, 0.8402, 0.8398, 0.8412, 0.8451, 0.8476, 0.8499, 0.85, 0.8533, 0.8547, 0.8571, 0.8591, 0.8617, 0.8633, 0.8647, 0.8678, 0.8704, 0.8725, 0.8744, 0.8774, 0.8807, 0.8793, 0.8831, 0.8858, 0.8874, 0.8914, 0.8923, 0.896, 0.8971, 0.8998, 0.9009, 0.9045, 0.9056, 0.9097, 0.9113, 0.9137, 0.9138, 0.9161, 0.9215, 0.9228, 0.9238, 0.9259, 0.9309, 0.932, 0.9337, 0.9352, 0.9383, 0.9386, 0.9427, 0.9442, 0.9457, 0.9472, 0.9506, 0.9523, 0.9545, 0.9561, 0.958, 0.9594, 0.9622, 0.9627, 0.9643, 0.9659, 0.9667, 0.9689, 0.9695, 0.9712, 0.9728, 0.974, 0.9755, 0.9764, 0.9775, 0.9782, 0.9797, 0.9802, 0.9802, 0.9816, 0.9835, 0.9837, 0.9836, 0.9844, 0.9838, 0.9854, 0.9865, 0.9858, 0.9869, 0.9875, 0.9873, 0.9875, 0.9885, 0.988, 0.9882, 0.9892, 0.9888, 0.9893, 0.9883, 0.9892, 0.9888, 0.9893, 0.99, 0.9896, 0.9904, 0.9897, 0.9909, 0.9901, 0.9898, 0.9905, 0.9895]\n",
            "time:  [41.55, 39.85, 40.0, 40.02, 40.05, 40.05, 40.02, 40.06, 40.05, 40.22, 40.15, 40.0, 40.06, 39.97, 40.18, 40.19, 40.02, 39.99, 40.04, 40.18, 40.15, 40.16, 40.17, 40.2, 39.98, 40.03, 39.96, 39.98, 40.01, 40.01, 40.15, 40.13, 39.95, 39.96, 40.14, 40.01, 40.03, 40.13, 39.95, 40.07, 39.93, 39.96, 40.12, 40.11, 40.15, 40.12, 40.17, 40.18, 40.12, 40.13, 40.09, 40.15, 40.17, 40.14, 39.95, 39.93, 40.12, 40.02, 39.93, 39.94, 40.13, 40.15, 40.11, 40.16, 39.95, 39.94, 40.15, 39.95, 39.99, 40.12, 39.82, 39.98, 39.97, 39.95, 39.96, 40.1, 40.17, 39.98, 39.95, 39.92, 40.12, 39.96, 39.94, 40.0, 40.16, 39.89, 39.99, 39.97, 39.94, 39.95, 39.99, 39.96, 40.11, 40.13, 40.11, 39.94, 40.06, 39.92, 39.94, 39.94, 39.95, 40.13, 40.14, 40.15, 40.14, 40.13, 40.09, 40.14, 40.09, 40.15, 40.0, 39.95, 39.98, 39.97, 40.04, 39.94, 39.95, 40.0, 39.96, 40.13, 40.15, 39.92, 39.95, 40.0, 40.01, 39.97, 40.15, 40.15, 40.18, 40.13, 40.13, 40.11, 40.14, 40.08, 39.98, 39.96, 40.02, 40.03, 40.0, 40.0, 39.99, 40.12, 40.12, 40.14, 39.97, 40.18, 39.87, 39.93, 40.15, 40.15, 40.15, 39.92, 40.01, 40.13, 40.14, 40.01, 39.96, 39.99, 39.96, 39.97, 40.0, 39.97, 39.97, 39.95, 40.15, 40.14, 40.14, 40.18, 40.17, 40.02, 39.98, 39.98, 40.15, 40.16, 40.17, 39.98, 40.02, 40.0, 40.0, 39.97, 40.16, 40.15, 40.2, 40.17, 40.18, 40.18, 40.12, 40.17, 40.17, 39.97, 40.03, 40.0, 40.01, 39.97, 40.05, 40.15, 39.84, 40.04, 39.99, 40.02]\n"
          ]
        }
      ]
    }
  ]
}