{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Results/SAM/CIFAR10/vgg16bn_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyl_beMyPMnl",
        "outputId": "e06a86c0-3c78-4f35-82ff-20c98c2a9776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: VGG16_BN\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar10 dataset!\n",
            "100% 170M/170M [00:03<00:00, 48.5MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "391\n",
            "50000\n",
            "optimizer: SAM\n",
            "SAM (\n",
            "Parameter Group 0\n",
            "    adaptive: False\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 0.1\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "Epoch: [0][0/391]\tTime 5.032 (5.032)\tData 0.423 (0.423)\tLoss 2.3912 (2.3912)\tPrec@1 5.469 (5.469)\n",
            "Epoch: [0][100/391]\tTime 0.097 (0.146)\tData 0.002 (0.006)\tLoss 1.9509 (2.0960)\tPrec@1 32.812 (18.750)\n",
            "Epoch: [0][200/391]\tTime 0.111 (0.123)\tData 0.011 (0.004)\tLoss 1.8632 (1.9825)\tPrec@1 27.344 (22.303)\n",
            "Epoch: [0][300/391]\tTime 0.098 (0.115)\tData 0.000 (0.003)\tLoss 1.7606 (1.9100)\tPrec@1 36.719 (24.862)\n",
            "Epoch: [0][390/391]\tTime 2.003 (0.116)\tData 0.000 (0.003)\tLoss 1.7801 (1.8638)\tPrec@1 35.000 (26.740)\n",
            "Total time : 45.444\n",
            "Train Loss: 1.8638, Train Accuracy: 0.2674\n",
            "Test Loss : 1.6159, Test Accuracy : 0.3748 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.362 (0.362)\tData 0.254 (0.254)\tLoss 1.6625 (1.6625)\tPrec@1 40.625 (40.625)\n",
            "Epoch: [1][100/391]\tTime 0.101 (0.104)\tData 0.000 (0.005)\tLoss 1.6449 (1.6491)\tPrec@1 34.375 (36.177)\n",
            "Epoch: [1][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.003)\tLoss 1.3122 (1.6057)\tPrec@1 50.781 (38.044)\n",
            "Epoch: [1][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.003)\tLoss 1.4996 (1.5740)\tPrec@1 41.406 (39.584)\n",
            "Epoch: [1][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 1.3847 (1.5403)\tPrec@1 46.250 (41.142)\n",
            "Total time : 40.318\n",
            "Train Loss: 1.5403, Train Accuracy: 0.4114\n",
            "Test Loss : 1.4616, Test Accuracy : 0.4438 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.377 (0.377)\tData 0.230 (0.230)\tLoss 1.5412 (1.5412)\tPrec@1 38.281 (38.281)\n",
            "Epoch: [2][100/391]\tTime 0.107 (0.106)\tData 0.011 (0.003)\tLoss 1.4071 (1.3837)\tPrec@1 46.875 (49.706)\n",
            "Epoch: [2][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 1.5780 (1.3591)\tPrec@1 44.531 (51.088)\n",
            "Epoch: [2][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 1.1817 (1.3273)\tPrec@1 58.594 (52.621)\n",
            "Epoch: [2][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 1.1432 (1.3004)\tPrec@1 60.000 (53.808)\n",
            "Total time : 40.362\n",
            "Train Loss: 1.3004, Train Accuracy: 0.5381\n",
            "Test Loss : 1.4302, Test Accuracy : 0.5230 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.516 (0.516)\tData 0.357 (0.357)\tLoss 1.1946 (1.1946)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [3][100/391]\tTime 0.101 (0.110)\tData 0.001 (0.007)\tLoss 1.1776 (1.1400)\tPrec@1 56.250 (60.032)\n",
            "Epoch: [3][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 1.0263 (1.1346)\tPrec@1 63.281 (60.650)\n",
            "Epoch: [3][300/391]\tTime 0.106 (0.105)\tData 0.000 (0.003)\tLoss 1.0682 (1.1186)\tPrec@1 61.719 (61.122)\n",
            "Epoch: [3][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.002)\tLoss 1.2406 (1.1015)\tPrec@1 53.750 (61.748)\n",
            "Total time : 40.645\n",
            "Train Loss: 1.1015, Train Accuracy: 0.6175\n",
            "Test Loss : 0.9596, Test Accuracy : 0.6688 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.585 (0.585)\tData 0.440 (0.440)\tLoss 0.9125 (0.9125)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [4][100/391]\tTime 0.104 (0.107)\tData 0.005 (0.005)\tLoss 0.8777 (1.0175)\tPrec@1 73.438 (64.774)\n",
            "Epoch: [4][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 1.0497 (1.0118)\tPrec@1 65.625 (65.127)\n",
            "Epoch: [4][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.9860 (1.0020)\tPrec@1 63.281 (65.602)\n",
            "Epoch: [4][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.7037 (0.9911)\tPrec@1 80.000 (66.028)\n",
            "Total time : 40.565\n",
            "Train Loss: 0.9911, Train Accuracy: 0.6603\n",
            "Test Loss : 0.9405, Test Accuracy : 0.6761 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.369 (0.369)\tData 0.260 (0.260)\tLoss 0.9169 (0.9169)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [5][100/391]\tTime 0.103 (0.105)\tData 0.000 (0.004)\tLoss 0.9186 (0.9269)\tPrec@1 67.188 (68.510)\n",
            "Epoch: [5][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 1.0158 (0.9178)\tPrec@1 63.281 (68.855)\n",
            "Epoch: [5][300/391]\tTime 0.112 (0.103)\tData 0.000 (0.002)\tLoss 0.9736 (0.9103)\tPrec@1 67.188 (69.170)\n",
            "Epoch: [5][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.8508 (0.9043)\tPrec@1 73.750 (69.400)\n",
            "Total time : 40.383\n",
            "Train Loss: 0.9043, Train Accuracy: 0.6940\n",
            "Test Loss : 0.9989, Test Accuracy : 0.6614 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.378 (0.378)\tData 0.262 (0.262)\tLoss 1.1010 (1.1010)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [6][100/391]\tTime 0.100 (0.105)\tData 0.001 (0.004)\tLoss 0.9882 (0.8505)\tPrec@1 64.844 (70.947)\n",
            "Epoch: [6][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.8149 (0.8550)\tPrec@1 73.438 (70.732)\n",
            "Epoch: [6][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.8459 (0.8511)\tPrec@1 69.531 (71.078)\n",
            "Epoch: [6][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.9995 (0.8468)\tPrec@1 67.500 (71.448)\n",
            "Total time : 40.389\n",
            "Train Loss: 0.8468, Train Accuracy: 0.7145\n",
            "Test Loss : 0.7842, Test Accuracy : 0.7388 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.382 (0.382)\tData 0.269 (0.269)\tLoss 0.8214 (0.8214)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [7][100/391]\tTime 0.109 (0.106)\tData 0.010 (0.004)\tLoss 0.7783 (0.8208)\tPrec@1 71.875 (72.594)\n",
            "Epoch: [7][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.8383 (0.8068)\tPrec@1 75.000 (73.154)\n",
            "Epoch: [7][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.7826 (0.8001)\tPrec@1 72.656 (73.456)\n",
            "Epoch: [7][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.8800 (0.8023)\tPrec@1 77.500 (73.414)\n",
            "Total time : 40.470\n",
            "Train Loss: 0.8023, Train Accuracy: 0.7341\n",
            "Test Loss : 0.7529, Test Accuracy : 0.7529 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.443 (0.443)\tData 0.342 (0.342)\tLoss 0.7948 (0.7948)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [8][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.004)\tLoss 0.8332 (0.7902)\tPrec@1 75.781 (74.420)\n",
            "Epoch: [8][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.7592 (0.7737)\tPrec@1 72.656 (74.926)\n",
            "Epoch: [8][300/391]\tTime 0.114 (0.104)\tData 0.011 (0.003)\tLoss 0.7000 (0.7758)\tPrec@1 78.906 (74.678)\n",
            "Epoch: [8][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.6680 (0.7674)\tPrec@1 75.000 (74.962)\n",
            "Total time : 40.571\n",
            "Train Loss: 0.7674, Train Accuracy: 0.7496\n",
            "Test Loss : 0.8675, Test Accuracy : 0.7222 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.524 (0.524)\tData 0.404 (0.404)\tLoss 0.7131 (0.7131)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [9][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.6647 (0.7498)\tPrec@1 79.688 (75.263)\n",
            "Epoch: [9][200/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.8165 (0.7488)\tPrec@1 71.094 (75.338)\n",
            "Epoch: [9][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.9102 (0.7455)\tPrec@1 74.219 (75.540)\n",
            "Epoch: [9][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.8453 (0.7420)\tPrec@1 71.250 (75.702)\n",
            "Total time : 40.503\n",
            "Train Loss: 0.7420, Train Accuracy: 0.7570\n",
            "Test Loss : 0.7213, Test Accuracy : 0.7653 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.419 (0.419)\tData 0.298 (0.298)\tLoss 0.7684 (0.7684)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [10][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.6723 (0.6968)\tPrec@1 79.688 (77.259)\n",
            "Epoch: [10][200/391]\tTime 0.112 (0.104)\tData 0.008 (0.003)\tLoss 0.7533 (0.7091)\tPrec@1 76.562 (76.706)\n",
            "Epoch: [10][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6422 (0.7056)\tPrec@1 77.344 (76.939)\n",
            "Epoch: [10][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.8073 (0.7076)\tPrec@1 72.500 (76.950)\n",
            "Total time : 40.375\n",
            "Train Loss: 0.7076, Train Accuracy: 0.7695\n",
            "Test Loss : 0.6504, Test Accuracy : 0.7903 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.382 (0.382)\tData 0.263 (0.263)\tLoss 0.7015 (0.7015)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [11][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.8609 (0.6811)\tPrec@1 68.750 (77.816)\n",
            "Epoch: [11][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.7309 (0.6831)\tPrec@1 78.906 (77.876)\n",
            "Epoch: [11][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.7046 (0.6917)\tPrec@1 77.344 (77.608)\n",
            "Epoch: [11][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.6703 (0.6915)\tPrec@1 78.750 (77.656)\n",
            "Total time : 40.345\n",
            "Train Loss: 0.6915, Train Accuracy: 0.7766\n",
            "Test Loss : 0.7447, Test Accuracy : 0.7558 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.267 (0.267)\tData 0.166 (0.166)\tLoss 0.7538 (0.7538)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [12][100/391]\tTime 0.105 (0.105)\tData 0.000 (0.003)\tLoss 0.7089 (0.6664)\tPrec@1 75.000 (78.504)\n",
            "Epoch: [12][200/391]\tTime 0.104 (0.103)\tData 0.000 (0.002)\tLoss 0.7012 (0.6764)\tPrec@1 74.219 (78.323)\n",
            "Epoch: [12][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6935 (0.6833)\tPrec@1 80.469 (78.003)\n",
            "Epoch: [12][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.5320 (0.6812)\tPrec@1 82.500 (78.190)\n",
            "Total time : 40.230\n",
            "Train Loss: 0.6812, Train Accuracy: 0.7819\n",
            "Test Loss : 0.6553, Test Accuracy : 0.7820 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.422 (0.422)\tData 0.324 (0.324)\tLoss 0.7159 (0.7159)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [13][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.7334 (0.6464)\tPrec@1 75.000 (79.223)\n",
            "Epoch: [13][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.6939 (0.6559)\tPrec@1 78.125 (78.852)\n",
            "Epoch: [13][300/391]\tTime 0.108 (0.105)\tData 0.010 (0.003)\tLoss 0.7251 (0.6593)\tPrec@1 75.000 (78.706)\n",
            "Epoch: [13][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.5859 (0.6618)\tPrec@1 81.250 (78.690)\n",
            "Total time : 40.626\n",
            "Train Loss: 0.6618, Train Accuracy: 0.7869\n",
            "Test Loss : 0.6483, Test Accuracy : 0.7903 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.466 (0.466)\tData 0.339 (0.339)\tLoss 0.4575 (0.4575)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [14][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.8811 (0.6429)\tPrec@1 73.438 (79.394)\n",
            "Epoch: [14][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.8131 (0.6589)\tPrec@1 74.219 (79.042)\n",
            "Epoch: [14][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4492 (0.6521)\tPrec@1 86.719 (79.202)\n",
            "Epoch: [14][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.6011 (0.6519)\tPrec@1 82.500 (79.102)\n",
            "Total time : 40.488\n",
            "Train Loss: 0.6519, Train Accuracy: 0.7910\n",
            "Test Loss : 0.8752, Test Accuracy : 0.7258 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.391 (0.391)\tData 0.278 (0.278)\tLoss 0.6196 (0.6196)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [15][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.5354 (0.6479)\tPrec@1 83.594 (79.316)\n",
            "Epoch: [15][200/391]\tTime 0.112 (0.104)\tData 0.007 (0.003)\tLoss 0.6815 (0.6365)\tPrec@1 76.562 (79.575)\n",
            "Epoch: [15][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6116 (0.6351)\tPrec@1 83.594 (79.716)\n",
            "Epoch: [15][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.4901 (0.6351)\tPrec@1 87.500 (79.656)\n",
            "Total time : 40.303\n",
            "Train Loss: 0.6351, Train Accuracy: 0.7966\n",
            "Test Loss : 0.6711, Test Accuracy : 0.7772 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.370 (0.370)\tData 0.261 (0.261)\tLoss 0.7448 (0.7448)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [16][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.7487 (0.6161)\tPrec@1 75.781 (80.299)\n",
            "Epoch: [16][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.5506 (0.6280)\tPrec@1 83.594 (79.944)\n",
            "Epoch: [16][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.7308 (0.6264)\tPrec@1 76.562 (79.913)\n",
            "Epoch: [16][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.6689 (0.6242)\tPrec@1 75.000 (79.984)\n",
            "Total time : 40.461\n",
            "Train Loss: 0.6242, Train Accuracy: 0.7998\n",
            "Test Loss : 0.6796, Test Accuracy : 0.7809 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.368 (0.368)\tData 0.267 (0.267)\tLoss 0.7029 (0.7029)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [17][100/391]\tTime 0.110 (0.105)\tData 0.012 (0.004)\tLoss 0.5978 (0.6070)\tPrec@1 78.906 (80.546)\n",
            "Epoch: [17][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.6579 (0.6185)\tPrec@1 75.781 (80.022)\n",
            "Epoch: [17][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5440 (0.6175)\tPrec@1 82.031 (80.017)\n",
            "Epoch: [17][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.5388 (0.6108)\tPrec@1 80.000 (80.316)\n",
            "Total time : 40.400\n",
            "Train Loss: 0.6108, Train Accuracy: 0.8032\n",
            "Test Loss : 0.7134, Test Accuracy : 0.7663 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.408 (0.408)\tData 0.266 (0.266)\tLoss 0.7579 (0.7579)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [18][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.5390 (0.6027)\tPrec@1 80.469 (80.995)\n",
            "Epoch: [18][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.004)\tLoss 0.6560 (0.5978)\tPrec@1 79.688 (80.993)\n",
            "Epoch: [18][300/391]\tTime 0.111 (0.103)\tData 0.012 (0.003)\tLoss 0.6564 (0.6008)\tPrec@1 80.469 (80.975)\n",
            "Epoch: [18][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.5893 (0.6052)\tPrec@1 80.000 (80.822)\n",
            "Total time : 40.526\n",
            "Train Loss: 0.6052, Train Accuracy: 0.8082\n",
            "Test Loss : 0.6194, Test Accuracy : 0.7876 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.595 (0.595)\tData 0.455 (0.455)\tLoss 0.4204 (0.4204)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [19][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.006)\tLoss 0.5363 (0.5830)\tPrec@1 82.812 (81.242)\n",
            "Epoch: [19][200/391]\tTime 0.101 (0.105)\tData 0.001 (0.004)\tLoss 0.5196 (0.5851)\tPrec@1 82.812 (81.308)\n",
            "Epoch: [19][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.5464 (0.5959)\tPrec@1 82.812 (81.016)\n",
            "Epoch: [19][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.6302 (0.5978)\tPrec@1 76.250 (80.890)\n",
            "Total time : 40.753\n",
            "Train Loss: 0.5978, Train Accuracy: 0.8089\n",
            "Test Loss : 0.6614, Test Accuracy : 0.7817 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.393 (0.393)\tData 0.272 (0.272)\tLoss 0.6328 (0.6328)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [20][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.6225 (0.5817)\tPrec@1 79.688 (81.590)\n",
            "Epoch: [20][200/391]\tTime 0.117 (0.104)\tData 0.000 (0.002)\tLoss 0.6685 (0.5780)\tPrec@1 75.781 (81.615)\n",
            "Epoch: [20][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5830 (0.5867)\tPrec@1 78.125 (81.299)\n",
            "Epoch: [20][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.5654 (0.5852)\tPrec@1 87.500 (81.408)\n",
            "Total time : 40.330\n",
            "Train Loss: 0.5852, Train Accuracy: 0.8141\n",
            "Test Loss : 0.6017, Test Accuracy : 0.8067 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.413 (0.413)\tData 0.297 (0.297)\tLoss 0.5390 (0.5390)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [21][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.5295 (0.5709)\tPrec@1 80.469 (81.575)\n",
            "Epoch: [21][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.5632 (0.5707)\tPrec@1 81.250 (81.817)\n",
            "Epoch: [21][300/391]\tTime 0.111 (0.105)\tData 0.015 (0.003)\tLoss 0.5561 (0.5752)\tPrec@1 80.469 (81.657)\n",
            "Epoch: [21][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.7056 (0.5773)\tPrec@1 75.000 (81.676)\n",
            "Total time : 40.670\n",
            "Train Loss: 0.5773, Train Accuracy: 0.8168\n",
            "Test Loss : 0.6937, Test Accuracy : 0.7859 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.579 (0.579)\tData 0.463 (0.463)\tLoss 0.5507 (0.5507)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [22][100/391]\tTime 0.103 (0.106)\tData 0.006 (0.005)\tLoss 0.6464 (0.5702)\tPrec@1 77.344 (82.124)\n",
            "Epoch: [22][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.5722 (0.5725)\tPrec@1 81.250 (82.047)\n",
            "Epoch: [22][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.5126 (0.5711)\tPrec@1 81.250 (82.013)\n",
            "Epoch: [22][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.5059 (0.5766)\tPrec@1 87.500 (81.762)\n",
            "Total time : 40.468\n",
            "Train Loss: 0.5766, Train Accuracy: 0.8176\n",
            "Test Loss : 0.6503, Test Accuracy : 0.7927 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.406 (0.406)\tData 0.297 (0.297)\tLoss 0.5142 (0.5142)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [23][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.5126 (0.5527)\tPrec@1 82.812 (82.310)\n",
            "Epoch: [23][200/391]\tTime 0.101 (0.104)\tData 0.004 (0.003)\tLoss 0.6067 (0.5604)\tPrec@1 81.250 (82.222)\n",
            "Epoch: [23][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.5695 (0.5613)\tPrec@1 83.594 (82.226)\n",
            "Epoch: [23][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.7274 (0.5626)\tPrec@1 75.000 (82.132)\n",
            "Total time : 40.335\n",
            "Train Loss: 0.5626, Train Accuracy: 0.8213\n",
            "Test Loss : 0.6028, Test Accuracy : 0.7993 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.658 (0.658)\tData 0.530 (0.530)\tLoss 0.4940 (0.4940)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [24][100/391]\tTime 0.100 (0.111)\tData 0.000 (0.008)\tLoss 0.4943 (0.5531)\tPrec@1 84.375 (82.248)\n",
            "Epoch: [24][200/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.4741 (0.5566)\tPrec@1 86.719 (82.369)\n",
            "Epoch: [24][300/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.5210 (0.5580)\tPrec@1 85.156 (82.392)\n",
            "Epoch: [24][390/391]\tTime 0.073 (0.105)\tData 0.000 (0.003)\tLoss 0.3827 (0.5559)\tPrec@1 87.500 (82.376)\n",
            "Total time : 40.913\n",
            "Train Loss: 0.5559, Train Accuracy: 0.8238\n",
            "Test Loss : 0.6148, Test Accuracy : 0.7932 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.396 (0.396)\tData 0.265 (0.265)\tLoss 0.3683 (0.3683)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [25][100/391]\tTime 0.112 (0.106)\tData 0.001 (0.004)\tLoss 0.5003 (0.5410)\tPrec@1 85.156 (82.774)\n",
            "Epoch: [25][200/391]\tTime 0.103 (0.104)\tData 0.000 (0.002)\tLoss 0.5837 (0.5515)\tPrec@1 80.469 (82.416)\n",
            "Epoch: [25][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6186 (0.5495)\tPrec@1 80.469 (82.496)\n",
            "Epoch: [25][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.6687 (0.5514)\tPrec@1 82.500 (82.460)\n",
            "Total time : 40.353\n",
            "Train Loss: 0.5514, Train Accuracy: 0.8246\n",
            "Test Loss : 0.6371, Test Accuracy : 0.7868 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.386 (0.386)\tData 0.267 (0.267)\tLoss 0.5873 (0.5873)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [26][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.6542 (0.5279)\tPrec@1 77.344 (83.161)\n",
            "Epoch: [26][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.6683 (0.5407)\tPrec@1 78.125 (82.778)\n",
            "Epoch: [26][300/391]\tTime 0.108 (0.104)\tData 0.009 (0.003)\tLoss 0.7105 (0.5390)\tPrec@1 72.656 (82.789)\n",
            "Epoch: [26][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.6681 (0.5399)\tPrec@1 78.750 (82.788)\n",
            "Total time : 40.541\n",
            "Train Loss: 0.5399, Train Accuracy: 0.8279\n",
            "Test Loss : 0.5212, Test Accuracy : 0.8278 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.506 (0.506)\tData 0.360 (0.360)\tLoss 0.6319 (0.6319)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [27][100/391]\tTime 0.102 (0.106)\tData 0.002 (0.004)\tLoss 0.5703 (0.5457)\tPrec@1 82.812 (82.828)\n",
            "Epoch: [27][200/391]\tTime 0.102 (0.104)\tData 0.002 (0.003)\tLoss 0.5230 (0.5486)\tPrec@1 82.031 (82.606)\n",
            "Epoch: [27][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4402 (0.5487)\tPrec@1 85.938 (82.579)\n",
            "Epoch: [27][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.4861 (0.5463)\tPrec@1 86.250 (82.662)\n",
            "Total time : 40.507\n",
            "Train Loss: 0.5463, Train Accuracy: 0.8266\n",
            "Test Loss : 0.4853, Test Accuracy : 0.8427 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.380 (0.380)\tData 0.275 (0.275)\tLoss 0.6427 (0.6427)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [28][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.4143 (0.5270)\tPrec@1 88.281 (83.122)\n",
            "Epoch: [28][200/391]\tTime 0.106 (0.104)\tData 0.000 (0.003)\tLoss 0.5138 (0.5300)\tPrec@1 81.250 (83.205)\n",
            "Epoch: [28][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6484 (0.5252)\tPrec@1 78.125 (83.324)\n",
            "Epoch: [28][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.4450 (0.5287)\tPrec@1 85.000 (83.170)\n",
            "Total time : 40.278\n",
            "Train Loss: 0.5287, Train Accuracy: 0.8317\n",
            "Test Loss : 0.5443, Test Accuracy : 0.8296 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.476 (0.476)\tData 0.317 (0.317)\tLoss 0.5030 (0.5030)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [29][100/391]\tTime 0.104 (0.108)\tData 0.000 (0.006)\tLoss 0.4548 (0.5247)\tPrec@1 81.250 (83.563)\n",
            "Epoch: [29][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.6105 (0.5319)\tPrec@1 82.031 (83.376)\n",
            "Epoch: [29][300/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.4268 (0.5334)\tPrec@1 89.062 (83.212)\n",
            "Epoch: [29][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.6686 (0.5346)\tPrec@1 80.000 (83.178)\n",
            "Total time : 40.553\n",
            "Train Loss: 0.5346, Train Accuracy: 0.8318\n",
            "Test Loss : 0.4718, Test Accuracy : 0.8509 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.344 (0.344)\tData 0.221 (0.221)\tLoss 0.4591 (0.4591)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [30][100/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.4023 (0.5281)\tPrec@1 88.281 (83.393)\n",
            "Epoch: [30][200/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.5332 (0.5242)\tPrec@1 81.250 (83.539)\n",
            "Epoch: [30][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6059 (0.5324)\tPrec@1 79.688 (83.306)\n",
            "Epoch: [30][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.5515 (0.5300)\tPrec@1 77.500 (83.346)\n",
            "Total time : 40.247\n",
            "Train Loss: 0.5300, Train Accuracy: 0.8335\n",
            "Test Loss : 0.5468, Test Accuracy : 0.8295 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.393 (0.393)\tData 0.258 (0.258)\tLoss 0.6374 (0.6374)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [31][100/391]\tTime 0.102 (0.107)\tData 0.000 (0.005)\tLoss 0.4049 (0.5047)\tPrec@1 86.719 (84.004)\n",
            "Epoch: [31][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.6234 (0.5189)\tPrec@1 79.688 (83.648)\n",
            "Epoch: [31][300/391]\tTime 0.107 (0.104)\tData 0.006 (0.003)\tLoss 0.6066 (0.5262)\tPrec@1 79.688 (83.469)\n",
            "Epoch: [31][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.4405 (0.5305)\tPrec@1 82.500 (83.348)\n",
            "Total time : 40.558\n",
            "Train Loss: 0.5305, Train Accuracy: 0.8335\n",
            "Test Loss : 0.5331, Test Accuracy : 0.8266 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.610 (0.610)\tData 0.459 (0.459)\tLoss 0.4761 (0.4761)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [32][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.005)\tLoss 0.4731 (0.5170)\tPrec@1 84.375 (83.710)\n",
            "Epoch: [32][200/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.6613 (0.5234)\tPrec@1 79.688 (83.574)\n",
            "Epoch: [32][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.3986 (0.5257)\tPrec@1 87.500 (83.461)\n",
            "Epoch: [32][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.2690 (0.5254)\tPrec@1 93.750 (83.486)\n",
            "Total time : 40.608\n",
            "Train Loss: 0.5254, Train Accuracy: 0.8349\n",
            "Test Loss : 0.4721, Test Accuracy : 0.8446 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.269 (0.269)\tData 0.169 (0.169)\tLoss 0.4055 (0.4055)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [33][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.6128 (0.5144)\tPrec@1 82.031 (83.903)\n",
            "Epoch: [33][200/391]\tTime 0.107 (0.104)\tData 0.000 (0.003)\tLoss 0.5224 (0.5150)\tPrec@1 82.812 (83.800)\n",
            "Epoch: [33][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.5193 (0.5155)\tPrec@1 83.594 (83.814)\n",
            "Epoch: [33][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.6708 (0.5147)\tPrec@1 78.750 (83.872)\n",
            "Total time : 40.283\n",
            "Train Loss: 0.5147, Train Accuracy: 0.8387\n",
            "Test Loss : 0.5553, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.411 (0.411)\tData 0.289 (0.289)\tLoss 0.4450 (0.4450)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [34][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.5347 (0.4913)\tPrec@1 83.594 (84.607)\n",
            "Epoch: [34][200/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.3390 (0.5070)\tPrec@1 90.625 (84.223)\n",
            "Epoch: [34][300/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.5626 (0.5041)\tPrec@1 82.812 (84.276)\n",
            "Epoch: [34][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.003)\tLoss 0.5196 (0.5109)\tPrec@1 86.250 (84.018)\n",
            "Total time : 40.676\n",
            "Train Loss: 0.5109, Train Accuracy: 0.8402\n",
            "Test Loss : 0.6661, Test Accuracy : 0.7766 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.409 (0.409)\tData 0.263 (0.263)\tLoss 0.5824 (0.5824)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [35][100/391]\tTime 0.111 (0.105)\tData 0.013 (0.003)\tLoss 0.3826 (0.5051)\tPrec@1 88.281 (84.344)\n",
            "Epoch: [35][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4454 (0.5072)\tPrec@1 85.156 (84.239)\n",
            "Epoch: [35][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.6140 (0.5131)\tPrec@1 78.125 (83.895)\n",
            "Epoch: [35][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.5667 (0.5126)\tPrec@1 80.000 (83.894)\n",
            "Total time : 40.344\n",
            "Train Loss: 0.5126, Train Accuracy: 0.8389\n",
            "Test Loss : 0.5196, Test Accuracy : 0.8361 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.344 (0.344)\tData 0.209 (0.209)\tLoss 0.3403 (0.3403)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [36][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.6273 (0.4984)\tPrec@1 77.344 (84.414)\n",
            "Epoch: [36][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4729 (0.5040)\tPrec@1 83.594 (84.192)\n",
            "Epoch: [36][300/391]\tTime 0.105 (0.103)\tData 0.000 (0.002)\tLoss 0.5380 (0.5053)\tPrec@1 80.469 (84.115)\n",
            "Epoch: [36][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4955 (0.5034)\tPrec@1 82.500 (84.222)\n",
            "Total time : 40.400\n",
            "Train Loss: 0.5034, Train Accuracy: 0.8422\n",
            "Test Loss : 0.4501, Test Accuracy : 0.8522 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.488 (0.488)\tData 0.309 (0.309)\tLoss 0.4838 (0.4838)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [37][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.4353 (0.4984)\tPrec@1 88.281 (84.197)\n",
            "Epoch: [37][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.5225 (0.5027)\tPrec@1 81.250 (84.165)\n",
            "Epoch: [37][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.6054 (0.5073)\tPrec@1 78.125 (84.006)\n",
            "Epoch: [37][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.6466 (0.5063)\tPrec@1 80.000 (84.026)\n",
            "Total time : 40.434\n",
            "Train Loss: 0.5063, Train Accuracy: 0.8403\n",
            "Test Loss : 0.4912, Test Accuracy : 0.8423 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.380 (0.380)\tData 0.263 (0.263)\tLoss 0.4795 (0.4795)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [38][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.5746 (0.4827)\tPrec@1 82.812 (85.187)\n",
            "Epoch: [38][200/391]\tTime 0.107 (0.103)\tData 0.000 (0.002)\tLoss 0.5565 (0.4961)\tPrec@1 80.469 (84.585)\n",
            "Epoch: [38][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.3727 (0.4957)\tPrec@1 85.938 (84.557)\n",
            "Epoch: [38][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.4231 (0.4966)\tPrec@1 87.500 (84.484)\n",
            "Total time : 40.284\n",
            "Train Loss: 0.4966, Train Accuracy: 0.8448\n",
            "Test Loss : 0.4557, Test Accuracy : 0.8553 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.436 (0.436)\tData 0.284 (0.284)\tLoss 0.3627 (0.3627)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [39][100/391]\tTime 0.102 (0.106)\tData 0.004 (0.004)\tLoss 0.4446 (0.4941)\tPrec@1 85.156 (84.715)\n",
            "Epoch: [39][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.4110 (0.4917)\tPrec@1 89.062 (84.585)\n",
            "Epoch: [39][300/391]\tTime 0.104 (0.104)\tData 0.006 (0.003)\tLoss 0.6540 (0.5032)\tPrec@1 76.562 (84.139)\n",
            "Epoch: [39][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.5159 (0.5063)\tPrec@1 85.000 (84.020)\n",
            "Total time : 40.417\n",
            "Train Loss: 0.5063, Train Accuracy: 0.8402\n",
            "Test Loss : 0.4194, Test Accuracy : 0.8664 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.304 (0.304)\tData 0.186 (0.186)\tLoss 0.3898 (0.3898)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [40][100/391]\tTime 0.106 (0.104)\tData 0.000 (0.003)\tLoss 0.5799 (0.4769)\tPrec@1 79.688 (84.947)\n",
            "Epoch: [40][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.5889 (0.4851)\tPrec@1 79.688 (84.694)\n",
            "Epoch: [40][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5061 (0.4886)\tPrec@1 83.594 (84.653)\n",
            "Epoch: [40][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.5348 (0.4882)\tPrec@1 83.750 (84.640)\n",
            "Total time : 40.303\n",
            "Train Loss: 0.4882, Train Accuracy: 0.8464\n",
            "Test Loss : 0.5293, Test Accuracy : 0.8281 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.376 (0.376)\tData 0.260 (0.260)\tLoss 0.3900 (0.3900)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [41][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.5247 (0.4861)\tPrec@1 84.375 (84.638)\n",
            "Epoch: [41][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.4680 (0.4908)\tPrec@1 85.938 (84.503)\n",
            "Epoch: [41][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4232 (0.4916)\tPrec@1 85.156 (84.435)\n",
            "Epoch: [41][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.5539 (0.4897)\tPrec@1 81.250 (84.506)\n",
            "Total time : 40.369\n",
            "Train Loss: 0.4897, Train Accuracy: 0.8451\n",
            "Test Loss : 0.4516, Test Accuracy : 0.8531 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.374 (0.374)\tData 0.262 (0.262)\tLoss 0.3877 (0.3877)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [42][100/391]\tTime 0.103 (0.108)\tData 0.000 (0.005)\tLoss 0.5056 (0.4681)\tPrec@1 84.375 (85.017)\n",
            "Epoch: [42][200/391]\tTime 0.102 (0.106)\tData 0.000 (0.003)\tLoss 0.4417 (0.4745)\tPrec@1 83.594 (84.861)\n",
            "Epoch: [42][300/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.4313 (0.4759)\tPrec@1 87.500 (84.790)\n",
            "Epoch: [42][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.5247 (0.4757)\tPrec@1 78.750 (84.778)\n",
            "Total time : 40.584\n",
            "Train Loss: 0.4757, Train Accuracy: 0.8478\n",
            "Test Loss : 0.4824, Test Accuracy : 0.8402 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.384 (0.384)\tData 0.255 (0.255)\tLoss 0.4394 (0.4394)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [43][100/391]\tTime 0.103 (0.105)\tData 0.000 (0.004)\tLoss 0.4728 (0.4647)\tPrec@1 85.938 (85.156)\n",
            "Epoch: [43][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.4993 (0.4748)\tPrec@1 86.719 (85.001)\n",
            "Epoch: [43][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5826 (0.4747)\tPrec@1 85.156 (84.993)\n",
            "Epoch: [43][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.4815 (0.4789)\tPrec@1 83.750 (84.826)\n",
            "Total time : 40.328\n",
            "Train Loss: 0.4789, Train Accuracy: 0.8483\n",
            "Test Loss : 0.4461, Test Accuracy : 0.8524 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.421 (0.421)\tData 0.302 (0.302)\tLoss 0.4369 (0.4369)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [44][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.4504 (0.4700)\tPrec@1 83.594 (84.986)\n",
            "Epoch: [44][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.3982 (0.4746)\tPrec@1 92.969 (84.775)\n",
            "Epoch: [44][300/391]\tTime 0.104 (0.104)\tData 0.006 (0.003)\tLoss 0.5402 (0.4788)\tPrec@1 83.594 (84.609)\n",
            "Epoch: [44][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4686 (0.4797)\tPrec@1 85.000 (84.680)\n",
            "Total time : 40.458\n",
            "Train Loss: 0.4797, Train Accuracy: 0.8468\n",
            "Test Loss : 0.5169, Test Accuracy : 0.8368 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.615 (0.615)\tData 0.436 (0.436)\tLoss 0.6011 (0.6011)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [45][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.006)\tLoss 0.4318 (0.4796)\tPrec@1 87.500 (85.257)\n",
            "Epoch: [45][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.4305 (0.4766)\tPrec@1 87.500 (85.036)\n",
            "Epoch: [45][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.4926 (0.4798)\tPrec@1 83.594 (84.949)\n",
            "Epoch: [45][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.4596 (0.4800)\tPrec@1 90.000 (84.924)\n",
            "Total time : 40.628\n",
            "Train Loss: 0.4800, Train Accuracy: 0.8492\n",
            "Test Loss : 0.5001, Test Accuracy : 0.8330 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.429 (0.429)\tData 0.317 (0.317)\tLoss 0.5089 (0.5089)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [46][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.4115 (0.4704)\tPrec@1 89.062 (85.164)\n",
            "Epoch: [46][200/391]\tTime 0.110 (0.104)\tData 0.000 (0.003)\tLoss 0.3618 (0.4610)\tPrec@1 90.625 (85.630)\n",
            "Epoch: [46][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.4721 (0.4678)\tPrec@1 84.375 (85.442)\n",
            "Epoch: [46][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.5647 (0.4704)\tPrec@1 80.000 (85.340)\n",
            "Total time : 40.381\n",
            "Train Loss: 0.4704, Train Accuracy: 0.8534\n",
            "Test Loss : 0.5207, Test Accuracy : 0.8265 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.401 (0.401)\tData 0.277 (0.277)\tLoss 0.4266 (0.4266)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [47][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.4884 (0.4643)\tPrec@1 84.375 (85.288)\n",
            "Epoch: [47][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.5076 (0.4581)\tPrec@1 80.469 (85.370)\n",
            "Epoch: [47][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4614 (0.4668)\tPrec@1 84.375 (85.247)\n",
            "Epoch: [47][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.4473 (0.4739)\tPrec@1 87.500 (84.988)\n",
            "Total time : 40.472\n",
            "Train Loss: 0.4739, Train Accuracy: 0.8499\n",
            "Test Loss : 0.4664, Test Accuracy : 0.8548 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.336 (0.336)\tData 0.210 (0.210)\tLoss 0.5467 (0.5467)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [48][100/391]\tTime 0.104 (0.105)\tData 0.008 (0.004)\tLoss 0.4489 (0.4752)\tPrec@1 88.281 (85.156)\n",
            "Epoch: [48][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.4414 (0.4570)\tPrec@1 87.500 (85.681)\n",
            "Epoch: [48][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5499 (0.4551)\tPrec@1 79.688 (85.706)\n",
            "Epoch: [48][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.5314 (0.4570)\tPrec@1 83.750 (85.694)\n",
            "Total time : 40.252\n",
            "Train Loss: 0.4570, Train Accuracy: 0.8569\n",
            "Test Loss : 0.5387, Test Accuracy : 0.8226 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.384 (0.384)\tData 0.260 (0.260)\tLoss 0.5404 (0.5404)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [49][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.4283 (0.4649)\tPrec@1 86.719 (85.326)\n",
            "Epoch: [49][200/391]\tTime 0.101 (0.104)\tData 0.001 (0.003)\tLoss 0.4966 (0.4692)\tPrec@1 83.594 (85.277)\n",
            "Epoch: [49][300/391]\tTime 0.104 (0.104)\tData 0.003 (0.002)\tLoss 0.4295 (0.4673)\tPrec@1 85.938 (85.338)\n",
            "Epoch: [49][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.6285 (0.4689)\tPrec@1 85.000 (85.264)\n",
            "Total time : 40.735\n",
            "Train Loss: 0.4689, Train Accuracy: 0.8526\n",
            "Test Loss : 0.4092, Test Accuracy : 0.8686 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.375 (0.375)\tData 0.252 (0.252)\tLoss 0.4987 (0.4987)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [50][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.3627 (0.4484)\tPrec@1 89.844 (85.984)\n",
            "Epoch: [50][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.5390 (0.4547)\tPrec@1 81.250 (85.829)\n",
            "Epoch: [50][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.4422 (0.4594)\tPrec@1 85.938 (85.665)\n",
            "Epoch: [50][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.6299 (0.4614)\tPrec@1 81.250 (85.632)\n",
            "Total time : 40.309\n",
            "Train Loss: 0.4614, Train Accuracy: 0.8563\n",
            "Test Loss : 0.4562, Test Accuracy : 0.8454 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.380 (0.380)\tData 0.262 (0.262)\tLoss 0.4934 (0.4934)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [51][100/391]\tTime 0.102 (0.112)\tData 0.000 (0.006)\tLoss 0.4424 (0.4526)\tPrec@1 82.812 (86.123)\n",
            "Epoch: [51][200/391]\tTime 0.131 (0.114)\tData 0.000 (0.006)\tLoss 0.4358 (0.4479)\tPrec@1 86.719 (85.949)\n",
            "Epoch: [51][300/391]\tTime 0.144 (0.115)\tData 0.019 (0.006)\tLoss 0.4511 (0.4548)\tPrec@1 86.719 (85.717)\n",
            "Epoch: [51][390/391]\tTime 0.076 (0.116)\tData 0.000 (0.006)\tLoss 0.5677 (0.4563)\tPrec@1 81.250 (85.574)\n",
            "Total time : 45.225\n",
            "Train Loss: 0.4563, Train Accuracy: 0.8557\n",
            "Test Loss : 0.4377, Test Accuracy : 0.8587 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.645 (0.645)\tData 0.473 (0.473)\tLoss 0.5473 (0.5473)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [52][100/391]\tTime 0.109 (0.126)\tData 0.005 (0.011)\tLoss 0.3902 (0.4535)\tPrec@1 88.281 (85.698)\n",
            "Epoch: [52][200/391]\tTime 0.101 (0.119)\tData 0.000 (0.009)\tLoss 0.4248 (0.4544)\tPrec@1 87.500 (85.627)\n",
            "Epoch: [52][300/391]\tTime 0.104 (0.114)\tData 0.000 (0.006)\tLoss 0.3677 (0.4549)\tPrec@1 88.281 (85.652)\n",
            "Epoch: [52][390/391]\tTime 0.073 (0.111)\tData 0.000 (0.005)\tLoss 0.4887 (0.4557)\tPrec@1 80.000 (85.672)\n",
            "Total time : 43.383\n",
            "Train Loss: 0.4557, Train Accuracy: 0.8567\n",
            "Test Loss : 0.4402, Test Accuracy : 0.8536 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.495 (0.495)\tData 0.367 (0.367)\tLoss 0.3995 (0.3995)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [53][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.5816 (0.4470)\tPrec@1 82.031 (86.054)\n",
            "Epoch: [53][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.5759 (0.4557)\tPrec@1 84.375 (85.782)\n",
            "Epoch: [53][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4653 (0.4590)\tPrec@1 85.938 (85.600)\n",
            "Epoch: [53][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.4095 (0.4596)\tPrec@1 87.500 (85.552)\n",
            "Total time : 40.409\n",
            "Train Loss: 0.4596, Train Accuracy: 0.8555\n",
            "Test Loss : 0.4398, Test Accuracy : 0.8592 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.407 (0.407)\tData 0.295 (0.295)\tLoss 0.5244 (0.5244)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [54][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.4452 (0.4398)\tPrec@1 86.719 (86.092)\n",
            "Epoch: [54][200/391]\tTime 0.108 (0.104)\tData 0.011 (0.003)\tLoss 0.4662 (0.4447)\tPrec@1 88.281 (86.039)\n",
            "Epoch: [54][300/391]\tTime 0.103 (0.104)\tData 0.000 (0.003)\tLoss 0.4933 (0.4494)\tPrec@1 84.375 (86.002)\n",
            "Epoch: [54][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.5042 (0.4469)\tPrec@1 82.500 (86.052)\n",
            "Total time : 40.447\n",
            "Train Loss: 0.4469, Train Accuracy: 0.8605\n",
            "Test Loss : 0.3880, Test Accuracy : 0.8771 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.409 (0.409)\tData 0.313 (0.313)\tLoss 0.5035 (0.5035)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [55][100/391]\tTime 0.101 (0.106)\tData 0.001 (0.005)\tLoss 0.3542 (0.4206)\tPrec@1 87.500 (86.525)\n",
            "Epoch: [55][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.5152 (0.4327)\tPrec@1 84.375 (86.338)\n",
            "Epoch: [55][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.5201 (0.4343)\tPrec@1 84.375 (86.272)\n",
            "Epoch: [55][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4981 (0.4399)\tPrec@1 85.000 (86.078)\n",
            "Total time : 40.352\n",
            "Train Loss: 0.4399, Train Accuracy: 0.8608\n",
            "Test Loss : 0.5135, Test Accuracy : 0.8296 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.346 (0.346)\tData 0.236 (0.236)\tLoss 0.4813 (0.4813)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [56][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.5808 (0.4320)\tPrec@1 81.250 (86.216)\n",
            "Epoch: [56][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.4186 (0.4399)\tPrec@1 83.594 (86.054)\n",
            "Epoch: [56][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4313 (0.4373)\tPrec@1 86.719 (86.137)\n",
            "Epoch: [56][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4646 (0.4413)\tPrec@1 85.000 (85.934)\n",
            "Total time : 40.312\n",
            "Train Loss: 0.4413, Train Accuracy: 0.8593\n",
            "Test Loss : 0.6017, Test Accuracy : 0.8108 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.372 (0.372)\tData 0.251 (0.251)\tLoss 0.6017 (0.6017)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [57][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.3081 (0.4400)\tPrec@1 91.406 (86.046)\n",
            "Epoch: [57][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.4846 (0.4480)\tPrec@1 85.938 (86.004)\n",
            "Epoch: [57][300/391]\tTime 0.108 (0.104)\tData 0.007 (0.002)\tLoss 0.4595 (0.4439)\tPrec@1 87.500 (86.127)\n",
            "Epoch: [57][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4205 (0.4499)\tPrec@1 87.500 (85.950)\n",
            "Total time : 40.338\n",
            "Train Loss: 0.4499, Train Accuracy: 0.8595\n",
            "Test Loss : 0.5281, Test Accuracy : 0.8240 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.628 (0.628)\tData 0.517 (0.517)\tLoss 0.3265 (0.3265)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [58][100/391]\tTime 0.108 (0.106)\tData 0.009 (0.006)\tLoss 0.4342 (0.4294)\tPrec@1 91.406 (86.773)\n",
            "Epoch: [58][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.4498 (0.4344)\tPrec@1 88.281 (86.579)\n",
            "Epoch: [58][300/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.3941 (0.4361)\tPrec@1 87.500 (86.405)\n",
            "Epoch: [58][390/391]\tTime 0.072 (0.105)\tData 0.000 (0.003)\tLoss 0.4459 (0.4428)\tPrec@1 86.250 (86.174)\n",
            "Total time : 40.871\n",
            "Train Loss: 0.4428, Train Accuracy: 0.8617\n",
            "Test Loss : 0.4312, Test Accuracy : 0.8609 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.380 (0.380)\tData 0.271 (0.271)\tLoss 0.5081 (0.5081)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [59][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.4442 (0.4365)\tPrec@1 85.156 (86.494)\n",
            "Epoch: [59][200/391]\tTime 0.106 (0.104)\tData 0.000 (0.003)\tLoss 0.2835 (0.4310)\tPrec@1 93.750 (86.563)\n",
            "Epoch: [59][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3228 (0.4299)\tPrec@1 92.188 (86.555)\n",
            "Epoch: [59][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.3762 (0.4337)\tPrec@1 90.000 (86.440)\n",
            "Total time : 40.517\n",
            "Train Loss: 0.4337, Train Accuracy: 0.8644\n",
            "Test Loss : 0.4873, Test Accuracy : 0.8296 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.319 (0.319)\tData 0.212 (0.212)\tLoss 0.4297 (0.4297)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [60][100/391]\tTime 0.100 (0.105)\tData 0.000 (0.004)\tLoss 0.2854 (0.4294)\tPrec@1 92.188 (86.533)\n",
            "Epoch: [60][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3942 (0.4342)\tPrec@1 85.156 (86.501)\n",
            "Epoch: [60][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.5268 (0.4396)\tPrec@1 84.375 (86.252)\n",
            "Epoch: [60][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3875 (0.4383)\tPrec@1 92.500 (86.258)\n",
            "Total time : 40.197\n",
            "Train Loss: 0.4383, Train Accuracy: 0.8626\n",
            "Test Loss : 0.3926, Test Accuracy : 0.8732 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.371 (0.371)\tData 0.259 (0.259)\tLoss 0.4060 (0.4060)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [61][100/391]\tTime 0.106 (0.105)\tData 0.007 (0.004)\tLoss 0.3536 (0.4315)\tPrec@1 90.625 (86.564)\n",
            "Epoch: [61][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.3295 (0.4345)\tPrec@1 89.062 (86.505)\n",
            "Epoch: [61][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4306 (0.4332)\tPrec@1 86.719 (86.470)\n",
            "Epoch: [61][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.5171 (0.4340)\tPrec@1 78.750 (86.394)\n",
            "Total time : 40.369\n",
            "Train Loss: 0.4340, Train Accuracy: 0.8639\n",
            "Test Loss : 0.6046, Test Accuracy : 0.8140 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.393 (0.393)\tData 0.275 (0.275)\tLoss 0.4699 (0.4699)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [62][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.3265 (0.4109)\tPrec@1 91.406 (87.136)\n",
            "Epoch: [62][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4843 (0.4281)\tPrec@1 86.719 (86.524)\n",
            "Epoch: [62][300/391]\tTime 0.109 (0.104)\tData 0.000 (0.002)\tLoss 0.3934 (0.4361)\tPrec@1 87.500 (86.192)\n",
            "Epoch: [62][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.5520 (0.4367)\tPrec@1 83.750 (86.256)\n",
            "Total time : 40.318\n",
            "Train Loss: 0.4367, Train Accuracy: 0.8626\n",
            "Test Loss : 0.5584, Test Accuracy : 0.8276 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.505 (0.505)\tData 0.383 (0.383)\tLoss 0.4071 (0.4071)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [63][100/391]\tTime 0.110 (0.105)\tData 0.010 (0.004)\tLoss 0.3351 (0.4278)\tPrec@1 91.406 (86.610)\n",
            "Epoch: [63][200/391]\tTime 0.101 (0.104)\tData 0.001 (0.003)\tLoss 0.4761 (0.4199)\tPrec@1 85.156 (86.800)\n",
            "Epoch: [63][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4499 (0.4262)\tPrec@1 85.156 (86.620)\n",
            "Epoch: [63][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.4682 (0.4294)\tPrec@1 83.750 (86.516)\n",
            "Total time : 40.475\n",
            "Train Loss: 0.4294, Train Accuracy: 0.8652\n",
            "Test Loss : 0.5077, Test Accuracy : 0.8310 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.419 (0.419)\tData 0.313 (0.313)\tLoss 0.4537 (0.4537)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [64][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.3821 (0.4273)\tPrec@1 85.938 (86.904)\n",
            "Epoch: [64][200/391]\tTime 0.121 (0.105)\tData 0.000 (0.003)\tLoss 0.3949 (0.4212)\tPrec@1 88.281 (86.944)\n",
            "Epoch: [64][300/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.4798 (0.4259)\tPrec@1 81.250 (86.656)\n",
            "Epoch: [64][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.3443 (0.4307)\tPrec@1 87.500 (86.534)\n",
            "Total time : 40.741\n",
            "Train Loss: 0.4307, Train Accuracy: 0.8653\n",
            "Test Loss : 0.4198, Test Accuracy : 0.8639 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.304 (0.304)\tData 0.206 (0.206)\tLoss 0.5045 (0.5045)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [65][100/391]\tTime 0.102 (0.105)\tData 0.001 (0.004)\tLoss 0.2651 (0.4152)\tPrec@1 91.406 (86.989)\n",
            "Epoch: [65][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.5786 (0.4217)\tPrec@1 82.031 (86.734)\n",
            "Epoch: [65][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.3952 (0.4241)\tPrec@1 90.625 (86.659)\n",
            "Epoch: [65][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.5169 (0.4246)\tPrec@1 81.250 (86.692)\n",
            "Total time : 40.172\n",
            "Train Loss: 0.4246, Train Accuracy: 0.8669\n",
            "Test Loss : 0.4695, Test Accuracy : 0.8510 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.380 (0.380)\tData 0.264 (0.264)\tLoss 0.4087 (0.4087)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [66][100/391]\tTime 0.106 (0.105)\tData 0.000 (0.004)\tLoss 0.4017 (0.3968)\tPrec@1 86.719 (87.709)\n",
            "Epoch: [66][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4126 (0.4104)\tPrec@1 89.062 (87.146)\n",
            "Epoch: [66][300/391]\tTime 0.101 (0.103)\tData 0.001 (0.002)\tLoss 0.4177 (0.4114)\tPrec@1 91.406 (87.178)\n",
            "Epoch: [66][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3282 (0.4128)\tPrec@1 90.000 (87.092)\n",
            "Total time : 40.341\n",
            "Train Loss: 0.4128, Train Accuracy: 0.8709\n",
            "Test Loss : 0.7273, Test Accuracy : 0.7902 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.412 (0.412)\tData 0.294 (0.294)\tLoss 0.4177 (0.4177)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [67][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.3458 (0.4028)\tPrec@1 86.719 (87.423)\n",
            "Epoch: [67][200/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.4259 (0.4095)\tPrec@1 85.156 (87.275)\n",
            "Epoch: [67][300/391]\tTime 0.114 (0.104)\tData 0.015 (0.003)\tLoss 0.4944 (0.4137)\tPrec@1 86.719 (87.142)\n",
            "Epoch: [67][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.3939 (0.4174)\tPrec@1 88.750 (87.008)\n",
            "Total time : 40.412\n",
            "Train Loss: 0.4174, Train Accuracy: 0.8701\n",
            "Test Loss : 0.4137, Test Accuracy : 0.8621 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.554 (0.554)\tData 0.443 (0.443)\tLoss 0.3489 (0.3489)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [68][100/391]\tTime 0.114 (0.106)\tData 0.017 (0.005)\tLoss 0.3681 (0.4054)\tPrec@1 89.844 (87.392)\n",
            "Epoch: [68][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4348 (0.4156)\tPrec@1 85.938 (87.053)\n",
            "Epoch: [68][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.3713 (0.4149)\tPrec@1 86.719 (87.025)\n",
            "Epoch: [68][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.4098 (0.4164)\tPrec@1 90.000 (86.968)\n",
            "Total time : 40.416\n",
            "Train Loss: 0.4164, Train Accuracy: 0.8697\n",
            "Test Loss : 0.3833, Test Accuracy : 0.8766 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.292 (0.292)\tData 0.188 (0.188)\tLoss 0.4155 (0.4155)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [69][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.3455 (0.4034)\tPrec@1 89.062 (87.384)\n",
            "Epoch: [69][200/391]\tTime 0.111 (0.105)\tData 0.002 (0.003)\tLoss 0.4160 (0.4069)\tPrec@1 85.156 (87.205)\n",
            "Epoch: [69][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.5330 (0.4017)\tPrec@1 82.031 (87.401)\n",
            "Epoch: [69][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.5147 (0.4085)\tPrec@1 81.250 (87.176)\n",
            "Total time : 40.534\n",
            "Train Loss: 0.4085, Train Accuracy: 0.8718\n",
            "Test Loss : 0.4188, Test Accuracy : 0.8646 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.381 (0.381)\tData 0.253 (0.253)\tLoss 0.4718 (0.4718)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [70][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.4030 (0.3989)\tPrec@1 87.500 (87.577)\n",
            "Epoch: [70][200/391]\tTime 0.100 (0.104)\tData 0.001 (0.003)\tLoss 0.3740 (0.4066)\tPrec@1 87.500 (87.247)\n",
            "Epoch: [70][300/391]\tTime 0.101 (0.104)\tData 0.001 (0.002)\tLoss 0.3780 (0.4024)\tPrec@1 88.281 (87.458)\n",
            "Epoch: [70][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3709 (0.4065)\tPrec@1 87.500 (87.314)\n",
            "Total time : 40.299\n",
            "Train Loss: 0.4065, Train Accuracy: 0.8731\n",
            "Test Loss : 0.3989, Test Accuracy : 0.8732 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.371 (0.371)\tData 0.259 (0.259)\tLoss 0.4259 (0.4259)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [71][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.3012 (0.4015)\tPrec@1 90.625 (87.485)\n",
            "Epoch: [71][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4390 (0.4007)\tPrec@1 86.719 (87.582)\n",
            "Epoch: [71][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.2815 (0.4052)\tPrec@1 93.750 (87.466)\n",
            "Epoch: [71][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.7765 (0.4088)\tPrec@1 81.250 (87.328)\n",
            "Total time : 40.425\n",
            "Train Loss: 0.4088, Train Accuracy: 0.8733\n",
            "Test Loss : 0.3975, Test Accuracy : 0.8687 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.399 (0.399)\tData 0.298 (0.298)\tLoss 0.4159 (0.4159)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [72][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.3553 (0.3744)\tPrec@1 86.719 (88.606)\n",
            "Epoch: [72][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4336 (0.3876)\tPrec@1 86.719 (88.025)\n",
            "Epoch: [72][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.3869 (0.3978)\tPrec@1 87.500 (87.710)\n",
            "Epoch: [72][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.5623 (0.3969)\tPrec@1 83.750 (87.796)\n",
            "Total time : 40.275\n",
            "Train Loss: 0.3969, Train Accuracy: 0.8780\n",
            "Test Loss : 0.4392, Test Accuracy : 0.8558 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.394 (0.394)\tData 0.259 (0.259)\tLoss 0.3898 (0.3898)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [73][100/391]\tTime 0.100 (0.105)\tData 0.000 (0.004)\tLoss 0.3526 (0.3941)\tPrec@1 88.281 (87.840)\n",
            "Epoch: [73][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4729 (0.3975)\tPrec@1 87.500 (87.675)\n",
            "Epoch: [73][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.5764 (0.4002)\tPrec@1 82.031 (87.531)\n",
            "Epoch: [73][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3726 (0.4012)\tPrec@1 90.000 (87.570)\n",
            "Total time : 40.317\n",
            "Train Loss: 0.4012, Train Accuracy: 0.8757\n",
            "Test Loss : 0.3721, Test Accuracy : 0.8816 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.387 (0.387)\tData 0.264 (0.264)\tLoss 0.3477 (0.3477)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [74][100/391]\tTime 0.117 (0.106)\tData 0.016 (0.004)\tLoss 0.3408 (0.3844)\tPrec@1 88.281 (88.351)\n",
            "Epoch: [74][200/391]\tTime 0.108 (0.105)\tData 0.000 (0.003)\tLoss 0.4744 (0.3971)\tPrec@1 86.719 (87.803)\n",
            "Epoch: [74][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2768 (0.3959)\tPrec@1 90.625 (87.791)\n",
            "Epoch: [74][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.3379 (0.3943)\tPrec@1 91.250 (87.812)\n",
            "Total time : 40.488\n",
            "Train Loss: 0.3943, Train Accuracy: 0.8781\n",
            "Test Loss : 0.3465, Test Accuracy : 0.8888 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.366 (0.366)\tData 0.254 (0.254)\tLoss 0.4057 (0.4057)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [75][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.005)\tLoss 0.4904 (0.3612)\tPrec@1 85.938 (88.707)\n",
            "Epoch: [75][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.3070 (0.3796)\tPrec@1 90.625 (88.258)\n",
            "Epoch: [75][300/391]\tTime 0.110 (0.104)\tData 0.015 (0.003)\tLoss 0.4764 (0.3892)\tPrec@1 84.375 (87.863)\n",
            "Epoch: [75][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.3530 (0.3877)\tPrec@1 90.000 (87.958)\n",
            "Total time : 40.301\n",
            "Train Loss: 0.3877, Train Accuracy: 0.8796\n",
            "Test Loss : 0.3922, Test Accuracy : 0.8711 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.517 (0.517)\tData 0.360 (0.360)\tLoss 0.3292 (0.3292)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [76][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.4426 (0.3780)\tPrec@1 88.281 (88.026)\n",
            "Epoch: [76][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2851 (0.3826)\tPrec@1 92.969 (87.861)\n",
            "Epoch: [76][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.3814 (0.3840)\tPrec@1 87.500 (87.879)\n",
            "Epoch: [76][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.5165 (0.3836)\tPrec@1 85.000 (87.902)\n",
            "Total time : 40.573\n",
            "Train Loss: 0.3836, Train Accuracy: 0.8790\n",
            "Test Loss : 0.4522, Test Accuracy : 0.8512 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.305 (0.305)\tData 0.190 (0.190)\tLoss 0.3896 (0.3896)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [77][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.4106 (0.3798)\tPrec@1 88.281 (88.204)\n",
            "Epoch: [77][200/391]\tTime 0.099 (0.104)\tData 0.000 (0.003)\tLoss 0.4140 (0.3858)\tPrec@1 86.719 (87.978)\n",
            "Epoch: [77][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.4034 (0.3879)\tPrec@1 86.719 (87.876)\n",
            "Epoch: [77][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.4021 (0.3893)\tPrec@1 91.250 (87.848)\n",
            "Total time : 40.192\n",
            "Train Loss: 0.3893, Train Accuracy: 0.8785\n",
            "Test Loss : 0.3362, Test Accuracy : 0.8920 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.362 (0.362)\tData 0.256 (0.256)\tLoss 0.3410 (0.3410)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [78][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.3298 (0.3656)\tPrec@1 90.625 (89.109)\n",
            "Epoch: [78][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.4119 (0.3757)\tPrec@1 90.625 (88.487)\n",
            "Epoch: [78][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.2982 (0.3775)\tPrec@1 89.844 (88.445)\n",
            "Epoch: [78][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.2932 (0.3819)\tPrec@1 92.500 (88.296)\n",
            "Total time : 40.225\n",
            "Train Loss: 0.3819, Train Accuracy: 0.8830\n",
            "Test Loss : 0.3777, Test Accuracy : 0.8768 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.385 (0.385)\tData 0.261 (0.261)\tLoss 0.3320 (0.3320)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [79][100/391]\tTime 0.133 (0.106)\tData 0.020 (0.004)\tLoss 0.3742 (0.3673)\tPrec@1 91.406 (88.722)\n",
            "Epoch: [79][200/391]\tTime 0.101 (0.105)\tData 0.001 (0.003)\tLoss 0.3172 (0.3730)\tPrec@1 90.625 (88.448)\n",
            "Epoch: [79][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.3059 (0.3727)\tPrec@1 91.406 (88.453)\n",
            "Epoch: [79][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.002)\tLoss 0.3142 (0.3744)\tPrec@1 91.250 (88.464)\n",
            "Total time : 40.604\n",
            "Train Loss: 0.3744, Train Accuracy: 0.8846\n",
            "Test Loss : 0.4130, Test Accuracy : 0.8685 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.374 (0.374)\tData 0.252 (0.252)\tLoss 0.3217 (0.3217)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [80][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.3838 (0.3864)\tPrec@1 91.406 (87.910)\n",
            "Epoch: [80][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.4837 (0.3848)\tPrec@1 84.375 (88.036)\n",
            "Epoch: [80][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.4310 (0.3819)\tPrec@1 83.594 (88.094)\n",
            "Epoch: [80][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4193 (0.3816)\tPrec@1 88.750 (88.180)\n",
            "Total time : 40.262\n",
            "Train Loss: 0.3816, Train Accuracy: 0.8818\n",
            "Test Loss : 0.3464, Test Accuracy : 0.8836 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.489 (0.489)\tData 0.333 (0.333)\tLoss 0.3791 (0.3791)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [81][100/391]\tTime 0.102 (0.107)\tData 0.000 (0.005)\tLoss 0.3624 (0.3693)\tPrec@1 89.062 (88.521)\n",
            "Epoch: [81][200/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.3223 (0.3679)\tPrec@1 90.625 (88.728)\n",
            "Epoch: [81][300/391]\tTime 0.106 (0.105)\tData 0.008 (0.003)\tLoss 0.3620 (0.3727)\tPrec@1 91.406 (88.554)\n",
            "Epoch: [81][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.4386 (0.3755)\tPrec@1 85.000 (88.440)\n",
            "Total time : 40.696\n",
            "Train Loss: 0.3755, Train Accuracy: 0.8844\n",
            "Test Loss : 0.4100, Test Accuracy : 0.8650 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.388 (0.388)\tData 0.265 (0.265)\tLoss 0.5530 (0.5530)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [82][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.4291 (0.3760)\tPrec@1 85.156 (88.258)\n",
            "Epoch: [82][200/391]\tTime 0.101 (0.104)\tData 0.002 (0.002)\tLoss 0.2837 (0.3673)\tPrec@1 92.188 (88.697)\n",
            "Epoch: [82][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.3567 (0.3659)\tPrec@1 89.062 (88.800)\n",
            "Epoch: [82][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.3712 (0.3682)\tPrec@1 87.500 (88.678)\n",
            "Total time : 40.339\n",
            "Train Loss: 0.3682, Train Accuracy: 0.8868\n",
            "Test Loss : 0.4713, Test Accuracy : 0.8343 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.377 (0.377)\tData 0.249 (0.249)\tLoss 0.3657 (0.3657)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [83][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.4671 (0.3594)\tPrec@1 86.719 (89.032)\n",
            "Epoch: [83][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.4226 (0.3642)\tPrec@1 85.938 (88.794)\n",
            "Epoch: [83][300/391]\tTime 0.106 (0.104)\tData 0.010 (0.002)\tLoss 0.3715 (0.3703)\tPrec@1 89.062 (88.600)\n",
            "Epoch: [83][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3473 (0.3735)\tPrec@1 88.750 (88.514)\n",
            "Total time : 40.246\n",
            "Train Loss: 0.3735, Train Accuracy: 0.8851\n",
            "Test Loss : 0.3495, Test Accuracy : 0.8863 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.464 (0.464)\tData 0.346 (0.346)\tLoss 0.4138 (0.4138)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [84][100/391]\tTime 0.108 (0.106)\tData 0.010 (0.005)\tLoss 0.3265 (0.3641)\tPrec@1 91.406 (88.583)\n",
            "Epoch: [84][200/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.3500 (0.3686)\tPrec@1 86.719 (88.631)\n",
            "Epoch: [84][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.4747 (0.3716)\tPrec@1 84.375 (88.481)\n",
            "Epoch: [84][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.3011 (0.3689)\tPrec@1 91.250 (88.552)\n",
            "Total time : 40.503\n",
            "Train Loss: 0.3689, Train Accuracy: 0.8855\n",
            "Test Loss : 0.5307, Test Accuracy : 0.8256 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.315 (0.315)\tData 0.218 (0.218)\tLoss 0.2971 (0.2971)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [85][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.3867 (0.3625)\tPrec@1 88.281 (88.753)\n",
            "Epoch: [85][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.3266 (0.3650)\tPrec@1 92.188 (88.740)\n",
            "Epoch: [85][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4538 (0.3628)\tPrec@1 86.719 (88.824)\n",
            "Epoch: [85][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.2733 (0.3638)\tPrec@1 92.500 (88.792)\n",
            "Total time : 40.339\n",
            "Train Loss: 0.3638, Train Accuracy: 0.8879\n",
            "Test Loss : 0.3576, Test Accuracy : 0.8813 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.395 (0.395)\tData 0.269 (0.269)\tLoss 0.3130 (0.3130)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [86][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.5220 (0.3501)\tPrec@1 82.812 (89.202)\n",
            "Epoch: [86][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3189 (0.3549)\tPrec@1 89.844 (88.903)\n",
            "Epoch: [86][300/391]\tTime 0.103 (0.105)\tData 0.000 (0.003)\tLoss 0.3313 (0.3614)\tPrec@1 89.844 (88.738)\n",
            "Epoch: [86][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.4466 (0.3621)\tPrec@1 86.250 (88.712)\n",
            "Total time : 40.595\n",
            "Train Loss: 0.3621, Train Accuracy: 0.8871\n",
            "Test Loss : 0.3741, Test Accuracy : 0.8724 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.413 (0.413)\tData 0.286 (0.286)\tLoss 0.3197 (0.3197)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [87][100/391]\tTime 0.111 (0.106)\tData 0.011 (0.005)\tLoss 0.2795 (0.3472)\tPrec@1 92.188 (89.271)\n",
            "Epoch: [87][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3076 (0.3586)\tPrec@1 92.188 (88.853)\n",
            "Epoch: [87][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.3939 (0.3579)\tPrec@1 89.844 (88.953)\n",
            "Epoch: [87][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.3338 (0.3590)\tPrec@1 90.000 (88.956)\n",
            "Total time : 40.333\n",
            "Train Loss: 0.3590, Train Accuracy: 0.8896\n",
            "Test Loss : 0.3209, Test Accuracy : 0.8929 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.388 (0.388)\tData 0.273 (0.273)\tLoss 0.3624 (0.3624)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [88][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.2439 (0.3378)\tPrec@1 95.312 (89.790)\n",
            "Epoch: [88][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2892 (0.3502)\tPrec@1 93.750 (89.191)\n",
            "Epoch: [88][300/391]\tTime 0.114 (0.104)\tData 0.010 (0.003)\tLoss 0.3665 (0.3546)\tPrec@1 89.062 (89.073)\n",
            "Epoch: [88][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.5200 (0.3589)\tPrec@1 85.000 (88.928)\n",
            "Total time : 40.373\n",
            "Train Loss: 0.3589, Train Accuracy: 0.8893\n",
            "Test Loss : 0.3723, Test Accuracy : 0.8774 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.455 (0.455)\tData 0.337 (0.337)\tLoss 0.3456 (0.3456)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [89][100/391]\tTime 0.107 (0.109)\tData 0.000 (0.007)\tLoss 0.3266 (0.3408)\tPrec@1 90.625 (89.534)\n",
            "Epoch: [89][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.3483 (0.3474)\tPrec@1 89.062 (89.377)\n",
            "Epoch: [89][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2625 (0.3440)\tPrec@1 90.625 (89.496)\n",
            "Epoch: [89][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.003)\tLoss 0.3941 (0.3462)\tPrec@1 86.250 (89.396)\n",
            "Total time : 40.795\n",
            "Train Loss: 0.3462, Train Accuracy: 0.8940\n",
            "Test Loss : 0.3852, Test Accuracy : 0.8722 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.400 (0.400)\tData 0.274 (0.274)\tLoss 0.3575 (0.3575)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [90][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.2575 (0.3477)\tPrec@1 93.750 (89.380)\n",
            "Epoch: [90][200/391]\tTime 0.113 (0.104)\tData 0.014 (0.003)\tLoss 0.3276 (0.3413)\tPrec@1 89.062 (89.556)\n",
            "Epoch: [90][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2156 (0.3462)\tPrec@1 95.312 (89.449)\n",
            "Epoch: [90][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.4080 (0.3455)\tPrec@1 85.000 (89.482)\n",
            "Total time : 40.401\n",
            "Train Loss: 0.3455, Train Accuracy: 0.8948\n",
            "Test Loss : 0.3436, Test Accuracy : 0.8920 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.290 (0.290)\tData 0.189 (0.189)\tLoss 0.3216 (0.3216)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [91][100/391]\tTime 0.100 (0.105)\tData 0.000 (0.004)\tLoss 0.3094 (0.3353)\tPrec@1 92.969 (89.983)\n",
            "Epoch: [91][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.2825 (0.3334)\tPrec@1 93.750 (89.929)\n",
            "Epoch: [91][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3665 (0.3399)\tPrec@1 91.406 (89.771)\n",
            "Epoch: [91][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.3805 (0.3469)\tPrec@1 86.250 (89.458)\n",
            "Total time : 40.404\n",
            "Train Loss: 0.3469, Train Accuracy: 0.8946\n",
            "Test Loss : 0.3514, Test Accuracy : 0.8842 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.393 (0.393)\tData 0.268 (0.268)\tLoss 0.3683 (0.3683)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [92][100/391]\tTime 0.106 (0.105)\tData 0.000 (0.004)\tLoss 0.4012 (0.3324)\tPrec@1 88.281 (89.821)\n",
            "Epoch: [92][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.3358 (0.3363)\tPrec@1 89.062 (89.646)\n",
            "Epoch: [92][300/391]\tTime 0.100 (0.103)\tData 0.000 (0.002)\tLoss 0.3307 (0.3392)\tPrec@1 92.188 (89.571)\n",
            "Epoch: [92][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3070 (0.3403)\tPrec@1 92.500 (89.486)\n",
            "Total time : 40.306\n",
            "Train Loss: 0.3403, Train Accuracy: 0.8949\n",
            "Test Loss : 0.3065, Test Accuracy : 0.8970 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.379 (0.379)\tData 0.258 (0.258)\tLoss 0.2405 (0.2405)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [93][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.3551 (0.3414)\tPrec@1 85.938 (89.140)\n",
            "Epoch: [93][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3054 (0.3381)\tPrec@1 91.406 (89.525)\n",
            "Epoch: [93][300/391]\tTime 0.114 (0.104)\tData 0.000 (0.002)\tLoss 0.3363 (0.3379)\tPrec@1 92.188 (89.460)\n",
            "Epoch: [93][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.2638 (0.3369)\tPrec@1 91.250 (89.488)\n",
            "Total time : 40.315\n",
            "Train Loss: 0.3369, Train Accuracy: 0.8949\n",
            "Test Loss : 0.3300, Test Accuracy : 0.8952 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.668 (0.668)\tData 0.517 (0.517)\tLoss 0.3345 (0.3345)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [94][100/391]\tTime 0.101 (0.110)\tData 0.000 (0.007)\tLoss 0.3566 (0.3227)\tPrec@1 89.844 (90.300)\n",
            "Epoch: [94][200/391]\tTime 0.101 (0.106)\tData 0.001 (0.004)\tLoss 0.3315 (0.3288)\tPrec@1 87.500 (90.007)\n",
            "Epoch: [94][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2775 (0.3338)\tPrec@1 92.188 (89.826)\n",
            "Epoch: [94][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.2341 (0.3348)\tPrec@1 95.000 (89.796)\n",
            "Total time : 40.786\n",
            "Train Loss: 0.3348, Train Accuracy: 0.8980\n",
            "Test Loss : 0.3846, Test Accuracy : 0.8723 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.404 (0.404)\tData 0.290 (0.290)\tLoss 0.3477 (0.3477)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [95][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.005)\tLoss 0.3101 (0.3174)\tPrec@1 91.406 (90.377)\n",
            "Epoch: [95][200/391]\tTime 0.105 (0.104)\tData 0.007 (0.003)\tLoss 0.3679 (0.3303)\tPrec@1 85.938 (89.766)\n",
            "Epoch: [95][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.003)\tLoss 0.3001 (0.3337)\tPrec@1 91.406 (89.732)\n",
            "Epoch: [95][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.3609 (0.3363)\tPrec@1 86.250 (89.628)\n",
            "Total time : 40.384\n",
            "Train Loss: 0.3363, Train Accuracy: 0.8963\n",
            "Test Loss : 0.4868, Test Accuracy : 0.8403 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.380 (0.380)\tData 0.253 (0.253)\tLoss 0.3175 (0.3175)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [96][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.3487 (0.3228)\tPrec@1 89.844 (89.944)\n",
            "Epoch: [96][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.2935 (0.3271)\tPrec@1 89.844 (89.933)\n",
            "Epoch: [96][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.2546 (0.3304)\tPrec@1 93.750 (89.987)\n",
            "Epoch: [96][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.4183 (0.3330)\tPrec@1 90.000 (89.868)\n",
            "Total time : 40.483\n",
            "Train Loss: 0.3330, Train Accuracy: 0.8987\n",
            "Test Loss : 0.3641, Test Accuracy : 0.8790 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.306 (0.306)\tData 0.179 (0.179)\tLoss 0.2700 (0.2700)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [97][100/391]\tTime 0.108 (0.105)\tData 0.000 (0.004)\tLoss 0.2953 (0.3191)\tPrec@1 89.844 (90.470)\n",
            "Epoch: [97][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.4458 (0.3243)\tPrec@1 87.500 (90.089)\n",
            "Epoch: [97][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2405 (0.3275)\tPrec@1 93.750 (89.958)\n",
            "Epoch: [97][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.2667 (0.3290)\tPrec@1 91.250 (89.948)\n",
            "Total time : 40.351\n",
            "Train Loss: 0.3290, Train Accuracy: 0.8995\n",
            "Test Loss : 0.3727, Test Accuracy : 0.8801 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.399 (0.399)\tData 0.293 (0.293)\tLoss 0.2596 (0.2596)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [98][100/391]\tTime 0.103 (0.106)\tData 0.000 (0.005)\tLoss 0.3746 (0.3115)\tPrec@1 86.719 (90.439)\n",
            "Epoch: [98][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.2651 (0.3217)\tPrec@1 92.188 (90.069)\n",
            "Epoch: [98][300/391]\tTime 0.107 (0.104)\tData 0.000 (0.002)\tLoss 0.2926 (0.3249)\tPrec@1 90.625 (90.062)\n",
            "Epoch: [98][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.2661 (0.3268)\tPrec@1 91.250 (89.994)\n",
            "Total time : 40.471\n",
            "Train Loss: 0.3268, Train Accuracy: 0.8999\n",
            "Test Loss : 0.2941, Test Accuracy : 0.9057 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.592 (0.592)\tData 0.427 (0.427)\tLoss 0.3837 (0.3837)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [99][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.005)\tLoss 0.3022 (0.3242)\tPrec@1 87.500 (89.898)\n",
            "Epoch: [99][200/391]\tTime 0.102 (0.105)\tData 0.001 (0.004)\tLoss 0.2777 (0.3206)\tPrec@1 92.188 (90.058)\n",
            "Epoch: [99][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3522 (0.3182)\tPrec@1 88.281 (90.197)\n",
            "Epoch: [99][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.003)\tLoss 0.3119 (0.3223)\tPrec@1 90.000 (90.152)\n",
            "Total time : 40.689\n",
            "Train Loss: 0.3223, Train Accuracy: 0.9015\n",
            "Test Loss : 0.3093, Test Accuracy : 0.8997 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.391 (0.391)\tData 0.265 (0.265)\tLoss 0.3558 (0.3558)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [100][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.3665 (0.3138)\tPrec@1 87.500 (90.540)\n",
            "Epoch: [100][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.3509 (0.3135)\tPrec@1 89.062 (90.458)\n",
            "Epoch: [100][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.3972 (0.3183)\tPrec@1 88.281 (90.303)\n",
            "Epoch: [100][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.2917 (0.3174)\tPrec@1 93.750 (90.320)\n",
            "Total time : 40.409\n",
            "Train Loss: 0.3174, Train Accuracy: 0.9032\n",
            "Test Loss : 0.3230, Test Accuracy : 0.8905 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.385 (0.385)\tData 0.272 (0.272)\tLoss 0.3476 (0.3476)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [101][100/391]\tTime 0.101 (0.105)\tData 0.001 (0.004)\tLoss 0.3211 (0.3040)\tPrec@1 90.625 (90.726)\n",
            "Epoch: [101][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2501 (0.3044)\tPrec@1 93.750 (90.780)\n",
            "Epoch: [101][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.3740 (0.3085)\tPrec@1 86.719 (90.586)\n",
            "Epoch: [101][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.002)\tLoss 0.2949 (0.3100)\tPrec@1 91.250 (90.568)\n",
            "Total time : 40.474\n",
            "Train Loss: 0.3100, Train Accuracy: 0.9057\n",
            "Test Loss : 0.3488, Test Accuracy : 0.8880 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.399 (0.399)\tData 0.274 (0.274)\tLoss 0.3114 (0.3114)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [102][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.3637 (0.3052)\tPrec@1 88.281 (90.733)\n",
            "Epoch: [102][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.3445 (0.3089)\tPrec@1 86.719 (90.598)\n",
            "Epoch: [102][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.3463 (0.3107)\tPrec@1 89.062 (90.563)\n",
            "Epoch: [102][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3273 (0.3095)\tPrec@1 90.000 (90.578)\n",
            "Total time : 40.458\n",
            "Train Loss: 0.3095, Train Accuracy: 0.9058\n",
            "Test Loss : 0.3065, Test Accuracy : 0.8997 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.320 (0.320)\tData 0.213 (0.213)\tLoss 0.2716 (0.2716)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [103][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.3955 (0.2884)\tPrec@1 86.719 (91.329)\n",
            "Epoch: [103][200/391]\tTime 0.105 (0.104)\tData 0.000 (0.003)\tLoss 0.2981 (0.2958)\tPrec@1 92.969 (91.091)\n",
            "Epoch: [103][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2671 (0.3054)\tPrec@1 93.750 (90.856)\n",
            "Epoch: [103][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.3183 (0.3086)\tPrec@1 88.750 (90.732)\n",
            "Total time : 40.624\n",
            "Train Loss: 0.3086, Train Accuracy: 0.9073\n",
            "Test Loss : 0.3029, Test Accuracy : 0.8976 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.379 (0.379)\tData 0.264 (0.264)\tLoss 0.2532 (0.2532)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [104][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.2928 (0.2872)\tPrec@1 91.406 (91.476)\n",
            "Epoch: [104][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3615 (0.2931)\tPrec@1 88.281 (91.317)\n",
            "Epoch: [104][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3750 (0.2946)\tPrec@1 88.281 (91.238)\n",
            "Epoch: [104][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.3512 (0.2990)\tPrec@1 88.750 (91.122)\n",
            "Total time : 40.304\n",
            "Train Loss: 0.2990, Train Accuracy: 0.9112\n",
            "Test Loss : 0.2801, Test Accuracy : 0.9060 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.384 (0.384)\tData 0.262 (0.262)\tLoss 0.3610 (0.3610)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [105][100/391]\tTime 0.105 (0.104)\tData 0.000 (0.003)\tLoss 0.3462 (0.2979)\tPrec@1 89.844 (91.151)\n",
            "Epoch: [105][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.2541 (0.3013)\tPrec@1 92.969 (91.014)\n",
            "Epoch: [105][300/391]\tTime 0.102 (0.103)\tData 0.001 (0.002)\tLoss 0.3126 (0.3066)\tPrec@1 91.406 (90.794)\n",
            "Epoch: [105][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3673 (0.3082)\tPrec@1 90.000 (90.658)\n",
            "Total time : 40.310\n",
            "Train Loss: 0.3082, Train Accuracy: 0.9066\n",
            "Test Loss : 0.2933, Test Accuracy : 0.9055 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.387 (0.387)\tData 0.268 (0.268)\tLoss 0.3124 (0.3124)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [106][100/391]\tTime 0.101 (0.109)\tData 0.000 (0.006)\tLoss 0.2870 (0.2902)\tPrec@1 91.406 (91.375)\n",
            "Epoch: [106][200/391]\tTime 0.114 (0.106)\tData 0.019 (0.004)\tLoss 0.2833 (0.2879)\tPrec@1 91.406 (91.305)\n",
            "Epoch: [106][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2897 (0.2914)\tPrec@1 92.969 (91.248)\n",
            "Epoch: [106][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.3558 (0.2964)\tPrec@1 90.000 (91.104)\n",
            "Total time : 40.662\n",
            "Train Loss: 0.2964, Train Accuracy: 0.9110\n",
            "Test Loss : 0.2793, Test Accuracy : 0.9119 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.409 (0.409)\tData 0.291 (0.291)\tLoss 0.2357 (0.2357)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [107][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.3063 (0.2851)\tPrec@1 89.844 (91.360)\n",
            "Epoch: [107][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.3023 (0.2890)\tPrec@1 90.625 (91.457)\n",
            "Epoch: [107][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.3506 (0.2922)\tPrec@1 89.844 (91.318)\n",
            "Epoch: [107][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.3433 (0.2933)\tPrec@1 88.750 (91.242)\n",
            "Total time : 40.344\n",
            "Train Loss: 0.2933, Train Accuracy: 0.9124\n",
            "Test Loss : 0.3020, Test Accuracy : 0.9004 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.346 (0.346)\tData 0.238 (0.238)\tLoss 0.2911 (0.2911)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [108][100/391]\tTime 0.110 (0.105)\tData 0.000 (0.004)\tLoss 0.3491 (0.2873)\tPrec@1 89.062 (91.368)\n",
            "Epoch: [108][200/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.4051 (0.2887)\tPrec@1 85.156 (91.325)\n",
            "Epoch: [108][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.3010 (0.2946)\tPrec@1 90.625 (91.144)\n",
            "Epoch: [108][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.2629 (0.2968)\tPrec@1 95.000 (91.052)\n",
            "Total time : 40.446\n",
            "Train Loss: 0.2968, Train Accuracy: 0.9105\n",
            "Test Loss : 0.2745, Test Accuracy : 0.9119 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.380 (0.380)\tData 0.276 (0.276)\tLoss 0.1995 (0.1995)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [109][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.2051 (0.2812)\tPrec@1 94.531 (91.515)\n",
            "Epoch: [109][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3279 (0.2861)\tPrec@1 90.625 (91.402)\n",
            "Epoch: [109][300/391]\tTime 0.103 (0.104)\tData 0.004 (0.002)\tLoss 0.2731 (0.2875)\tPrec@1 92.969 (91.357)\n",
            "Epoch: [109][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.2275 (0.2888)\tPrec@1 95.000 (91.346)\n",
            "Total time : 40.308\n",
            "Train Loss: 0.2888, Train Accuracy: 0.9135\n",
            "Test Loss : 0.2963, Test Accuracy : 0.9053 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.481 (0.481)\tData 0.326 (0.326)\tLoss 0.3405 (0.3405)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [110][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.005)\tLoss 0.2609 (0.2896)\tPrec@1 93.750 (91.259)\n",
            "Epoch: [110][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.2504 (0.2889)\tPrec@1 91.406 (91.286)\n",
            "Epoch: [110][300/391]\tTime 0.101 (0.105)\tData 0.001 (0.003)\tLoss 0.3390 (0.2879)\tPrec@1 90.625 (91.391)\n",
            "Epoch: [110][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.1938 (0.2870)\tPrec@1 97.500 (91.496)\n",
            "Total time : 40.639\n",
            "Train Loss: 0.2870, Train Accuracy: 0.9150\n",
            "Test Loss : 0.2745, Test Accuracy : 0.9114 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.564 (0.564)\tData 0.401 (0.401)\tLoss 0.3012 (0.3012)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [111][100/391]\tTime 0.101 (0.109)\tData 0.000 (0.006)\tLoss 0.2510 (0.2705)\tPrec@1 94.531 (91.685)\n",
            "Epoch: [111][200/391]\tTime 0.114 (0.106)\tData 0.011 (0.004)\tLoss 0.2648 (0.2786)\tPrec@1 92.188 (91.468)\n",
            "Epoch: [111][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3209 (0.2787)\tPrec@1 88.281 (91.539)\n",
            "Epoch: [111][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.2724 (0.2832)\tPrec@1 92.500 (91.398)\n",
            "Total time : 40.674\n",
            "Train Loss: 0.2832, Train Accuracy: 0.9140\n",
            "Test Loss : 0.3000, Test Accuracy : 0.9070 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.341 (0.341)\tData 0.220 (0.220)\tLoss 0.2048 (0.2048)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [112][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.004)\tLoss 0.3757 (0.2706)\tPrec@1 85.156 (91.754)\n",
            "Epoch: [112][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2575 (0.2739)\tPrec@1 92.969 (91.748)\n",
            "Epoch: [112][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.2927 (0.2794)\tPrec@1 89.062 (91.629)\n",
            "Epoch: [112][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.2801 (0.2806)\tPrec@1 88.750 (91.652)\n",
            "Total time : 40.326\n",
            "Train Loss: 0.2806, Train Accuracy: 0.9165\n",
            "Test Loss : 0.2779, Test Accuracy : 0.9093 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.377 (0.377)\tData 0.277 (0.277)\tLoss 0.2797 (0.2797)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [113][100/391]\tTime 0.111 (0.105)\tData 0.011 (0.004)\tLoss 0.2959 (0.2674)\tPrec@1 91.406 (91.932)\n",
            "Epoch: [113][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.3685 (0.2731)\tPrec@1 91.406 (91.694)\n",
            "Epoch: [113][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.4504 (0.2766)\tPrec@1 85.156 (91.694)\n",
            "Epoch: [113][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.2745 (0.2806)\tPrec@1 90.000 (91.550)\n",
            "Total time : 40.515\n",
            "Train Loss: 0.2806, Train Accuracy: 0.9155\n",
            "Test Loss : 0.3002, Test Accuracy : 0.9036 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.381 (0.381)\tData 0.251 (0.251)\tLoss 0.3359 (0.3359)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [114][100/391]\tTime 0.101 (0.106)\tData 0.001 (0.005)\tLoss 0.3229 (0.2605)\tPrec@1 89.844 (92.203)\n",
            "Epoch: [114][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2409 (0.2642)\tPrec@1 92.188 (92.048)\n",
            "Epoch: [114][300/391]\tTime 0.111 (0.103)\tData 0.011 (0.002)\tLoss 0.3175 (0.2701)\tPrec@1 92.969 (91.920)\n",
            "Epoch: [114][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.3304 (0.2732)\tPrec@1 90.000 (91.818)\n",
            "Total time : 40.331\n",
            "Train Loss: 0.2732, Train Accuracy: 0.9182\n",
            "Test Loss : 0.3279, Test Accuracy : 0.8904 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.417 (0.417)\tData 0.291 (0.291)\tLoss 0.3058 (0.3058)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [115][100/391]\tTime 0.102 (0.107)\tData 0.000 (0.005)\tLoss 0.2671 (0.2681)\tPrec@1 91.406 (92.064)\n",
            "Epoch: [115][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2664 (0.2704)\tPrec@1 89.062 (91.958)\n",
            "Epoch: [115][300/391]\tTime 0.103 (0.104)\tData 0.001 (0.003)\tLoss 0.2132 (0.2675)\tPrec@1 93.750 (92.058)\n",
            "Epoch: [115][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.003)\tLoss 0.1714 (0.2661)\tPrec@1 96.250 (92.066)\n",
            "Total time : 40.607\n",
            "Train Loss: 0.2661, Train Accuracy: 0.9207\n",
            "Test Loss : 0.2716, Test Accuracy : 0.9119 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.382 (0.382)\tData 0.255 (0.255)\tLoss 0.2066 (0.2066)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [116][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.2341 (0.2438)\tPrec@1 92.969 (93.007)\n",
            "Epoch: [116][200/391]\tTime 0.109 (0.104)\tData 0.012 (0.003)\tLoss 0.3528 (0.2559)\tPrec@1 88.281 (92.498)\n",
            "Epoch: [116][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2097 (0.2613)\tPrec@1 93.750 (92.317)\n",
            "Epoch: [116][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1842 (0.2636)\tPrec@1 95.000 (92.218)\n",
            "Total time : 40.306\n",
            "Train Loss: 0.2636, Train Accuracy: 0.9222\n",
            "Test Loss : 0.2464, Test Accuracy : 0.9184 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.436 (0.436)\tData 0.330 (0.330)\tLoss 0.2389 (0.2389)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [117][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.1988 (0.2488)\tPrec@1 96.094 (92.621)\n",
            "Epoch: [117][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.1963 (0.2503)\tPrec@1 95.312 (92.611)\n",
            "Epoch: [117][300/391]\tTime 0.108 (0.104)\tData 0.000 (0.003)\tLoss 0.2824 (0.2560)\tPrec@1 91.406 (92.447)\n",
            "Epoch: [117][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.1694 (0.2604)\tPrec@1 93.750 (92.266)\n",
            "Total time : 40.417\n",
            "Train Loss: 0.2604, Train Accuracy: 0.9227\n",
            "Test Loss : 0.2691, Test Accuracy : 0.9084 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.614 (0.614)\tData 0.444 (0.444)\tLoss 0.2258 (0.2258)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [118][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.006)\tLoss 0.3401 (0.2572)\tPrec@1 88.281 (92.358)\n",
            "Epoch: [118][200/391]\tTime 0.105 (0.106)\tData 0.008 (0.004)\tLoss 0.2695 (0.2549)\tPrec@1 93.750 (92.557)\n",
            "Epoch: [118][300/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.3332 (0.2577)\tPrec@1 87.500 (92.502)\n",
            "Epoch: [118][390/391]\tTime 0.074 (0.105)\tData 0.000 (0.003)\tLoss 0.2240 (0.2585)\tPrec@1 92.500 (92.480)\n",
            "Total time : 40.877\n",
            "Train Loss: 0.2585, Train Accuracy: 0.9248\n",
            "Test Loss : 0.2646, Test Accuracy : 0.9122 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.389 (0.389)\tData 0.274 (0.274)\tLoss 0.3396 (0.3396)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [119][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.2705 (0.2430)\tPrec@1 92.188 (92.868)\n",
            "Epoch: [119][200/391]\tTime 0.107 (0.105)\tData 0.000 (0.003)\tLoss 0.3578 (0.2518)\tPrec@1 90.625 (92.549)\n",
            "Epoch: [119][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.1619 (0.2523)\tPrec@1 97.656 (92.637)\n",
            "Epoch: [119][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.3434 (0.2532)\tPrec@1 91.250 (92.596)\n",
            "Total time : 40.471\n",
            "Train Loss: 0.2532, Train Accuracy: 0.9260\n",
            "Test Loss : 0.2485, Test Accuracy : 0.9193 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.374 (0.374)\tData 0.257 (0.257)\tLoss 0.2018 (0.2018)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [120][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.2718 (0.2534)\tPrec@1 92.969 (92.644)\n",
            "Epoch: [120][200/391]\tTime 0.108 (0.105)\tData 0.001 (0.003)\tLoss 0.1882 (0.2488)\tPrec@1 96.094 (92.755)\n",
            "Epoch: [120][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.2827 (0.2497)\tPrec@1 92.969 (92.683)\n",
            "Epoch: [120][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.3209 (0.2499)\tPrec@1 88.750 (92.692)\n",
            "Total time : 40.512\n",
            "Train Loss: 0.2499, Train Accuracy: 0.9269\n",
            "Test Loss : 0.2969, Test Accuracy : 0.9040 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.425 (0.425)\tData 0.304 (0.304)\tLoss 0.2517 (0.2517)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [121][100/391]\tTime 0.112 (0.106)\tData 0.004 (0.004)\tLoss 0.1870 (0.2369)\tPrec@1 95.312 (93.332)\n",
            "Epoch: [121][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.1928 (0.2392)\tPrec@1 94.531 (93.260)\n",
            "Epoch: [121][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.1770 (0.2448)\tPrec@1 96.094 (93.023)\n",
            "Epoch: [121][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.2750 (0.2496)\tPrec@1 91.250 (92.846)\n",
            "Total time : 40.660\n",
            "Train Loss: 0.2496, Train Accuracy: 0.9285\n",
            "Test Loss : 0.2305, Test Accuracy : 0.9260 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.369 (0.369)\tData 0.256 (0.256)\tLoss 0.2678 (0.2678)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [122][100/391]\tTime 0.109 (0.106)\tData 0.007 (0.004)\tLoss 0.1788 (0.2379)\tPrec@1 95.312 (93.147)\n",
            "Epoch: [122][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2790 (0.2424)\tPrec@1 92.969 (93.093)\n",
            "Epoch: [122][300/391]\tTime 0.128 (0.104)\tData 0.025 (0.002)\tLoss 0.2711 (0.2465)\tPrec@1 89.844 (92.875)\n",
            "Epoch: [122][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.3514 (0.2489)\tPrec@1 88.750 (92.816)\n",
            "Total time : 40.371\n",
            "Train Loss: 0.2489, Train Accuracy: 0.9282\n",
            "Test Loss : 0.2927, Test Accuracy : 0.9023 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.502 (0.502)\tData 0.384 (0.384)\tLoss 0.2039 (0.2039)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [123][100/391]\tTime 0.114 (0.106)\tData 0.017 (0.004)\tLoss 0.2381 (0.2424)\tPrec@1 92.969 (93.239)\n",
            "Epoch: [123][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2511 (0.2465)\tPrec@1 91.406 (93.043)\n",
            "Epoch: [123][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.2371 (0.2439)\tPrec@1 92.188 (93.002)\n",
            "Epoch: [123][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.3531 (0.2453)\tPrec@1 88.750 (92.920)\n",
            "Total time : 40.404\n",
            "Train Loss: 0.2453, Train Accuracy: 0.9292\n",
            "Test Loss : 0.2664, Test Accuracy : 0.9107 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.380 (0.380)\tData 0.268 (0.268)\tLoss 0.1893 (0.1893)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [124][100/391]\tTime 0.100 (0.109)\tData 0.000 (0.006)\tLoss 0.2225 (0.2350)\tPrec@1 93.750 (93.332)\n",
            "Epoch: [124][200/391]\tTime 0.110 (0.105)\tData 0.000 (0.004)\tLoss 0.2237 (0.2384)\tPrec@1 95.312 (93.233)\n",
            "Epoch: [124][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.2349 (0.2371)\tPrec@1 96.875 (93.223)\n",
            "Epoch: [124][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.1363 (0.2377)\tPrec@1 97.500 (93.206)\n",
            "Total time : 40.588\n",
            "Train Loss: 0.2377, Train Accuracy: 0.9321\n",
            "Test Loss : 0.2724, Test Accuracy : 0.9103 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.379 (0.379)\tData 0.250 (0.250)\tLoss 0.3091 (0.3091)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [125][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.2151 (0.2276)\tPrec@1 92.969 (93.704)\n",
            "Epoch: [125][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2212 (0.2286)\tPrec@1 93.750 (93.579)\n",
            "Epoch: [125][300/391]\tTime 0.101 (0.104)\tData 0.002 (0.003)\tLoss 0.2505 (0.2307)\tPrec@1 92.188 (93.509)\n",
            "Epoch: [125][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.1720 (0.2341)\tPrec@1 96.250 (93.394)\n",
            "Total time : 40.289\n",
            "Train Loss: 0.2341, Train Accuracy: 0.9339\n",
            "Test Loss : 0.2588, Test Accuracy : 0.9122 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.378 (0.378)\tData 0.263 (0.263)\tLoss 0.2246 (0.2246)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [126][100/391]\tTime 0.105 (0.104)\tData 0.000 (0.003)\tLoss 0.1742 (0.2327)\tPrec@1 92.188 (93.394)\n",
            "Epoch: [126][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2328 (0.2318)\tPrec@1 92.969 (93.315)\n",
            "Epoch: [126][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.2264 (0.2327)\tPrec@1 94.531 (93.343)\n",
            "Epoch: [126][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.2078 (0.2350)\tPrec@1 93.750 (93.278)\n",
            "Total time : 40.590\n",
            "Train Loss: 0.2350, Train Accuracy: 0.9328\n",
            "Test Loss : 0.2508, Test Accuracy : 0.9196 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.397 (0.397)\tData 0.273 (0.273)\tLoss 0.1779 (0.1779)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [127][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.1927 (0.2241)\tPrec@1 94.531 (93.711)\n",
            "Epoch: [127][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2405 (0.2271)\tPrec@1 93.750 (93.509)\n",
            "Epoch: [127][300/391]\tTime 0.105 (0.103)\tData 0.007 (0.002)\tLoss 0.1936 (0.2244)\tPrec@1 94.531 (93.664)\n",
            "Epoch: [127][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.1801 (0.2278)\tPrec@1 97.500 (93.530)\n",
            "Total time : 40.386\n",
            "Train Loss: 0.2278, Train Accuracy: 0.9353\n",
            "Test Loss : 0.2384, Test Accuracy : 0.9236 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.435 (0.435)\tData 0.288 (0.288)\tLoss 0.1593 (0.1593)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [128][100/391]\tTime 0.101 (0.106)\tData 0.001 (0.004)\tLoss 0.2463 (0.2218)\tPrec@1 92.969 (93.936)\n",
            "Epoch: [128][200/391]\tTime 0.102 (0.104)\tData 0.001 (0.003)\tLoss 0.2175 (0.2225)\tPrec@1 93.750 (93.886)\n",
            "Epoch: [128][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.3203 (0.2247)\tPrec@1 89.062 (93.776)\n",
            "Epoch: [128][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.3242 (0.2268)\tPrec@1 88.750 (93.654)\n",
            "Total time : 40.734\n",
            "Train Loss: 0.2268, Train Accuracy: 0.9365\n",
            "Test Loss : 0.2296, Test Accuracy : 0.9247 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.394 (0.394)\tData 0.264 (0.264)\tLoss 0.2421 (0.2421)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [129][100/391]\tTime 0.122 (0.106)\tData 0.013 (0.004)\tLoss 0.2009 (0.2201)\tPrec@1 92.188 (93.773)\n",
            "Epoch: [129][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2213 (0.2190)\tPrec@1 94.531 (93.762)\n",
            "Epoch: [129][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.2150 (0.2187)\tPrec@1 94.531 (93.838)\n",
            "Epoch: [129][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.2028 (0.2217)\tPrec@1 92.500 (93.730)\n",
            "Total time : 40.463\n",
            "Train Loss: 0.2217, Train Accuracy: 0.9373\n",
            "Test Loss : 0.2392, Test Accuracy : 0.9215 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.432 (0.432)\tData 0.269 (0.269)\tLoss 0.1562 (0.1562)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [130][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.004)\tLoss 0.1453 (0.2180)\tPrec@1 97.656 (93.943)\n",
            "Epoch: [130][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2363 (0.2178)\tPrec@1 92.969 (93.886)\n",
            "Epoch: [130][300/391]\tTime 0.114 (0.104)\tData 0.010 (0.002)\tLoss 0.1775 (0.2195)\tPrec@1 95.312 (93.802)\n",
            "Epoch: [130][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.3679 (0.2224)\tPrec@1 87.500 (93.716)\n",
            "Total time : 40.546\n",
            "Train Loss: 0.2224, Train Accuracy: 0.9372\n",
            "Test Loss : 0.2379, Test Accuracy : 0.9230 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.626 (0.626)\tData 0.455 (0.455)\tLoss 0.2272 (0.2272)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [131][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.006)\tLoss 0.1729 (0.2167)\tPrec@1 96.875 (94.168)\n",
            "Epoch: [131][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.1572 (0.2131)\tPrec@1 95.312 (94.150)\n",
            "Epoch: [131][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.2696 (0.2159)\tPrec@1 91.406 (94.010)\n",
            "Epoch: [131][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.003)\tLoss 0.2290 (0.2166)\tPrec@1 95.000 (94.006)\n",
            "Total time : 40.674\n",
            "Train Loss: 0.2166, Train Accuracy: 0.9401\n",
            "Test Loss : 0.2235, Test Accuracy : 0.9275 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.409 (0.409)\tData 0.283 (0.283)\tLoss 0.1633 (0.1633)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [132][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.1717 (0.2091)\tPrec@1 94.531 (94.098)\n",
            "Epoch: [132][200/391]\tTime 0.111 (0.104)\tData 0.008 (0.003)\tLoss 0.1725 (0.2117)\tPrec@1 95.312 (93.991)\n",
            "Epoch: [132][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.2496 (0.2146)\tPrec@1 92.969 (93.914)\n",
            "Epoch: [132][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.2063 (0.2145)\tPrec@1 93.750 (93.956)\n",
            "Total time : 40.351\n",
            "Train Loss: 0.2145, Train Accuracy: 0.9396\n",
            "Test Loss : 0.2220, Test Accuracy : 0.9280 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.594 (0.594)\tData 0.392 (0.392)\tLoss 0.2232 (0.2232)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [133][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.006)\tLoss 0.1778 (0.2035)\tPrec@1 94.531 (94.214)\n",
            "Epoch: [133][200/391]\tTime 0.100 (0.106)\tData 0.000 (0.004)\tLoss 0.2291 (0.2049)\tPrec@1 92.969 (94.321)\n",
            "Epoch: [133][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2169 (0.2073)\tPrec@1 94.531 (94.228)\n",
            "Epoch: [133][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.002)\tLoss 0.2982 (0.2092)\tPrec@1 92.500 (94.140)\n",
            "Total time : 40.575\n",
            "Train Loss: 0.2092, Train Accuracy: 0.9414\n",
            "Test Loss : 0.2267, Test Accuracy : 0.9280 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.370 (0.370)\tData 0.262 (0.262)\tLoss 0.1855 (0.1855)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [134][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.2801 (0.1951)\tPrec@1 92.969 (94.802)\n",
            "Epoch: [134][200/391]\tTime 0.104 (0.104)\tData 0.006 (0.003)\tLoss 0.1803 (0.1978)\tPrec@1 92.969 (94.671)\n",
            "Epoch: [134][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1219 (0.1986)\tPrec@1 96.875 (94.684)\n",
            "Epoch: [134][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.2449 (0.2034)\tPrec@1 91.250 (94.518)\n",
            "Total time : 40.362\n",
            "Train Loss: 0.2034, Train Accuracy: 0.9452\n",
            "Test Loss : 0.2075, Test Accuracy : 0.9347 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.375 (0.375)\tData 0.281 (0.281)\tLoss 0.1820 (0.1820)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [135][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.1966 (0.2004)\tPrec@1 95.312 (94.407)\n",
            "Epoch: [135][200/391]\tTime 0.104 (0.105)\tData 0.000 (0.003)\tLoss 0.1734 (0.2028)\tPrec@1 92.188 (94.419)\n",
            "Epoch: [135][300/391]\tTime 0.108 (0.104)\tData 0.008 (0.003)\tLoss 0.1802 (0.2000)\tPrec@1 95.312 (94.529)\n",
            "Epoch: [135][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.2045 (0.1987)\tPrec@1 95.000 (94.564)\n",
            "Total time : 40.420\n",
            "Train Loss: 0.1987, Train Accuracy: 0.9456\n",
            "Test Loss : 0.2094, Test Accuracy : 0.9325 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.497 (0.497)\tData 0.344 (0.344)\tLoss 0.2035 (0.2035)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [136][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.2144 (0.1907)\tPrec@1 92.188 (94.841)\n",
            "Epoch: [136][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2355 (0.1960)\tPrec@1 92.188 (94.535)\n",
            "Epoch: [136][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.2311 (0.1972)\tPrec@1 93.750 (94.523)\n",
            "Epoch: [136][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.1700 (0.1992)\tPrec@1 96.250 (94.462)\n",
            "Total time : 40.516\n",
            "Train Loss: 0.1992, Train Accuracy: 0.9446\n",
            "Test Loss : 0.2123, Test Accuracy : 0.9276 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.377 (0.377)\tData 0.260 (0.260)\tLoss 0.2094 (0.2094)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [137][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.004)\tLoss 0.2516 (0.1884)\tPrec@1 92.188 (94.895)\n",
            "Epoch: [137][200/391]\tTime 0.110 (0.105)\tData 0.010 (0.003)\tLoss 0.1654 (0.1934)\tPrec@1 95.312 (94.710)\n",
            "Epoch: [137][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.1895 (0.1969)\tPrec@1 94.531 (94.622)\n",
            "Epoch: [137][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.2665 (0.1986)\tPrec@1 91.250 (94.570)\n",
            "Total time : 40.538\n",
            "Train Loss: 0.1986, Train Accuracy: 0.9457\n",
            "Test Loss : 0.2160, Test Accuracy : 0.9309 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.400 (0.400)\tData 0.276 (0.276)\tLoss 0.2639 (0.2639)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [138][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1743 (0.1900)\tPrec@1 94.531 (94.895)\n",
            "Epoch: [138][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1612 (0.1954)\tPrec@1 96.875 (94.582)\n",
            "Epoch: [138][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.1990 (0.1948)\tPrec@1 93.750 (94.645)\n",
            "Epoch: [138][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.3115 (0.1961)\tPrec@1 92.500 (94.598)\n",
            "Total time : 40.342\n",
            "Train Loss: 0.1961, Train Accuracy: 0.9460\n",
            "Test Loss : 0.2103, Test Accuracy : 0.9309 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.431 (0.431)\tData 0.295 (0.295)\tLoss 0.1569 (0.1569)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [139][100/391]\tTime 0.112 (0.106)\tData 0.011 (0.004)\tLoss 0.1602 (0.1889)\tPrec@1 96.875 (95.034)\n",
            "Epoch: [139][200/391]\tTime 0.102 (0.104)\tData 0.001 (0.003)\tLoss 0.1953 (0.1855)\tPrec@1 94.531 (94.932)\n",
            "Epoch: [139][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.1805 (0.1873)\tPrec@1 96.094 (94.921)\n",
            "Epoch: [139][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.2199 (0.1893)\tPrec@1 95.000 (94.826)\n",
            "Total time : 40.707\n",
            "Train Loss: 0.1893, Train Accuracy: 0.9483\n",
            "Test Loss : 0.1985, Test Accuracy : 0.9345 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.421 (0.421)\tData 0.315 (0.315)\tLoss 0.1758 (0.1758)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [140][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.2665 (0.1793)\tPrec@1 90.625 (95.312)\n",
            "Epoch: [140][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.2282 (0.1852)\tPrec@1 95.312 (95.114)\n",
            "Epoch: [140][300/391]\tTime 0.108 (0.104)\tData 0.000 (0.002)\tLoss 0.1957 (0.1837)\tPrec@1 94.531 (95.100)\n",
            "Epoch: [140][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1931 (0.1848)\tPrec@1 95.000 (95.038)\n",
            "Total time : 40.365\n",
            "Train Loss: 0.1848, Train Accuracy: 0.9504\n",
            "Test Loss : 0.2172, Test Accuracy : 0.9282 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.373 (0.373)\tData 0.273 (0.273)\tLoss 0.1430 (0.1430)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [141][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.005)\tLoss 0.1845 (0.1743)\tPrec@1 96.094 (95.490)\n",
            "Epoch: [141][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2170 (0.1800)\tPrec@1 92.969 (95.204)\n",
            "Epoch: [141][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.1555 (0.1821)\tPrec@1 96.094 (95.058)\n",
            "Epoch: [141][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.003)\tLoss 0.1781 (0.1832)\tPrec@1 97.500 (95.068)\n",
            "Total time : 40.745\n",
            "Train Loss: 0.1832, Train Accuracy: 0.9507\n",
            "Test Loss : 0.1854, Test Accuracy : 0.9407 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.385 (0.385)\tData 0.286 (0.286)\tLoss 0.1664 (0.1664)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [142][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.1445 (0.1713)\tPrec@1 96.094 (95.436)\n",
            "Epoch: [142][200/391]\tTime 0.098 (0.104)\tData 0.000 (0.003)\tLoss 0.1270 (0.1798)\tPrec@1 96.094 (95.204)\n",
            "Epoch: [142][300/391]\tTime 0.102 (0.103)\tData 0.001 (0.002)\tLoss 0.1845 (0.1822)\tPrec@1 96.094 (95.107)\n",
            "Epoch: [142][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.2042 (0.1808)\tPrec@1 96.250 (95.232)\n",
            "Total time : 40.376\n",
            "Train Loss: 0.1808, Train Accuracy: 0.9523\n",
            "Test Loss : 0.1922, Test Accuracy : 0.9378 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.290 (0.290)\tData 0.179 (0.179)\tLoss 0.1412 (0.1412)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [143][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.2524 (0.1690)\tPrec@1 92.188 (95.405)\n",
            "Epoch: [143][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.2517 (0.1765)\tPrec@1 92.188 (95.250)\n",
            "Epoch: [143][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1977 (0.1776)\tPrec@1 93.750 (95.261)\n",
            "Epoch: [143][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1206 (0.1767)\tPrec@1 97.500 (95.318)\n",
            "Total time : 40.269\n",
            "Train Loss: 0.1767, Train Accuracy: 0.9532\n",
            "Test Loss : 0.1980, Test Accuracy : 0.9364 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.635 (0.635)\tData 0.464 (0.464)\tLoss 0.1819 (0.1819)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [144][100/391]\tTime 0.103 (0.108)\tData 0.000 (0.006)\tLoss 0.1130 (0.1649)\tPrec@1 97.656 (95.583)\n",
            "Epoch: [144][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.2050 (0.1701)\tPrec@1 93.750 (95.491)\n",
            "Epoch: [144][300/391]\tTime 0.100 (0.105)\tData 0.000 (0.003)\tLoss 0.1382 (0.1720)\tPrec@1 96.875 (95.466)\n",
            "Epoch: [144][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.2081 (0.1749)\tPrec@1 96.250 (95.348)\n",
            "Total time : 40.690\n",
            "Train Loss: 0.1749, Train Accuracy: 0.9535\n",
            "Test Loss : 0.1964, Test Accuracy : 0.9360 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.379 (0.379)\tData 0.257 (0.257)\tLoss 0.1836 (0.1836)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [145][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1650 (0.1764)\tPrec@1 96.094 (95.452)\n",
            "Epoch: [145][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1908 (0.1743)\tPrec@1 93.750 (95.406)\n",
            "Epoch: [145][300/391]\tTime 0.111 (0.103)\tData 0.009 (0.002)\tLoss 0.1634 (0.1701)\tPrec@1 96.094 (95.499)\n",
            "Epoch: [145][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1698 (0.1709)\tPrec@1 93.750 (95.422)\n",
            "Total time : 40.322\n",
            "Train Loss: 0.1709, Train Accuracy: 0.9542\n",
            "Test Loss : 0.2069, Test Accuracy : 0.9303 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.570 (0.570)\tData 0.456 (0.456)\tLoss 0.1800 (0.1800)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [146][100/391]\tTime 0.101 (0.110)\tData 0.000 (0.008)\tLoss 0.1527 (0.1611)\tPrec@1 96.094 (95.676)\n",
            "Epoch: [146][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.1446 (0.1616)\tPrec@1 96.875 (95.798)\n",
            "Epoch: [146][300/391]\tTime 0.102 (0.105)\tData 0.000 (0.004)\tLoss 0.1444 (0.1634)\tPrec@1 96.875 (95.785)\n",
            "Epoch: [146][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.003)\tLoss 0.1135 (0.1664)\tPrec@1 96.250 (95.706)\n",
            "Total time : 40.827\n",
            "Train Loss: 0.1664, Train Accuracy: 0.9571\n",
            "Test Loss : 0.1967, Test Accuracy : 0.9364 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.404 (0.404)\tData 0.281 (0.281)\tLoss 0.1457 (0.1457)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [147][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1096 (0.1607)\tPrec@1 97.656 (95.653)\n",
            "Epoch: [147][200/391]\tTime 0.113 (0.104)\tData 0.000 (0.002)\tLoss 0.2338 (0.1650)\tPrec@1 92.969 (95.627)\n",
            "Epoch: [147][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1544 (0.1635)\tPrec@1 97.656 (95.694)\n",
            "Epoch: [147][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0829 (0.1657)\tPrec@1 100.000 (95.654)\n",
            "Total time : 40.453\n",
            "Train Loss: 0.1657, Train Accuracy: 0.9565\n",
            "Test Loss : 0.2137, Test Accuracy : 0.9285 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.380 (0.380)\tData 0.270 (0.270)\tLoss 0.1853 (0.1853)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [148][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.005)\tLoss 0.1595 (0.1605)\tPrec@1 96.094 (95.877)\n",
            "Epoch: [148][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.2380 (0.1637)\tPrec@1 94.531 (95.752)\n",
            "Epoch: [148][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1116 (0.1630)\tPrec@1 97.656 (95.733)\n",
            "Epoch: [148][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.2843 (0.1637)\tPrec@1 90.000 (95.700)\n",
            "Total time : 40.276\n",
            "Train Loss: 0.1637, Train Accuracy: 0.9570\n",
            "Test Loss : 0.1855, Test Accuracy : 0.9406 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.419 (0.419)\tData 0.285 (0.285)\tLoss 0.1714 (0.1714)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [149][100/391]\tTime 0.110 (0.105)\tData 0.000 (0.003)\tLoss 0.1783 (0.1597)\tPrec@1 94.531 (95.900)\n",
            "Epoch: [149][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.1578 (0.1610)\tPrec@1 94.531 (95.802)\n",
            "Epoch: [149][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1428 (0.1597)\tPrec@1 96.094 (95.803)\n",
            "Epoch: [149][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.1443 (0.1605)\tPrec@1 97.500 (95.788)\n",
            "Total time : 40.293\n",
            "Train Loss: 0.1605, Train Accuracy: 0.9579\n",
            "Test Loss : 0.1870, Test Accuracy : 0.9381 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.415 (0.415)\tData 0.310 (0.310)\tLoss 0.2676 (0.2676)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [150][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.1105 (0.1586)\tPrec@1 98.438 (95.908)\n",
            "Epoch: [150][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.1434 (0.1559)\tPrec@1 96.094 (96.035)\n",
            "Epoch: [150][300/391]\tTime 0.103 (0.104)\tData 0.005 (0.003)\tLoss 0.1717 (0.1603)\tPrec@1 95.312 (95.873)\n",
            "Epoch: [150][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.003)\tLoss 0.1489 (0.1598)\tPrec@1 95.000 (95.884)\n",
            "Total time : 40.426\n",
            "Train Loss: 0.1598, Train Accuracy: 0.9588\n",
            "Test Loss : 0.1820, Test Accuracy : 0.9400 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.633 (0.633)\tData 0.442 (0.442)\tLoss 0.1458 (0.1458)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [151][100/391]\tTime 0.101 (0.108)\tData 0.000 (0.006)\tLoss 0.1417 (0.1547)\tPrec@1 96.094 (96.055)\n",
            "Epoch: [151][200/391]\tTime 0.100 (0.105)\tData 0.000 (0.004)\tLoss 0.1242 (0.1515)\tPrec@1 96.094 (96.168)\n",
            "Epoch: [151][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1252 (0.1519)\tPrec@1 96.094 (96.143)\n",
            "Epoch: [151][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.003)\tLoss 0.2422 (0.1515)\tPrec@1 93.750 (96.178)\n",
            "Total time : 40.619\n",
            "Train Loss: 0.1515, Train Accuracy: 0.9618\n",
            "Test Loss : 0.1886, Test Accuracy : 0.9376 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.398 (0.398)\tData 0.255 (0.255)\tLoss 0.1821 (0.1821)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [152][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.0889 (0.1464)\tPrec@1 99.219 (96.395)\n",
            "Epoch: [152][200/391]\tTime 0.109 (0.104)\tData 0.011 (0.002)\tLoss 0.1705 (0.1440)\tPrec@1 95.312 (96.405)\n",
            "Epoch: [152][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1766 (0.1470)\tPrec@1 95.312 (96.273)\n",
            "Epoch: [152][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.1580 (0.1487)\tPrec@1 97.500 (96.240)\n",
            "Total time : 40.540\n",
            "Train Loss: 0.1487, Train Accuracy: 0.9624\n",
            "Test Loss : 0.1825, Test Accuracy : 0.9385 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.390 (0.390)\tData 0.266 (0.266)\tLoss 0.1454 (0.1454)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [153][100/391]\tTime 0.101 (0.106)\tData 0.001 (0.005)\tLoss 0.1666 (0.1450)\tPrec@1 96.094 (96.388)\n",
            "Epoch: [153][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.1736 (0.1466)\tPrec@1 95.312 (96.374)\n",
            "Epoch: [153][300/391]\tTime 0.107 (0.104)\tData 0.002 (0.002)\tLoss 0.1489 (0.1471)\tPrec@1 96.875 (96.366)\n",
            "Epoch: [153][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1901 (0.1482)\tPrec@1 96.250 (96.300)\n",
            "Total time : 40.300\n",
            "Train Loss: 0.1482, Train Accuracy: 0.9630\n",
            "Test Loss : 0.1872, Test Accuracy : 0.9397 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.517 (0.517)\tData 0.393 (0.393)\tLoss 0.1786 (0.1786)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [154][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.005)\tLoss 0.1603 (0.1488)\tPrec@1 96.875 (96.210)\n",
            "Epoch: [154][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.1246 (0.1474)\tPrec@1 96.875 (96.261)\n",
            "Epoch: [154][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.1453 (0.1452)\tPrec@1 96.875 (96.358)\n",
            "Epoch: [154][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.1206 (0.1444)\tPrec@1 97.500 (96.384)\n",
            "Total time : 40.637\n",
            "Train Loss: 0.1444, Train Accuracy: 0.9638\n",
            "Test Loss : 0.1797, Test Accuracy : 0.9415 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.417 (0.417)\tData 0.300 (0.300)\tLoss 0.1156 (0.1156)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [155][100/391]\tTime 0.106 (0.106)\tData 0.000 (0.004)\tLoss 0.1132 (0.1401)\tPrec@1 98.438 (96.597)\n",
            "Epoch: [155][200/391]\tTime 0.105 (0.104)\tData 0.000 (0.003)\tLoss 0.1612 (0.1377)\tPrec@1 96.094 (96.743)\n",
            "Epoch: [155][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.1163 (0.1402)\tPrec@1 97.656 (96.621)\n",
            "Epoch: [155][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.1785 (0.1432)\tPrec@1 92.500 (96.500)\n",
            "Total time : 40.341\n",
            "Train Loss: 0.1432, Train Accuracy: 0.9650\n",
            "Test Loss : 0.1795, Test Accuracy : 0.9427 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.396 (0.396)\tData 0.253 (0.253)\tLoss 0.1546 (0.1546)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [156][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.1796 (0.1383)\tPrec@1 95.312 (96.442)\n",
            "Epoch: [156][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1442 (0.1382)\tPrec@1 95.312 (96.482)\n",
            "Epoch: [156][300/391]\tTime 0.101 (0.104)\tData 0.001 (0.002)\tLoss 0.1755 (0.1411)\tPrec@1 93.750 (96.408)\n",
            "Epoch: [156][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.1193 (0.1421)\tPrec@1 98.750 (96.428)\n",
            "Total time : 40.457\n",
            "Train Loss: 0.1421, Train Accuracy: 0.9643\n",
            "Test Loss : 0.1673, Test Accuracy : 0.9452 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.318 (0.318)\tData 0.216 (0.216)\tLoss 0.1194 (0.1194)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [157][100/391]\tTime 0.111 (0.108)\tData 0.008 (0.005)\tLoss 0.1270 (0.1389)\tPrec@1 96.875 (96.566)\n",
            "Epoch: [157][200/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.1364 (0.1399)\tPrec@1 97.656 (96.591)\n",
            "Epoch: [157][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.1236 (0.1374)\tPrec@1 96.875 (96.701)\n",
            "Epoch: [157][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.1841 (0.1358)\tPrec@1 95.000 (96.736)\n",
            "Total time : 40.650\n",
            "Train Loss: 0.1358, Train Accuracy: 0.9674\n",
            "Test Loss : 0.1663, Test Accuracy : 0.9459 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.414 (0.414)\tData 0.280 (0.280)\tLoss 0.0785 (0.0785)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [158][100/391]\tTime 0.101 (0.106)\tData 0.001 (0.005)\tLoss 0.1186 (0.1342)\tPrec@1 98.438 (96.805)\n",
            "Epoch: [158][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.1457 (0.1354)\tPrec@1 95.312 (96.704)\n",
            "Epoch: [158][300/391]\tTime 0.111 (0.104)\tData 0.006 (0.003)\tLoss 0.1555 (0.1341)\tPrec@1 97.656 (96.771)\n",
            "Epoch: [158][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.2080 (0.1365)\tPrec@1 95.000 (96.676)\n",
            "Total time : 40.421\n",
            "Train Loss: 0.1365, Train Accuracy: 0.9668\n",
            "Test Loss : 0.1665, Test Accuracy : 0.9460 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.648 (0.648)\tData 0.442 (0.442)\tLoss 0.1200 (0.1200)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [159][100/391]\tTime 0.099 (0.109)\tData 0.000 (0.007)\tLoss 0.1597 (0.1297)\tPrec@1 96.094 (96.983)\n",
            "Epoch: [159][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1278 (0.1288)\tPrec@1 96.875 (96.929)\n",
            "Epoch: [159][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.1235 (0.1298)\tPrec@1 97.656 (96.904)\n",
            "Epoch: [159][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.003)\tLoss 0.1019 (0.1305)\tPrec@1 97.500 (96.846)\n",
            "Total time : 40.858\n",
            "Train Loss: 0.1305, Train Accuracy: 0.9685\n",
            "Test Loss : 0.1624, Test Accuracy : 0.9469 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.384 (0.384)\tData 0.268 (0.268)\tLoss 0.1103 (0.1103)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [160][100/391]\tTime 0.103 (0.106)\tData 0.000 (0.005)\tLoss 0.1682 (0.1312)\tPrec@1 93.750 (96.929)\n",
            "Epoch: [160][200/391]\tTime 0.110 (0.104)\tData 0.007 (0.003)\tLoss 0.1291 (0.1316)\tPrec@1 96.875 (96.914)\n",
            "Epoch: [160][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1381 (0.1324)\tPrec@1 96.875 (96.872)\n",
            "Epoch: [160][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.1125 (0.1312)\tPrec@1 97.500 (96.888)\n",
            "Total time : 40.442\n",
            "Train Loss: 0.1312, Train Accuracy: 0.9689\n",
            "Test Loss : 0.1783, Test Accuracy : 0.9407 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.392 (0.392)\tData 0.270 (0.270)\tLoss 0.1528 (0.1528)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [161][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.1520 (0.1263)\tPrec@1 96.875 (96.798)\n",
            "Epoch: [161][200/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.1090 (0.1261)\tPrec@1 97.656 (96.929)\n",
            "Epoch: [161][300/391]\tTime 0.108 (0.105)\tData 0.009 (0.003)\tLoss 0.1052 (0.1273)\tPrec@1 97.656 (96.911)\n",
            "Epoch: [161][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.1611 (0.1277)\tPrec@1 96.250 (96.900)\n",
            "Total time : 40.736\n",
            "Train Loss: 0.1277, Train Accuracy: 0.9690\n",
            "Test Loss : 0.1695, Test Accuracy : 0.9439 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.596 (0.596)\tData 0.443 (0.443)\tLoss 0.1398 (0.1398)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [162][100/391]\tTime 0.100 (0.107)\tData 0.000 (0.005)\tLoss 0.0858 (0.1210)\tPrec@1 98.438 (97.223)\n",
            "Epoch: [162][200/391]\tTime 0.103 (0.105)\tData 0.000 (0.004)\tLoss 0.1717 (0.1243)\tPrec@1 95.312 (97.077)\n",
            "Epoch: [162][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.1328 (0.1266)\tPrec@1 97.656 (96.968)\n",
            "Epoch: [162][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.1264 (0.1267)\tPrec@1 97.500 (96.962)\n",
            "Total time : 40.630\n",
            "Train Loss: 0.1267, Train Accuracy: 0.9696\n",
            "Test Loss : 0.1655, Test Accuracy : 0.9452 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.320 (0.320)\tData 0.204 (0.204)\tLoss 0.1048 (0.1048)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [163][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.1402 (0.1218)\tPrec@1 97.656 (97.107)\n",
            "Epoch: [163][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1093 (0.1219)\tPrec@1 98.438 (97.209)\n",
            "Epoch: [163][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.1255 (0.1216)\tPrec@1 95.312 (97.148)\n",
            "Epoch: [163][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1855 (0.1238)\tPrec@1 95.000 (97.058)\n",
            "Total time : 40.426\n",
            "Train Loss: 0.1238, Train Accuracy: 0.9706\n",
            "Test Loss : 0.1634, Test Accuracy : 0.9460 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.401 (0.401)\tData 0.295 (0.295)\tLoss 0.1241 (0.1241)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [164][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.005)\tLoss 0.1999 (0.1255)\tPrec@1 90.625 (96.890)\n",
            "Epoch: [164][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.0872 (0.1255)\tPrec@1 99.219 (96.988)\n",
            "Epoch: [164][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.1610 (0.1262)\tPrec@1 94.531 (96.992)\n",
            "Epoch: [164][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0924 (0.1244)\tPrec@1 97.500 (97.046)\n",
            "Total time : 40.458\n",
            "Train Loss: 0.1244, Train Accuracy: 0.9705\n",
            "Test Loss : 0.1644, Test Accuracy : 0.9478 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.385 (0.385)\tData 0.258 (0.258)\tLoss 0.1228 (0.1228)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [165][100/391]\tTime 0.119 (0.106)\tData 0.021 (0.004)\tLoss 0.0615 (0.1182)\tPrec@1 99.219 (97.285)\n",
            "Epoch: [165][200/391]\tTime 0.101 (0.104)\tData 0.001 (0.003)\tLoss 0.1166 (0.1169)\tPrec@1 96.094 (97.252)\n",
            "Epoch: [165][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.1484 (0.1175)\tPrec@1 96.094 (97.225)\n",
            "Epoch: [165][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.002)\tLoss 0.0738 (0.1185)\tPrec@1 98.750 (97.174)\n",
            "Total time : 40.473\n",
            "Train Loss: 0.1185, Train Accuracy: 0.9717\n",
            "Test Loss : 0.1612, Test Accuracy : 0.9478 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.280 (0.280)\tData 0.170 (0.170)\tLoss 0.1141 (0.1141)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [166][100/391]\tTime 0.102 (0.105)\tData 0.000 (0.005)\tLoss 0.1272 (0.1078)\tPrec@1 95.312 (97.556)\n",
            "Epoch: [166][200/391]\tTime 0.112 (0.104)\tData 0.005 (0.003)\tLoss 0.1254 (0.1125)\tPrec@1 96.875 (97.345)\n",
            "Epoch: [166][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.1176 (0.1118)\tPrec@1 97.656 (97.399)\n",
            "Epoch: [166][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0847 (0.1130)\tPrec@1 98.750 (97.396)\n",
            "Total time : 40.308\n",
            "Train Loss: 0.1130, Train Accuracy: 0.9740\n",
            "Test Loss : 0.1626, Test Accuracy : 0.9480 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.577 (0.577)\tData 0.397 (0.397)\tLoss 0.1591 (0.1591)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [167][100/391]\tTime 0.102 (0.108)\tData 0.000 (0.005)\tLoss 0.1405 (0.1187)\tPrec@1 95.312 (97.316)\n",
            "Epoch: [167][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.1339 (0.1168)\tPrec@1 96.875 (97.322)\n",
            "Epoch: [167][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1124 (0.1135)\tPrec@1 96.875 (97.415)\n",
            "Epoch: [167][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.003)\tLoss 0.0638 (0.1152)\tPrec@1 100.000 (97.396)\n",
            "Total time : 40.816\n",
            "Train Loss: 0.1152, Train Accuracy: 0.9740\n",
            "Test Loss : 0.1603, Test Accuracy : 0.9481 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.405 (0.405)\tData 0.300 (0.300)\tLoss 0.1449 (0.1449)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [168][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.1012 (0.1049)\tPrec@1 96.875 (97.509)\n",
            "Epoch: [168][200/391]\tTime 0.106 (0.104)\tData 0.003 (0.003)\tLoss 0.1155 (0.1120)\tPrec@1 97.656 (97.353)\n",
            "Epoch: [168][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.1377 (0.1104)\tPrec@1 96.094 (97.438)\n",
            "Epoch: [168][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.1117 (0.1112)\tPrec@1 95.000 (97.374)\n",
            "Total time : 40.338\n",
            "Train Loss: 0.1112, Train Accuracy: 0.9737\n",
            "Test Loss : 0.1586, Test Accuracy : 0.9471 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.379 (0.379)\tData 0.265 (0.265)\tLoss 0.1182 (0.1182)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [169][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1210 (0.1087)\tPrec@1 99.219 (97.532)\n",
            "Epoch: [169][200/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.1513 (0.1126)\tPrec@1 96.094 (97.404)\n",
            "Epoch: [169][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.1280 (0.1112)\tPrec@1 96.094 (97.425)\n",
            "Epoch: [169][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.1042 (0.1105)\tPrec@1 98.750 (97.428)\n",
            "Total time : 40.405\n",
            "Train Loss: 0.1105, Train Accuracy: 0.9743\n",
            "Test Loss : 0.1582, Test Accuracy : 0.9478 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.395 (0.395)\tData 0.285 (0.285)\tLoss 0.1131 (0.1131)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [170][100/391]\tTime 0.132 (0.107)\tData 0.025 (0.005)\tLoss 0.1821 (0.1011)\tPrec@1 94.531 (97.710)\n",
            "Epoch: [170][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.1163 (0.1074)\tPrec@1 96.875 (97.501)\n",
            "Epoch: [170][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.0757 (0.1058)\tPrec@1 99.219 (97.597)\n",
            "Epoch: [170][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.0951 (0.1077)\tPrec@1 97.500 (97.550)\n",
            "Total time : 40.508\n",
            "Train Loss: 0.1077, Train Accuracy: 0.9755\n",
            "Test Loss : 0.1545, Test Accuracy : 0.9492 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.380 (0.380)\tData 0.255 (0.255)\tLoss 0.0962 (0.0962)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [171][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.0862 (0.1085)\tPrec@1 98.438 (97.478)\n",
            "Epoch: [171][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1029 (0.1067)\tPrec@1 98.438 (97.606)\n",
            "Epoch: [171][300/391]\tTime 0.110 (0.103)\tData 0.008 (0.002)\tLoss 0.1102 (0.1062)\tPrec@1 96.875 (97.617)\n",
            "Epoch: [171][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.1662 (0.1052)\tPrec@1 96.250 (97.664)\n",
            "Total time : 40.337\n",
            "Train Loss: 0.1052, Train Accuracy: 0.9766\n",
            "Test Loss : 0.1551, Test Accuracy : 0.9494 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.386 (0.386)\tData 0.289 (0.289)\tLoss 0.0763 (0.0763)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [172][100/391]\tTime 0.119 (0.108)\tData 0.000 (0.006)\tLoss 0.1298 (0.1041)\tPrec@1 97.656 (97.664)\n",
            "Epoch: [172][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.0572 (0.1069)\tPrec@1 100.000 (97.528)\n",
            "Epoch: [172][300/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.1277 (0.1050)\tPrec@1 97.656 (97.599)\n",
            "Epoch: [172][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.1184 (0.1061)\tPrec@1 97.500 (97.574)\n",
            "Total time : 40.743\n",
            "Train Loss: 0.1061, Train Accuracy: 0.9757\n",
            "Test Loss : 0.1516, Test Accuracy : 0.9518 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.376 (0.376)\tData 0.260 (0.260)\tLoss 0.0889 (0.0889)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [173][100/391]\tTime 0.103 (0.105)\tData 0.000 (0.004)\tLoss 0.0932 (0.0928)\tPrec@1 97.656 (97.935)\n",
            "Epoch: [173][200/391]\tTime 0.108 (0.103)\tData 0.000 (0.002)\tLoss 0.0930 (0.0968)\tPrec@1 96.875 (97.874)\n",
            "Epoch: [173][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1036 (0.0987)\tPrec@1 96.875 (97.744)\n",
            "Epoch: [173][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.0779 (0.0996)\tPrec@1 98.750 (97.724)\n",
            "Total time : 40.192\n",
            "Train Loss: 0.0996, Train Accuracy: 0.9772\n",
            "Test Loss : 0.1494, Test Accuracy : 0.9524 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.381 (0.381)\tData 0.258 (0.258)\tLoss 0.0634 (0.0634)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [174][100/391]\tTime 0.102 (0.106)\tData 0.001 (0.005)\tLoss 0.0827 (0.0952)\tPrec@1 98.438 (97.912)\n",
            "Epoch: [174][200/391]\tTime 0.107 (0.105)\tData 0.001 (0.004)\tLoss 0.1174 (0.0978)\tPrec@1 96.094 (97.781)\n",
            "Epoch: [174][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1134 (0.0991)\tPrec@1 98.438 (97.716)\n",
            "Epoch: [174][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.003)\tLoss 0.1012 (0.0991)\tPrec@1 97.500 (97.736)\n",
            "Total time : 40.466\n",
            "Train Loss: 0.0991, Train Accuracy: 0.9774\n",
            "Test Loss : 0.1503, Test Accuracy : 0.9501 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.334 (0.334)\tData 0.236 (0.236)\tLoss 0.0590 (0.0590)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [175][100/391]\tTime 0.111 (0.105)\tData 0.000 (0.003)\tLoss 0.0785 (0.0944)\tPrec@1 98.438 (97.927)\n",
            "Epoch: [175][200/391]\tTime 0.105 (0.103)\tData 0.007 (0.002)\tLoss 0.1312 (0.0973)\tPrec@1 96.875 (97.874)\n",
            "Epoch: [175][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.0962 (0.0980)\tPrec@1 97.656 (97.851)\n",
            "Epoch: [175][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.0516 (0.0987)\tPrec@1 100.000 (97.808)\n",
            "Total time : 40.270\n",
            "Train Loss: 0.0987, Train Accuracy: 0.9781\n",
            "Test Loss : 0.1480, Test Accuracy : 0.9514 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.383 (0.383)\tData 0.270 (0.270)\tLoss 0.1235 (0.1235)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [176][100/391]\tTime 0.102 (0.106)\tData 0.000 (0.004)\tLoss 0.0516 (0.0940)\tPrec@1 99.219 (97.896)\n",
            "Epoch: [176][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1499 (0.0966)\tPrec@1 95.312 (97.808)\n",
            "Epoch: [176][300/391]\tTime 0.108 (0.104)\tData 0.000 (0.002)\tLoss 0.0748 (0.0968)\tPrec@1 97.656 (97.817)\n",
            "Epoch: [176][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.0792 (0.0980)\tPrec@1 97.500 (97.754)\n",
            "Total time : 40.443\n",
            "Train Loss: 0.0980, Train Accuracy: 0.9775\n",
            "Test Loss : 0.1497, Test Accuracy : 0.9514 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.449 (0.449)\tData 0.312 (0.312)\tLoss 0.0971 (0.0971)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [177][100/391]\tTime 0.102 (0.108)\tData 0.000 (0.004)\tLoss 0.0947 (0.0993)\tPrec@1 97.656 (97.741)\n",
            "Epoch: [177][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.0965 (0.0977)\tPrec@1 96.875 (97.808)\n",
            "Epoch: [177][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.1116 (0.0976)\tPrec@1 97.656 (97.822)\n",
            "Epoch: [177][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.0910 (0.0980)\tPrec@1 100.000 (97.816)\n",
            "Total time : 40.553\n",
            "Train Loss: 0.0980, Train Accuracy: 0.9782\n",
            "Test Loss : 0.1502, Test Accuracy : 0.9509 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.396 (0.396)\tData 0.273 (0.273)\tLoss 0.0934 (0.0934)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [178][100/391]\tTime 0.103 (0.105)\tData 0.000 (0.004)\tLoss 0.1144 (0.0983)\tPrec@1 97.656 (97.772)\n",
            "Epoch: [178][200/391]\tTime 0.111 (0.104)\tData 0.000 (0.002)\tLoss 0.0828 (0.0973)\tPrec@1 98.438 (97.734)\n",
            "Epoch: [178][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.0919 (0.0968)\tPrec@1 97.656 (97.778)\n",
            "Epoch: [178][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.0572 (0.0962)\tPrec@1 98.750 (97.780)\n",
            "Total time : 40.683\n",
            "Train Loss: 0.0962, Train Accuracy: 0.9778\n",
            "Test Loss : 0.1495, Test Accuracy : 0.9511 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.418 (0.418)\tData 0.292 (0.292)\tLoss 0.1355 (0.1355)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [179][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.0793 (0.0995)\tPrec@1 100.000 (97.749)\n",
            "Epoch: [179][200/391]\tTime 0.101 (0.105)\tData 0.001 (0.003)\tLoss 0.1527 (0.0988)\tPrec@1 95.312 (97.816)\n",
            "Epoch: [179][300/391]\tTime 0.106 (0.104)\tData 0.000 (0.003)\tLoss 0.1153 (0.0973)\tPrec@1 96.875 (97.848)\n",
            "Epoch: [179][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1819 (0.0957)\tPrec@1 93.750 (97.870)\n",
            "Total time : 40.440\n",
            "Train Loss: 0.0957, Train Accuracy: 0.9787\n",
            "Test Loss : 0.1501, Test Accuracy : 0.9518 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.560 (0.560)\tData 0.383 (0.383)\tLoss 0.0654 (0.0654)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [180][100/391]\tTime 0.101 (0.107)\tData 0.000 (0.004)\tLoss 0.1059 (0.0963)\tPrec@1 96.875 (97.695)\n",
            "Epoch: [180][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.0672 (0.0938)\tPrec@1 98.438 (97.854)\n",
            "Epoch: [180][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.0841 (0.0930)\tPrec@1 99.219 (97.877)\n",
            "Epoch: [180][390/391]\tTime 0.074 (0.104)\tData 0.000 (0.002)\tLoss 0.0905 (0.0937)\tPrec@1 96.250 (97.824)\n",
            "Total time : 40.614\n",
            "Train Loss: 0.0937, Train Accuracy: 0.9782\n",
            "Test Loss : 0.1494, Test Accuracy : 0.9515 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.502 (0.502)\tData 0.391 (0.391)\tLoss 0.1278 (0.1278)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [181][100/391]\tTime 0.102 (0.107)\tData 0.000 (0.006)\tLoss 0.1040 (0.0937)\tPrec@1 96.094 (97.881)\n",
            "Epoch: [181][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.0801 (0.0948)\tPrec@1 97.656 (97.816)\n",
            "Epoch: [181][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.0885 (0.0923)\tPrec@1 97.656 (97.921)\n",
            "Epoch: [181][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.0432 (0.0905)\tPrec@1 100.000 (97.978)\n",
            "Total time : 40.394\n",
            "Train Loss: 0.0905, Train Accuracy: 0.9798\n",
            "Test Loss : 0.1506, Test Accuracy : 0.9504 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.421 (0.421)\tData 0.312 (0.312)\tLoss 0.1045 (0.1045)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [182][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.0998 (0.0870)\tPrec@1 97.656 (98.020)\n",
            "Epoch: [182][200/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.0498 (0.0891)\tPrec@1 100.000 (97.975)\n",
            "Epoch: [182][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.0929 (0.0909)\tPrec@1 98.438 (97.950)\n",
            "Epoch: [182][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.1188 (0.0915)\tPrec@1 97.500 (97.928)\n",
            "Total time : 40.398\n",
            "Train Loss: 0.0915, Train Accuracy: 0.9793\n",
            "Test Loss : 0.1496, Test Accuracy : 0.9533 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.412 (0.412)\tData 0.307 (0.307)\tLoss 0.1032 (0.1032)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [183][100/391]\tTime 0.103 (0.107)\tData 0.000 (0.006)\tLoss 0.0700 (0.0926)\tPrec@1 99.219 (97.873)\n",
            "Epoch: [183][200/391]\tTime 0.101 (0.105)\tData 0.000 (0.003)\tLoss 0.0965 (0.0926)\tPrec@1 96.875 (97.940)\n",
            "Epoch: [183][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.002)\tLoss 0.0397 (0.0907)\tPrec@1 100.000 (97.957)\n",
            "Epoch: [183][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.002)\tLoss 0.1634 (0.0912)\tPrec@1 96.250 (97.928)\n",
            "Total time : 40.515\n",
            "Train Loss: 0.0912, Train Accuracy: 0.9793\n",
            "Test Loss : 0.1493, Test Accuracy : 0.9519 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.388 (0.388)\tData 0.276 (0.276)\tLoss 0.0771 (0.0771)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [184][100/391]\tTime 0.102 (0.106)\tData 0.001 (0.005)\tLoss 0.0779 (0.0906)\tPrec@1 99.219 (98.020)\n",
            "Epoch: [184][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1213 (0.0937)\tPrec@1 98.438 (97.839)\n",
            "Epoch: [184][300/391]\tTime 0.107 (0.104)\tData 0.001 (0.003)\tLoss 0.0742 (0.0926)\tPrec@1 98.438 (97.900)\n",
            "Epoch: [184][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1015 (0.0911)\tPrec@1 96.250 (97.938)\n",
            "Total time : 40.299\n",
            "Train Loss: 0.0911, Train Accuracy: 0.9794\n",
            "Test Loss : 0.1487, Test Accuracy : 0.9525 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.595 (0.595)\tData 0.481 (0.481)\tLoss 0.0949 (0.0949)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [185][100/391]\tTime 0.108 (0.106)\tData 0.012 (0.006)\tLoss 0.1074 (0.0846)\tPrec@1 96.094 (98.159)\n",
            "Epoch: [185][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.0649 (0.0874)\tPrec@1 100.000 (98.076)\n",
            "Epoch: [185][300/391]\tTime 0.102 (0.105)\tData 0.000 (0.003)\tLoss 0.0831 (0.0873)\tPrec@1 98.438 (98.066)\n",
            "Epoch: [185][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.0732 (0.0884)\tPrec@1 100.000 (98.042)\n",
            "Total time : 40.852\n",
            "Train Loss: 0.0884, Train Accuracy: 0.9804\n",
            "Test Loss : 0.1471, Test Accuracy : 0.9530 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.400 (0.400)\tData 0.279 (0.279)\tLoss 0.0706 (0.0706)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [186][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1148 (0.0888)\tPrec@1 97.656 (98.012)\n",
            "Epoch: [186][200/391]\tTime 0.111 (0.104)\tData 0.000 (0.003)\tLoss 0.0690 (0.0873)\tPrec@1 100.000 (98.134)\n",
            "Epoch: [186][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.0681 (0.0866)\tPrec@1 99.219 (98.142)\n",
            "Epoch: [186][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0988 (0.0862)\tPrec@1 97.500 (98.134)\n",
            "Total time : 40.268\n",
            "Train Loss: 0.0862, Train Accuracy: 0.9813\n",
            "Test Loss : 0.1472, Test Accuracy : 0.9524 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.401 (0.401)\tData 0.263 (0.263)\tLoss 0.0574 (0.0574)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [187][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.0444 (0.0877)\tPrec@1 100.000 (97.973)\n",
            "Epoch: [187][200/391]\tTime 0.110 (0.105)\tData 0.000 (0.003)\tLoss 0.0671 (0.0855)\tPrec@1 99.219 (98.107)\n",
            "Epoch: [187][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.0410 (0.0847)\tPrec@1 100.000 (98.118)\n",
            "Epoch: [187][390/391]\tTime 0.075 (0.103)\tData 0.000 (0.002)\tLoss 0.0693 (0.0854)\tPrec@1 100.000 (98.086)\n",
            "Total time : 40.458\n",
            "Train Loss: 0.0854, Train Accuracy: 0.9809\n",
            "Test Loss : 0.1451, Test Accuracy : 0.9537 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.402 (0.402)\tData 0.289 (0.289)\tLoss 0.1160 (0.1160)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [188][100/391]\tTime 0.118 (0.106)\tData 0.011 (0.005)\tLoss 0.1035 (0.0859)\tPrec@1 96.875 (98.105)\n",
            "Epoch: [188][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.0547 (0.0863)\tPrec@1 100.000 (98.095)\n",
            "Epoch: [188][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.002)\tLoss 0.0638 (0.0864)\tPrec@1 100.000 (98.030)\n",
            "Epoch: [188][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.0966 (0.0866)\tPrec@1 98.750 (98.040)\n",
            "Total time : 40.440\n",
            "Train Loss: 0.0866, Train Accuracy: 0.9804\n",
            "Test Loss : 0.1450, Test Accuracy : 0.9532 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.365 (0.365)\tData 0.261 (0.261)\tLoss 0.0986 (0.0986)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [189][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.0575 (0.0881)\tPrec@1 100.000 (97.966)\n",
            "Epoch: [189][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.0877 (0.0881)\tPrec@1 97.656 (97.971)\n",
            "Epoch: [189][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.1022 (0.0886)\tPrec@1 96.875 (97.970)\n",
            "Epoch: [189][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0696 (0.0877)\tPrec@1 98.750 (98.010)\n",
            "Total time : 40.456\n",
            "Train Loss: 0.0877, Train Accuracy: 0.9801\n",
            "Test Loss : 0.1462, Test Accuracy : 0.9538 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.507 (0.507)\tData 0.370 (0.370)\tLoss 0.0658 (0.0658)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [190][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.0664 (0.0823)\tPrec@1 98.438 (98.314)\n",
            "Epoch: [190][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.1610 (0.0829)\tPrec@1 95.312 (98.212)\n",
            "Epoch: [190][300/391]\tTime 0.102 (0.104)\tData 0.000 (0.003)\tLoss 0.0476 (0.0830)\tPrec@1 99.219 (98.162)\n",
            "Epoch: [190][390/391]\tTime 0.073 (0.104)\tData 0.000 (0.003)\tLoss 0.0431 (0.0823)\tPrec@1 100.000 (98.188)\n",
            "Total time : 40.489\n",
            "Train Loss: 0.0823, Train Accuracy: 0.9819\n",
            "Test Loss : 0.1442, Test Accuracy : 0.9542 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.415 (0.415)\tData 0.289 (0.289)\tLoss 0.1407 (0.1407)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [191][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.005)\tLoss 0.1045 (0.0866)\tPrec@1 96.875 (97.935)\n",
            "Epoch: [191][200/391]\tTime 0.105 (0.104)\tData 0.001 (0.003)\tLoss 0.0660 (0.0843)\tPrec@1 99.219 (98.130)\n",
            "Epoch: [191][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.0671 (0.0825)\tPrec@1 99.219 (98.212)\n",
            "Epoch: [191][390/391]\tTime 0.072 (0.104)\tData 0.000 (0.003)\tLoss 0.1036 (0.0816)\tPrec@1 98.750 (98.244)\n",
            "Total time : 40.652\n",
            "Train Loss: 0.0816, Train Accuracy: 0.9824\n",
            "Test Loss : 0.1450, Test Accuracy : 0.9538 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.401 (0.401)\tData 0.255 (0.255)\tLoss 0.0890 (0.0890)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [192][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.0475 (0.0819)\tPrec@1 100.000 (98.236)\n",
            "Epoch: [192][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.0555 (0.0809)\tPrec@1 98.438 (98.224)\n",
            "Epoch: [192][300/391]\tTime 0.103 (0.103)\tData 0.000 (0.002)\tLoss 0.1247 (0.0798)\tPrec@1 96.094 (98.274)\n",
            "Epoch: [192][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0919 (0.0811)\tPrec@1 97.500 (98.202)\n",
            "Total time : 40.216\n",
            "Train Loss: 0.0811, Train Accuracy: 0.9820\n",
            "Test Loss : 0.1444, Test Accuracy : 0.9536 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.384 (0.384)\tData 0.275 (0.275)\tLoss 0.0768 (0.0768)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [193][100/391]\tTime 0.100 (0.104)\tData 0.000 (0.004)\tLoss 0.1196 (0.0796)\tPrec@1 96.875 (98.252)\n",
            "Epoch: [193][200/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.0624 (0.0817)\tPrec@1 99.219 (98.189)\n",
            "Epoch: [193][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.1049 (0.0824)\tPrec@1 97.656 (98.139)\n",
            "Epoch: [193][390/391]\tTime 0.074 (0.103)\tData 0.000 (0.002)\tLoss 0.0651 (0.0822)\tPrec@1 98.750 (98.162)\n",
            "Total time : 40.385\n",
            "Train Loss: 0.0822, Train Accuracy: 0.9816\n",
            "Test Loss : 0.1440, Test Accuracy : 0.9541 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.349 (0.349)\tData 0.225 (0.225)\tLoss 0.0778 (0.0778)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [194][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.004)\tLoss 0.0637 (0.0800)\tPrec@1 98.438 (98.337)\n",
            "Epoch: [194][200/391]\tTime 0.110 (0.104)\tData 0.007 (0.003)\tLoss 0.0707 (0.0796)\tPrec@1 99.219 (98.309)\n",
            "Epoch: [194][300/391]\tTime 0.102 (0.103)\tData 0.000 (0.002)\tLoss 0.1031 (0.0813)\tPrec@1 97.656 (98.196)\n",
            "Epoch: [194][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1118 (0.0808)\tPrec@1 97.500 (98.228)\n",
            "Total time : 40.294\n",
            "Train Loss: 0.0808, Train Accuracy: 0.9823\n",
            "Test Loss : 0.1448, Test Accuracy : 0.9534 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.395 (0.395)\tData 0.275 (0.275)\tLoss 0.0828 (0.0828)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [195][100/391]\tTime 0.100 (0.106)\tData 0.000 (0.005)\tLoss 0.0783 (0.0878)\tPrec@1 98.438 (98.004)\n",
            "Epoch: [195][200/391]\tTime 0.100 (0.104)\tData 0.000 (0.003)\tLoss 0.1264 (0.0829)\tPrec@1 96.094 (98.193)\n",
            "Epoch: [195][300/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.0880 (0.0816)\tPrec@1 96.875 (98.248)\n",
            "Epoch: [195][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.1204 (0.0827)\tPrec@1 97.500 (98.204)\n",
            "Total time : 40.333\n",
            "Train Loss: 0.0827, Train Accuracy: 0.9820\n",
            "Test Loss : 0.1443, Test Accuracy : 0.9543 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.391 (0.391)\tData 0.281 (0.281)\tLoss 0.0710 (0.0710)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [196][100/391]\tTime 0.104 (0.107)\tData 0.006 (0.005)\tLoss 0.0588 (0.0807)\tPrec@1 100.000 (98.260)\n",
            "Epoch: [196][200/391]\tTime 0.099 (0.104)\tData 0.001 (0.003)\tLoss 0.1140 (0.0821)\tPrec@1 96.094 (98.185)\n",
            "Epoch: [196][300/391]\tTime 0.100 (0.104)\tData 0.000 (0.002)\tLoss 0.0823 (0.0828)\tPrec@1 97.656 (98.155)\n",
            "Epoch: [196][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0454 (0.0830)\tPrec@1 98.750 (98.108)\n",
            "Total time : 40.442\n",
            "Train Loss: 0.0830, Train Accuracy: 0.9811\n",
            "Test Loss : 0.1450, Test Accuracy : 0.9543 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.391 (0.391)\tData 0.273 (0.273)\tLoss 0.1337 (0.1337)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [197][100/391]\tTime 0.101 (0.105)\tData 0.000 (0.004)\tLoss 0.1095 (0.0835)\tPrec@1 97.656 (98.113)\n",
            "Epoch: [197][200/391]\tTime 0.101 (0.104)\tData 0.000 (0.003)\tLoss 0.0827 (0.0836)\tPrec@1 98.438 (98.037)\n",
            "Epoch: [197][300/391]\tTime 0.105 (0.104)\tData 0.007 (0.003)\tLoss 0.0993 (0.0829)\tPrec@1 96.875 (98.066)\n",
            "Epoch: [197][390/391]\tTime 0.072 (0.103)\tData 0.000 (0.002)\tLoss 0.0501 (0.0825)\tPrec@1 100.000 (98.104)\n",
            "Total time : 40.322\n",
            "Train Loss: 0.0825, Train Accuracy: 0.9810\n",
            "Test Loss : 0.1444, Test Accuracy : 0.9537 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.514 (0.514)\tData 0.368 (0.368)\tLoss 0.1136 (0.1136)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [198][100/391]\tTime 0.109 (0.108)\tData 0.012 (0.006)\tLoss 0.1012 (0.0824)\tPrec@1 97.656 (98.105)\n",
            "Epoch: [198][200/391]\tTime 0.101 (0.106)\tData 0.000 (0.004)\tLoss 0.1371 (0.0827)\tPrec@1 96.875 (98.142)\n",
            "Epoch: [198][300/391]\tTime 0.103 (0.105)\tData 0.000 (0.003)\tLoss 0.0890 (0.0825)\tPrec@1 97.656 (98.206)\n",
            "Epoch: [198][390/391]\tTime 0.075 (0.104)\tData 0.000 (0.003)\tLoss 0.1090 (0.0820)\tPrec@1 97.500 (98.206)\n",
            "Total time : 40.823\n",
            "Train Loss: 0.0820, Train Accuracy: 0.9821\n",
            "Test Loss : 0.1446, Test Accuracy : 0.9539 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.417 (0.417)\tData 0.268 (0.268)\tLoss 0.1107 (0.1107)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [199][100/391]\tTime 0.101 (0.106)\tData 0.000 (0.005)\tLoss 0.0786 (0.0821)\tPrec@1 99.219 (98.205)\n",
            "Epoch: [199][200/391]\tTime 0.112 (0.104)\tData 0.006 (0.003)\tLoss 0.0823 (0.0804)\tPrec@1 97.656 (98.294)\n",
            "Epoch: [199][300/391]\tTime 0.101 (0.103)\tData 0.000 (0.002)\tLoss 0.0878 (0.0803)\tPrec@1 98.438 (98.258)\n",
            "Epoch: [199][390/391]\tTime 0.073 (0.103)\tData 0.000 (0.002)\tLoss 0.0591 (0.0807)\tPrec@1 100.000 (98.248)\n",
            "Total time : 40.331\n",
            "Train Loss: 0.0807, Train Accuracy: 0.9825\n",
            "Test Loss : 0.1451, Test Accuracy : 0.9546 \n",
            "\n",
            "train loss:  [1.8638, 1.5403, 1.3004, 1.1015, 0.9911, 0.9043, 0.8468, 0.8023, 0.7674, 0.742, 0.7076, 0.6915, 0.6812, 0.6618, 0.6519, 0.6351, 0.6242, 0.6108, 0.6052, 0.5978, 0.5852, 0.5773, 0.5766, 0.5626, 0.5559, 0.5514, 0.5399, 0.5463, 0.5287, 0.5346, 0.53, 0.5305, 0.5254, 0.5147, 0.5109, 0.5126, 0.5034, 0.5063, 0.4966, 0.5063, 0.4882, 0.4897, 0.4757, 0.4789, 0.4797, 0.48, 0.4704, 0.4739, 0.457, 0.4689, 0.4614, 0.4563, 0.4557, 0.4596, 0.4469, 0.4399, 0.4413, 0.4499, 0.4428, 0.4337, 0.4383, 0.434, 0.4367, 0.4294, 0.4307, 0.4246, 0.4128, 0.4174, 0.4164, 0.4085, 0.4065, 0.4088, 0.3969, 0.4012, 0.3943, 0.3877, 0.3836, 0.3893, 0.3819, 0.3744, 0.3816, 0.3755, 0.3682, 0.3735, 0.3689, 0.3638, 0.3621, 0.359, 0.3589, 0.3462, 0.3455, 0.3469, 0.3403, 0.3369, 0.3348, 0.3363, 0.333, 0.329, 0.3268, 0.3223, 0.3174, 0.31, 0.3095, 0.3086, 0.299, 0.3082, 0.2964, 0.2933, 0.2968, 0.2888, 0.287, 0.2832, 0.2806, 0.2806, 0.2732, 0.2661, 0.2636, 0.2604, 0.2585, 0.2532, 0.2499, 0.2496, 0.2489, 0.2453, 0.2377, 0.2341, 0.235, 0.2278, 0.2268, 0.2217, 0.2224, 0.2166, 0.2145, 0.2092, 0.2034, 0.1987, 0.1992, 0.1986, 0.1961, 0.1893, 0.1848, 0.1832, 0.1808, 0.1767, 0.1749, 0.1709, 0.1664, 0.1657, 0.1637, 0.1605, 0.1598, 0.1515, 0.1487, 0.1482, 0.1444, 0.1432, 0.1421, 0.1358, 0.1365, 0.1305, 0.1312, 0.1277, 0.1267, 0.1238, 0.1244, 0.1185, 0.113, 0.1152, 0.1112, 0.1105, 0.1077, 0.1052, 0.1061, 0.0996, 0.0991, 0.0987, 0.098, 0.098, 0.0962, 0.0957, 0.0937, 0.0905, 0.0915, 0.0912, 0.0911, 0.0884, 0.0862, 0.0854, 0.0866, 0.0877, 0.0823, 0.0816, 0.0811, 0.0822, 0.0808, 0.0827, 0.083, 0.0825, 0.082, 0.0807]\n",
            "train err:  [0.7326, 0.5886, 0.4619, 0.3825, 0.3397, 0.306, 0.2855, 0.2659, 0.2504, 0.243, 0.2305, 0.2234, 0.2181, 0.2131, 0.209, 0.2034, 0.2002, 0.1968, 0.1918, 0.1911, 0.1859, 0.1832, 0.1824, 0.1787, 0.1762, 0.1754, 0.1721, 0.1734, 0.1683, 0.1682, 0.1665, 0.1665, 0.1651, 0.1613, 0.1598, 0.1611, 0.1578, 0.1597, 0.1552, 0.1598, 0.1536, 0.1549, 0.1522, 0.1517, 0.1532, 0.1508, 0.1466, 0.1501, 0.1431, 0.1474, 0.1437, 0.1443, 0.1433, 0.1445, 0.1395, 0.1392, 0.1407, 0.1405, 0.1383, 0.1356, 0.1374, 0.1361, 0.1374, 0.1348, 0.1347, 0.1331, 0.1291, 0.1299, 0.1303, 0.1282, 0.1269, 0.1267, 0.122, 0.1243, 0.1219, 0.1204, 0.121, 0.1215, 0.117, 0.1154, 0.1182, 0.1156, 0.1132, 0.1149, 0.1145, 0.1121, 0.1129, 0.1104, 0.1107, 0.106, 0.1052, 0.1054, 0.1051, 0.1051, 0.102, 0.1037, 0.1013, 0.1005, 0.1001, 0.0985, 0.0968, 0.0943, 0.0942, 0.0927, 0.0888, 0.0934, 0.089, 0.0876, 0.0895, 0.0865, 0.085, 0.086, 0.0835, 0.0845, 0.0818, 0.0793, 0.0778, 0.0773, 0.0752, 0.074, 0.0731, 0.0715, 0.0718, 0.0708, 0.0679, 0.0661, 0.0672, 0.0647, 0.0635, 0.0627, 0.0628, 0.0599, 0.0604, 0.0586, 0.0548, 0.0544, 0.0554, 0.0543, 0.054, 0.0517, 0.0496, 0.0493, 0.0477, 0.0468, 0.0465, 0.0458, 0.0429, 0.0435, 0.043, 0.0421, 0.0412, 0.0382, 0.0376, 0.037, 0.0362, 0.035, 0.0357, 0.0326, 0.0332, 0.0315, 0.0311, 0.031, 0.0304, 0.0294, 0.0295, 0.0283, 0.026, 0.026, 0.0263, 0.0257, 0.0245, 0.0234, 0.0243, 0.0228, 0.0226, 0.0219, 0.0225, 0.0218, 0.0222, 0.0213, 0.0218, 0.0202, 0.0207, 0.0207, 0.0206, 0.0196, 0.0187, 0.0191, 0.0196, 0.0199, 0.0181, 0.0176, 0.018, 0.0184, 0.0177, 0.018, 0.0189, 0.019, 0.0179, 0.0175]\n",
            "train acc:  [0.2674, 0.4114, 0.5381, 0.6175, 0.6603, 0.694, 0.7145, 0.7341, 0.7496, 0.757, 0.7695, 0.7766, 0.7819, 0.7869, 0.791, 0.7966, 0.7998, 0.8032, 0.8082, 0.8089, 0.8141, 0.8168, 0.8176, 0.8213, 0.8238, 0.8246, 0.8279, 0.8266, 0.8317, 0.8318, 0.8335, 0.8335, 0.8349, 0.8387, 0.8402, 0.8389, 0.8422, 0.8403, 0.8448, 0.8402, 0.8464, 0.8451, 0.8478, 0.8483, 0.8468, 0.8492, 0.8534, 0.8499, 0.8569, 0.8526, 0.8563, 0.8557, 0.8567, 0.8555, 0.8605, 0.8608, 0.8593, 0.8595, 0.8617, 0.8644, 0.8626, 0.8639, 0.8626, 0.8652, 0.8653, 0.8669, 0.8709, 0.8701, 0.8697, 0.8718, 0.8731, 0.8733, 0.878, 0.8757, 0.8781, 0.8796, 0.879, 0.8785, 0.883, 0.8846, 0.8818, 0.8844, 0.8868, 0.8851, 0.8855, 0.8879, 0.8871, 0.8896, 0.8893, 0.894, 0.8948, 0.8946, 0.8949, 0.8949, 0.898, 0.8963, 0.8987, 0.8995, 0.8999, 0.9015, 0.9032, 0.9057, 0.9058, 0.9073, 0.9112, 0.9066, 0.911, 0.9124, 0.9105, 0.9135, 0.915, 0.914, 0.9165, 0.9155, 0.9182, 0.9207, 0.9222, 0.9227, 0.9248, 0.926, 0.9269, 0.9285, 0.9282, 0.9292, 0.9321, 0.9339, 0.9328, 0.9353, 0.9365, 0.9373, 0.9372, 0.9401, 0.9396, 0.9414, 0.9452, 0.9456, 0.9446, 0.9457, 0.946, 0.9483, 0.9504, 0.9507, 0.9523, 0.9532, 0.9535, 0.9542, 0.9571, 0.9565, 0.957, 0.9579, 0.9588, 0.9618, 0.9624, 0.963, 0.9638, 0.965, 0.9643, 0.9674, 0.9668, 0.9685, 0.9689, 0.969, 0.9696, 0.9706, 0.9705, 0.9717, 0.974, 0.974, 0.9737, 0.9743, 0.9755, 0.9766, 0.9757, 0.9772, 0.9774, 0.9781, 0.9775, 0.9782, 0.9778, 0.9787, 0.9782, 0.9798, 0.9793, 0.9793, 0.9794, 0.9804, 0.9813, 0.9809, 0.9804, 0.9801, 0.9819, 0.9824, 0.982, 0.9816, 0.9823, 0.982, 0.9811, 0.981, 0.9821, 0.9825]\n",
            "test loss:  [1.6159, 1.4616, 1.4302, 0.9596, 0.9405, 0.9989, 0.7842, 0.7529, 0.8675, 0.7213, 0.6504, 0.7447, 0.6553, 0.6483, 0.8752, 0.6711, 0.6796, 0.7134, 0.6194, 0.6614, 0.6017, 0.6937, 0.6503, 0.6028, 0.6148, 0.6371, 0.5212, 0.4853, 0.5443, 0.4718, 0.5468, 0.5331, 0.4721, 0.5553, 0.6661, 0.5196, 0.4501, 0.4912, 0.4557, 0.4194, 0.5293, 0.4516, 0.4824, 0.4461, 0.5169, 0.5001, 0.5207, 0.4664, 0.5387, 0.4092, 0.4562, 0.4377, 0.4402, 0.4398, 0.388, 0.5135, 0.6017, 0.5281, 0.4312, 0.4873, 0.3926, 0.6046, 0.5584, 0.5077, 0.4198, 0.4695, 0.7273, 0.4137, 0.3833, 0.4188, 0.3989, 0.3975, 0.4392, 0.3721, 0.3465, 0.3922, 0.4522, 0.3362, 0.3777, 0.413, 0.3464, 0.41, 0.4713, 0.3495, 0.5307, 0.3576, 0.3741, 0.3209, 0.3723, 0.3852, 0.3436, 0.3514, 0.3065, 0.33, 0.3846, 0.4868, 0.3641, 0.3727, 0.2941, 0.3093, 0.323, 0.3488, 0.3065, 0.3029, 0.2801, 0.2933, 0.2793, 0.302, 0.2745, 0.2963, 0.2745, 0.3, 0.2779, 0.3002, 0.3279, 0.2716, 0.2464, 0.2691, 0.2646, 0.2485, 0.2969, 0.2305, 0.2927, 0.2664, 0.2724, 0.2588, 0.2508, 0.2384, 0.2296, 0.2392, 0.2379, 0.2235, 0.222, 0.2267, 0.2075, 0.2094, 0.2123, 0.216, 0.2103, 0.1985, 0.2172, 0.1854, 0.1922, 0.198, 0.1964, 0.2069, 0.1967, 0.2137, 0.1855, 0.187, 0.182, 0.1886, 0.1825, 0.1872, 0.1797, 0.1795, 0.1673, 0.1663, 0.1665, 0.1624, 0.1783, 0.1695, 0.1655, 0.1634, 0.1644, 0.1612, 0.1626, 0.1603, 0.1586, 0.1582, 0.1545, 0.1551, 0.1516, 0.1494, 0.1503, 0.148, 0.1497, 0.1502, 0.1495, 0.1501, 0.1494, 0.1506, 0.1496, 0.1493, 0.1487, 0.1471, 0.1472, 0.1451, 0.145, 0.1462, 0.1442, 0.145, 0.1444, 0.144, 0.1448, 0.1443, 0.145, 0.1444, 0.1446, 0.1451]\n",
            "test err:  [0.6252, 0.5562, 0.477, 0.3312, 0.3239, 0.3386, 0.2612, 0.2471, 0.2778, 0.2347, 0.2097, 0.2442, 0.218, 0.2097, 0.2742, 0.2228, 0.2191, 0.2337, 0.2124, 0.2183, 0.1933, 0.2141, 0.2073, 0.2007, 0.2068, 0.2132, 0.1722, 0.1573, 0.1704, 0.1491, 0.1705, 0.1734, 0.1554, 0.1861, 0.2234, 0.1639, 0.1478, 0.1577, 0.1447, 0.1336, 0.1719, 0.1469, 0.1598, 0.1476, 0.1632, 0.167, 0.1735, 0.1452, 0.1774, 0.1314, 0.1546, 0.1413, 0.1464, 0.1408, 0.1229, 0.1704, 0.1892, 0.176, 0.1391, 0.1704, 0.1268, 0.186, 0.1724, 0.169, 0.1361, 0.149, 0.2098, 0.1379, 0.1234, 0.1354, 0.1268, 0.1313, 0.1442, 0.1184, 0.1112, 0.1289, 0.1488, 0.108, 0.1232, 0.1315, 0.1164, 0.135, 0.1657, 0.1137, 0.1744, 0.1187, 0.1276, 0.1071, 0.1226, 0.1278, 0.108, 0.1158, 0.103, 0.1048, 0.1277, 0.1597, 0.121, 0.1199, 0.0943, 0.1003, 0.1095, 0.112, 0.1003, 0.1024, 0.094, 0.0945, 0.0881, 0.0996, 0.0881, 0.0947, 0.0886, 0.093, 0.0907, 0.0964, 0.1096, 0.0881, 0.0816, 0.0916, 0.0878, 0.0807, 0.096, 0.074, 0.0977, 0.0893, 0.0897, 0.0878, 0.0804, 0.0764, 0.0753, 0.0785, 0.077, 0.0725, 0.072, 0.072, 0.0653, 0.0675, 0.0724, 0.0691, 0.0691, 0.0655, 0.0718, 0.0593, 0.0622, 0.0636, 0.064, 0.0697, 0.0636, 0.0715, 0.0594, 0.0619, 0.06, 0.0624, 0.0615, 0.0603, 0.0585, 0.0573, 0.0548, 0.0541, 0.054, 0.0531, 0.0593, 0.0561, 0.0548, 0.054, 0.0522, 0.0522, 0.052, 0.0519, 0.0529, 0.0522, 0.0508, 0.0506, 0.0482, 0.0476, 0.0499, 0.0486, 0.0486, 0.0491, 0.0489, 0.0482, 0.0485, 0.0496, 0.0467, 0.0481, 0.0475, 0.047, 0.0476, 0.0463, 0.0468, 0.0462, 0.0458, 0.0462, 0.0464, 0.0459, 0.0466, 0.0457, 0.0457, 0.0463, 0.0461, 0.0454]\n",
            "test acc:  [0.3748, 0.4438, 0.523, 0.6688, 0.6761, 0.6614, 0.7388, 0.7529, 0.7222, 0.7653, 0.7903, 0.7558, 0.782, 0.7903, 0.7258, 0.7772, 0.7809, 0.7663, 0.7876, 0.7817, 0.8067, 0.7859, 0.7927, 0.7993, 0.7932, 0.7868, 0.8278, 0.8427, 0.8296, 0.8509, 0.8295, 0.8266, 0.8446, 0.8139, 0.7766, 0.8361, 0.8522, 0.8423, 0.8553, 0.8664, 0.8281, 0.8531, 0.8402, 0.8524, 0.8368, 0.833, 0.8265, 0.8548, 0.8226, 0.8686, 0.8454, 0.8587, 0.8536, 0.8592, 0.8771, 0.8296, 0.8108, 0.824, 0.8609, 0.8296, 0.8732, 0.814, 0.8276, 0.831, 0.8639, 0.851, 0.7902, 0.8621, 0.8766, 0.8646, 0.8732, 0.8687, 0.8558, 0.8816, 0.8888, 0.8711, 0.8512, 0.892, 0.8768, 0.8685, 0.8836, 0.865, 0.8343, 0.8863, 0.8256, 0.8813, 0.8724, 0.8929, 0.8774, 0.8722, 0.892, 0.8842, 0.897, 0.8952, 0.8723, 0.8403, 0.879, 0.8801, 0.9057, 0.8997, 0.8905, 0.888, 0.8997, 0.8976, 0.906, 0.9055, 0.9119, 0.9004, 0.9119, 0.9053, 0.9114, 0.907, 0.9093, 0.9036, 0.8904, 0.9119, 0.9184, 0.9084, 0.9122, 0.9193, 0.904, 0.926, 0.9023, 0.9107, 0.9103, 0.9122, 0.9196, 0.9236, 0.9247, 0.9215, 0.923, 0.9275, 0.928, 0.928, 0.9347, 0.9325, 0.9276, 0.9309, 0.9309, 0.9345, 0.9282, 0.9407, 0.9378, 0.9364, 0.936, 0.9303, 0.9364, 0.9285, 0.9406, 0.9381, 0.94, 0.9376, 0.9385, 0.9397, 0.9415, 0.9427, 0.9452, 0.9459, 0.946, 0.9469, 0.9407, 0.9439, 0.9452, 0.946, 0.9478, 0.9478, 0.948, 0.9481, 0.9471, 0.9478, 0.9492, 0.9494, 0.9518, 0.9524, 0.9501, 0.9514, 0.9514, 0.9509, 0.9511, 0.9518, 0.9515, 0.9504, 0.9533, 0.9519, 0.9525, 0.953, 0.9524, 0.9537, 0.9532, 0.9538, 0.9542, 0.9538, 0.9536, 0.9541, 0.9534, 0.9543, 0.9543, 0.9537, 0.9539, 0.9546]\n",
            "ori train loss:  [1.9429, 1.6356, 1.4139, 1.22, 1.1097, 1.0279, 0.9763, 0.9346, 0.9034, 0.8799, 0.8466, 0.8321, 0.8229, 0.8037, 0.794, 0.7784, 0.7684, 0.7575, 0.7518, 0.7431, 0.7313, 0.7269, 0.726, 0.7095, 0.7051, 0.7029, 0.691, 0.6964, 0.6768, 0.6829, 0.6803, 0.6831, 0.681, 0.6685, 0.6621, 0.666, 0.6568, 0.6591, 0.6497, 0.6612, 0.6427, 0.645, 0.6303, 0.6316, 0.6344, 0.637, 0.6273, 0.6299, 0.6146, 0.6247, 0.6167, 0.6138, 0.6125, 0.6191, 0.6035, 0.5944, 0.5969, 0.6075, 0.6009, 0.5886, 0.5958, 0.5918, 0.5975, 0.5878, 0.5891, 0.5825, 0.5718, 0.5779, 0.5794, 0.5693, 0.5689, 0.5697, 0.5593, 0.5639, 0.5551, 0.5489, 0.5459, 0.5513, 0.5443, 0.5367, 0.5431, 0.5377, 0.532, 0.5369, 0.5329, 0.5268, 0.5277, 0.5232, 0.5243, 0.5126, 0.5119, 0.513, 0.5038, 0.5018, 0.4998, 0.5021, 0.5005, 0.4971, 0.4926, 0.4898, 0.4856, 0.4783, 0.4796, 0.4769, 0.4677, 0.4795, 0.4658, 0.4626, 0.4678, 0.458, 0.459, 0.4548, 0.4511, 0.4534, 0.4449, 0.4386, 0.4348, 0.4315, 0.43, 0.4268, 0.423, 0.4253, 0.4197, 0.4184, 0.4084, 0.4044, 0.4082, 0.4022, 0.4003, 0.3946, 0.3962, 0.3913, 0.387, 0.383, 0.3764, 0.3712, 0.3764, 0.3707, 0.3699, 0.3626, 0.3573, 0.3577, 0.3547, 0.3469, 0.3499, 0.3408, 0.3356, 0.3376, 0.3358, 0.3309, 0.3312, 0.3209, 0.3158, 0.3179, 0.3123, 0.3102, 0.3104, 0.3018, 0.3026, 0.2935, 0.2945, 0.2896, 0.288, 0.2845, 0.2858, 0.2743, 0.2694, 0.2707, 0.2676, 0.2643, 0.2616, 0.2578, 0.2574, 0.2474, 0.2466, 0.248, 0.2448, 0.2429, 0.2372, 0.2393, 0.2341, 0.2302, 0.23, 0.2317, 0.2312, 0.2283, 0.2221, 0.2203, 0.2191, 0.2218, 0.2162, 0.2124, 0.2146, 0.2125, 0.2111, 0.2146, 0.2147, 0.2131, 0.2117, 0.2123]\n",
            "ori train err:  [0.7592, 0.6232, 0.5036, 0.4209, 0.3786, 0.3463, 0.325, 0.3085, 0.2939, 0.2868, 0.274, 0.2679, 0.2623, 0.2564, 0.2537, 0.2493, 0.2455, 0.2412, 0.2384, 0.2353, 0.2315, 0.2292, 0.2288, 0.2239, 0.2217, 0.2209, 0.2188, 0.2179, 0.2128, 0.2141, 0.212, 0.2115, 0.2126, 0.2082, 0.2066, 0.2083, 0.2039, 0.2071, 0.2014, 0.2057, 0.2017, 0.2023, 0.1972, 0.1975, 0.1995, 0.197, 0.1946, 0.1971, 0.1929, 0.1946, 0.1919, 0.1909, 0.1893, 0.1923, 0.1879, 0.1874, 0.1856, 0.1877, 0.1877, 0.1849, 0.1874, 0.1837, 0.1873, 0.1827, 0.1824, 0.181, 0.1789, 0.1793, 0.1796, 0.1768, 0.1765, 0.1774, 0.1718, 0.1747, 0.1706, 0.1711, 0.1702, 0.1698, 0.1673, 0.1671, 0.1683, 0.165, 0.164, 0.1647, 0.1659, 0.1607, 0.1628, 0.161, 0.1625, 0.158, 0.1556, 0.1597, 0.1554, 0.1558, 0.1537, 0.1542, 0.154, 0.1524, 0.1526, 0.1495, 0.1478, 0.1466, 0.1462, 0.1449, 0.1408, 0.1455, 0.143, 0.1407, 0.142, 0.1395, 0.1392, 0.1385, 0.1361, 0.1369, 0.1351, 0.1325, 0.1306, 0.1293, 0.1309, 0.128, 0.1278, 0.1275, 0.1256, 0.1222, 0.1232, 0.1201, 0.1221, 0.1175, 0.1199, 0.1167, 0.1171, 0.1153, 0.1126, 0.1138, 0.1112, 0.1087, 0.1104, 0.1078, 0.1083, 0.106, 0.104, 0.1037, 0.1018, 0.0991, 0.1013, 0.097, 0.0961, 0.0961, 0.0956, 0.0942, 0.0939, 0.0912, 0.0889, 0.0868, 0.0872, 0.0863, 0.0872, 0.0832, 0.0843, 0.0808, 0.0818, 0.08, 0.0777, 0.0785, 0.0785, 0.0737, 0.0726, 0.0735, 0.072, 0.0713, 0.0695, 0.0699, 0.0694, 0.0645, 0.0656, 0.0663, 0.0646, 0.0634, 0.0624, 0.0636, 0.0607, 0.0598, 0.0606, 0.0611, 0.0601, 0.0603, 0.0584, 0.0581, 0.0571, 0.0578, 0.0562, 0.0551, 0.0561, 0.0553, 0.055, 0.0555, 0.0557, 0.0558, 0.0552, 0.0554]\n",
            "ori train acc:  [0.2408, 0.3768, 0.4964, 0.5791, 0.6214, 0.6537, 0.675, 0.6915, 0.7061, 0.7132, 0.726, 0.7321, 0.7377, 0.7436, 0.7463, 0.7507, 0.7545, 0.7588, 0.7616, 0.7647, 0.7685, 0.7708, 0.7712, 0.7761, 0.7783, 0.7791, 0.7812, 0.7821, 0.7872, 0.7859, 0.788, 0.7885, 0.7874, 0.7918, 0.7934, 0.7917, 0.7961, 0.7929, 0.7986, 0.7943, 0.7983, 0.7977, 0.8028, 0.8025, 0.8005, 0.803, 0.8054, 0.8029, 0.8071, 0.8054, 0.8081, 0.8091, 0.8107, 0.8077, 0.8121, 0.8126, 0.8144, 0.8123, 0.8123, 0.8151, 0.8126, 0.8163, 0.8127, 0.8173, 0.8176, 0.819, 0.8211, 0.8207, 0.8204, 0.8232, 0.8235, 0.8226, 0.8282, 0.8253, 0.8294, 0.8289, 0.8298, 0.8302, 0.8327, 0.8329, 0.8317, 0.835, 0.836, 0.8353, 0.8341, 0.8393, 0.8372, 0.839, 0.8375, 0.842, 0.8444, 0.8403, 0.8446, 0.8442, 0.8463, 0.8458, 0.846, 0.8476, 0.8474, 0.8505, 0.8522, 0.8534, 0.8538, 0.8551, 0.8592, 0.8545, 0.857, 0.8593, 0.858, 0.8605, 0.8608, 0.8615, 0.8639, 0.8631, 0.8649, 0.8675, 0.8694, 0.8707, 0.8691, 0.872, 0.8722, 0.8725, 0.8744, 0.8778, 0.8768, 0.8799, 0.8779, 0.8825, 0.8801, 0.8833, 0.8829, 0.8847, 0.8874, 0.8862, 0.8888, 0.8913, 0.8896, 0.8922, 0.8917, 0.894, 0.896, 0.8963, 0.8982, 0.9009, 0.8987, 0.903, 0.9039, 0.9039, 0.9044, 0.9058, 0.9061, 0.9088, 0.9111, 0.9132, 0.9128, 0.9137, 0.9128, 0.9168, 0.9157, 0.9192, 0.9182, 0.92, 0.9223, 0.9215, 0.9215, 0.9263, 0.9274, 0.9265, 0.928, 0.9287, 0.9305, 0.9301, 0.9306, 0.9355, 0.9344, 0.9337, 0.9354, 0.9366, 0.9376, 0.9364, 0.9393, 0.9402, 0.9394, 0.9389, 0.9399, 0.9397, 0.9416, 0.9419, 0.9429, 0.9422, 0.9438, 0.9449, 0.9439, 0.9447, 0.945, 0.9445, 0.9443, 0.9442, 0.9448, 0.9446]\n",
            "time:  [45.44, 40.32, 40.36, 40.65, 40.57, 40.38, 40.39, 40.47, 40.57, 40.5, 40.37, 40.35, 40.23, 40.63, 40.49, 40.3, 40.46, 40.4, 40.53, 40.75, 40.33, 40.67, 40.47, 40.33, 40.91, 40.35, 40.54, 40.51, 40.28, 40.55, 40.25, 40.56, 40.61, 40.28, 40.68, 40.34, 40.4, 40.43, 40.28, 40.42, 40.3, 40.37, 40.58, 40.33, 40.46, 40.63, 40.38, 40.47, 40.25, 40.74, 40.31, 45.23, 43.38, 40.41, 40.45, 40.35, 40.31, 40.34, 40.87, 40.52, 40.2, 40.37, 40.32, 40.47, 40.74, 40.17, 40.34, 40.41, 40.42, 40.53, 40.3, 40.42, 40.27, 40.32, 40.49, 40.3, 40.57, 40.19, 40.23, 40.6, 40.26, 40.7, 40.34, 40.25, 40.5, 40.34, 40.6, 40.33, 40.37, 40.79, 40.4, 40.4, 40.31, 40.31, 40.79, 40.38, 40.48, 40.35, 40.47, 40.69, 40.41, 40.47, 40.46, 40.62, 40.3, 40.31, 40.66, 40.34, 40.45, 40.31, 40.64, 40.67, 40.33, 40.51, 40.33, 40.61, 40.31, 40.42, 40.88, 40.47, 40.51, 40.66, 40.37, 40.4, 40.59, 40.29, 40.59, 40.39, 40.73, 40.46, 40.55, 40.67, 40.35, 40.57, 40.36, 40.42, 40.52, 40.54, 40.34, 40.71, 40.37, 40.75, 40.38, 40.27, 40.69, 40.32, 40.83, 40.45, 40.28, 40.29, 40.43, 40.62, 40.54, 40.3, 40.64, 40.34, 40.46, 40.65, 40.42, 40.86, 40.44, 40.74, 40.63, 40.43, 40.46, 40.47, 40.31, 40.82, 40.34, 40.4, 40.51, 40.34, 40.74, 40.19, 40.47, 40.27, 40.44, 40.55, 40.68, 40.44, 40.61, 40.39, 40.4, 40.52, 40.3, 40.85, 40.27, 40.46, 40.44, 40.46, 40.49, 40.65, 40.22, 40.38, 40.29, 40.33, 40.44, 40.32, 40.82, 40.33]\n"
          ]
        }
      ],
      "source": [
        "!python /content/trains.py \\\n",
        "    --optimizer SAM \\\n",
        "    --rho 0.1 \\\n",
        "    --T 0.1 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --arch VGG16_BN \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR10 \\\n",
        "    --epochs 200 \\\n",
        "    --batch-size 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5vbkIp5PgUI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNr06BQxnPklIqaI7UsyVAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}