{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOeaEDYZejEA9Dm5oNoCR0k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Results/FE-SAM(ours)/CIFAR10/vgg16_bn_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mk6dIGzNm0A",
        "outputId": "6390a737-c54e-435c-f067-6fd48d52f9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: VGG16_BN\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar10 dataset!\n",
            "100% 170M/170M [00:06<00:00, 27.8MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "391\n",
            "50000\n",
            "optimizer: FESAM\n",
            "FESAM (\n",
            "Parameter Group 0\n",
            "    T: 0.1\n",
            "    adaptive: False\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 0.1\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "Epoch: [0][0/391]\tTime 5.393 (5.393)\tData 0.416 (0.416)\tLoss 2.3912 (2.3912)\tPrec@1 11.719 (11.719)\n",
            "Epoch: [0][100/391]\tTime 0.114 (0.169)\tData 0.000 (0.006)\tLoss 1.9337 (2.0593)\tPrec@1 32.031 (21.790)\n",
            "Epoch: [0][200/391]\tTime 0.118 (0.143)\tData 0.000 (0.003)\tLoss 1.8769 (1.9416)\tPrec@1 29.688 (25.222)\n",
            "Epoch: [0][300/391]\tTime 0.116 (0.135)\tData 0.000 (0.003)\tLoss 1.6536 (1.8620)\tPrec@1 35.938 (28.665)\n",
            "Epoch: [0][390/391]\tTime 1.945 (0.135)\tData 0.000 (0.002)\tLoss 1.6413 (1.8112)\tPrec@1 42.500 (30.890)\n",
            "Total time : 52.798\n",
            "Train Loss: 1.8112, Train Accuracy: 0.3089\n",
            "Test Loss : 1.5104, Test Accuracy : 0.4111 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.422 (0.422)\tData 0.258 (0.258)\tLoss 1.6682 (1.6682)\tPrec@1 40.625 (40.625)\n",
            "Epoch: [1][100/391]\tTime 0.118 (0.122)\tData 0.000 (0.004)\tLoss 1.6041 (1.5611)\tPrec@1 40.625 (42.551)\n",
            "Epoch: [1][200/391]\tTime 0.117 (0.120)\tData 0.000 (0.002)\tLoss 1.3282 (1.5189)\tPrec@1 60.156 (44.776)\n",
            "Epoch: [1][300/391]\tTime 0.119 (0.120)\tData 0.000 (0.002)\tLoss 1.4311 (1.4829)\tPrec@1 53.906 (46.727)\n",
            "Epoch: [1][390/391]\tTime 0.087 (0.120)\tData 0.000 (0.002)\tLoss 1.2022 (1.4454)\tPrec@1 62.500 (48.650)\n",
            "Total time : 46.988\n",
            "Train Loss: 1.4454, Train Accuracy: 0.4865\n",
            "Test Loss : 1.1915, Test Accuracy : 0.5725 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.389 (0.389)\tData 0.215 (0.215)\tLoss 1.4324 (1.4324)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [2][100/391]\tTime 0.117 (0.124)\tData 0.000 (0.003)\tLoss 1.2124 (1.2294)\tPrec@1 59.375 (59.398)\n",
            "Epoch: [2][200/391]\tTime 0.119 (0.123)\tData 0.000 (0.002)\tLoss 1.3504 (1.2184)\tPrec@1 59.375 (60.145)\n",
            "Epoch: [2][300/391]\tTime 0.121 (0.122)\tData 0.000 (0.002)\tLoss 1.1089 (1.1951)\tPrec@1 62.500 (61.127)\n",
            "Epoch: [2][390/391]\tTime 0.087 (0.122)\tData 0.000 (0.002)\tLoss 1.0369 (1.1703)\tPrec@1 70.000 (62.178)\n",
            "Total time : 47.716\n",
            "Train Loss: 1.1703, Train Accuracy: 0.6218\n",
            "Test Loss : 0.9734, Test Accuracy : 0.6550 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.437 (0.437)\tData 0.258 (0.258)\tLoss 1.0444 (1.0444)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [3][100/391]\tTime 0.121 (0.125)\tData 0.000 (0.004)\tLoss 1.0260 (1.0282)\tPrec@1 64.844 (67.373)\n",
            "Epoch: [3][200/391]\tTime 0.123 (0.124)\tData 0.001 (0.002)\tLoss 1.0374 (1.0270)\tPrec@1 71.875 (67.650)\n",
            "Epoch: [3][300/391]\tTime 0.122 (0.124)\tData 0.000 (0.002)\tLoss 0.9956 (1.0194)\tPrec@1 68.750 (67.979)\n",
            "Epoch: [3][390/391]\tTime 0.089 (0.123)\tData 0.000 (0.002)\tLoss 1.1235 (1.0063)\tPrec@1 70.000 (68.440)\n",
            "Total time : 48.276\n",
            "Train Loss: 1.0063, Train Accuracy: 0.6844\n",
            "Test Loss : 0.8723, Test Accuracy : 0.6943 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.428 (0.428)\tData 0.276 (0.276)\tLoss 0.8535 (0.8535)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [4][100/391]\tTime 0.121 (0.126)\tData 0.000 (0.004)\tLoss 0.7974 (0.9233)\tPrec@1 71.094 (71.713)\n",
            "Epoch: [4][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 1.0249 (0.9266)\tPrec@1 69.531 (71.607)\n",
            "Epoch: [4][300/391]\tTime 0.121 (0.124)\tData 0.000 (0.002)\tLoss 0.9543 (0.9155)\tPrec@1 71.094 (72.090)\n",
            "Epoch: [4][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.6689 (0.9115)\tPrec@1 81.250 (72.324)\n",
            "Total time : 48.500\n",
            "Train Loss: 0.9115, Train Accuracy: 0.7232\n",
            "Test Loss : 0.7796, Test Accuracy : 0.7287 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.422 (0.422)\tData 0.290 (0.290)\tLoss 0.8568 (0.8568)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [5][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.7694 (0.8556)\tPrec@1 76.562 (74.776)\n",
            "Epoch: [5][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.9387 (0.8558)\tPrec@1 70.312 (74.642)\n",
            "Epoch: [5][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.9211 (0.8437)\tPrec@1 75.000 (75.086)\n",
            "Epoch: [5][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.7769 (0.8395)\tPrec@1 81.250 (75.386)\n",
            "Total time : 48.688\n",
            "Train Loss: 0.8395, Train Accuracy: 0.7539\n",
            "Test Loss : 0.7632, Test Accuracy : 0.7369 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.438 (0.438)\tData 0.296 (0.296)\tLoss 0.9758 (0.9758)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [6][100/391]\tTime 0.124 (0.127)\tData 0.000 (0.004)\tLoss 0.9342 (0.7978)\tPrec@1 69.531 (76.988)\n",
            "Epoch: [6][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.8432 (0.7888)\tPrec@1 75.781 (77.231)\n",
            "Epoch: [6][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.7905 (0.7887)\tPrec@1 81.250 (77.403)\n",
            "Epoch: [6][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.8957 (0.7840)\tPrec@1 76.250 (77.448)\n",
            "Total time : 48.763\n",
            "Train Loss: 0.7840, Train Accuracy: 0.7745\n",
            "Test Loss : 0.6699, Test Accuracy : 0.7772 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.459 (0.459)\tData 0.303 (0.303)\tLoss 0.7865 (0.7865)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [7][100/391]\tTime 0.122 (0.127)\tData 0.002 (0.004)\tLoss 0.8124 (0.7590)\tPrec@1 78.125 (78.581)\n",
            "Epoch: [7][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.8507 (0.7543)\tPrec@1 74.219 (79.069)\n",
            "Epoch: [7][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.7084 (0.7481)\tPrec@1 82.031 (79.179)\n",
            "Epoch: [7][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.9232 (0.7479)\tPrec@1 76.250 (79.190)\n",
            "Total time : 48.750\n",
            "Train Loss: 0.7479, Train Accuracy: 0.7919\n",
            "Test Loss : 0.6909, Test Accuracy : 0.7723 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.457 (0.457)\tData 0.302 (0.302)\tLoss 0.7787 (0.7787)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [8][100/391]\tTime 0.122 (0.128)\tData 0.001 (0.004)\tLoss 0.6754 (0.7392)\tPrec@1 83.594 (79.463)\n",
            "Epoch: [8][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.002)\tLoss 0.7273 (0.7228)\tPrec@1 76.562 (80.119)\n",
            "Epoch: [8][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.6754 (0.7261)\tPrec@1 82.812 (79.947)\n",
            "Epoch: [8][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.6139 (0.7219)\tPrec@1 83.750 (80.122)\n",
            "Total time : 48.818\n",
            "Train Loss: 0.7219, Train Accuracy: 0.8012\n",
            "Test Loss : 0.6470, Test Accuracy : 0.7861 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.596 (0.596)\tData 0.386 (0.386)\tLoss 0.7968 (0.7968)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [9][100/391]\tTime 0.126 (0.129)\tData 0.000 (0.005)\tLoss 0.6553 (0.7178)\tPrec@1 81.250 (80.322)\n",
            "Epoch: [9][200/391]\tTime 0.134 (0.126)\tData 0.008 (0.003)\tLoss 0.7740 (0.7175)\tPrec@1 76.562 (80.543)\n",
            "Epoch: [9][300/391]\tTime 0.137 (0.126)\tData 0.003 (0.002)\tLoss 0.8686 (0.7124)\tPrec@1 76.562 (80.630)\n",
            "Epoch: [9][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.7727 (0.7072)\tPrec@1 81.250 (80.884)\n",
            "Total time : 48.849\n",
            "Train Loss: 0.7072, Train Accuracy: 0.8088\n",
            "Test Loss : 0.6702, Test Accuracy : 0.7771 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.437 (0.437)\tData 0.276 (0.276)\tLoss 0.8165 (0.8165)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [10][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.6681 (0.6708)\tPrec@1 83.594 (82.712)\n",
            "Epoch: [10][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.6372 (0.6762)\tPrec@1 83.594 (82.315)\n",
            "Epoch: [10][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6339 (0.6726)\tPrec@1 82.812 (82.275)\n",
            "Epoch: [10][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.8102 (0.6759)\tPrec@1 76.250 (82.146)\n",
            "Total time : 48.743\n",
            "Train Loss: 0.6759, Train Accuracy: 0.8215\n",
            "Test Loss : 0.6266, Test Accuracy : 0.7955 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.430 (0.430)\tData 0.269 (0.269)\tLoss 0.6783 (0.6783)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [11][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.8043 (0.6568)\tPrec@1 82.031 (82.604)\n",
            "Epoch: [11][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.6521 (0.6540)\tPrec@1 85.156 (82.886)\n",
            "Epoch: [11][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6847 (0.6629)\tPrec@1 84.375 (82.457)\n",
            "Epoch: [11][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.5966 (0.6582)\tPrec@1 87.500 (82.692)\n",
            "Total time : 48.836\n",
            "Train Loss: 0.6582, Train Accuracy: 0.8269\n",
            "Test Loss : 0.5477, Test Accuracy : 0.8184 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.445 (0.445)\tData 0.303 (0.303)\tLoss 0.7767 (0.7767)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [12][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.6567 (0.6281)\tPrec@1 80.469 (83.764)\n",
            "Epoch: [12][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.6016 (0.6422)\tPrec@1 81.250 (83.279)\n",
            "Epoch: [12][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.7193 (0.6496)\tPrec@1 81.250 (82.986)\n",
            "Epoch: [12][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.5069 (0.6503)\tPrec@1 85.000 (82.938)\n",
            "Total time : 48.760\n",
            "Train Loss: 0.6503, Train Accuracy: 0.8294\n",
            "Test Loss : 0.7145, Test Accuracy : 0.7563 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.466 (0.466)\tData 0.305 (0.305)\tLoss 0.7141 (0.7141)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [13][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.7681 (0.6170)\tPrec@1 82.031 (84.019)\n",
            "Epoch: [13][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.7069 (0.6262)\tPrec@1 78.906 (83.924)\n",
            "Epoch: [13][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.6813 (0.6322)\tPrec@1 83.594 (83.724)\n",
            "Epoch: [13][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.6355 (0.6343)\tPrec@1 82.500 (83.624)\n",
            "Total time : 48.833\n",
            "Train Loss: 0.6343, Train Accuracy: 0.8362\n",
            "Test Loss : 0.5131, Test Accuracy : 0.8334 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.423 (0.423)\tData 0.260 (0.260)\tLoss 0.4820 (0.4820)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [14][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.7712 (0.6156)\tPrec@1 79.688 (84.398)\n",
            "Epoch: [14][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.7087 (0.6251)\tPrec@1 84.375 (84.196)\n",
            "Epoch: [14][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4384 (0.6248)\tPrec@1 89.844 (84.035)\n",
            "Epoch: [14][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5858 (0.6231)\tPrec@1 90.000 (84.052)\n",
            "Total time : 48.848\n",
            "Train Loss: 0.6231, Train Accuracy: 0.8405\n",
            "Test Loss : 0.5497, Test Accuracy : 0.8186 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.411 (0.411)\tData 0.272 (0.272)\tLoss 0.5481 (0.5481)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [15][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.5580 (0.6202)\tPrec@1 84.375 (84.011)\n",
            "Epoch: [15][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.6866 (0.6150)\tPrec@1 85.156 (84.231)\n",
            "Epoch: [15][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4836 (0.6118)\tPrec@1 89.844 (84.411)\n",
            "Epoch: [15][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5234 (0.6102)\tPrec@1 90.000 (84.368)\n",
            "Total time : 48.795\n",
            "Train Loss: 0.6102, Train Accuracy: 0.8437\n",
            "Test Loss : 0.5229, Test Accuracy : 0.8296 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.563 (0.563)\tData 0.366 (0.366)\tLoss 0.7096 (0.7096)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [16][100/391]\tTime 0.132 (0.129)\tData 0.006 (0.005)\tLoss 0.7839 (0.5834)\tPrec@1 81.250 (85.535)\n",
            "Epoch: [16][200/391]\tTime 0.136 (0.126)\tData 0.007 (0.003)\tLoss 0.4860 (0.6011)\tPrec@1 86.719 (85.032)\n",
            "Epoch: [16][300/391]\tTime 0.140 (0.125)\tData 0.009 (0.002)\tLoss 0.6367 (0.6067)\tPrec@1 83.594 (84.772)\n",
            "Epoch: [16][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.7489 (0.6023)\tPrec@1 86.250 (84.932)\n",
            "Total time : 48.856\n",
            "Train Loss: 0.6023, Train Accuracy: 0.8493\n",
            "Test Loss : 0.5606, Test Accuracy : 0.8157 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.440 (0.440)\tData 0.266 (0.266)\tLoss 0.6828 (0.6828)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [17][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.6112 (0.5915)\tPrec@1 82.812 (85.365)\n",
            "Epoch: [17][200/391]\tTime 0.122 (0.126)\tData 0.001 (0.003)\tLoss 0.5752 (0.5920)\tPrec@1 86.719 (85.277)\n",
            "Epoch: [17][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5842 (0.5918)\tPrec@1 80.469 (85.221)\n",
            "Epoch: [17][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4029 (0.5857)\tPrec@1 90.000 (85.402)\n",
            "Total time : 48.692\n",
            "Train Loss: 0.5857, Train Accuracy: 0.8540\n",
            "Test Loss : 0.5530, Test Accuracy : 0.8161 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.457 (0.457)\tData 0.296 (0.296)\tLoss 0.6381 (0.6381)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [18][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.4505 (0.5635)\tPrec@1 89.844 (86.208)\n",
            "Epoch: [18][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.6476 (0.5721)\tPrec@1 84.375 (85.941)\n",
            "Epoch: [18][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.5388 (0.5753)\tPrec@1 89.062 (85.841)\n",
            "Epoch: [18][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.6394 (0.5795)\tPrec@1 85.000 (85.764)\n",
            "Total time : 48.778\n",
            "Train Loss: 0.5795, Train Accuracy: 0.8576\n",
            "Test Loss : 0.5395, Test Accuracy : 0.8229 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.450 (0.450)\tData 0.301 (0.301)\tLoss 0.4240 (0.4240)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [19][100/391]\tTime 0.122 (0.128)\tData 0.001 (0.004)\tLoss 0.5073 (0.5633)\tPrec@1 90.625 (86.448)\n",
            "Epoch: [19][200/391]\tTime 0.124 (0.126)\tData 0.001 (0.002)\tLoss 0.4644 (0.5679)\tPrec@1 93.750 (86.077)\n",
            "Epoch: [19][300/391]\tTime 0.122 (0.125)\tData 0.001 (0.002)\tLoss 0.5115 (0.5777)\tPrec@1 85.938 (85.769)\n",
            "Epoch: [19][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.7083 (0.5760)\tPrec@1 81.250 (85.894)\n",
            "Total time : 48.794\n",
            "Train Loss: 0.5760, Train Accuracy: 0.8589\n",
            "Test Loss : 0.5166, Test Accuracy : 0.8291 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.443 (0.443)\tData 0.277 (0.277)\tLoss 0.5597 (0.5597)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [20][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.5957 (0.5619)\tPrec@1 83.594 (86.332)\n",
            "Epoch: [20][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.6511 (0.5574)\tPrec@1 84.375 (86.447)\n",
            "Epoch: [20][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5597 (0.5644)\tPrec@1 85.938 (86.093)\n",
            "Epoch: [20][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5772 (0.5652)\tPrec@1 86.250 (86.104)\n",
            "Total time : 48.842\n",
            "Train Loss: 0.5652, Train Accuracy: 0.8610\n",
            "Test Loss : 0.4550, Test Accuracy : 0.8497 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.423 (0.423)\tData 0.276 (0.276)\tLoss 0.4680 (0.4680)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [21][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.4643 (0.5663)\tPrec@1 88.281 (86.247)\n",
            "Epoch: [21][200/391]\tTime 0.121 (0.126)\tData 0.001 (0.003)\tLoss 0.5487 (0.5654)\tPrec@1 86.719 (86.423)\n",
            "Epoch: [21][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.5586 (0.5603)\tPrec@1 86.719 (86.483)\n",
            "Epoch: [21][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.6457 (0.5608)\tPrec@1 83.750 (86.454)\n",
            "Total time : 48.824\n",
            "Train Loss: 0.5608, Train Accuracy: 0.8645\n",
            "Test Loss : 0.4988, Test Accuracy : 0.8399 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.360 (0.360)\tData 0.183 (0.183)\tLoss 0.5360 (0.5360)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [22][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 0.6231 (0.5480)\tPrec@1 86.719 (87.152)\n",
            "Epoch: [22][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.5777 (0.5549)\tPrec@1 85.938 (86.917)\n",
            "Epoch: [22][300/391]\tTime 0.125 (0.125)\tData 0.004 (0.002)\tLoss 0.5625 (0.5544)\tPrec@1 85.938 (86.732)\n",
            "Epoch: [22][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.4798 (0.5568)\tPrec@1 92.500 (86.644)\n",
            "Total time : 48.794\n",
            "Train Loss: 0.5568, Train Accuracy: 0.8664\n",
            "Test Loss : 0.4896, Test Accuracy : 0.8406 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.310 (0.310)\tData 0.189 (0.189)\tLoss 0.5356 (0.5356)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [23][100/391]\tTime 0.124 (0.127)\tData 0.000 (0.003)\tLoss 0.4450 (0.5252)\tPrec@1 89.844 (87.492)\n",
            "Epoch: [23][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6007 (0.5341)\tPrec@1 86.719 (87.325)\n",
            "Epoch: [23][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6173 (0.5371)\tPrec@1 83.594 (87.191)\n",
            "Epoch: [23][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.6488 (0.5420)\tPrec@1 85.000 (86.916)\n",
            "Total time : 48.781\n",
            "Train Loss: 0.5420, Train Accuracy: 0.8692\n",
            "Test Loss : 0.4347, Test Accuracy : 0.8627 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.640 (0.640)\tData 0.449 (0.449)\tLoss 0.4933 (0.4933)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [24][100/391]\tTime 0.125 (0.130)\tData 0.000 (0.006)\tLoss 0.5422 (0.5422)\tPrec@1 87.500 (86.951)\n",
            "Epoch: [24][200/391]\tTime 0.130 (0.127)\tData 0.000 (0.004)\tLoss 0.4987 (0.5408)\tPrec@1 89.062 (87.037)\n",
            "Epoch: [24][300/391]\tTime 0.132 (0.126)\tData 0.009 (0.003)\tLoss 0.5423 (0.5416)\tPrec@1 87.500 (87.080)\n",
            "Epoch: [24][390/391]\tTime 0.094 (0.125)\tData 0.000 (0.002)\tLoss 0.3810 (0.5424)\tPrec@1 92.500 (87.054)\n",
            "Total time : 48.936\n",
            "Train Loss: 0.5424, Train Accuracy: 0.8705\n",
            "Test Loss : 0.4569, Test Accuracy : 0.8546 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.444 (0.444)\tData 0.275 (0.275)\tLoss 0.4319 (0.4319)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [25][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.5036 (0.5320)\tPrec@1 85.938 (87.330)\n",
            "Epoch: [25][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.6005 (0.5367)\tPrec@1 85.938 (87.208)\n",
            "Epoch: [25][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.5605 (0.5334)\tPrec@1 86.719 (87.388)\n",
            "Epoch: [25][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4682 (0.5366)\tPrec@1 91.250 (87.282)\n",
            "Total time : 48.688\n",
            "Train Loss: 0.5366, Train Accuracy: 0.8728\n",
            "Test Loss : 0.5044, Test Accuracy : 0.8352 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.379 (0.379)\tData 0.226 (0.226)\tLoss 0.5493 (0.5493)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [26][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.5930 (0.5205)\tPrec@1 85.156 (87.631)\n",
            "Epoch: [26][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.6825 (0.5333)\tPrec@1 85.156 (87.255)\n",
            "Epoch: [26][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.6284 (0.5324)\tPrec@1 86.719 (87.388)\n",
            "Epoch: [26][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.5640 (0.5321)\tPrec@1 86.250 (87.426)\n",
            "Total time : 48.781\n",
            "Train Loss: 0.5321, Train Accuracy: 0.8743\n",
            "Test Loss : 0.4387, Test Accuracy : 0.8523 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.390 (0.390)\tData 0.207 (0.207)\tLoss 0.6261 (0.6261)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [27][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.5192 (0.5238)\tPrec@1 88.281 (87.415)\n",
            "Epoch: [27][200/391]\tTime 0.123 (0.126)\tData 0.001 (0.002)\tLoss 0.4626 (0.5314)\tPrec@1 89.844 (87.201)\n",
            "Epoch: [27][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4802 (0.5358)\tPrec@1 89.844 (87.064)\n",
            "Epoch: [27][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4835 (0.5328)\tPrec@1 92.500 (87.240)\n",
            "Total time : 48.797\n",
            "Train Loss: 0.5328, Train Accuracy: 0.8724\n",
            "Test Loss : 0.4512, Test Accuracy : 0.8509 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.419 (0.419)\tData 0.270 (0.270)\tLoss 0.6676 (0.6676)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [28][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.3754 (0.5237)\tPrec@1 92.188 (87.639)\n",
            "Epoch: [28][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.4748 (0.5294)\tPrec@1 85.938 (87.504)\n",
            "Epoch: [28][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.6238 (0.5211)\tPrec@1 85.938 (87.591)\n",
            "Epoch: [28][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5621 (0.5235)\tPrec@1 87.500 (87.468)\n",
            "Total time : 48.899\n",
            "Train Loss: 0.5235, Train Accuracy: 0.8747\n",
            "Test Loss : 0.5756, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.448 (0.448)\tData 0.272 (0.272)\tLoss 0.4641 (0.4641)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [29][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.4417 (0.5146)\tPrec@1 88.281 (87.925)\n",
            "Epoch: [29][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.5328 (0.5228)\tPrec@1 85.938 (87.834)\n",
            "Epoch: [29][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.4697 (0.5277)\tPrec@1 92.188 (87.651)\n",
            "Epoch: [29][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.6137 (0.5263)\tPrec@1 87.500 (87.750)\n",
            "Total time : 48.820\n",
            "Train Loss: 0.5263, Train Accuracy: 0.8775\n",
            "Test Loss : 0.4433, Test Accuracy : 0.8589 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.437 (0.437)\tData 0.269 (0.269)\tLoss 0.4399 (0.4399)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [30][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.4263 (0.5203)\tPrec@1 89.844 (87.794)\n",
            "Epoch: [30][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5543 (0.5181)\tPrec@1 84.375 (87.896)\n",
            "Epoch: [30][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5310 (0.5225)\tPrec@1 85.938 (87.606)\n",
            "Epoch: [30][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5215 (0.5205)\tPrec@1 86.250 (87.672)\n",
            "Total time : 48.761\n",
            "Train Loss: 0.5205, Train Accuracy: 0.8767\n",
            "Test Loss : 0.4860, Test Accuracy : 0.8448 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.598 (0.598)\tData 0.397 (0.397)\tLoss 0.6353 (0.6353)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [31][100/391]\tTime 0.132 (0.130)\tData 0.005 (0.005)\tLoss 0.4238 (0.5000)\tPrec@1 89.844 (88.289)\n",
            "Epoch: [31][200/391]\tTime 0.126 (0.127)\tData 0.000 (0.003)\tLoss 0.5197 (0.5047)\tPrec@1 90.625 (88.235)\n",
            "Epoch: [31][300/391]\tTime 0.132 (0.126)\tData 0.000 (0.002)\tLoss 0.5891 (0.5154)\tPrec@1 85.938 (87.915)\n",
            "Epoch: [31][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3623 (0.5183)\tPrec@1 92.500 (87.824)\n",
            "Total time : 49.046\n",
            "Train Loss: 0.5183, Train Accuracy: 0.8782\n",
            "Test Loss : 0.4418, Test Accuracy : 0.8582 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.489 (0.489)\tData 0.347 (0.347)\tLoss 0.3582 (0.3582)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [32][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.5596 (0.5094)\tPrec@1 82.812 (88.320)\n",
            "Epoch: [32][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.003)\tLoss 0.6660 (0.5169)\tPrec@1 88.281 (88.192)\n",
            "Epoch: [32][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3687 (0.5213)\tPrec@1 92.188 (88.017)\n",
            "Epoch: [32][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2682 (0.5225)\tPrec@1 96.250 (87.918)\n",
            "Total time : 48.732\n",
            "Train Loss: 0.5225, Train Accuracy: 0.8792\n",
            "Test Loss : 0.4135, Test Accuracy : 0.8661 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.494 (0.494)\tData 0.312 (0.312)\tLoss 0.3985 (0.3985)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [33][100/391]\tTime 0.125 (0.128)\tData 0.000 (0.004)\tLoss 0.5665 (0.5000)\tPrec@1 89.062 (88.537)\n",
            "Epoch: [33][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.4740 (0.5002)\tPrec@1 90.625 (88.425)\n",
            "Epoch: [33][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4546 (0.5027)\tPrec@1 91.406 (88.268)\n",
            "Epoch: [33][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.7711 (0.5023)\tPrec@1 87.500 (88.320)\n",
            "Total time : 48.838\n",
            "Train Loss: 0.5023, Train Accuracy: 0.8832\n",
            "Test Loss : 0.4617, Test Accuracy : 0.8466 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.467 (0.467)\tData 0.280 (0.280)\tLoss 0.4494 (0.4494)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [34][100/391]\tTime 0.124 (0.128)\tData 0.000 (0.004)\tLoss 0.4769 (0.4863)\tPrec@1 88.281 (88.776)\n",
            "Epoch: [34][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.3267 (0.4951)\tPrec@1 94.531 (88.631)\n",
            "Epoch: [34][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5838 (0.4928)\tPrec@1 85.938 (88.650)\n",
            "Epoch: [34][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.5742 (0.5018)\tPrec@1 91.250 (88.430)\n",
            "Total time : 48.819\n",
            "Train Loss: 0.5018, Train Accuracy: 0.8843\n",
            "Test Loss : 0.4822, Test Accuracy : 0.8390 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.416 (0.416)\tData 0.270 (0.270)\tLoss 0.5389 (0.5389)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [35][100/391]\tTime 0.125 (0.127)\tData 0.000 (0.004)\tLoss 0.3559 (0.4981)\tPrec@1 92.969 (88.900)\n",
            "Epoch: [35][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.002)\tLoss 0.3500 (0.4996)\tPrec@1 92.969 (88.693)\n",
            "Epoch: [35][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.6476 (0.5086)\tPrec@1 83.594 (88.364)\n",
            "Epoch: [35][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5745 (0.5087)\tPrec@1 87.500 (88.302)\n",
            "Total time : 48.835\n",
            "Train Loss: 0.5087, Train Accuracy: 0.8830\n",
            "Test Loss : 0.4549, Test Accuracy : 0.8516 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.419 (0.419)\tData 0.267 (0.267)\tLoss 0.2961 (0.2961)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [36][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.5536 (0.4853)\tPrec@1 86.719 (88.699)\n",
            "Epoch: [36][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.5012 (0.4985)\tPrec@1 87.500 (88.410)\n",
            "Epoch: [36][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.6329 (0.4987)\tPrec@1 84.375 (88.528)\n",
            "Epoch: [36][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5490 (0.4987)\tPrec@1 88.750 (88.460)\n",
            "Total time : 48.928\n",
            "Train Loss: 0.4987, Train Accuracy: 0.8846\n",
            "Test Loss : 0.4261, Test Accuracy : 0.8635 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.463 (0.463)\tData 0.321 (0.321)\tLoss 0.4477 (0.4477)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [37][100/391]\tTime 0.124 (0.127)\tData 0.000 (0.005)\tLoss 0.5304 (0.4852)\tPrec@1 89.844 (88.877)\n",
            "Epoch: [37][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.5285 (0.4914)\tPrec@1 86.719 (88.619)\n",
            "Epoch: [37][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4737 (0.4973)\tPrec@1 89.844 (88.468)\n",
            "Epoch: [37][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5206 (0.4940)\tPrec@1 91.250 (88.590)\n",
            "Total time : 48.842\n",
            "Train Loss: 0.4940, Train Accuracy: 0.8859\n",
            "Test Loss : 0.4412, Test Accuracy : 0.8572 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.347 (0.347)\tData 0.201 (0.201)\tLoss 0.4392 (0.4392)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [38][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 0.6271 (0.4792)\tPrec@1 89.062 (89.372)\n",
            "Epoch: [38][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6042 (0.4918)\tPrec@1 85.938 (88.876)\n",
            "Epoch: [38][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4111 (0.4910)\tPrec@1 89.062 (88.707)\n",
            "Epoch: [38][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.4324 (0.4929)\tPrec@1 91.250 (88.602)\n",
            "Total time : 48.637\n",
            "Train Loss: 0.4929, Train Accuracy: 0.8860\n",
            "Test Loss : 0.4072, Test Accuracy : 0.8681 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.665 (0.665)\tData 0.434 (0.434)\tLoss 0.3583 (0.3583)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [39][100/391]\tTime 0.127 (0.130)\tData 0.001 (0.006)\tLoss 0.5173 (0.4847)\tPrec@1 89.062 (88.807)\n",
            "Epoch: [39][200/391]\tTime 0.127 (0.127)\tData 0.007 (0.003)\tLoss 0.3609 (0.4789)\tPrec@1 95.312 (89.109)\n",
            "Epoch: [39][300/391]\tTime 0.125 (0.126)\tData 0.007 (0.003)\tLoss 0.5966 (0.4877)\tPrec@1 87.500 (88.912)\n",
            "Epoch: [39][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 0.4648 (0.4890)\tPrec@1 92.500 (88.874)\n",
            "Total time : 49.015\n",
            "Train Loss: 0.4890, Train Accuracy: 0.8887\n",
            "Test Loss : 0.4298, Test Accuracy : 0.8594 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.432 (0.432)\tData 0.274 (0.274)\tLoss 0.3855 (0.3855)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [40][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.5459 (0.4687)\tPrec@1 89.844 (89.426)\n",
            "Epoch: [40][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.6454 (0.4809)\tPrec@1 86.719 (89.043)\n",
            "Epoch: [40][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4279 (0.4814)\tPrec@1 91.406 (89.075)\n",
            "Epoch: [40][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4993 (0.4823)\tPrec@1 91.250 (89.026)\n",
            "Total time : 48.771\n",
            "Train Loss: 0.4823, Train Accuracy: 0.8903\n",
            "Test Loss : 0.4185, Test Accuracy : 0.8624 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.420 (0.420)\tData 0.269 (0.269)\tLoss 0.4344 (0.4344)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [41][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.5822 (0.4741)\tPrec@1 87.500 (89.086)\n",
            "Epoch: [41][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.4764 (0.4808)\tPrec@1 90.625 (88.903)\n",
            "Epoch: [41][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4366 (0.4813)\tPrec@1 89.844 (88.977)\n",
            "Epoch: [41][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5228 (0.4831)\tPrec@1 88.750 (88.894)\n",
            "Total time : 48.834\n",
            "Train Loss: 0.4831, Train Accuracy: 0.8889\n",
            "Test Loss : 0.4299, Test Accuracy : 0.8584 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.451 (0.451)\tData 0.284 (0.284)\tLoss 0.4086 (0.4086)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [42][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.5582 (0.4785)\tPrec@1 85.156 (89.279)\n",
            "Epoch: [42][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.5612 (0.4770)\tPrec@1 84.375 (89.288)\n",
            "Epoch: [42][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4388 (0.4721)\tPrec@1 89.844 (89.231)\n",
            "Epoch: [42][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4309 (0.4721)\tPrec@1 91.250 (89.254)\n",
            "Total time : 48.814\n",
            "Train Loss: 0.4721, Train Accuracy: 0.8925\n",
            "Test Loss : 0.5163, Test Accuracy : 0.8279 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.473 (0.473)\tData 0.293 (0.293)\tLoss 0.4655 (0.4655)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [43][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3973 (0.4456)\tPrec@1 89.062 (89.859)\n",
            "Epoch: [43][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.3787 (0.4632)\tPrec@1 90.625 (89.506)\n",
            "Epoch: [43][300/391]\tTime 0.121 (0.125)\tData 0.001 (0.002)\tLoss 0.6211 (0.4658)\tPrec@1 83.594 (89.447)\n",
            "Epoch: [43][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.3840 (0.4707)\tPrec@1 93.750 (89.308)\n",
            "Total time : 48.669\n",
            "Train Loss: 0.4707, Train Accuracy: 0.8931\n",
            "Test Loss : 0.3988, Test Accuracy : 0.8743 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.455 (0.455)\tData 0.314 (0.314)\tLoss 0.3724 (0.3724)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [44][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.4982 (0.4682)\tPrec@1 89.844 (89.140)\n",
            "Epoch: [44][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.4358 (0.4708)\tPrec@1 89.844 (89.125)\n",
            "Epoch: [44][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.5400 (0.4708)\tPrec@1 89.062 (89.135)\n",
            "Epoch: [44][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5770 (0.4714)\tPrec@1 88.750 (89.152)\n",
            "Total time : 48.830\n",
            "Train Loss: 0.4714, Train Accuracy: 0.8915\n",
            "Test Loss : 0.5351, Test Accuracy : 0.8301 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.455 (0.455)\tData 0.259 (0.259)\tLoss 0.5388 (0.5388)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [45][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 0.5048 (0.4675)\tPrec@1 85.156 (89.411)\n",
            "Epoch: [45][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.4711 (0.4650)\tPrec@1 89.062 (89.642)\n",
            "Epoch: [45][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5283 (0.4710)\tPrec@1 87.500 (89.390)\n",
            "Epoch: [45][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.5148 (0.4725)\tPrec@1 92.500 (89.374)\n",
            "Total time : 48.797\n",
            "Train Loss: 0.4725, Train Accuracy: 0.8937\n",
            "Test Loss : 0.4437, Test Accuracy : 0.8630 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.666 (0.666)\tData 0.450 (0.450)\tLoss 0.5463 (0.5463)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [46][100/391]\tTime 0.128 (0.130)\tData 0.000 (0.005)\tLoss 0.3791 (0.4657)\tPrec@1 89.844 (89.395)\n",
            "Epoch: [46][200/391]\tTime 0.128 (0.127)\tData 0.000 (0.003)\tLoss 0.3829 (0.4492)\tPrec@1 94.531 (89.937)\n",
            "Epoch: [46][300/391]\tTime 0.141 (0.126)\tData 0.010 (0.002)\tLoss 0.5049 (0.4594)\tPrec@1 85.938 (89.610)\n",
            "Epoch: [46][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.6477 (0.4613)\tPrec@1 88.750 (89.618)\n",
            "Total time : 48.955\n",
            "Train Loss: 0.4613, Train Accuracy: 0.8962\n",
            "Test Loss : 0.4331, Test Accuracy : 0.8557 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.425 (0.425)\tData 0.267 (0.267)\tLoss 0.4808 (0.4808)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [47][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4580 (0.4608)\tPrec@1 88.281 (89.558)\n",
            "Epoch: [47][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.5327 (0.4511)\tPrec@1 89.062 (89.832)\n",
            "Epoch: [47][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4357 (0.4528)\tPrec@1 89.844 (89.802)\n",
            "Epoch: [47][390/391]\tTime 0.093 (0.124)\tData 0.000 (0.002)\tLoss 0.4795 (0.4587)\tPrec@1 91.250 (89.578)\n",
            "Total time : 48.550\n",
            "Train Loss: 0.4587, Train Accuracy: 0.8958\n",
            "Test Loss : 0.3870, Test Accuracy : 0.8725 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.465 (0.465)\tData 0.319 (0.319)\tLoss 0.4274 (0.4274)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [48][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4956 (0.4600)\tPrec@1 89.062 (89.782)\n",
            "Epoch: [48][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.4429 (0.4518)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [48][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4645 (0.4530)\tPrec@1 86.719 (89.745)\n",
            "Epoch: [48][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4317 (0.4564)\tPrec@1 90.000 (89.698)\n",
            "Total time : 48.748\n",
            "Train Loss: 0.4564, Train Accuracy: 0.8970\n",
            "Test Loss : 0.4584, Test Accuracy : 0.8493 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.424 (0.424)\tData 0.248 (0.248)\tLoss 0.5155 (0.5155)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [49][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.3975 (0.4560)\tPrec@1 96.094 (90.037)\n",
            "Epoch: [49][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.5547 (0.4598)\tPrec@1 88.281 (89.750)\n",
            "Epoch: [49][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4559 (0.4640)\tPrec@1 92.188 (89.550)\n",
            "Epoch: [49][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.5732 (0.4633)\tPrec@1 91.250 (89.570)\n",
            "Total time : 48.737\n",
            "Train Loss: 0.4633, Train Accuracy: 0.8957\n",
            "Test Loss : 0.3610, Test Accuracy : 0.8813 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.436 (0.436)\tData 0.272 (0.272)\tLoss 0.4249 (0.4249)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [50][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3717 (0.4412)\tPrec@1 92.969 (90.130)\n",
            "Epoch: [50][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.4316 (0.4522)\tPrec@1 89.062 (89.906)\n",
            "Epoch: [50][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3330 (0.4518)\tPrec@1 95.312 (89.885)\n",
            "Epoch: [50][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.6121 (0.4558)\tPrec@1 87.500 (89.718)\n",
            "Total time : 48.712\n",
            "Train Loss: 0.4558, Train Accuracy: 0.8972\n",
            "Test Loss : 0.3872, Test Accuracy : 0.8777 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.440 (0.440)\tData 0.273 (0.273)\tLoss 0.4353 (0.4353)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [51][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4426 (0.4362)\tPrec@1 89.844 (90.617)\n",
            "Epoch: [51][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.3678 (0.4420)\tPrec@1 92.969 (90.283)\n",
            "Epoch: [51][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4238 (0.4480)\tPrec@1 89.844 (90.096)\n",
            "Epoch: [51][390/391]\tTime 0.088 (0.124)\tData 0.000 (0.002)\tLoss 0.5522 (0.4519)\tPrec@1 86.250 (89.898)\n",
            "Total time : 48.671\n",
            "Train Loss: 0.4519, Train Accuracy: 0.8990\n",
            "Test Loss : 0.4464, Test Accuracy : 0.8521 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.439 (0.439)\tData 0.274 (0.274)\tLoss 0.4901 (0.4901)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [52][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3334 (0.4519)\tPrec@1 92.188 (89.465)\n",
            "Epoch: [52][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.4280 (0.4481)\tPrec@1 88.281 (89.568)\n",
            "Epoch: [52][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3954 (0.4524)\tPrec@1 91.406 (89.646)\n",
            "Epoch: [52][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4232 (0.4505)\tPrec@1 91.250 (89.758)\n",
            "Total time : 48.772\n",
            "Train Loss: 0.4505, Train Accuracy: 0.8976\n",
            "Test Loss : 0.3715, Test Accuracy : 0.8762 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.353 (0.353)\tData 0.209 (0.209)\tLoss 0.3826 (0.3826)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [53][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.6498 (0.4277)\tPrec@1 85.938 (90.424)\n",
            "Epoch: [53][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.5050 (0.4382)\tPrec@1 87.500 (90.108)\n",
            "Epoch: [53][300/391]\tTime 0.125 (0.125)\tData 0.005 (0.002)\tLoss 0.3682 (0.4439)\tPrec@1 93.750 (90.036)\n",
            "Epoch: [53][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.4133 (0.4457)\tPrec@1 90.000 (89.990)\n",
            "Total time : 48.739\n",
            "Train Loss: 0.4457, Train Accuracy: 0.8999\n",
            "Test Loss : 0.3816, Test Accuracy : 0.8759 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.618 (0.618)\tData 0.402 (0.402)\tLoss 0.3654 (0.3654)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [54][100/391]\tTime 0.125 (0.129)\tData 0.002 (0.005)\tLoss 0.5118 (0.4235)\tPrec@1 89.844 (90.602)\n",
            "Epoch: [54][200/391]\tTime 0.134 (0.127)\tData 0.009 (0.003)\tLoss 0.4487 (0.4372)\tPrec@1 89.844 (90.104)\n",
            "Epoch: [54][300/391]\tTime 0.146 (0.126)\tData 0.008 (0.003)\tLoss 0.4232 (0.4419)\tPrec@1 90.625 (90.137)\n",
            "Epoch: [54][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 0.4658 (0.4397)\tPrec@1 93.750 (90.158)\n",
            "Total time : 48.839\n",
            "Train Loss: 0.4397, Train Accuracy: 0.9016\n",
            "Test Loss : 0.3569, Test Accuracy : 0.8828 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.437 (0.437)\tData 0.268 (0.268)\tLoss 0.4530 (0.4530)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [55][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3428 (0.4165)\tPrec@1 94.531 (90.702)\n",
            "Epoch: [55][200/391]\tTime 0.121 (0.126)\tData 0.001 (0.002)\tLoss 0.4871 (0.4262)\tPrec@1 86.719 (90.477)\n",
            "Epoch: [55][300/391]\tTime 0.122 (0.125)\tData 0.001 (0.002)\tLoss 0.5556 (0.4307)\tPrec@1 89.844 (90.306)\n",
            "Epoch: [55][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.5788 (0.4363)\tPrec@1 86.250 (90.178)\n",
            "Total time : 48.733\n",
            "Train Loss: 0.4363, Train Accuracy: 0.9018\n",
            "Test Loss : 0.4384, Test Accuracy : 0.8563 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.385 (0.385)\tData 0.192 (0.192)\tLoss 0.5370 (0.5370)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [56][100/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.5580 (0.4269)\tPrec@1 89.844 (90.625)\n",
            "Epoch: [56][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4563 (0.4313)\tPrec@1 90.625 (90.571)\n",
            "Epoch: [56][300/391]\tTime 0.122 (0.124)\tData 0.000 (0.002)\tLoss 0.4205 (0.4303)\tPrec@1 92.969 (90.586)\n",
            "Epoch: [56][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.4627 (0.4373)\tPrec@1 91.250 (90.402)\n",
            "Total time : 48.562\n",
            "Train Loss: 0.4373, Train Accuracy: 0.9040\n",
            "Test Loss : 0.3898, Test Accuracy : 0.8723 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.430 (0.430)\tData 0.274 (0.274)\tLoss 0.5157 (0.5157)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [57][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3304 (0.4273)\tPrec@1 92.969 (90.826)\n",
            "Epoch: [57][200/391]\tTime 0.122 (0.125)\tData 0.001 (0.003)\tLoss 0.4540 (0.4394)\tPrec@1 87.500 (90.427)\n",
            "Epoch: [57][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4302 (0.4403)\tPrec@1 90.625 (90.298)\n",
            "Epoch: [57][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4880 (0.4436)\tPrec@1 88.750 (90.100)\n",
            "Total time : 48.757\n",
            "Train Loss: 0.4436, Train Accuracy: 0.9010\n",
            "Test Loss : 0.4196, Test Accuracy : 0.8606 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.418 (0.418)\tData 0.269 (0.269)\tLoss 0.2961 (0.2961)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [58][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.4012 (0.4182)\tPrec@1 93.750 (90.640)\n",
            "Epoch: [58][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.3974 (0.4234)\tPrec@1 91.406 (90.676)\n",
            "Epoch: [58][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4211 (0.4281)\tPrec@1 86.719 (90.565)\n",
            "Epoch: [58][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4032 (0.4321)\tPrec@1 90.000 (90.382)\n",
            "Total time : 48.749\n",
            "Train Loss: 0.4321, Train Accuracy: 0.9038\n",
            "Test Loss : 0.3946, Test Accuracy : 0.8712 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.460 (0.460)\tData 0.319 (0.319)\tLoss 0.4943 (0.4943)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [59][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.005)\tLoss 0.4506 (0.4290)\tPrec@1 87.500 (90.470)\n",
            "Epoch: [59][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.3053 (0.4249)\tPrec@1 92.969 (90.641)\n",
            "Epoch: [59][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3392 (0.4248)\tPrec@1 93.750 (90.537)\n",
            "Epoch: [59][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.4410 (0.4301)\tPrec@1 92.500 (90.492)\n",
            "Total time : 48.661\n",
            "Train Loss: 0.4301, Train Accuracy: 0.9049\n",
            "Test Loss : 0.4200, Test Accuracy : 0.8656 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.390 (0.390)\tData 0.229 (0.229)\tLoss 0.5178 (0.5178)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [60][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 0.3102 (0.4272)\tPrec@1 92.969 (90.455)\n",
            "Epoch: [60][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3118 (0.4279)\tPrec@1 92.188 (90.617)\n",
            "Epoch: [60][300/391]\tTime 0.123 (0.124)\tData 0.000 (0.002)\tLoss 0.4658 (0.4283)\tPrec@1 86.719 (90.500)\n",
            "Epoch: [60][390/391]\tTime 0.093 (0.124)\tData 0.000 (0.002)\tLoss 0.4252 (0.4294)\tPrec@1 90.000 (90.508)\n",
            "Total time : 48.611\n",
            "Train Loss: 0.4294, Train Accuracy: 0.9051\n",
            "Test Loss : 0.3517, Test Accuracy : 0.8845 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.593 (0.593)\tData 0.373 (0.373)\tLoss 0.3721 (0.3721)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [61][100/391]\tTime 0.136 (0.129)\tData 0.007 (0.005)\tLoss 0.3891 (0.4311)\tPrec@1 92.188 (90.617)\n",
            "Epoch: [61][200/391]\tTime 0.133 (0.127)\tData 0.000 (0.003)\tLoss 0.3486 (0.4328)\tPrec@1 93.750 (90.551)\n",
            "Epoch: [61][300/391]\tTime 0.132 (0.126)\tData 0.000 (0.002)\tLoss 0.4993 (0.4310)\tPrec@1 89.062 (90.490)\n",
            "Epoch: [61][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5675 (0.4317)\tPrec@1 83.750 (90.416)\n",
            "Total time : 48.887\n",
            "Train Loss: 0.4317, Train Accuracy: 0.9042\n",
            "Test Loss : 0.3838, Test Accuracy : 0.8740 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.401 (0.401)\tData 0.249 (0.249)\tLoss 0.3459 (0.3459)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [62][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.3648 (0.4099)\tPrec@1 92.188 (90.780)\n",
            "Epoch: [62][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4753 (0.4172)\tPrec@1 89.062 (90.738)\n",
            "Epoch: [62][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3427 (0.4234)\tPrec@1 91.406 (90.508)\n",
            "Epoch: [62][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.5184 (0.4247)\tPrec@1 90.000 (90.542)\n",
            "Total time : 48.600\n",
            "Train Loss: 0.4247, Train Accuracy: 0.9054\n",
            "Test Loss : 0.3752, Test Accuracy : 0.8807 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.423 (0.423)\tData 0.257 (0.257)\tLoss 0.4667 (0.4667)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [63][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.3705 (0.4274)\tPrec@1 90.625 (90.439)\n",
            "Epoch: [63][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.3435 (0.4141)\tPrec@1 93.750 (90.738)\n",
            "Epoch: [63][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4559 (0.4227)\tPrec@1 89.062 (90.539)\n",
            "Epoch: [63][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4794 (0.4244)\tPrec@1 95.000 (90.422)\n",
            "Total time : 48.699\n",
            "Train Loss: 0.4244, Train Accuracy: 0.9042\n",
            "Test Loss : 0.3867, Test Accuracy : 0.8697 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.421 (0.421)\tData 0.270 (0.270)\tLoss 0.3907 (0.3907)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [64][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3585 (0.4202)\tPrec@1 93.750 (90.710)\n",
            "Epoch: [64][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.3894 (0.4194)\tPrec@1 90.625 (90.676)\n",
            "Epoch: [64][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4685 (0.4218)\tPrec@1 86.719 (90.532)\n",
            "Epoch: [64][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 0.4201 (0.4259)\tPrec@1 91.250 (90.372)\n",
            "Total time : 48.746\n",
            "Train Loss: 0.4259, Train Accuracy: 0.9037\n",
            "Test Loss : 0.4043, Test Accuracy : 0.8723 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.441 (0.441)\tData 0.269 (0.269)\tLoss 0.4356 (0.4356)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [65][100/391]\tTime 0.122 (0.127)\tData 0.001 (0.004)\tLoss 0.2101 (0.4088)\tPrec@1 97.656 (91.081)\n",
            "Epoch: [65][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.5031 (0.4118)\tPrec@1 84.375 (90.913)\n",
            "Epoch: [65][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4184 (0.4130)\tPrec@1 89.844 (90.921)\n",
            "Epoch: [65][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3846 (0.4143)\tPrec@1 92.500 (90.906)\n",
            "Total time : 48.798\n",
            "Train Loss: 0.4143, Train Accuracy: 0.9091\n",
            "Test Loss : 0.3867, Test Accuracy : 0.8773 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.367 (0.367)\tData 0.218 (0.218)\tLoss 0.3900 (0.3900)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [66][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3499 (0.3784)\tPrec@1 91.406 (92.110)\n",
            "Epoch: [66][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4203 (0.3980)\tPrec@1 89.844 (91.426)\n",
            "Epoch: [66][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4244 (0.4014)\tPrec@1 91.406 (91.326)\n",
            "Epoch: [66][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4045 (0.4041)\tPrec@1 96.250 (91.178)\n",
            "Total time : 48.692\n",
            "Train Loss: 0.4041, Train Accuracy: 0.9118\n",
            "Test Loss : 0.4308, Test Accuracy : 0.8622 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.432 (0.432)\tData 0.262 (0.262)\tLoss 0.4020 (0.4020)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [67][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3528 (0.4024)\tPrec@1 92.969 (91.306)\n",
            "Epoch: [67][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4767 (0.4079)\tPrec@1 91.406 (91.033)\n",
            "Epoch: [67][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4686 (0.4099)\tPrec@1 86.719 (91.012)\n",
            "Epoch: [67][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.3249 (0.4133)\tPrec@1 96.250 (90.952)\n",
            "Total time : 48.650\n",
            "Train Loss: 0.4133, Train Accuracy: 0.9095\n",
            "Test Loss : 0.3474, Test Accuracy : 0.8860 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.457 (0.457)\tData 0.222 (0.222)\tLoss 0.3458 (0.3458)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [68][100/391]\tTime 0.136 (0.128)\tData 0.001 (0.003)\tLoss 0.4668 (0.4003)\tPrec@1 89.844 (91.205)\n",
            "Epoch: [68][200/391]\tTime 0.138 (0.126)\tData 0.001 (0.002)\tLoss 0.3655 (0.4050)\tPrec@1 92.969 (91.142)\n",
            "Epoch: [68][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3258 (0.4072)\tPrec@1 91.406 (90.968)\n",
            "Epoch: [68][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3863 (0.4080)\tPrec@1 95.000 (90.962)\n",
            "Total time : 48.812\n",
            "Train Loss: 0.4080, Train Accuracy: 0.9096\n",
            "Test Loss : 0.3595, Test Accuracy : 0.8810 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.557 (0.557)\tData 0.391 (0.391)\tLoss 0.3667 (0.3667)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [69][100/391]\tTime 0.140 (0.129)\tData 0.006 (0.005)\tLoss 0.3458 (0.4005)\tPrec@1 93.750 (91.391)\n",
            "Epoch: [69][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.3822 (0.3991)\tPrec@1 87.500 (91.259)\n",
            "Epoch: [69][300/391]\tTime 0.133 (0.126)\tData 0.007 (0.002)\tLoss 0.5931 (0.4006)\tPrec@1 86.719 (91.282)\n",
            "Epoch: [69][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4555 (0.4076)\tPrec@1 92.500 (91.040)\n",
            "Total time : 48.861\n",
            "Train Loss: 0.4076, Train Accuracy: 0.9104\n",
            "Test Loss : 0.3833, Test Accuracy : 0.8743 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.418 (0.418)\tData 0.274 (0.274)\tLoss 0.4120 (0.4120)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [70][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.4102 (0.3909)\tPrec@1 90.625 (91.545)\n",
            "Epoch: [70][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3236 (0.3978)\tPrec@1 91.406 (91.387)\n",
            "Epoch: [70][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3416 (0.3974)\tPrec@1 93.750 (91.375)\n",
            "Epoch: [70][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3692 (0.4007)\tPrec@1 91.250 (91.198)\n",
            "Total time : 48.698\n",
            "Train Loss: 0.4007, Train Accuracy: 0.9120\n",
            "Test Loss : 0.3597, Test Accuracy : 0.8832 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.432 (0.432)\tData 0.275 (0.275)\tLoss 0.3884 (0.3884)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [71][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2754 (0.3947)\tPrec@1 92.969 (91.290)\n",
            "Epoch: [71][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.4312 (0.3941)\tPrec@1 88.281 (91.278)\n",
            "Epoch: [71][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3004 (0.3990)\tPrec@1 93.750 (91.170)\n",
            "Epoch: [71][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5741 (0.4010)\tPrec@1 92.500 (91.038)\n",
            "Total time : 48.787\n",
            "Train Loss: 0.4010, Train Accuracy: 0.9104\n",
            "Test Loss : 0.3274, Test Accuracy : 0.8931 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.436 (0.436)\tData 0.275 (0.275)\tLoss 0.4089 (0.4089)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [72][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3029 (0.3672)\tPrec@1 95.312 (92.536)\n",
            "Epoch: [72][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.4708 (0.3859)\tPrec@1 88.281 (91.799)\n",
            "Epoch: [72][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4711 (0.3937)\tPrec@1 92.188 (91.557)\n",
            "Epoch: [72][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5053 (0.3926)\tPrec@1 86.250 (91.534)\n",
            "Total time : 48.737\n",
            "Train Loss: 0.3926, Train Accuracy: 0.9153\n",
            "Test Loss : 0.3532, Test Accuracy : 0.8832 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.420 (0.420)\tData 0.257 (0.257)\tLoss 0.3660 (0.3660)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [73][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.4022 (0.3873)\tPrec@1 91.406 (91.344)\n",
            "Epoch: [73][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.5283 (0.3868)\tPrec@1 89.844 (91.488)\n",
            "Epoch: [73][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.5831 (0.3908)\tPrec@1 86.719 (91.321)\n",
            "Epoch: [73][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3298 (0.3917)\tPrec@1 92.500 (91.384)\n",
            "Total time : 48.743\n",
            "Train Loss: 0.3917, Train Accuracy: 0.9138\n",
            "Test Loss : 0.3323, Test Accuracy : 0.8938 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.413 (0.413)\tData 0.261 (0.261)\tLoss 0.3730 (0.3730)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [74][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3850 (0.3786)\tPrec@1 88.281 (91.770)\n",
            "Epoch: [74][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3751 (0.3866)\tPrec@1 92.969 (91.492)\n",
            "Epoch: [74][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2930 (0.3872)\tPrec@1 94.531 (91.492)\n",
            "Epoch: [74][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4309 (0.3860)\tPrec@1 92.500 (91.626)\n",
            "Total time : 48.696\n",
            "Train Loss: 0.3860, Train Accuracy: 0.9163\n",
            "Test Loss : 0.3151, Test Accuracy : 0.9015 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.527 (0.527)\tData 0.302 (0.302)\tLoss 0.3685 (0.3685)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [75][100/391]\tTime 0.124 (0.128)\tData 0.005 (0.004)\tLoss 0.3633 (0.3547)\tPrec@1 92.969 (92.458)\n",
            "Epoch: [75][200/391]\tTime 0.134 (0.126)\tData 0.011 (0.002)\tLoss 0.2891 (0.3710)\tPrec@1 92.969 (91.958)\n",
            "Epoch: [75][300/391]\tTime 0.126 (0.125)\tData 0.000 (0.002)\tLoss 0.4265 (0.3784)\tPrec@1 91.406 (91.757)\n",
            "Epoch: [75][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.3346 (0.3788)\tPrec@1 93.750 (91.740)\n",
            "Total time : 48.849\n",
            "Train Loss: 0.3788, Train Accuracy: 0.9174\n",
            "Test Loss : 0.3538, Test Accuracy : 0.8793 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.490 (0.490)\tData 0.344 (0.344)\tLoss 0.3888 (0.3888)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [76][100/391]\tTime 0.120 (0.128)\tData 0.000 (0.004)\tLoss 0.4677 (0.3727)\tPrec@1 90.625 (91.932)\n",
            "Epoch: [76][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2740 (0.3750)\tPrec@1 93.750 (91.857)\n",
            "Epoch: [76][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3220 (0.3815)\tPrec@1 89.844 (91.720)\n",
            "Epoch: [76][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5178 (0.3812)\tPrec@1 85.000 (91.732)\n",
            "Total time : 48.714\n",
            "Train Loss: 0.3812, Train Accuracy: 0.9173\n",
            "Test Loss : 0.3380, Test Accuracy : 0.8846 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.427 (0.427)\tData 0.255 (0.255)\tLoss 0.3666 (0.3666)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [77][100/391]\tTime 0.122 (0.126)\tData 0.000 (0.004)\tLoss 0.5535 (0.3832)\tPrec@1 86.719 (91.700)\n",
            "Epoch: [77][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4112 (0.3829)\tPrec@1 89.062 (91.601)\n",
            "Epoch: [77][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3496 (0.3838)\tPrec@1 95.312 (91.604)\n",
            "Epoch: [77][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.4286 (0.3858)\tPrec@1 92.500 (91.524)\n",
            "Total time : 48.588\n",
            "Train Loss: 0.3858, Train Accuracy: 0.9152\n",
            "Test Loss : 0.3149, Test Accuracy : 0.8935 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.442 (0.442)\tData 0.271 (0.271)\tLoss 0.3844 (0.3844)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [78][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.3764 (0.3683)\tPrec@1 90.625 (92.334)\n",
            "Epoch: [78][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.3775 (0.3806)\tPrec@1 94.531 (91.931)\n",
            "Epoch: [78][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2906 (0.3843)\tPrec@1 93.750 (91.728)\n",
            "Epoch: [78][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.2611 (0.3833)\tPrec@1 95.000 (91.746)\n",
            "Total time : 48.628\n",
            "Train Loss: 0.3833, Train Accuracy: 0.9175\n",
            "Test Loss : 0.3187, Test Accuracy : 0.8967 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.409 (0.409)\tData 0.261 (0.261)\tLoss 0.2798 (0.2798)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [79][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3542 (0.3689)\tPrec@1 92.188 (92.071)\n",
            "Epoch: [79][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.3086 (0.3664)\tPrec@1 92.969 (91.919)\n",
            "Epoch: [79][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3389 (0.3694)\tPrec@1 92.969 (91.860)\n",
            "Epoch: [79][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3948 (0.3720)\tPrec@1 93.750 (91.826)\n",
            "Total time : 48.754\n",
            "Train Loss: 0.3720, Train Accuracy: 0.9183\n",
            "Test Loss : 0.3735, Test Accuracy : 0.8736 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.398 (0.398)\tData 0.239 (0.239)\tLoss 0.3134 (0.3134)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [80][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.3250 (0.3730)\tPrec@1 92.969 (91.901)\n",
            "Epoch: [80][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4689 (0.3709)\tPrec@1 86.719 (91.884)\n",
            "Epoch: [80][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.4379 (0.3719)\tPrec@1 85.938 (91.832)\n",
            "Epoch: [80][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.4611 (0.3709)\tPrec@1 90.000 (91.842)\n",
            "Total time : 48.667\n",
            "Train Loss: 0.3709, Train Accuracy: 0.9184\n",
            "Test Loss : 0.3274, Test Accuracy : 0.8933 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.343 (0.343)\tData 0.172 (0.172)\tLoss 0.4165 (0.4165)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [81][100/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.3642 (0.3638)\tPrec@1 95.312 (92.450)\n",
            "Epoch: [81][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3031 (0.3638)\tPrec@1 94.531 (92.269)\n",
            "Epoch: [81][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3555 (0.3704)\tPrec@1 96.875 (92.094)\n",
            "Epoch: [81][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3477 (0.3702)\tPrec@1 97.500 (92.150)\n",
            "Total time : 48.719\n",
            "Train Loss: 0.3702, Train Accuracy: 0.9215\n",
            "Test Loss : 0.3732, Test Accuracy : 0.8723 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.443 (0.443)\tData 0.286 (0.286)\tLoss 0.4656 (0.4656)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [82][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.4060 (0.3599)\tPrec@1 91.406 (92.450)\n",
            "Epoch: [82][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.003)\tLoss 0.3051 (0.3601)\tPrec@1 94.531 (92.257)\n",
            "Epoch: [82][300/391]\tTime 0.127 (0.125)\tData 0.000 (0.002)\tLoss 0.3270 (0.3604)\tPrec@1 94.531 (92.250)\n",
            "Epoch: [82][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3303 (0.3623)\tPrec@1 93.750 (92.190)\n",
            "Total time : 48.789\n",
            "Train Loss: 0.3623, Train Accuracy: 0.9219\n",
            "Test Loss : 0.3356, Test Accuracy : 0.8877 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.631 (0.631)\tData 0.441 (0.441)\tLoss 0.3108 (0.3108)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [83][100/391]\tTime 0.128 (0.129)\tData 0.000 (0.006)\tLoss 0.4536 (0.3501)\tPrec@1 90.625 (92.969)\n",
            "Epoch: [83][200/391]\tTime 0.130 (0.127)\tData 0.007 (0.004)\tLoss 0.3919 (0.3548)\tPrec@1 89.844 (92.619)\n",
            "Epoch: [83][300/391]\tTime 0.133 (0.126)\tData 0.009 (0.003)\tLoss 0.3754 (0.3616)\tPrec@1 93.750 (92.367)\n",
            "Epoch: [83][390/391]\tTime 0.094 (0.125)\tData 0.000 (0.002)\tLoss 0.3482 (0.3661)\tPrec@1 95.000 (92.152)\n",
            "Total time : 48.774\n",
            "Train Loss: 0.3661, Train Accuracy: 0.9215\n",
            "Test Loss : 0.3277, Test Accuracy : 0.8891 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.422 (0.422)\tData 0.233 (0.233)\tLoss 0.3926 (0.3926)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [84][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 0.3407 (0.3514)\tPrec@1 92.969 (92.435)\n",
            "Epoch: [84][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3866 (0.3588)\tPrec@1 92.188 (92.366)\n",
            "Epoch: [84][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4035 (0.3601)\tPrec@1 91.406 (92.268)\n",
            "Epoch: [84][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2494 (0.3593)\tPrec@1 93.750 (92.224)\n",
            "Total time : 48.741\n",
            "Train Loss: 0.3593, Train Accuracy: 0.9222\n",
            "Test Loss : 0.3362, Test Accuracy : 0.8905 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.450 (0.450)\tData 0.262 (0.262)\tLoss 0.3098 (0.3098)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [85][100/391]\tTime 0.124 (0.128)\tData 0.000 (0.004)\tLoss 0.3729 (0.3476)\tPrec@1 90.625 (92.683)\n",
            "Epoch: [85][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.3756 (0.3526)\tPrec@1 90.625 (92.483)\n",
            "Epoch: [85][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.5112 (0.3552)\tPrec@1 86.719 (92.328)\n",
            "Epoch: [85][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3172 (0.3557)\tPrec@1 95.000 (92.310)\n",
            "Total time : 48.771\n",
            "Train Loss: 0.3557, Train Accuracy: 0.9231\n",
            "Test Loss : 0.2900, Test Accuracy : 0.9059 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.463 (0.463)\tData 0.271 (0.271)\tLoss 0.3456 (0.3456)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [86][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.4133 (0.3416)\tPrec@1 90.625 (93.085)\n",
            "Epoch: [86][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2976 (0.3446)\tPrec@1 92.188 (92.774)\n",
            "Epoch: [86][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3222 (0.3520)\tPrec@1 91.406 (92.540)\n",
            "Epoch: [86][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4412 (0.3523)\tPrec@1 91.250 (92.478)\n",
            "Total time : 48.710\n",
            "Train Loss: 0.3523, Train Accuracy: 0.9248\n",
            "Test Loss : 0.2948, Test Accuracy : 0.9034 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.425 (0.425)\tData 0.276 (0.276)\tLoss 0.3189 (0.3189)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [87][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.2708 (0.3416)\tPrec@1 93.750 (92.621)\n",
            "Epoch: [87][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2800 (0.3513)\tPrec@1 95.312 (92.285)\n",
            "Epoch: [87][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3226 (0.3501)\tPrec@1 92.969 (92.333)\n",
            "Epoch: [87][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2981 (0.3491)\tPrec@1 96.250 (92.454)\n",
            "Total time : 48.713\n",
            "Train Loss: 0.3491, Train Accuracy: 0.9245\n",
            "Test Loss : 0.3068, Test Accuracy : 0.9013 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.380 (0.380)\tData 0.216 (0.216)\tLoss 0.4075 (0.4075)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [88][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.2094 (0.3305)\tPrec@1 96.875 (92.938)\n",
            "Epoch: [88][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.2690 (0.3418)\tPrec@1 95.312 (92.561)\n",
            "Epoch: [88][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3336 (0.3457)\tPrec@1 93.750 (92.424)\n",
            "Epoch: [88][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.5043 (0.3481)\tPrec@1 90.000 (92.430)\n",
            "Total time : 48.795\n",
            "Train Loss: 0.3481, Train Accuracy: 0.9243\n",
            "Test Loss : 0.3268, Test Accuracy : 0.8948 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.457 (0.457)\tData 0.294 (0.294)\tLoss 0.3387 (0.3387)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [89][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3606 (0.3410)\tPrec@1 92.969 (92.621)\n",
            "Epoch: [89][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.3672 (0.3446)\tPrec@1 92.188 (92.666)\n",
            "Epoch: [89][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2753 (0.3410)\tPrec@1 96.875 (92.712)\n",
            "Epoch: [89][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4324 (0.3436)\tPrec@1 88.750 (92.642)\n",
            "Total time : 48.844\n",
            "Train Loss: 0.3436, Train Accuracy: 0.9264\n",
            "Test Loss : 0.3544, Test Accuracy : 0.8859 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.602 (0.602)\tData 0.390 (0.390)\tLoss 0.3577 (0.3577)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [90][100/391]\tTime 0.134 (0.129)\tData 0.011 (0.005)\tLoss 0.3009 (0.3512)\tPrec@1 95.312 (92.458)\n",
            "Epoch: [90][200/391]\tTime 0.129 (0.126)\tData 0.001 (0.003)\tLoss 0.3136 (0.3369)\tPrec@1 92.969 (92.681)\n",
            "Epoch: [90][300/391]\tTime 0.128 (0.125)\tData 0.000 (0.002)\tLoss 0.2442 (0.3408)\tPrec@1 96.875 (92.686)\n",
            "Epoch: [90][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3696 (0.3408)\tPrec@1 91.250 (92.704)\n",
            "Total time : 48.814\n",
            "Train Loss: 0.3408, Train Accuracy: 0.9270\n",
            "Test Loss : 0.2944, Test Accuracy : 0.9017 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.449 (0.449)\tData 0.267 (0.267)\tLoss 0.2855 (0.2855)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [91][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2686 (0.3248)\tPrec@1 96.094 (92.822)\n",
            "Epoch: [91][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2927 (0.3237)\tPrec@1 92.969 (93.008)\n",
            "Epoch: [91][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3450 (0.3279)\tPrec@1 92.188 (92.927)\n",
            "Epoch: [91][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.2948 (0.3357)\tPrec@1 91.250 (92.770)\n",
            "Total time : 48.602\n",
            "Train Loss: 0.3357, Train Accuracy: 0.9277\n",
            "Test Loss : 0.3049, Test Accuracy : 0.8987 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.443 (0.443)\tData 0.270 (0.270)\tLoss 0.3339 (0.3339)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [92][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.4259 (0.3210)\tPrec@1 91.406 (93.224)\n",
            "Epoch: [92][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.2857 (0.3228)\tPrec@1 95.312 (93.206)\n",
            "Epoch: [92][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3103 (0.3270)\tPrec@1 93.750 (93.028)\n",
            "Epoch: [92][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.3994 (0.3301)\tPrec@1 93.750 (92.968)\n",
            "Total time : 48.757\n",
            "Train Loss: 0.3301, Train Accuracy: 0.9297\n",
            "Test Loss : 0.3042, Test Accuracy : 0.9024 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.448 (0.448)\tData 0.309 (0.309)\tLoss 0.2729 (0.2729)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [93][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2822 (0.3291)\tPrec@1 95.312 (92.953)\n",
            "Epoch: [93][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.3903 (0.3261)\tPrec@1 95.312 (93.074)\n",
            "Epoch: [93][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2357 (0.3294)\tPrec@1 95.312 (92.997)\n",
            "Epoch: [93][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2784 (0.3281)\tPrec@1 96.250 (93.042)\n",
            "Total time : 48.683\n",
            "Train Loss: 0.3281, Train Accuracy: 0.9304\n",
            "Test Loss : 0.3085, Test Accuracy : 0.9028 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.443 (0.443)\tData 0.250 (0.250)\tLoss 0.3360 (0.3360)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [94][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3285 (0.3210)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [94][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2886 (0.3199)\tPrec@1 92.188 (93.093)\n",
            "Epoch: [94][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.2223 (0.3260)\tPrec@1 96.875 (92.901)\n",
            "Epoch: [94][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.2422 (0.3262)\tPrec@1 96.250 (92.942)\n",
            "Total time : 48.940\n",
            "Train Loss: 0.3262, Train Accuracy: 0.9294\n",
            "Test Loss : 0.3078, Test Accuracy : 0.9014 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.429 (0.429)\tData 0.293 (0.293)\tLoss 0.3569 (0.3569)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [95][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3084 (0.3170)\tPrec@1 92.188 (93.247)\n",
            "Epoch: [95][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.3333 (0.3246)\tPrec@1 91.406 (92.992)\n",
            "Epoch: [95][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2681 (0.3254)\tPrec@1 96.875 (93.000)\n",
            "Epoch: [95][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2910 (0.3270)\tPrec@1 92.500 (92.900)\n",
            "Total time : 48.786\n",
            "Train Loss: 0.3270, Train Accuracy: 0.9290\n",
            "Test Loss : 0.2945, Test Accuracy : 0.9012 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.432 (0.432)\tData 0.278 (0.278)\tLoss 0.3489 (0.3489)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [96][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.2825 (0.3047)\tPrec@1 95.312 (93.541)\n",
            "Epoch: [96][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.3203 (0.3178)\tPrec@1 92.969 (93.225)\n",
            "Epoch: [96][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2815 (0.3195)\tPrec@1 95.312 (93.259)\n",
            "Epoch: [96][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3626 (0.3231)\tPrec@1 91.250 (93.180)\n",
            "Total time : 48.755\n",
            "Train Loss: 0.3231, Train Accuracy: 0.9318\n",
            "Test Loss : 0.3297, Test Accuracy : 0.8863 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.532 (0.532)\tData 0.287 (0.287)\tLoss 0.2394 (0.2394)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [97][100/391]\tTime 0.125 (0.128)\tData 0.000 (0.004)\tLoss 0.3287 (0.3208)\tPrec@1 92.188 (93.301)\n",
            "Epoch: [97][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 0.4207 (0.3175)\tPrec@1 91.406 (93.322)\n",
            "Epoch: [97][300/391]\tTime 0.126 (0.125)\tData 0.000 (0.002)\tLoss 0.3162 (0.3216)\tPrec@1 93.750 (93.226)\n",
            "Epoch: [97][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2844 (0.3226)\tPrec@1 92.500 (93.164)\n",
            "Total time : 48.887\n",
            "Train Loss: 0.3226, Train Accuracy: 0.9316\n",
            "Test Loss : 0.3045, Test Accuracy : 0.9013 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.529 (0.529)\tData 0.337 (0.337)\tLoss 0.2651 (0.2651)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [98][100/391]\tTime 0.132 (0.129)\tData 0.000 (0.005)\tLoss 0.3588 (0.2985)\tPrec@1 92.188 (93.789)\n",
            "Epoch: [98][200/391]\tTime 0.125 (0.127)\tData 0.001 (0.003)\tLoss 0.2531 (0.3071)\tPrec@1 96.875 (93.579)\n",
            "Epoch: [98][300/391]\tTime 0.144 (0.126)\tData 0.013 (0.002)\tLoss 0.3254 (0.3127)\tPrec@1 93.750 (93.470)\n",
            "Epoch: [98][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 0.2905 (0.3150)\tPrec@1 93.750 (93.400)\n",
            "Total time : 48.968\n",
            "Train Loss: 0.3150, Train Accuracy: 0.9340\n",
            "Test Loss : 0.2836, Test Accuracy : 0.9069 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.445 (0.445)\tData 0.281 (0.281)\tLoss 0.3839 (0.3839)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [99][100/391]\tTime 0.124 (0.127)\tData 0.000 (0.004)\tLoss 0.2289 (0.3152)\tPrec@1 96.875 (93.294)\n",
            "Epoch: [99][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2813 (0.3092)\tPrec@1 94.531 (93.408)\n",
            "Epoch: [99][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3562 (0.3106)\tPrec@1 90.625 (93.433)\n",
            "Epoch: [99][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2712 (0.3153)\tPrec@1 97.500 (93.352)\n",
            "Total time : 48.764\n",
            "Train Loss: 0.3153, Train Accuracy: 0.9335\n",
            "Test Loss : 0.2715, Test Accuracy : 0.9149 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.447 (0.447)\tData 0.301 (0.301)\tLoss 0.3309 (0.3309)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [100][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.3412 (0.3025)\tPrec@1 91.406 (93.758)\n",
            "Epoch: [100][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.3235 (0.3030)\tPrec@1 91.406 (93.664)\n",
            "Epoch: [100][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4844 (0.3091)\tPrec@1 89.844 (93.371)\n",
            "Epoch: [100][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2900 (0.3101)\tPrec@1 95.000 (93.370)\n",
            "Total time : 48.820\n",
            "Train Loss: 0.3101, Train Accuracy: 0.9337\n",
            "Test Loss : 0.2733, Test Accuracy : 0.9096 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.405 (0.405)\tData 0.280 (0.280)\tLoss 0.3277 (0.3277)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [101][100/391]\tTime 0.124 (0.127)\tData 0.001 (0.004)\tLoss 0.3351 (0.2944)\tPrec@1 92.188 (94.028)\n",
            "Epoch: [101][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2743 (0.2957)\tPrec@1 95.312 (93.952)\n",
            "Epoch: [101][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3120 (0.3017)\tPrec@1 92.969 (93.825)\n",
            "Epoch: [101][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3589 (0.3039)\tPrec@1 93.750 (93.736)\n",
            "Total time : 48.733\n",
            "Train Loss: 0.3039, Train Accuracy: 0.9374\n",
            "Test Loss : 0.3024, Test Accuracy : 0.9000 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.452 (0.452)\tData 0.308 (0.308)\tLoss 0.3263 (0.3263)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [102][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.3151 (0.2954)\tPrec@1 94.531 (93.866)\n",
            "Epoch: [102][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.3364 (0.3025)\tPrec@1 92.188 (93.672)\n",
            "Epoch: [102][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3242 (0.3060)\tPrec@1 92.969 (93.490)\n",
            "Epoch: [102][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3940 (0.3057)\tPrec@1 90.000 (93.482)\n",
            "Total time : 48.744\n",
            "Train Loss: 0.3057, Train Accuracy: 0.9348\n",
            "Test Loss : 0.2821, Test Accuracy : 0.9087 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.446 (0.446)\tData 0.280 (0.280)\tLoss 0.2827 (0.2827)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [103][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2955 (0.2776)\tPrec@1 95.312 (94.369)\n",
            "Epoch: [103][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2416 (0.2850)\tPrec@1 93.750 (94.038)\n",
            "Epoch: [103][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2844 (0.2949)\tPrec@1 94.531 (93.766)\n",
            "Epoch: [103][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.3668 (0.2985)\tPrec@1 92.500 (93.658)\n",
            "Total time : 48.675\n",
            "Train Loss: 0.2985, Train Accuracy: 0.9366\n",
            "Test Loss : 0.2861, Test Accuracy : 0.9029 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.349 (0.349)\tData 0.188 (0.188)\tLoss 0.2672 (0.2672)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [104][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.2734 (0.2871)\tPrec@1 93.750 (94.121)\n",
            "Epoch: [104][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3432 (0.2879)\tPrec@1 92.969 (93.983)\n",
            "Epoch: [104][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2882 (0.2876)\tPrec@1 94.531 (94.004)\n",
            "Epoch: [104][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3704 (0.2912)\tPrec@1 95.000 (93.894)\n",
            "Total time : 48.742\n",
            "Train Loss: 0.2912, Train Accuracy: 0.9389\n",
            "Test Loss : 0.2659, Test Accuracy : 0.9128 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.584 (0.584)\tData 0.385 (0.385)\tLoss 0.3901 (0.3901)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [105][100/391]\tTime 0.131 (0.130)\tData 0.014 (0.005)\tLoss 0.3190 (0.2907)\tPrec@1 94.531 (93.959)\n",
            "Epoch: [105][200/391]\tTime 0.127 (0.127)\tData 0.000 (0.003)\tLoss 0.2865 (0.2965)\tPrec@1 94.531 (93.773)\n",
            "Epoch: [105][300/391]\tTime 0.124 (0.126)\tData 0.005 (0.002)\tLoss 0.2943 (0.3008)\tPrec@1 91.406 (93.631)\n",
            "Epoch: [105][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4082 (0.2996)\tPrec@1 92.500 (93.662)\n",
            "Total time : 48.983\n",
            "Train Loss: 0.2996, Train Accuracy: 0.9366\n",
            "Test Loss : 0.2656, Test Accuracy : 0.9165 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.424 (0.424)\tData 0.262 (0.262)\tLoss 0.2555 (0.2555)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [106][100/391]\tTime 0.121 (0.126)\tData 0.000 (0.004)\tLoss 0.2726 (0.2873)\tPrec@1 95.312 (93.858)\n",
            "Epoch: [106][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2784 (0.2841)\tPrec@1 92.969 (93.987)\n",
            "Epoch: [106][300/391]\tTime 0.120 (0.125)\tData 0.000 (0.002)\tLoss 0.2795 (0.2892)\tPrec@1 92.969 (93.908)\n",
            "Epoch: [106][390/391]\tTime 0.092 (0.124)\tData 0.000 (0.002)\tLoss 0.3389 (0.2926)\tPrec@1 92.500 (93.848)\n",
            "Total time : 48.473\n",
            "Train Loss: 0.2926, Train Accuracy: 0.9385\n",
            "Test Loss : 0.2575, Test Accuracy : 0.9175 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.415 (0.415)\tData 0.268 (0.268)\tLoss 0.2563 (0.2563)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [107][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3497 (0.2854)\tPrec@1 92.188 (94.152)\n",
            "Epoch: [107][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3105 (0.2854)\tPrec@1 92.969 (94.267)\n",
            "Epoch: [107][300/391]\tTime 0.124 (0.125)\tData 0.001 (0.002)\tLoss 0.2612 (0.2839)\tPrec@1 95.312 (94.160)\n",
            "Epoch: [107][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2549 (0.2858)\tPrec@1 93.750 (93.996)\n",
            "Total time : 48.757\n",
            "Train Loss: 0.2858, Train Accuracy: 0.9400\n",
            "Test Loss : 0.2521, Test Accuracy : 0.9174 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.435 (0.435)\tData 0.266 (0.266)\tLoss 0.2446 (0.2446)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [108][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2988 (0.2737)\tPrec@1 92.188 (94.230)\n",
            "Epoch: [108][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4087 (0.2809)\tPrec@1 90.625 (94.042)\n",
            "Epoch: [108][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3157 (0.2868)\tPrec@1 91.406 (93.908)\n",
            "Epoch: [108][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.2340 (0.2890)\tPrec@1 96.250 (93.884)\n",
            "Total time : 48.580\n",
            "Train Loss: 0.2890, Train Accuracy: 0.9388\n",
            "Test Loss : 0.2371, Test Accuracy : 0.9227 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.435 (0.435)\tData 0.278 (0.278)\tLoss 0.1650 (0.1650)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [109][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2147 (0.2769)\tPrec@1 98.438 (94.183)\n",
            "Epoch: [109][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3261 (0.2789)\tPrec@1 96.094 (94.170)\n",
            "Epoch: [109][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2859 (0.2782)\tPrec@1 96.094 (94.194)\n",
            "Epoch: [109][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1766 (0.2769)\tPrec@1 96.250 (94.262)\n",
            "Total time : 48.708\n",
            "Train Loss: 0.2769, Train Accuracy: 0.9426\n",
            "Test Loss : 0.2581, Test Accuracy : 0.9158 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.552 (0.552)\tData 0.404 (0.404)\tLoss 0.3050 (0.3050)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [110][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 0.2960 (0.2761)\tPrec@1 93.750 (94.160)\n",
            "Epoch: [110][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2691 (0.2765)\tPrec@1 94.531 (94.197)\n",
            "Epoch: [110][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.3563 (0.2779)\tPrec@1 90.625 (94.191)\n",
            "Epoch: [110][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1959 (0.2782)\tPrec@1 97.500 (94.196)\n",
            "Total time : 48.914\n",
            "Train Loss: 0.2782, Train Accuracy: 0.9420\n",
            "Test Loss : 0.2437, Test Accuracy : 0.9206 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.393 (0.393)\tData 0.255 (0.255)\tLoss 0.3087 (0.3087)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [111][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2655 (0.2654)\tPrec@1 95.312 (94.407)\n",
            "Epoch: [111][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2948 (0.2707)\tPrec@1 93.750 (94.380)\n",
            "Epoch: [111][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2943 (0.2699)\tPrec@1 92.969 (94.440)\n",
            "Epoch: [111][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.2865 (0.2757)\tPrec@1 97.500 (94.298)\n",
            "Total time : 48.674\n",
            "Train Loss: 0.2757, Train Accuracy: 0.9430\n",
            "Test Loss : 0.2695, Test Accuracy : 0.9123 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.679 (0.679)\tData 0.453 (0.453)\tLoss 0.2273 (0.2273)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [112][100/391]\tTime 0.141 (0.130)\tData 0.009 (0.006)\tLoss 0.3693 (0.2562)\tPrec@1 91.406 (94.725)\n",
            "Epoch: [112][200/391]\tTime 0.129 (0.127)\tData 0.009 (0.004)\tLoss 0.1950 (0.2600)\tPrec@1 98.438 (94.597)\n",
            "Epoch: [112][300/391]\tTime 0.134 (0.126)\tData 0.000 (0.003)\tLoss 0.3070 (0.2645)\tPrec@1 92.188 (94.555)\n",
            "Epoch: [112][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.3196 (0.2676)\tPrec@1 92.500 (94.448)\n",
            "Total time : 48.932\n",
            "Train Loss: 0.2676, Train Accuracy: 0.9445\n",
            "Test Loss : 0.2583, Test Accuracy : 0.9163 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.412 (0.412)\tData 0.232 (0.232)\tLoss 0.2886 (0.2886)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [113][100/391]\tTime 0.124 (0.127)\tData 0.000 (0.004)\tLoss 0.2547 (0.2569)\tPrec@1 96.094 (94.701)\n",
            "Epoch: [113][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3102 (0.2601)\tPrec@1 94.531 (94.601)\n",
            "Epoch: [113][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3935 (0.2674)\tPrec@1 89.844 (94.456)\n",
            "Epoch: [113][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1896 (0.2705)\tPrec@1 98.750 (94.336)\n",
            "Total time : 48.689\n",
            "Train Loss: 0.2705, Train Accuracy: 0.9434\n",
            "Test Loss : 0.2482, Test Accuracy : 0.9198 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.443 (0.443)\tData 0.289 (0.289)\tLoss 0.2749 (0.2749)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [114][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2600 (0.2542)\tPrec@1 96.094 (94.725)\n",
            "Epoch: [114][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.2567 (0.2577)\tPrec@1 94.531 (94.590)\n",
            "Epoch: [114][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3294 (0.2615)\tPrec@1 92.188 (94.536)\n",
            "Epoch: [114][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.3194 (0.2649)\tPrec@1 91.250 (94.404)\n",
            "Total time : 48.641\n",
            "Train Loss: 0.2649, Train Accuracy: 0.9440\n",
            "Test Loss : 0.2670, Test Accuracy : 0.9161 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.438 (0.438)\tData 0.251 (0.251)\tLoss 0.3262 (0.3262)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [115][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2639 (0.2575)\tPrec@1 94.531 (94.539)\n",
            "Epoch: [115][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 0.2123 (0.2611)\tPrec@1 95.312 (94.527)\n",
            "Epoch: [115][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.2365 (0.2603)\tPrec@1 94.531 (94.627)\n",
            "Epoch: [115][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.2699 (0.2578)\tPrec@1 95.000 (94.726)\n",
            "Total time : 48.886\n",
            "Train Loss: 0.2578, Train Accuracy: 0.9473\n",
            "Test Loss : 0.2352, Test Accuracy : 0.9238 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.459 (0.459)\tData 0.288 (0.288)\tLoss 0.1913 (0.1913)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [116][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.2280 (0.2397)\tPrec@1 95.312 (95.173)\n",
            "Epoch: [116][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3785 (0.2477)\tPrec@1 92.188 (94.967)\n",
            "Epoch: [116][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2049 (0.2504)\tPrec@1 96.875 (94.918)\n",
            "Epoch: [116][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1769 (0.2528)\tPrec@1 96.250 (94.814)\n",
            "Total time : 48.745\n",
            "Train Loss: 0.2528, Train Accuracy: 0.9481\n",
            "Test Loss : 0.2417, Test Accuracy : 0.9217 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.432 (0.432)\tData 0.277 (0.277)\tLoss 0.2032 (0.2032)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [117][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2196 (0.2386)\tPrec@1 96.875 (95.096)\n",
            "Epoch: [117][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2037 (0.2428)\tPrec@1 95.312 (94.947)\n",
            "Epoch: [117][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2829 (0.2463)\tPrec@1 94.531 (94.884)\n",
            "Epoch: [117][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2051 (0.2513)\tPrec@1 97.500 (94.760)\n",
            "Total time : 48.687\n",
            "Train Loss: 0.2513, Train Accuracy: 0.9476\n",
            "Test Loss : 0.2506, Test Accuracy : 0.9163 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.447 (0.447)\tData 0.272 (0.272)\tLoss 0.2855 (0.2855)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [118][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3173 (0.2461)\tPrec@1 91.406 (94.903)\n",
            "Epoch: [118][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2375 (0.2431)\tPrec@1 95.312 (94.935)\n",
            "Epoch: [118][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3224 (0.2461)\tPrec@1 92.188 (94.869)\n",
            "Epoch: [118][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1779 (0.2476)\tPrec@1 98.750 (94.872)\n",
            "Total time : 48.788\n",
            "Train Loss: 0.2476, Train Accuracy: 0.9487\n",
            "Test Loss : 0.2299, Test Accuracy : 0.9252 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.465 (0.465)\tData 0.320 (0.320)\tLoss 0.2777 (0.2777)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [119][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2825 (0.2311)\tPrec@1 93.750 (95.320)\n",
            "Epoch: [119][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3266 (0.2424)\tPrec@1 93.750 (95.013)\n",
            "Epoch: [119][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1521 (0.2449)\tPrec@1 98.438 (94.941)\n",
            "Epoch: [119][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.3122 (0.2445)\tPrec@1 95.000 (94.920)\n",
            "Total time : 48.627\n",
            "Train Loss: 0.2445, Train Accuracy: 0.9492\n",
            "Test Loss : 0.2261, Test Accuracy : 0.9253 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.673 (0.673)\tData 0.491 (0.491)\tLoss 0.1805 (0.1805)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [120][100/391]\tTime 0.132 (0.129)\tData 0.010 (0.006)\tLoss 0.2390 (0.2438)\tPrec@1 94.531 (94.810)\n",
            "Epoch: [120][200/391]\tTime 0.130 (0.127)\tData 0.000 (0.004)\tLoss 0.2045 (0.2377)\tPrec@1 96.875 (95.103)\n",
            "Epoch: [120][300/391]\tTime 0.137 (0.126)\tData 0.007 (0.003)\tLoss 0.2722 (0.2372)\tPrec@1 92.969 (95.115)\n",
            "Epoch: [120][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2589 (0.2363)\tPrec@1 93.750 (95.162)\n",
            "Total time : 48.835\n",
            "Train Loss: 0.2363, Train Accuracy: 0.9516\n",
            "Test Loss : 0.2439, Test Accuracy : 0.9232 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.451 (0.451)\tData 0.253 (0.253)\tLoss 0.1622 (0.1622)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [121][100/391]\tTime 0.121 (0.127)\tData 0.001 (0.004)\tLoss 0.1796 (0.2228)\tPrec@1 99.219 (95.583)\n",
            "Epoch: [121][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1994 (0.2262)\tPrec@1 96.094 (95.507)\n",
            "Epoch: [121][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1918 (0.2334)\tPrec@1 96.875 (95.297)\n",
            "Epoch: [121][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.2570 (0.2384)\tPrec@1 95.000 (95.140)\n",
            "Total time : 48.650\n",
            "Train Loss: 0.2384, Train Accuracy: 0.9514\n",
            "Test Loss : 0.2260, Test Accuracy : 0.9267 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.440 (0.440)\tData 0.283 (0.283)\tLoss 0.2377 (0.2377)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [122][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.1779 (0.2251)\tPrec@1 96.094 (95.498)\n",
            "Epoch: [122][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.3003 (0.2305)\tPrec@1 94.531 (95.320)\n",
            "Epoch: [122][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3073 (0.2328)\tPrec@1 92.188 (95.284)\n",
            "Epoch: [122][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2555 (0.2351)\tPrec@1 93.750 (95.206)\n",
            "Total time : 48.724\n",
            "Train Loss: 0.2351, Train Accuracy: 0.9521\n",
            "Test Loss : 0.2423, Test Accuracy : 0.9202 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.436 (0.436)\tData 0.270 (0.270)\tLoss 0.1795 (0.1795)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [123][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2042 (0.2339)\tPrec@1 97.656 (95.073)\n",
            "Epoch: [123][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.2278 (0.2344)\tPrec@1 96.094 (95.083)\n",
            "Epoch: [123][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2145 (0.2339)\tPrec@1 95.312 (95.105)\n",
            "Epoch: [123][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3177 (0.2344)\tPrec@1 93.750 (95.106)\n",
            "Total time : 48.792\n",
            "Train Loss: 0.2344, Train Accuracy: 0.9511\n",
            "Test Loss : 0.2349, Test Accuracy : 0.9213 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.392 (0.392)\tData 0.240 (0.240)\tLoss 0.1744 (0.1744)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [124][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.1744 (0.2225)\tPrec@1 97.656 (95.498)\n",
            "Epoch: [124][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2108 (0.2243)\tPrec@1 96.094 (95.414)\n",
            "Epoch: [124][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1881 (0.2252)\tPrec@1 98.438 (95.447)\n",
            "Epoch: [124][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.1300 (0.2276)\tPrec@1 98.750 (95.352)\n",
            "Total time : 48.635\n",
            "Train Loss: 0.2276, Train Accuracy: 0.9535\n",
            "Test Loss : 0.2349, Test Accuracy : 0.9227 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.468 (0.468)\tData 0.331 (0.331)\tLoss 0.2269 (0.2269)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [125][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2130 (0.2150)\tPrec@1 95.312 (95.784)\n",
            "Epoch: [125][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1965 (0.2194)\tPrec@1 97.656 (95.577)\n",
            "Epoch: [125][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2348 (0.2215)\tPrec@1 94.531 (95.523)\n",
            "Epoch: [125][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1729 (0.2246)\tPrec@1 96.250 (95.380)\n",
            "Total time : 48.853\n",
            "Train Loss: 0.2246, Train Accuracy: 0.9538\n",
            "Test Loss : 0.2548, Test Accuracy : 0.9125 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.495 (0.495)\tData 0.276 (0.276)\tLoss 0.2383 (0.2383)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [126][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.1477 (0.2259)\tPrec@1 97.656 (95.490)\n",
            "Epoch: [126][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1638 (0.2234)\tPrec@1 96.094 (95.561)\n",
            "Epoch: [126][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2894 (0.2233)\tPrec@1 94.531 (95.528)\n",
            "Epoch: [126][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1975 (0.2252)\tPrec@1 96.250 (95.440)\n",
            "Total time : 48.863\n",
            "Train Loss: 0.2252, Train Accuracy: 0.9544\n",
            "Test Loss : 0.2246, Test Accuracy : 0.9271 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.410 (0.410)\tData 0.190 (0.190)\tLoss 0.1621 (0.1621)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [127][100/391]\tTime 0.135 (0.128)\tData 0.012 (0.004)\tLoss 0.1718 (0.2119)\tPrec@1 98.438 (95.753)\n",
            "Epoch: [127][200/391]\tTime 0.135 (0.126)\tData 0.012 (0.002)\tLoss 0.3276 (0.2174)\tPrec@1 92.969 (95.666)\n",
            "Epoch: [127][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1625 (0.2154)\tPrec@1 96.875 (95.767)\n",
            "Epoch: [127][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.001)\tLoss 0.1963 (0.2179)\tPrec@1 97.500 (95.612)\n",
            "Total time : 48.751\n",
            "Train Loss: 0.2179, Train Accuracy: 0.9561\n",
            "Test Loss : 0.2232, Test Accuracy : 0.9269 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.591 (0.591)\tData 0.351 (0.351)\tLoss 0.1080 (0.1080)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [128][100/391]\tTime 0.143 (0.130)\tData 0.012 (0.005)\tLoss 0.2474 (0.2120)\tPrec@1 95.312 (95.885)\n",
            "Epoch: [128][200/391]\tTime 0.142 (0.127)\tData 0.015 (0.003)\tLoss 0.2487 (0.2104)\tPrec@1 94.531 (95.740)\n",
            "Epoch: [128][300/391]\tTime 0.141 (0.126)\tData 0.002 (0.002)\tLoss 0.2765 (0.2144)\tPrec@1 94.531 (95.650)\n",
            "Epoch: [128][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2756 (0.2153)\tPrec@1 91.250 (95.636)\n",
            "Total time : 48.921\n",
            "Train Loss: 0.2153, Train Accuracy: 0.9564\n",
            "Test Loss : 0.1948, Test Accuracy : 0.9377 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.433 (0.433)\tData 0.267 (0.267)\tLoss 0.2104 (0.2104)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [129][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1606 (0.2031)\tPrec@1 95.312 (95.730)\n",
            "Epoch: [129][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.2224 (0.2042)\tPrec@1 94.531 (95.775)\n",
            "Epoch: [129][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.2187 (0.2067)\tPrec@1 95.312 (95.795)\n",
            "Epoch: [129][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2193 (0.2113)\tPrec@1 95.000 (95.760)\n",
            "Total time : 48.750\n",
            "Train Loss: 0.2113, Train Accuracy: 0.9576\n",
            "Test Loss : 0.2156, Test Accuracy : 0.9314 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.413 (0.413)\tData 0.223 (0.223)\tLoss 0.1621 (0.1621)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [130][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.1608 (0.2106)\tPrec@1 97.656 (95.730)\n",
            "Epoch: [130][200/391]\tTime 0.123 (0.126)\tData 0.001 (0.002)\tLoss 0.2233 (0.2119)\tPrec@1 95.312 (95.678)\n",
            "Epoch: [130][300/391]\tTime 0.128 (0.125)\tData 0.000 (0.002)\tLoss 0.2275 (0.2110)\tPrec@1 95.312 (95.691)\n",
            "Epoch: [130][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.3146 (0.2121)\tPrec@1 95.000 (95.678)\n",
            "Total time : 48.747\n",
            "Train Loss: 0.2121, Train Accuracy: 0.9568\n",
            "Test Loss : 0.2129, Test Accuracy : 0.9325 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.362 (0.362)\tData 0.233 (0.233)\tLoss 0.1947 (0.1947)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [131][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.1627 (0.2084)\tPrec@1 96.875 (95.715)\n",
            "Epoch: [131][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1473 (0.2033)\tPrec@1 98.438 (95.849)\n",
            "Epoch: [131][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1973 (0.2070)\tPrec@1 95.312 (95.800)\n",
            "Epoch: [131][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2123 (0.2075)\tPrec@1 93.750 (95.738)\n",
            "Total time : 48.717\n",
            "Train Loss: 0.2075, Train Accuracy: 0.9574\n",
            "Test Loss : 0.2043, Test Accuracy : 0.9322 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.439 (0.439)\tData 0.273 (0.273)\tLoss 0.1489 (0.1489)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [132][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1851 (0.1969)\tPrec@1 95.312 (96.071)\n",
            "Epoch: [132][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1821 (0.1975)\tPrec@1 97.656 (96.098)\n",
            "Epoch: [132][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2080 (0.2004)\tPrec@1 94.531 (95.972)\n",
            "Epoch: [132][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2059 (0.2015)\tPrec@1 95.000 (95.954)\n",
            "Total time : 48.800\n",
            "Train Loss: 0.2015, Train Accuracy: 0.9595\n",
            "Test Loss : 0.2133, Test Accuracy : 0.9315 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.462 (0.462)\tData 0.275 (0.275)\tLoss 0.1894 (0.1894)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [133][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.1989 (0.1989)\tPrec@1 96.094 (96.125)\n",
            "Epoch: [133][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.1639 (0.1945)\tPrec@1 97.656 (96.164)\n",
            "Epoch: [133][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2021 (0.1974)\tPrec@1 95.312 (96.050)\n",
            "Epoch: [133][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2697 (0.2005)\tPrec@1 93.750 (95.936)\n",
            "Total time : 48.888\n",
            "Train Loss: 0.2005, Train Accuracy: 0.9594\n",
            "Test Loss : 0.2092, Test Accuracy : 0.9342 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.432 (0.432)\tData 0.273 (0.273)\tLoss 0.1516 (0.1516)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [134][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2792 (0.1849)\tPrec@1 93.750 (96.542)\n",
            "Epoch: [134][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1918 (0.1912)\tPrec@1 95.312 (96.319)\n",
            "Epoch: [134][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1209 (0.1907)\tPrec@1 97.656 (96.288)\n",
            "Epoch: [134][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1879 (0.1955)\tPrec@1 97.500 (96.140)\n",
            "Total time : 48.776\n",
            "Train Loss: 0.1955, Train Accuracy: 0.9614\n",
            "Test Loss : 0.1992, Test Accuracy : 0.9353 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.546 (0.546)\tData 0.321 (0.321)\tLoss 0.1917 (0.1917)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [135][100/391]\tTime 0.129 (0.129)\tData 0.010 (0.005)\tLoss 0.2461 (0.1886)\tPrec@1 95.312 (96.248)\n",
            "Epoch: [135][200/391]\tTime 0.126 (0.126)\tData 0.000 (0.003)\tLoss 0.1759 (0.1921)\tPrec@1 96.875 (96.171)\n",
            "Epoch: [135][300/391]\tTime 0.129 (0.126)\tData 0.000 (0.002)\tLoss 0.1807 (0.1919)\tPrec@1 96.875 (96.179)\n",
            "Epoch: [135][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2764 (0.1909)\tPrec@1 96.250 (96.164)\n",
            "Total time : 48.904\n",
            "Train Loss: 0.1909, Train Accuracy: 0.9616\n",
            "Test Loss : 0.1934, Test Accuracy : 0.9371 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.437 (0.437)\tData 0.280 (0.280)\tLoss 0.1699 (0.1699)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [136][100/391]\tTime 0.122 (0.127)\tData 0.001 (0.004)\tLoss 0.2159 (0.1801)\tPrec@1 94.531 (96.372)\n",
            "Epoch: [136][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.2593 (0.1830)\tPrec@1 93.750 (96.350)\n",
            "Epoch: [136][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2258 (0.1870)\tPrec@1 93.750 (96.301)\n",
            "Epoch: [136][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.1705 (0.1880)\tPrec@1 97.500 (96.220)\n",
            "Total time : 48.616\n",
            "Train Loss: 0.1880, Train Accuracy: 0.9622\n",
            "Test Loss : 0.2003, Test Accuracy : 0.9327 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.444 (0.444)\tData 0.298 (0.298)\tLoss 0.2015 (0.2015)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [137][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.005)\tLoss 0.2419 (0.1738)\tPrec@1 96.094 (96.519)\n",
            "Epoch: [137][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1471 (0.1770)\tPrec@1 97.656 (96.409)\n",
            "Epoch: [137][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1686 (0.1805)\tPrec@1 97.656 (96.317)\n",
            "Epoch: [137][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2414 (0.1825)\tPrec@1 95.000 (96.284)\n",
            "Total time : 48.745\n",
            "Train Loss: 0.1825, Train Accuracy: 0.9628\n",
            "Test Loss : 0.1994, Test Accuracy : 0.9377 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.446 (0.446)\tData 0.314 (0.314)\tLoss 0.2849 (0.2849)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [138][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1661 (0.1848)\tPrec@1 97.656 (96.264)\n",
            "Epoch: [138][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.1743 (0.1879)\tPrec@1 97.656 (96.179)\n",
            "Epoch: [138][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1710 (0.1853)\tPrec@1 96.094 (96.221)\n",
            "Epoch: [138][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.2379 (0.1863)\tPrec@1 95.000 (96.212)\n",
            "Total time : 48.633\n",
            "Train Loss: 0.1863, Train Accuracy: 0.9621\n",
            "Test Loss : 0.1957, Test Accuracy : 0.9355 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.409 (0.409)\tData 0.240 (0.240)\tLoss 0.1506 (0.1506)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [139][100/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1208 (0.1756)\tPrec@1 98.438 (96.310)\n",
            "Epoch: [139][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2038 (0.1747)\tPrec@1 95.312 (96.323)\n",
            "Epoch: [139][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1517 (0.1749)\tPrec@1 96.094 (96.353)\n",
            "Epoch: [139][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2000 (0.1768)\tPrec@1 96.250 (96.394)\n",
            "Total time : 48.734\n",
            "Train Loss: 0.1768, Train Accuracy: 0.9639\n",
            "Test Loss : 0.2137, Test Accuracy : 0.9285 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.354 (0.354)\tData 0.192 (0.192)\tLoss 0.1280 (0.1280)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [140][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.2217 (0.1664)\tPrec@1 95.312 (96.689)\n",
            "Epoch: [140][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.1959 (0.1735)\tPrec@1 96.094 (96.432)\n",
            "Epoch: [140][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1838 (0.1726)\tPrec@1 95.312 (96.455)\n",
            "Epoch: [140][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2360 (0.1747)\tPrec@1 96.250 (96.392)\n",
            "Total time : 48.765\n",
            "Train Loss: 0.1747, Train Accuracy: 0.9639\n",
            "Test Loss : 0.1984, Test Accuracy : 0.9353 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.451 (0.451)\tData 0.313 (0.313)\tLoss 0.1431 (0.1431)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [141][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2071 (0.1696)\tPrec@1 94.531 (96.666)\n",
            "Epoch: [141][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2316 (0.1726)\tPrec@1 94.531 (96.661)\n",
            "Epoch: [141][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1488 (0.1745)\tPrec@1 96.875 (96.530)\n",
            "Epoch: [141][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1999 (0.1738)\tPrec@1 96.250 (96.562)\n",
            "Total time : 48.780\n",
            "Train Loss: 0.1738, Train Accuracy: 0.9656\n",
            "Test Loss : 0.1813, Test Accuracy : 0.9382 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.465 (0.465)\tData 0.275 (0.275)\tLoss 0.1545 (0.1545)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [142][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.1380 (0.1615)\tPrec@1 96.875 (96.682)\n",
            "Epoch: [142][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1359 (0.1689)\tPrec@1 97.656 (96.521)\n",
            "Epoch: [142][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1478 (0.1727)\tPrec@1 99.219 (96.431)\n",
            "Epoch: [142][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2635 (0.1716)\tPrec@1 93.750 (96.496)\n",
            "Total time : 48.768\n",
            "Train Loss: 0.1716, Train Accuracy: 0.9650\n",
            "Test Loss : 0.1887, Test Accuracy : 0.9363 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.620 (0.620)\tData 0.419 (0.419)\tLoss 0.1473 (0.1473)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [143][100/391]\tTime 0.130 (0.129)\tData 0.012 (0.006)\tLoss 0.2542 (0.1642)\tPrec@1 93.750 (96.713)\n",
            "Epoch: [143][200/391]\tTime 0.129 (0.127)\tData 0.011 (0.003)\tLoss 0.2107 (0.1649)\tPrec@1 93.750 (96.603)\n",
            "Epoch: [143][300/391]\tTime 0.127 (0.126)\tData 0.005 (0.003)\tLoss 0.1602 (0.1661)\tPrec@1 96.875 (96.597)\n",
            "Epoch: [143][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1632 (0.1660)\tPrec@1 95.000 (96.648)\n",
            "Total time : 48.848\n",
            "Train Loss: 0.1660, Train Accuracy: 0.9665\n",
            "Test Loss : 0.1974, Test Accuracy : 0.9362 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.346 (0.346)\tData 0.191 (0.191)\tLoss 0.1620 (0.1620)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [144][100/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1440 (0.1566)\tPrec@1 96.875 (97.022)\n",
            "Epoch: [144][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2192 (0.1594)\tPrec@1 93.750 (96.852)\n",
            "Epoch: [144][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1456 (0.1602)\tPrec@1 96.875 (96.839)\n",
            "Epoch: [144][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.001)\tLoss 0.2214 (0.1626)\tPrec@1 95.000 (96.754)\n",
            "Total time : 48.581\n",
            "Train Loss: 0.1626, Train Accuracy: 0.9675\n",
            "Test Loss : 0.1881, Test Accuracy : 0.9388 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.467 (0.467)\tData 0.308 (0.308)\tLoss 0.1628 (0.1628)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [145][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.1547 (0.1642)\tPrec@1 96.875 (96.581)\n",
            "Epoch: [145][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1384 (0.1607)\tPrec@1 98.438 (96.720)\n",
            "Epoch: [145][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1003 (0.1566)\tPrec@1 98.438 (96.875)\n",
            "Epoch: [145][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2263 (0.1573)\tPrec@1 93.750 (96.832)\n",
            "Total time : 48.758\n",
            "Train Loss: 0.1573, Train Accuracy: 0.9683\n",
            "Test Loss : 0.1906, Test Accuracy : 0.9351 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.469 (0.469)\tData 0.327 (0.327)\tLoss 0.1924 (0.1924)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [146][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.1455 (0.1548)\tPrec@1 96.875 (96.906)\n",
            "Epoch: [146][200/391]\tTime 0.122 (0.126)\tData 0.001 (0.003)\tLoss 0.1173 (0.1542)\tPrec@1 98.438 (96.953)\n",
            "Epoch: [146][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1157 (0.1563)\tPrec@1 96.875 (96.904)\n",
            "Epoch: [146][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0761 (0.1576)\tPrec@1 98.750 (96.856)\n",
            "Total time : 48.809\n",
            "Train Loss: 0.1576, Train Accuracy: 0.9686\n",
            "Test Loss : 0.1977, Test Accuracy : 0.9346 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.479 (0.479)\tData 0.328 (0.328)\tLoss 0.1639 (0.1639)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [147][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.1263 (0.1472)\tPrec@1 99.219 (97.146)\n",
            "Epoch: [147][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.2273 (0.1497)\tPrec@1 92.969 (97.042)\n",
            "Epoch: [147][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1504 (0.1490)\tPrec@1 97.656 (97.059)\n",
            "Epoch: [147][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.0687 (0.1514)\tPrec@1 100.000 (96.984)\n",
            "Total time : 48.707\n",
            "Train Loss: 0.1514, Train Accuracy: 0.9698\n",
            "Test Loss : 0.1850, Test Accuracy : 0.9398 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.459 (0.459)\tData 0.283 (0.283)\tLoss 0.1604 (0.1604)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [148][100/391]\tTime 0.125 (0.127)\tData 0.000 (0.004)\tLoss 0.1527 (0.1479)\tPrec@1 97.656 (97.045)\n",
            "Epoch: [148][200/391]\tTime 0.139 (0.126)\tData 0.000 (0.003)\tLoss 0.2626 (0.1511)\tPrec@1 92.969 (97.011)\n",
            "Epoch: [148][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.1257 (0.1516)\tPrec@1 99.219 (96.922)\n",
            "Epoch: [148][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1910 (0.1529)\tPrec@1 93.750 (96.882)\n",
            "Total time : 48.992\n",
            "Train Loss: 0.1529, Train Accuracy: 0.9688\n",
            "Test Loss : 0.1852, Test Accuracy : 0.9380 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.470 (0.470)\tData 0.289 (0.289)\tLoss 0.1693 (0.1693)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [149][100/391]\tTime 0.125 (0.128)\tData 0.000 (0.004)\tLoss 0.1785 (0.1477)\tPrec@1 96.094 (97.068)\n",
            "Epoch: [149][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.1337 (0.1538)\tPrec@1 97.656 (96.887)\n",
            "Epoch: [149][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1521 (0.1517)\tPrec@1 96.875 (96.898)\n",
            "Epoch: [149][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1670 (0.1518)\tPrec@1 96.250 (96.860)\n",
            "Total time : 48.853\n",
            "Train Loss: 0.1518, Train Accuracy: 0.9686\n",
            "Test Loss : 0.1790, Test Accuracy : 0.9413 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.468 (0.468)\tData 0.286 (0.286)\tLoss 0.2266 (0.2266)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [150][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.1424 (0.1455)\tPrec@1 97.656 (96.968)\n",
            "Epoch: [150][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1256 (0.1452)\tPrec@1 96.094 (97.085)\n",
            "Epoch: [150][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1323 (0.1469)\tPrec@1 96.875 (97.020)\n",
            "Epoch: [150][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1112 (0.1473)\tPrec@1 97.500 (97.020)\n",
            "Total time : 48.878\n",
            "Train Loss: 0.1473, Train Accuracy: 0.9702\n",
            "Test Loss : 0.1767, Test Accuracy : 0.9395 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.536 (0.536)\tData 0.350 (0.350)\tLoss 0.1081 (0.1081)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [151][100/391]\tTime 0.140 (0.130)\tData 0.007 (0.005)\tLoss 0.1717 (0.1425)\tPrec@1 96.875 (96.921)\n",
            "Epoch: [151][200/391]\tTime 0.129 (0.127)\tData 0.000 (0.003)\tLoss 0.1126 (0.1393)\tPrec@1 98.438 (97.054)\n",
            "Epoch: [151][300/391]\tTime 0.129 (0.126)\tData 0.007 (0.002)\tLoss 0.1315 (0.1398)\tPrec@1 97.656 (97.080)\n",
            "Epoch: [151][390/391]\tTime 0.091 (0.126)\tData 0.000 (0.002)\tLoss 0.1835 (0.1411)\tPrec@1 96.250 (97.082)\n",
            "Total time : 49.088\n",
            "Train Loss: 0.1411, Train Accuracy: 0.9708\n",
            "Test Loss : 0.1786, Test Accuracy : 0.9406 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.401 (0.401)\tData 0.207 (0.207)\tLoss 0.1522 (0.1522)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [152][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.0886 (0.1295)\tPrec@1 100.000 (97.386)\n",
            "Epoch: [152][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.1689 (0.1286)\tPrec@1 95.312 (97.442)\n",
            "Epoch: [152][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1637 (0.1324)\tPrec@1 96.094 (97.402)\n",
            "Epoch: [152][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.001)\tLoss 0.1163 (0.1344)\tPrec@1 98.750 (97.326)\n",
            "Total time : 48.625\n",
            "Train Loss: 0.1344, Train Accuracy: 0.9733\n",
            "Test Loss : 0.1745, Test Accuracy : 0.9424 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.448 (0.448)\tData 0.276 (0.276)\tLoss 0.1238 (0.1238)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [153][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.1877 (0.1315)\tPrec@1 93.750 (97.486)\n",
            "Epoch: [153][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1601 (0.1335)\tPrec@1 96.094 (97.380)\n",
            "Epoch: [153][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1217 (0.1358)\tPrec@1 98.438 (97.355)\n",
            "Epoch: [153][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1752 (0.1369)\tPrec@1 96.250 (97.288)\n",
            "Total time : 48.755\n",
            "Train Loss: 0.1369, Train Accuracy: 0.9729\n",
            "Test Loss : 0.1737, Test Accuracy : 0.9425 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.428 (0.428)\tData 0.261 (0.261)\tLoss 0.1899 (0.1899)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [154][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1377 (0.1379)\tPrec@1 96.875 (97.115)\n",
            "Epoch: [154][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1260 (0.1373)\tPrec@1 99.219 (97.229)\n",
            "Epoch: [154][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1437 (0.1360)\tPrec@1 98.438 (97.244)\n",
            "Epoch: [154][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.1076 (0.1345)\tPrec@1 97.500 (97.266)\n",
            "Total time : 48.663\n",
            "Train Loss: 0.1345, Train Accuracy: 0.9727\n",
            "Test Loss : 0.1760, Test Accuracy : 0.9419 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.430 (0.430)\tData 0.264 (0.264)\tLoss 0.0971 (0.0971)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [155][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1001 (0.1258)\tPrec@1 99.219 (97.556)\n",
            "Epoch: [155][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1310 (0.1287)\tPrec@1 96.875 (97.400)\n",
            "Epoch: [155][300/391]\tTime 0.121 (0.125)\tData 0.001 (0.002)\tLoss 0.0931 (0.1290)\tPrec@1 98.438 (97.433)\n",
            "Epoch: [155][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.1545 (0.1309)\tPrec@1 97.500 (97.412)\n",
            "Total time : 48.715\n",
            "Train Loss: 0.1309, Train Accuracy: 0.9741\n",
            "Test Loss : 0.1706, Test Accuracy : 0.9431 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.456 (0.456)\tData 0.328 (0.328)\tLoss 0.1196 (0.1196)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [156][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.1484 (0.1270)\tPrec@1 96.094 (97.416)\n",
            "Epoch: [156][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1153 (0.1267)\tPrec@1 97.656 (97.462)\n",
            "Epoch: [156][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1716 (0.1285)\tPrec@1 94.531 (97.407)\n",
            "Epoch: [156][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.1196 (0.1287)\tPrec@1 97.500 (97.414)\n",
            "Total time : 48.794\n",
            "Train Loss: 0.1287, Train Accuracy: 0.9741\n",
            "Test Loss : 0.1660, Test Accuracy : 0.9468 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.433 (0.433)\tData 0.264 (0.264)\tLoss 0.1037 (0.1037)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [157][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1074 (0.1236)\tPrec@1 98.438 (97.409)\n",
            "Epoch: [157][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1131 (0.1250)\tPrec@1 98.438 (97.407)\n",
            "Epoch: [157][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1265 (0.1250)\tPrec@1 97.656 (97.425)\n",
            "Epoch: [157][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.1620 (0.1245)\tPrec@1 97.500 (97.454)\n",
            "Total time : 48.674\n",
            "Train Loss: 0.1245, Train Accuracy: 0.9745\n",
            "Test Loss : 0.1655, Test Accuracy : 0.9457 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.633 (0.633)\tData 0.390 (0.390)\tLoss 0.0706 (0.0706)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [158][100/391]\tTime 0.132 (0.129)\tData 0.007 (0.005)\tLoss 0.1040 (0.1164)\tPrec@1 98.438 (97.594)\n",
            "Epoch: [158][200/391]\tTime 0.125 (0.127)\tData 0.000 (0.003)\tLoss 0.1113 (0.1209)\tPrec@1 99.219 (97.474)\n",
            "Epoch: [158][300/391]\tTime 0.135 (0.126)\tData 0.000 (0.002)\tLoss 0.1623 (0.1219)\tPrec@1 97.656 (97.433)\n",
            "Epoch: [158][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1890 (0.1248)\tPrec@1 97.500 (97.402)\n",
            "Total time : 48.929\n",
            "Train Loss: 0.1248, Train Accuracy: 0.9740\n",
            "Test Loss : 0.1670, Test Accuracy : 0.9449 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.435 (0.435)\tData 0.282 (0.282)\tLoss 0.0777 (0.0777)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [159][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1876 (0.1184)\tPrec@1 94.531 (97.734)\n",
            "Epoch: [159][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.1290 (0.1153)\tPrec@1 96.875 (97.722)\n",
            "Epoch: [159][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0995 (0.1157)\tPrec@1 98.438 (97.690)\n",
            "Epoch: [159][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.1015 (0.1150)\tPrec@1 98.750 (97.736)\n",
            "Total time : 48.568\n",
            "Train Loss: 0.1150, Train Accuracy: 0.9774\n",
            "Test Loss : 0.1644, Test Accuracy : 0.9466 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.445 (0.445)\tData 0.314 (0.314)\tLoss 0.0971 (0.0971)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [160][100/391]\tTime 0.123 (0.127)\tData 0.001 (0.005)\tLoss 0.1567 (0.1180)\tPrec@1 96.875 (97.602)\n",
            "Epoch: [160][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.0903 (0.1212)\tPrec@1 96.875 (97.571)\n",
            "Epoch: [160][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.003)\tLoss 0.1144 (0.1205)\tPrec@1 97.656 (97.563)\n",
            "Epoch: [160][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0897 (0.1190)\tPrec@1 100.000 (97.580)\n",
            "Total time : 48.735\n",
            "Train Loss: 0.1190, Train Accuracy: 0.9758\n",
            "Test Loss : 0.1646, Test Accuracy : 0.9475 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.452 (0.452)\tData 0.319 (0.319)\tLoss 0.1432 (0.1432)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [161][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1370 (0.1175)\tPrec@1 96.094 (97.525)\n",
            "Epoch: [161][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.1228 (0.1154)\tPrec@1 96.094 (97.555)\n",
            "Epoch: [161][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0774 (0.1155)\tPrec@1 97.656 (97.542)\n",
            "Epoch: [161][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1395 (0.1161)\tPrec@1 96.250 (97.536)\n",
            "Total time : 48.778\n",
            "Train Loss: 0.1161, Train Accuracy: 0.9754\n",
            "Test Loss : 0.1637, Test Accuracy : 0.9474 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.411 (0.411)\tData 0.274 (0.274)\tLoss 0.0906 (0.0906)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [162][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.0649 (0.1086)\tPrec@1 100.000 (97.950)\n",
            "Epoch: [162][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1530 (0.1117)\tPrec@1 96.875 (97.707)\n",
            "Epoch: [162][300/391]\tTime 0.122 (0.125)\tData 0.003 (0.002)\tLoss 0.1553 (0.1140)\tPrec@1 95.312 (97.659)\n",
            "Epoch: [162][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.0873 (0.1142)\tPrec@1 97.500 (97.610)\n",
            "Total time : 48.650\n",
            "Train Loss: 0.1142, Train Accuracy: 0.9761\n",
            "Test Loss : 0.1590, Test Accuracy : 0.9476 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.421 (0.421)\tData 0.275 (0.275)\tLoss 0.0958 (0.0958)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [163][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1473 (0.1045)\tPrec@1 96.094 (97.803)\n",
            "Epoch: [163][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.0805 (0.1068)\tPrec@1 99.219 (97.800)\n",
            "Epoch: [163][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1186 (0.1074)\tPrec@1 96.875 (97.752)\n",
            "Epoch: [163][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1979 (0.1106)\tPrec@1 95.000 (97.648)\n",
            "Total time : 48.732\n",
            "Train Loss: 0.1106, Train Accuracy: 0.9765\n",
            "Test Loss : 0.1554, Test Accuracy : 0.9505 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.461 (0.461)\tData 0.320 (0.320)\tLoss 0.1026 (0.1026)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [164][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.005)\tLoss 0.1651 (0.1057)\tPrec@1 92.188 (97.857)\n",
            "Epoch: [164][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.0889 (0.1075)\tPrec@1 99.219 (97.750)\n",
            "Epoch: [164][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1340 (0.1086)\tPrec@1 96.094 (97.765)\n",
            "Epoch: [164][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 0.0751 (0.1076)\tPrec@1 98.750 (97.780)\n",
            "Total time : 48.755\n",
            "Train Loss: 0.1076, Train Accuracy: 0.9778\n",
            "Test Loss : 0.1582, Test Accuracy : 0.9484 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.474 (0.474)\tData 0.267 (0.267)\tLoss 0.0986 (0.0986)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [165][100/391]\tTime 0.126 (0.128)\tData 0.000 (0.004)\tLoss 0.0566 (0.1054)\tPrec@1 99.219 (97.888)\n",
            "Epoch: [165][200/391]\tTime 0.126 (0.126)\tData 0.000 (0.003)\tLoss 0.1096 (0.1070)\tPrec@1 96.875 (97.796)\n",
            "Epoch: [165][300/391]\tTime 0.132 (0.125)\tData 0.010 (0.002)\tLoss 0.1190 (0.1076)\tPrec@1 96.094 (97.768)\n",
            "Epoch: [165][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1078 (0.1076)\tPrec@1 97.500 (97.740)\n",
            "Total time : 48.865\n",
            "Train Loss: 0.1076, Train Accuracy: 0.9774\n",
            "Test Loss : 0.1528, Test Accuracy : 0.9512 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.594 (0.594)\tData 0.406 (0.406)\tLoss 0.1007 (0.1007)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [166][100/391]\tTime 0.119 (0.129)\tData 0.000 (0.005)\tLoss 0.1297 (0.0966)\tPrec@1 96.875 (98.113)\n",
            "Epoch: [166][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1058 (0.0983)\tPrec@1 97.656 (98.037)\n",
            "Epoch: [166][300/391]\tTime 0.132 (0.125)\tData 0.002 (0.003)\tLoss 0.0928 (0.0993)\tPrec@1 99.219 (97.978)\n",
            "Epoch: [166][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0602 (0.1012)\tPrec@1 100.000 (97.896)\n",
            "Total time : 48.714\n",
            "Train Loss: 0.1012, Train Accuracy: 0.9790\n",
            "Test Loss : 0.1521, Test Accuracy : 0.9520 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.444 (0.444)\tData 0.273 (0.273)\tLoss 0.1403 (0.1403)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [167][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1044 (0.1021)\tPrec@1 96.875 (97.857)\n",
            "Epoch: [167][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.1054 (0.1027)\tPrec@1 98.438 (97.866)\n",
            "Epoch: [167][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0833 (0.0996)\tPrec@1 99.219 (97.950)\n",
            "Epoch: [167][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.1063 (0.1015)\tPrec@1 95.000 (97.878)\n",
            "Total time : 48.668\n",
            "Train Loss: 0.1015, Train Accuracy: 0.9788\n",
            "Test Loss : 0.1528, Test Accuracy : 0.9504 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.439 (0.439)\tData 0.270 (0.270)\tLoss 0.1632 (0.1632)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [168][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1084 (0.0969)\tPrec@1 97.656 (98.066)\n",
            "Epoch: [168][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.0769 (0.1014)\tPrec@1 100.000 (97.913)\n",
            "Epoch: [168][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.0994 (0.0990)\tPrec@1 96.094 (97.963)\n",
            "Epoch: [168][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.1050 (0.0988)\tPrec@1 97.500 (97.920)\n",
            "Total time : 48.749\n",
            "Train Loss: 0.0988, Train Accuracy: 0.9792\n",
            "Test Loss : 0.1499, Test Accuracy : 0.9515 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.428 (0.428)\tData 0.271 (0.271)\tLoss 0.1335 (0.1335)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [169][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1013 (0.1001)\tPrec@1 98.438 (98.012)\n",
            "Epoch: [169][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.1480 (0.1010)\tPrec@1 94.531 (97.936)\n",
            "Epoch: [169][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0881 (0.0988)\tPrec@1 97.656 (97.960)\n",
            "Epoch: [169][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.1014 (0.0974)\tPrec@1 96.250 (97.928)\n",
            "Total time : 48.752\n",
            "Train Loss: 0.0974, Train Accuracy: 0.9793\n",
            "Test Loss : 0.1581, Test Accuracy : 0.9501 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.426 (0.426)\tData 0.270 (0.270)\tLoss 0.0950 (0.0950)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [170][100/391]\tTime 0.122 (0.126)\tData 0.000 (0.004)\tLoss 0.1722 (0.0878)\tPrec@1 96.875 (98.190)\n",
            "Epoch: [170][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1375 (0.0946)\tPrec@1 96.875 (97.979)\n",
            "Epoch: [170][300/391]\tTime 0.120 (0.125)\tData 0.000 (0.002)\tLoss 0.0653 (0.0925)\tPrec@1 99.219 (98.066)\n",
            "Epoch: [170][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.0784 (0.0933)\tPrec@1 100.000 (98.028)\n",
            "Total time : 48.672\n",
            "Train Loss: 0.0933, Train Accuracy: 0.9803\n",
            "Test Loss : 0.1510, Test Accuracy : 0.9508 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.492 (0.492)\tData 0.304 (0.304)\tLoss 0.0756 (0.0756)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [171][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.0959 (0.0900)\tPrec@1 99.219 (98.120)\n",
            "Epoch: [171][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.0915 (0.0906)\tPrec@1 98.438 (98.134)\n",
            "Epoch: [171][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0692 (0.0914)\tPrec@1 98.438 (98.103)\n",
            "Epoch: [171][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.1415 (0.0905)\tPrec@1 96.250 (98.130)\n",
            "Total time : 48.785\n",
            "Train Loss: 0.0905, Train Accuracy: 0.9813\n",
            "Test Loss : 0.1489, Test Accuracy : 0.9526 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.444 (0.444)\tData 0.273 (0.273)\tLoss 0.0771 (0.0771)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [172][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1241 (0.0885)\tPrec@1 96.875 (98.058)\n",
            "Epoch: [172][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.0471 (0.0917)\tPrec@1 100.000 (97.959)\n",
            "Epoch: [172][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1080 (0.0915)\tPrec@1 98.438 (97.999)\n",
            "Epoch: [172][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0755 (0.0923)\tPrec@1 98.750 (98.000)\n",
            "Total time : 48.774\n",
            "Train Loss: 0.0923, Train Accuracy: 0.9800\n",
            "Test Loss : 0.1493, Test Accuracy : 0.9524 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.568 (0.568)\tData 0.379 (0.379)\tLoss 0.0567 (0.0567)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [173][100/391]\tTime 0.132 (0.129)\tData 0.007 (0.005)\tLoss 0.0702 (0.0799)\tPrec@1 98.438 (98.345)\n",
            "Epoch: [173][200/391]\tTime 0.143 (0.127)\tData 0.010 (0.003)\tLoss 0.0685 (0.0835)\tPrec@1 99.219 (98.193)\n",
            "Epoch: [173][300/391]\tTime 0.131 (0.125)\tData 0.010 (0.002)\tLoss 0.0898 (0.0843)\tPrec@1 97.656 (98.157)\n",
            "Epoch: [173][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1126 (0.0853)\tPrec@1 98.750 (98.114)\n",
            "Total time : 48.797\n",
            "Train Loss: 0.0853, Train Accuracy: 0.9811\n",
            "Test Loss : 0.1508, Test Accuracy : 0.9521 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.423 (0.423)\tData 0.261 (0.261)\tLoss 0.0562 (0.0562)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [174][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0546 (0.0779)\tPrec@1 99.219 (98.438)\n",
            "Epoch: [174][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.1024 (0.0823)\tPrec@1 96.875 (98.298)\n",
            "Epoch: [174][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0828 (0.0840)\tPrec@1 99.219 (98.269)\n",
            "Epoch: [174][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0768 (0.0840)\tPrec@1 97.500 (98.264)\n",
            "Total time : 48.681\n",
            "Train Loss: 0.0840, Train Accuracy: 0.9826\n",
            "Test Loss : 0.1487, Test Accuracy : 0.9528 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.366 (0.366)\tData 0.202 (0.202)\tLoss 0.0483 (0.0483)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [175][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.0728 (0.0806)\tPrec@1 98.438 (98.244)\n",
            "Epoch: [175][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1130 (0.0822)\tPrec@1 96.875 (98.216)\n",
            "Epoch: [175][300/391]\tTime 0.126 (0.125)\tData 0.000 (0.002)\tLoss 0.0810 (0.0825)\tPrec@1 98.438 (98.214)\n",
            "Epoch: [175][390/391]\tTime 0.092 (0.124)\tData 0.000 (0.002)\tLoss 0.0424 (0.0829)\tPrec@1 100.000 (98.196)\n",
            "Total time : 48.644\n",
            "Train Loss: 0.0829, Train Accuracy: 0.9820\n",
            "Test Loss : 0.1462, Test Accuracy : 0.9531 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.469 (0.469)\tData 0.340 (0.340)\tLoss 0.1003 (0.1003)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [176][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.005)\tLoss 0.0583 (0.0788)\tPrec@1 99.219 (98.407)\n",
            "Epoch: [176][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.1237 (0.0814)\tPrec@1 96.094 (98.294)\n",
            "Epoch: [176][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0756 (0.0817)\tPrec@1 99.219 (98.271)\n",
            "Epoch: [176][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0372 (0.0821)\tPrec@1 100.000 (98.228)\n",
            "Total time : 48.690\n",
            "Train Loss: 0.0821, Train Accuracy: 0.9823\n",
            "Test Loss : 0.1458, Test Accuracy : 0.9531 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.430 (0.430)\tData 0.302 (0.302)\tLoss 0.0782 (0.0782)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [177][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.0983 (0.0836)\tPrec@1 97.656 (98.213)\n",
            "Epoch: [177][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.0667 (0.0820)\tPrec@1 98.438 (98.274)\n",
            "Epoch: [177][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0929 (0.0810)\tPrec@1 97.656 (98.264)\n",
            "Epoch: [177][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.0748 (0.0806)\tPrec@1 97.500 (98.250)\n",
            "Total time : 48.841\n",
            "Train Loss: 0.0806, Train Accuracy: 0.9825\n",
            "Test Loss : 0.1475, Test Accuracy : 0.9533 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.449 (0.449)\tData 0.291 (0.291)\tLoss 0.0630 (0.0630)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [178][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1006 (0.0810)\tPrec@1 96.875 (98.182)\n",
            "Epoch: [178][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.0625 (0.0793)\tPrec@1 98.438 (98.298)\n",
            "Epoch: [178][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0567 (0.0799)\tPrec@1 99.219 (98.277)\n",
            "Epoch: [178][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.0454 (0.0793)\tPrec@1 100.000 (98.266)\n",
            "Total time : 48.712\n",
            "Train Loss: 0.0793, Train Accuracy: 0.9827\n",
            "Test Loss : 0.1491, Test Accuracy : 0.9540 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.410 (0.410)\tData 0.251 (0.251)\tLoss 0.1050 (0.1050)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [179][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0687 (0.0789)\tPrec@1 99.219 (98.321)\n",
            "Epoch: [179][200/391]\tTime 0.121 (0.125)\tData 0.001 (0.002)\tLoss 0.1391 (0.0782)\tPrec@1 95.312 (98.329)\n",
            "Epoch: [179][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.0776 (0.0781)\tPrec@1 98.438 (98.287)\n",
            "Epoch: [179][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.1541 (0.0773)\tPrec@1 95.000 (98.284)\n",
            "Total time : 48.622\n",
            "Train Loss: 0.0773, Train Accuracy: 0.9828\n",
            "Test Loss : 0.1463, Test Accuracy : 0.9541 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.364 (0.364)\tData 0.186 (0.186)\tLoss 0.0483 (0.0483)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [180][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 0.0677 (0.0780)\tPrec@1 97.656 (98.252)\n",
            "Epoch: [180][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0563 (0.0755)\tPrec@1 98.438 (98.325)\n",
            "Epoch: [180][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1016 (0.0756)\tPrec@1 98.438 (98.308)\n",
            "Epoch: [180][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.0476 (0.0765)\tPrec@1 100.000 (98.276)\n",
            "Total time : 48.712\n",
            "Train Loss: 0.0765, Train Accuracy: 0.9828\n",
            "Test Loss : 0.1455, Test Accuracy : 0.9557 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.502 (0.502)\tData 0.321 (0.321)\tLoss 0.1013 (0.1013)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [181][100/391]\tTime 0.132 (0.129)\tData 0.007 (0.005)\tLoss 0.0809 (0.0767)\tPrec@1 98.438 (98.244)\n",
            "Epoch: [181][200/391]\tTime 0.130 (0.127)\tData 0.007 (0.003)\tLoss 0.0580 (0.0782)\tPrec@1 97.656 (98.235)\n",
            "Epoch: [181][300/391]\tTime 0.133 (0.126)\tData 0.010 (0.002)\tLoss 0.0617 (0.0765)\tPrec@1 99.219 (98.331)\n",
            "Epoch: [181][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0305 (0.0750)\tPrec@1 100.000 (98.366)\n",
            "Total time : 48.867\n",
            "Train Loss: 0.0750, Train Accuracy: 0.9837\n",
            "Test Loss : 0.1475, Test Accuracy : 0.9545 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.442 (0.442)\tData 0.277 (0.277)\tLoss 0.0862 (0.0862)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [182][100/391]\tTime 0.128 (0.127)\tData 0.000 (0.004)\tLoss 0.0728 (0.0666)\tPrec@1 98.438 (98.554)\n",
            "Epoch: [182][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.0267 (0.0700)\tPrec@1 100.000 (98.488)\n",
            "Epoch: [182][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0764 (0.0713)\tPrec@1 99.219 (98.458)\n",
            "Epoch: [182][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.0768 (0.0726)\tPrec@1 100.000 (98.446)\n",
            "Total time : 48.599\n",
            "Train Loss: 0.0726, Train Accuracy: 0.9845\n",
            "Test Loss : 0.1482, Test Accuracy : 0.9538 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.444 (0.444)\tData 0.290 (0.290)\tLoss 0.0794 (0.0794)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [183][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0572 (0.0729)\tPrec@1 99.219 (98.321)\n",
            "Epoch: [183][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0722 (0.0737)\tPrec@1 97.656 (98.340)\n",
            "Epoch: [183][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0453 (0.0723)\tPrec@1 99.219 (98.357)\n",
            "Epoch: [183][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0980 (0.0719)\tPrec@1 97.500 (98.386)\n",
            "Total time : 48.708\n",
            "Train Loss: 0.0719, Train Accuracy: 0.9839\n",
            "Test Loss : 0.1477, Test Accuracy : 0.9547 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.425 (0.425)\tData 0.288 (0.288)\tLoss 0.0444 (0.0444)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [184][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0607 (0.0753)\tPrec@1 97.656 (98.291)\n",
            "Epoch: [184][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.0861 (0.0753)\tPrec@1 97.656 (98.231)\n",
            "Epoch: [184][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0601 (0.0737)\tPrec@1 98.438 (98.274)\n",
            "Epoch: [184][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0820 (0.0720)\tPrec@1 97.500 (98.348)\n",
            "Total time : 48.840\n",
            "Train Loss: 0.0720, Train Accuracy: 0.9835\n",
            "Test Loss : 0.1529, Test Accuracy : 0.9535 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.479 (0.479)\tData 0.312 (0.312)\tLoss 0.1162 (0.1162)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [185][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 0.1075 (0.0654)\tPrec@1 96.875 (98.561)\n",
            "Epoch: [185][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.0875 (0.0697)\tPrec@1 98.438 (98.414)\n",
            "Epoch: [185][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0704 (0.0692)\tPrec@1 97.656 (98.448)\n",
            "Epoch: [185][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0613 (0.0700)\tPrec@1 100.000 (98.424)\n",
            "Total time : 48.755\n",
            "Train Loss: 0.0700, Train Accuracy: 0.9842\n",
            "Test Loss : 0.1464, Test Accuracy : 0.9551 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.377 (0.377)\tData 0.211 (0.211)\tLoss 0.0772 (0.0772)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [186][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0698 (0.0721)\tPrec@1 99.219 (98.337)\n",
            "Epoch: [186][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0530 (0.0699)\tPrec@1 98.438 (98.426)\n",
            "Epoch: [186][300/391]\tTime 0.126 (0.125)\tData 0.000 (0.002)\tLoss 0.0464 (0.0687)\tPrec@1 99.219 (98.463)\n",
            "Epoch: [186][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0715 (0.0677)\tPrec@1 98.750 (98.496)\n",
            "Total time : 48.744\n",
            "Train Loss: 0.0677, Train Accuracy: 0.9850\n",
            "Test Loss : 0.1477, Test Accuracy : 0.9539 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.469 (0.469)\tData 0.300 (0.300)\tLoss 0.0517 (0.0517)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [187][100/391]\tTime 0.124 (0.128)\tData 0.000 (0.004)\tLoss 0.0361 (0.0699)\tPrec@1 100.000 (98.461)\n",
            "Epoch: [187][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.0360 (0.0672)\tPrec@1 100.000 (98.519)\n",
            "Epoch: [187][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.0318 (0.0664)\tPrec@1 100.000 (98.534)\n",
            "Epoch: [187][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0858 (0.0669)\tPrec@1 97.500 (98.512)\n",
            "Total time : 48.781\n",
            "Train Loss: 0.0669, Train Accuracy: 0.9851\n",
            "Test Loss : 0.1430, Test Accuracy : 0.9565 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.579 (0.579)\tData 0.371 (0.371)\tLoss 0.0860 (0.0860)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [188][100/391]\tTime 0.136 (0.129)\tData 0.006 (0.005)\tLoss 0.0747 (0.0674)\tPrec@1 96.875 (98.461)\n",
            "Epoch: [188][200/391]\tTime 0.135 (0.126)\tData 0.006 (0.003)\tLoss 0.0385 (0.0673)\tPrec@1 99.219 (98.476)\n",
            "Epoch: [188][300/391]\tTime 0.133 (0.125)\tData 0.008 (0.002)\tLoss 0.0360 (0.0677)\tPrec@1 100.000 (98.445)\n",
            "Epoch: [188][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.0890 (0.0677)\tPrec@1 98.750 (98.428)\n",
            "Total time : 48.827\n",
            "Train Loss: 0.0677, Train Accuracy: 0.9843\n",
            "Test Loss : 0.1459, Test Accuracy : 0.9550 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.356 (0.356)\tData 0.210 (0.210)\tLoss 0.0820 (0.0820)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [189][100/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.0375 (0.0690)\tPrec@1 100.000 (98.306)\n",
            "Epoch: [189][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0631 (0.0692)\tPrec@1 98.438 (98.391)\n",
            "Epoch: [189][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0696 (0.0698)\tPrec@1 97.656 (98.378)\n",
            "Epoch: [189][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.0775 (0.0689)\tPrec@1 97.500 (98.426)\n",
            "Total time : 48.633\n",
            "Train Loss: 0.0689, Train Accuracy: 0.9843\n",
            "Test Loss : 0.1440, Test Accuracy : 0.9558 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.437 (0.437)\tData 0.277 (0.277)\tLoss 0.0572 (0.0572)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [190][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.0786 (0.0660)\tPrec@1 97.656 (98.600)\n",
            "Epoch: [190][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1827 (0.0654)\tPrec@1 94.531 (98.581)\n",
            "Epoch: [190][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0440 (0.0658)\tPrec@1 98.438 (98.500)\n",
            "Epoch: [190][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.0254 (0.0647)\tPrec@1 100.000 (98.546)\n",
            "Total time : 48.734\n",
            "Train Loss: 0.0647, Train Accuracy: 0.9855\n",
            "Test Loss : 0.1434, Test Accuracy : 0.9561 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.437 (0.437)\tData 0.268 (0.268)\tLoss 0.0823 (0.0823)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [191][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0586 (0.0665)\tPrec@1 99.219 (98.453)\n",
            "Epoch: [191][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.003)\tLoss 0.0577 (0.0648)\tPrec@1 99.219 (98.601)\n",
            "Epoch: [191][300/391]\tTime 0.120 (0.125)\tData 0.000 (0.002)\tLoss 0.0443 (0.0644)\tPrec@1 99.219 (98.583)\n",
            "Epoch: [191][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.0924 (0.0641)\tPrec@1 98.750 (98.580)\n",
            "Total time : 48.705\n",
            "Train Loss: 0.0641, Train Accuracy: 0.9858\n",
            "Test Loss : 0.1426, Test Accuracy : 0.9566 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.453 (0.453)\tData 0.315 (0.315)\tLoss 0.0773 (0.0773)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [192][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0430 (0.0634)\tPrec@1 100.000 (98.615)\n",
            "Epoch: [192][200/391]\tTime 0.125 (0.125)\tData 0.003 (0.003)\tLoss 0.0557 (0.0644)\tPrec@1 99.219 (98.554)\n",
            "Epoch: [192][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.0877 (0.0630)\tPrec@1 98.438 (98.617)\n",
            "Epoch: [192][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.0673 (0.0634)\tPrec@1 98.750 (98.582)\n",
            "Total time : 48.702\n",
            "Train Loss: 0.0634, Train Accuracy: 0.9858\n",
            "Test Loss : 0.1431, Test Accuracy : 0.9567 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.479 (0.479)\tData 0.319 (0.319)\tLoss 0.0587 (0.0587)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [193][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.0852 (0.0624)\tPrec@1 97.656 (98.623)\n",
            "Epoch: [193][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 0.0422 (0.0646)\tPrec@1 100.000 (98.523)\n",
            "Epoch: [193][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.0828 (0.0650)\tPrec@1 97.656 (98.508)\n",
            "Epoch: [193][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0899 (0.0644)\tPrec@1 96.250 (98.542)\n",
            "Total time : 48.859\n",
            "Train Loss: 0.0644, Train Accuracy: 0.9854\n",
            "Test Loss : 0.1429, Test Accuracy : 0.9564 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.441 (0.441)\tData 0.260 (0.260)\tLoss 0.0514 (0.0514)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [194][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.0470 (0.0614)\tPrec@1 99.219 (98.600)\n",
            "Epoch: [194][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0465 (0.0618)\tPrec@1 99.219 (98.589)\n",
            "Epoch: [194][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0758 (0.0632)\tPrec@1 97.656 (98.536)\n",
            "Epoch: [194][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1202 (0.0630)\tPrec@1 95.000 (98.568)\n",
            "Total time : 48.776\n",
            "Train Loss: 0.0630, Train Accuracy: 0.9857\n",
            "Test Loss : 0.1441, Test Accuracy : 0.9563 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.583 (0.583)\tData 0.375 (0.375)\tLoss 0.0758 (0.0758)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [195][100/391]\tTime 0.133 (0.129)\tData 0.000 (0.005)\tLoss 0.0588 (0.0691)\tPrec@1 99.219 (98.407)\n",
            "Epoch: [195][200/391]\tTime 0.134 (0.126)\tData 0.000 (0.003)\tLoss 0.1067 (0.0659)\tPrec@1 97.656 (98.511)\n",
            "Epoch: [195][300/391]\tTime 0.130 (0.126)\tData 0.000 (0.002)\tLoss 0.0776 (0.0641)\tPrec@1 97.656 (98.606)\n",
            "Epoch: [195][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0815 (0.0646)\tPrec@1 97.500 (98.588)\n",
            "Total time : 48.877\n",
            "Train Loss: 0.0646, Train Accuracy: 0.9859\n",
            "Test Loss : 0.1430, Test Accuracy : 0.9566 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.489 (0.489)\tData 0.338 (0.338)\tLoss 0.0341 (0.0341)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [196][100/391]\tTime 0.122 (0.127)\tData 0.001 (0.005)\tLoss 0.0413 (0.0625)\tPrec@1 98.438 (98.546)\n",
            "Epoch: [196][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.0946 (0.0639)\tPrec@1 97.656 (98.527)\n",
            "Epoch: [196][300/391]\tTime 0.123 (0.125)\tData 0.006 (0.003)\tLoss 0.0672 (0.0644)\tPrec@1 96.875 (98.505)\n",
            "Epoch: [196][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.0356 (0.0643)\tPrec@1 98.750 (98.508)\n",
            "Total time : 48.701\n",
            "Train Loss: 0.0643, Train Accuracy: 0.9851\n",
            "Test Loss : 0.1445, Test Accuracy : 0.9577 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.453 (0.453)\tData 0.301 (0.301)\tLoss 0.1321 (0.1321)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [197][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.0852 (0.0639)\tPrec@1 97.656 (98.515)\n",
            "Epoch: [197][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.0627 (0.0643)\tPrec@1 98.438 (98.457)\n",
            "Epoch: [197][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0599 (0.0650)\tPrec@1 99.219 (98.453)\n",
            "Epoch: [197][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.0372 (0.0651)\tPrec@1 100.000 (98.466)\n",
            "Total time : 48.620\n",
            "Train Loss: 0.0651, Train Accuracy: 0.9847\n",
            "Test Loss : 0.1443, Test Accuracy : 0.9578 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.443 (0.443)\tData 0.271 (0.271)\tLoss 0.0842 (0.0842)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [198][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.0789 (0.0651)\tPrec@1 98.438 (98.461)\n",
            "Epoch: [198][200/391]\tTime 0.124 (0.125)\tData 0.001 (0.002)\tLoss 0.1193 (0.0644)\tPrec@1 96.094 (98.519)\n",
            "Epoch: [198][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.0491 (0.0637)\tPrec@1 98.438 (98.578)\n",
            "Epoch: [198][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.0761 (0.0633)\tPrec@1 96.250 (98.578)\n",
            "Total time : 48.687\n",
            "Train Loss: 0.0633, Train Accuracy: 0.9858\n",
            "Test Loss : 0.1436, Test Accuracy : 0.9567 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.390 (0.390)\tData 0.232 (0.232)\tLoss 0.0816 (0.0816)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [199][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.0512 (0.0651)\tPrec@1 99.219 (98.461)\n",
            "Epoch: [199][200/391]\tTime 0.121 (0.125)\tData 0.001 (0.003)\tLoss 0.0701 (0.0627)\tPrec@1 97.656 (98.570)\n",
            "Epoch: [199][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.0952 (0.0626)\tPrec@1 97.656 (98.575)\n",
            "Epoch: [199][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.0575 (0.0634)\tPrec@1 98.750 (98.560)\n",
            "Total time : 48.725\n",
            "Train Loss: 0.0634, Train Accuracy: 0.9856\n",
            "Test Loss : 0.1444, Test Accuracy : 0.9563 \n",
            "\n",
            "train loss:  [1.8112, 1.4454, 1.1703, 1.0063, 0.9115, 0.8395, 0.784, 0.7479, 0.7219, 0.7072, 0.6759, 0.6582, 0.6503, 0.6343, 0.6231, 0.6102, 0.6023, 0.5857, 0.5795, 0.576, 0.5652, 0.5608, 0.5568, 0.542, 0.5424, 0.5366, 0.5321, 0.5328, 0.5235, 0.5263, 0.5205, 0.5183, 0.5225, 0.5023, 0.5018, 0.5087, 0.4987, 0.494, 0.4929, 0.489, 0.4823, 0.4831, 0.4721, 0.4707, 0.4714, 0.4725, 0.4613, 0.4587, 0.4564, 0.4633, 0.4558, 0.4519, 0.4505, 0.4457, 0.4397, 0.4363, 0.4373, 0.4436, 0.4321, 0.4301, 0.4294, 0.4317, 0.4247, 0.4244, 0.4259, 0.4143, 0.4041, 0.4133, 0.408, 0.4076, 0.4007, 0.401, 0.3926, 0.3917, 0.386, 0.3788, 0.3812, 0.3858, 0.3833, 0.372, 0.3709, 0.3702, 0.3623, 0.3661, 0.3593, 0.3557, 0.3523, 0.3491, 0.3481, 0.3436, 0.3408, 0.3357, 0.3301, 0.3281, 0.3262, 0.327, 0.3231, 0.3226, 0.315, 0.3153, 0.3101, 0.3039, 0.3057, 0.2985, 0.2912, 0.2996, 0.2926, 0.2858, 0.289, 0.2769, 0.2782, 0.2757, 0.2676, 0.2705, 0.2649, 0.2578, 0.2528, 0.2513, 0.2476, 0.2445, 0.2363, 0.2384, 0.2351, 0.2344, 0.2276, 0.2246, 0.2252, 0.2179, 0.2153, 0.2113, 0.2121, 0.2075, 0.2015, 0.2005, 0.1955, 0.1909, 0.188, 0.1825, 0.1863, 0.1768, 0.1747, 0.1738, 0.1716, 0.166, 0.1626, 0.1573, 0.1576, 0.1514, 0.1529, 0.1518, 0.1473, 0.1411, 0.1344, 0.1369, 0.1345, 0.1309, 0.1287, 0.1245, 0.1248, 0.115, 0.119, 0.1161, 0.1142, 0.1106, 0.1076, 0.1076, 0.1012, 0.1015, 0.0988, 0.0974, 0.0933, 0.0905, 0.0923, 0.0853, 0.084, 0.0829, 0.0821, 0.0806, 0.0793, 0.0773, 0.0765, 0.075, 0.0726, 0.0719, 0.072, 0.07, 0.0677, 0.0669, 0.0677, 0.0689, 0.0647, 0.0641, 0.0634, 0.0644, 0.063, 0.0646, 0.0643, 0.0651, 0.0633, 0.0634]\n",
            "train err:  [0.6911, 0.5135, 0.3782, 0.3156, 0.2768, 0.2461, 0.2255, 0.2081, 0.1988, 0.1912, 0.1785, 0.1731, 0.1706, 0.1638, 0.1595, 0.1563, 0.1507, 0.146, 0.1424, 0.1411, 0.139, 0.1355, 0.1336, 0.1308, 0.1295, 0.1272, 0.1257, 0.1276, 0.1253, 0.1225, 0.1233, 0.1218, 0.1208, 0.1168, 0.1157, 0.117, 0.1154, 0.1141, 0.114, 0.1113, 0.1097, 0.1111, 0.1075, 0.1069, 0.1085, 0.1063, 0.1038, 0.1042, 0.103, 0.1043, 0.1028, 0.101, 0.1024, 0.1001, 0.0984, 0.0982, 0.096, 0.099, 0.0962, 0.0951, 0.0949, 0.0958, 0.0946, 0.0958, 0.0963, 0.0909, 0.0882, 0.0905, 0.0904, 0.0896, 0.088, 0.0896, 0.0847, 0.0862, 0.0837, 0.0826, 0.0827, 0.0848, 0.0825, 0.0817, 0.0816, 0.0785, 0.0781, 0.0785, 0.0778, 0.0769, 0.0752, 0.0755, 0.0757, 0.0736, 0.073, 0.0723, 0.0703, 0.0696, 0.0706, 0.071, 0.0682, 0.0684, 0.066, 0.0665, 0.0663, 0.0626, 0.0652, 0.0634, 0.0611, 0.0634, 0.0615, 0.06, 0.0612, 0.0574, 0.058, 0.057, 0.0555, 0.0566, 0.056, 0.0527, 0.0519, 0.0524, 0.0513, 0.0508, 0.0484, 0.0486, 0.0479, 0.0489, 0.0465, 0.0462, 0.0456, 0.0439, 0.0436, 0.0424, 0.0432, 0.0426, 0.0405, 0.0406, 0.0386, 0.0384, 0.0378, 0.0372, 0.0379, 0.0361, 0.0361, 0.0344, 0.035, 0.0335, 0.0325, 0.0317, 0.0314, 0.0302, 0.0312, 0.0314, 0.0298, 0.0292, 0.0267, 0.0271, 0.0273, 0.0259, 0.0259, 0.0255, 0.026, 0.0226, 0.0242, 0.0246, 0.0239, 0.0235, 0.0222, 0.0226, 0.021, 0.0212, 0.0208, 0.0207, 0.0197, 0.0187, 0.02, 0.0189, 0.0174, 0.018, 0.0177, 0.0175, 0.0173, 0.0172, 0.0172, 0.0163, 0.0155, 0.0161, 0.0165, 0.0158, 0.015, 0.0149, 0.0157, 0.0157, 0.0145, 0.0142, 0.0142, 0.0146, 0.0143, 0.0141, 0.0149, 0.0153, 0.0142, 0.0144]\n",
            "train acc:  [0.3089, 0.4865, 0.6218, 0.6844, 0.7232, 0.7539, 0.7745, 0.7919, 0.8012, 0.8088, 0.8215, 0.8269, 0.8294, 0.8362, 0.8405, 0.8437, 0.8493, 0.854, 0.8576, 0.8589, 0.861, 0.8645, 0.8664, 0.8692, 0.8705, 0.8728, 0.8743, 0.8724, 0.8747, 0.8775, 0.8767, 0.8782, 0.8792, 0.8832, 0.8843, 0.883, 0.8846, 0.8859, 0.886, 0.8887, 0.8903, 0.8889, 0.8925, 0.8931, 0.8915, 0.8937, 0.8962, 0.8958, 0.897, 0.8957, 0.8972, 0.899, 0.8976, 0.8999, 0.9016, 0.9018, 0.904, 0.901, 0.9038, 0.9049, 0.9051, 0.9042, 0.9054, 0.9042, 0.9037, 0.9091, 0.9118, 0.9095, 0.9096, 0.9104, 0.912, 0.9104, 0.9153, 0.9138, 0.9163, 0.9174, 0.9173, 0.9152, 0.9175, 0.9183, 0.9184, 0.9215, 0.9219, 0.9215, 0.9222, 0.9231, 0.9248, 0.9245, 0.9243, 0.9264, 0.927, 0.9277, 0.9297, 0.9304, 0.9294, 0.929, 0.9318, 0.9316, 0.934, 0.9335, 0.9337, 0.9374, 0.9348, 0.9366, 0.9389, 0.9366, 0.9385, 0.94, 0.9388, 0.9426, 0.942, 0.943, 0.9445, 0.9434, 0.944, 0.9473, 0.9481, 0.9476, 0.9487, 0.9492, 0.9516, 0.9514, 0.9521, 0.9511, 0.9535, 0.9538, 0.9544, 0.9561, 0.9564, 0.9576, 0.9568, 0.9574, 0.9595, 0.9594, 0.9614, 0.9616, 0.9622, 0.9628, 0.9621, 0.9639, 0.9639, 0.9656, 0.965, 0.9665, 0.9675, 0.9683, 0.9686, 0.9698, 0.9688, 0.9686, 0.9702, 0.9708, 0.9733, 0.9729, 0.9727, 0.9741, 0.9741, 0.9745, 0.974, 0.9774, 0.9758, 0.9754, 0.9761, 0.9765, 0.9778, 0.9774, 0.979, 0.9788, 0.9792, 0.9793, 0.9803, 0.9813, 0.98, 0.9811, 0.9826, 0.982, 0.9823, 0.9825, 0.9827, 0.9828, 0.9828, 0.9837, 0.9845, 0.9839, 0.9835, 0.9842, 0.985, 0.9851, 0.9843, 0.9843, 0.9855, 0.9858, 0.9858, 0.9854, 0.9857, 0.9859, 0.9851, 0.9847, 0.9858, 0.9856]\n",
            "test loss:  [1.5104, 1.1915, 0.9734, 0.8723, 0.7796, 0.7632, 0.6699, 0.6909, 0.647, 0.6702, 0.6266, 0.5477, 0.7145, 0.5131, 0.5497, 0.5229, 0.5606, 0.553, 0.5395, 0.5166, 0.455, 0.4988, 0.4896, 0.4347, 0.4569, 0.5044, 0.4387, 0.4512, 0.5756, 0.4433, 0.486, 0.4418, 0.4135, 0.4617, 0.4822, 0.4549, 0.4261, 0.4412, 0.4072, 0.4298, 0.4185, 0.4299, 0.5163, 0.3988, 0.5351, 0.4437, 0.4331, 0.387, 0.4584, 0.361, 0.3872, 0.4464, 0.3715, 0.3816, 0.3569, 0.4384, 0.3898, 0.4196, 0.3946, 0.42, 0.3517, 0.3838, 0.3752, 0.3867, 0.4043, 0.3867, 0.4308, 0.3474, 0.3595, 0.3833, 0.3597, 0.3274, 0.3532, 0.3323, 0.3151, 0.3538, 0.338, 0.3149, 0.3187, 0.3735, 0.3274, 0.3732, 0.3356, 0.3277, 0.3362, 0.29, 0.2948, 0.3068, 0.3268, 0.3544, 0.2944, 0.3049, 0.3042, 0.3085, 0.3078, 0.2945, 0.3297, 0.3045, 0.2836, 0.2715, 0.2733, 0.3024, 0.2821, 0.2861, 0.2659, 0.2656, 0.2575, 0.2521, 0.2371, 0.2581, 0.2437, 0.2695, 0.2583, 0.2482, 0.267, 0.2352, 0.2417, 0.2506, 0.2299, 0.2261, 0.2439, 0.226, 0.2423, 0.2349, 0.2349, 0.2548, 0.2246, 0.2232, 0.1948, 0.2156, 0.2129, 0.2043, 0.2133, 0.2092, 0.1992, 0.1934, 0.2003, 0.1994, 0.1957, 0.2137, 0.1984, 0.1813, 0.1887, 0.1974, 0.1881, 0.1906, 0.1977, 0.185, 0.1852, 0.179, 0.1767, 0.1786, 0.1745, 0.1737, 0.176, 0.1706, 0.166, 0.1655, 0.167, 0.1644, 0.1646, 0.1637, 0.159, 0.1554, 0.1582, 0.1528, 0.1521, 0.1528, 0.1499, 0.1581, 0.151, 0.1489, 0.1493, 0.1508, 0.1487, 0.1462, 0.1458, 0.1475, 0.1491, 0.1463, 0.1455, 0.1475, 0.1482, 0.1477, 0.1529, 0.1464, 0.1477, 0.143, 0.1459, 0.144, 0.1434, 0.1426, 0.1431, 0.1429, 0.1441, 0.143, 0.1445, 0.1443, 0.1436, 0.1444]\n",
            "test err:  [0.5889, 0.4275, 0.345, 0.3057, 0.2713, 0.2631, 0.2228, 0.2277, 0.2139, 0.2229, 0.2045, 0.1816, 0.2437, 0.1666, 0.1814, 0.1704, 0.1843, 0.1839, 0.1771, 0.1709, 0.1503, 0.1601, 0.1594, 0.1373, 0.1454, 0.1648, 0.1477, 0.1491, 0.1861, 0.1411, 0.1552, 0.1418, 0.1339, 0.1534, 0.161, 0.1484, 0.1365, 0.1428, 0.1319, 0.1406, 0.1376, 0.1416, 0.1721, 0.1257, 0.1699, 0.137, 0.1443, 0.1275, 0.1507, 0.1187, 0.1223, 0.1479, 0.1238, 0.1241, 0.1172, 0.1437, 0.1277, 0.1394, 0.1288, 0.1344, 0.1155, 0.126, 0.1193, 0.1303, 0.1277, 0.1227, 0.1378, 0.114, 0.119, 0.1257, 0.1168, 0.1069, 0.1168, 0.1062, 0.0985, 0.1207, 0.1154, 0.1065, 0.1033, 0.1264, 0.1067, 0.1277, 0.1123, 0.1109, 0.1095, 0.0941, 0.0966, 0.0987, 0.1052, 0.1141, 0.0983, 0.1013, 0.0976, 0.0972, 0.0986, 0.0988, 0.1137, 0.0987, 0.0931, 0.0851, 0.0904, 0.1, 0.0913, 0.0971, 0.0872, 0.0835, 0.0825, 0.0826, 0.0773, 0.0842, 0.0794, 0.0877, 0.0837, 0.0802, 0.0839, 0.0762, 0.0783, 0.0837, 0.0748, 0.0747, 0.0768, 0.0733, 0.0798, 0.0787, 0.0773, 0.0875, 0.0729, 0.0731, 0.0623, 0.0686, 0.0675, 0.0678, 0.0685, 0.0658, 0.0647, 0.0629, 0.0673, 0.0623, 0.0645, 0.0715, 0.0647, 0.0618, 0.0637, 0.0638, 0.0612, 0.0649, 0.0654, 0.0602, 0.062, 0.0587, 0.0605, 0.0594, 0.0576, 0.0575, 0.0581, 0.0569, 0.0532, 0.0543, 0.0551, 0.0534, 0.0525, 0.0526, 0.0524, 0.0495, 0.0516, 0.0488, 0.048, 0.0496, 0.0485, 0.0499, 0.0492, 0.0474, 0.0476, 0.0479, 0.0472, 0.0469, 0.0469, 0.0467, 0.046, 0.0459, 0.0443, 0.0455, 0.0462, 0.0453, 0.0465, 0.0449, 0.0461, 0.0435, 0.045, 0.0442, 0.0439, 0.0434, 0.0433, 0.0436, 0.0437, 0.0434, 0.0423, 0.0422, 0.0433, 0.0437]\n",
            "test acc:  [0.4111, 0.5725, 0.655, 0.6943, 0.7287, 0.7369, 0.7772, 0.7723, 0.7861, 0.7771, 0.7955, 0.8184, 0.7563, 0.8334, 0.8186, 0.8296, 0.8157, 0.8161, 0.8229, 0.8291, 0.8497, 0.8399, 0.8406, 0.8627, 0.8546, 0.8352, 0.8523, 0.8509, 0.8139, 0.8589, 0.8448, 0.8582, 0.8661, 0.8466, 0.839, 0.8516, 0.8635, 0.8572, 0.8681, 0.8594, 0.8624, 0.8584, 0.8279, 0.8743, 0.8301, 0.863, 0.8557, 0.8725, 0.8493, 0.8813, 0.8777, 0.8521, 0.8762, 0.8759, 0.8828, 0.8563, 0.8723, 0.8606, 0.8712, 0.8656, 0.8845, 0.874, 0.8807, 0.8697, 0.8723, 0.8773, 0.8622, 0.886, 0.881, 0.8743, 0.8832, 0.8931, 0.8832, 0.8938, 0.9015, 0.8793, 0.8846, 0.8935, 0.8967, 0.8736, 0.8933, 0.8723, 0.8877, 0.8891, 0.8905, 0.9059, 0.9034, 0.9013, 0.8948, 0.8859, 0.9017, 0.8987, 0.9024, 0.9028, 0.9014, 0.9012, 0.8863, 0.9013, 0.9069, 0.9149, 0.9096, 0.9, 0.9087, 0.9029, 0.9128, 0.9165, 0.9175, 0.9174, 0.9227, 0.9158, 0.9206, 0.9123, 0.9163, 0.9198, 0.9161, 0.9238, 0.9217, 0.9163, 0.9252, 0.9253, 0.9232, 0.9267, 0.9202, 0.9213, 0.9227, 0.9125, 0.9271, 0.9269, 0.9377, 0.9314, 0.9325, 0.9322, 0.9315, 0.9342, 0.9353, 0.9371, 0.9327, 0.9377, 0.9355, 0.9285, 0.9353, 0.9382, 0.9363, 0.9362, 0.9388, 0.9351, 0.9346, 0.9398, 0.938, 0.9413, 0.9395, 0.9406, 0.9424, 0.9425, 0.9419, 0.9431, 0.9468, 0.9457, 0.9449, 0.9466, 0.9475, 0.9474, 0.9476, 0.9505, 0.9484, 0.9512, 0.952, 0.9504, 0.9515, 0.9501, 0.9508, 0.9526, 0.9524, 0.9521, 0.9528, 0.9531, 0.9531, 0.9533, 0.954, 0.9541, 0.9557, 0.9545, 0.9538, 0.9547, 0.9535, 0.9551, 0.9539, 0.9565, 0.955, 0.9558, 0.9561, 0.9566, 0.9567, 0.9564, 0.9563, 0.9566, 0.9577, 0.9578, 0.9567, 0.9563]\n",
            "ori train loss:  [1.8112, 1.4454, 1.1703, 1.0063, 0.9115, 0.8395, 0.784, 0.7479, 0.7219, 0.7072, 0.6759, 0.6582, 0.6503, 0.6343, 0.6231, 0.6102, 0.6023, 0.5857, 0.5795, 0.576, 0.5652, 0.5608, 0.5568, 0.542, 0.5424, 0.5366, 0.5321, 0.5328, 0.5235, 0.5263, 0.5205, 0.5183, 0.5225, 0.5023, 0.5018, 0.5087, 0.4987, 0.494, 0.4929, 0.489, 0.4823, 0.4831, 0.4721, 0.4707, 0.4714, 0.4725, 0.4613, 0.4587, 0.4564, 0.4633, 0.4558, 0.4519, 0.4505, 0.4457, 0.4397, 0.4363, 0.4373, 0.4436, 0.4321, 0.4301, 0.4294, 0.4317, 0.4247, 0.4244, 0.4259, 0.4143, 0.4041, 0.4133, 0.408, 0.4076, 0.4007, 0.401, 0.3926, 0.3917, 0.386, 0.3788, 0.3812, 0.3858, 0.3833, 0.372, 0.3709, 0.3702, 0.3623, 0.3661, 0.3593, 0.3557, 0.3523, 0.3491, 0.3481, 0.3436, 0.3408, 0.3357, 0.3301, 0.3281, 0.3262, 0.327, 0.3231, 0.3226, 0.315, 0.3153, 0.3101, 0.3039, 0.3057, 0.2985, 0.2912, 0.2996, 0.2926, 0.2858, 0.289, 0.2769, 0.2782, 0.2757, 0.2676, 0.2705, 0.2649, 0.2578, 0.2528, 0.2513, 0.2476, 0.2445, 0.2363, 0.2384, 0.2351, 0.2344, 0.2276, 0.2246, 0.2252, 0.2179, 0.2153, 0.2113, 0.2121, 0.2075, 0.2015, 0.2005, 0.1955, 0.1909, 0.188, 0.1825, 0.1863, 0.1768, 0.1747, 0.1738, 0.1716, 0.166, 0.1626, 0.1573, 0.1576, 0.1514, 0.1529, 0.1518, 0.1473, 0.1411, 0.1344, 0.1369, 0.1345, 0.1309, 0.1287, 0.1245, 0.1248, 0.115, 0.119, 0.1161, 0.1142, 0.1106, 0.1076, 0.1076, 0.1012, 0.1015, 0.0988, 0.0974, 0.0933, 0.0905, 0.0923, 0.0853, 0.084, 0.0829, 0.0821, 0.0806, 0.0793, 0.0773, 0.0765, 0.075, 0.0726, 0.0719, 0.072, 0.07, 0.0677, 0.0669, 0.0677, 0.0689, 0.0647, 0.0641, 0.0634, 0.0644, 0.063, 0.0646, 0.0643, 0.0651, 0.0633, 0.0634]\n",
            "ori train err:  [0.6911, 0.5135, 0.3782, 0.3156, 0.2768, 0.2461, 0.2255, 0.2081, 0.1988, 0.1912, 0.1785, 0.1731, 0.1706, 0.1638, 0.1595, 0.1563, 0.1507, 0.146, 0.1424, 0.1411, 0.139, 0.1355, 0.1336, 0.1308, 0.1295, 0.1272, 0.1257, 0.1276, 0.1253, 0.1225, 0.1233, 0.1218, 0.1208, 0.1168, 0.1157, 0.117, 0.1154, 0.1141, 0.114, 0.1113, 0.1097, 0.1111, 0.1075, 0.1069, 0.1085, 0.1063, 0.1038, 0.1042, 0.103, 0.1043, 0.1028, 0.101, 0.1024, 0.1001, 0.0984, 0.0982, 0.096, 0.099, 0.0962, 0.0951, 0.0949, 0.0958, 0.0946, 0.0958, 0.0963, 0.0909, 0.0882, 0.0905, 0.0904, 0.0896, 0.088, 0.0896, 0.0847, 0.0862, 0.0837, 0.0826, 0.0827, 0.0848, 0.0825, 0.0817, 0.0816, 0.0785, 0.0781, 0.0785, 0.0778, 0.0769, 0.0752, 0.0755, 0.0757, 0.0736, 0.073, 0.0723, 0.0703, 0.0696, 0.0706, 0.071, 0.0682, 0.0684, 0.066, 0.0665, 0.0663, 0.0626, 0.0652, 0.0634, 0.0611, 0.0634, 0.0615, 0.06, 0.0612, 0.0574, 0.058, 0.057, 0.0555, 0.0566, 0.056, 0.0527, 0.0519, 0.0524, 0.0513, 0.0508, 0.0484, 0.0486, 0.0479, 0.0489, 0.0465, 0.0462, 0.0456, 0.0439, 0.0436, 0.0424, 0.0432, 0.0426, 0.0405, 0.0406, 0.0386, 0.0384, 0.0378, 0.0372, 0.0379, 0.0361, 0.0361, 0.0344, 0.035, 0.0335, 0.0325, 0.0317, 0.0314, 0.0302, 0.0312, 0.0314, 0.0298, 0.0292, 0.0267, 0.0271, 0.0273, 0.0259, 0.0259, 0.0255, 0.026, 0.0226, 0.0242, 0.0246, 0.0239, 0.0235, 0.0222, 0.0226, 0.021, 0.0212, 0.0208, 0.0207, 0.0197, 0.0187, 0.02, 0.0189, 0.0174, 0.018, 0.0177, 0.0175, 0.0173, 0.0172, 0.0172, 0.0163, 0.0155, 0.0161, 0.0165, 0.0158, 0.015, 0.0149, 0.0157, 0.0157, 0.0145, 0.0142, 0.0142, 0.0146, 0.0143, 0.0141, 0.0149, 0.0153, 0.0142, 0.0144]\n",
            "ori train acc:  [0.3089, 0.4865, 0.6218, 0.6844, 0.7232, 0.7539, 0.7745, 0.7919, 0.8012, 0.8088, 0.8215, 0.8269, 0.8294, 0.8362, 0.8405, 0.8437, 0.8493, 0.854, 0.8576, 0.8589, 0.861, 0.8645, 0.8664, 0.8692, 0.8705, 0.8728, 0.8743, 0.8724, 0.8747, 0.8775, 0.8767, 0.8782, 0.8792, 0.8832, 0.8843, 0.883, 0.8846, 0.8859, 0.886, 0.8887, 0.8903, 0.8889, 0.8925, 0.8931, 0.8915, 0.8937, 0.8962, 0.8958, 0.897, 0.8957, 0.8972, 0.899, 0.8976, 0.8999, 0.9016, 0.9018, 0.904, 0.901, 0.9038, 0.9049, 0.9051, 0.9042, 0.9054, 0.9042, 0.9037, 0.9091, 0.9118, 0.9095, 0.9096, 0.9104, 0.912, 0.9104, 0.9153, 0.9138, 0.9163, 0.9174, 0.9173, 0.9152, 0.9175, 0.9183, 0.9184, 0.9215, 0.9219, 0.9215, 0.9222, 0.9231, 0.9248, 0.9245, 0.9243, 0.9264, 0.927, 0.9277, 0.9297, 0.9304, 0.9294, 0.929, 0.9318, 0.9316, 0.934, 0.9335, 0.9337, 0.9374, 0.9348, 0.9366, 0.9389, 0.9366, 0.9385, 0.94, 0.9388, 0.9426, 0.942, 0.943, 0.9445, 0.9434, 0.944, 0.9473, 0.9481, 0.9476, 0.9487, 0.9492, 0.9516, 0.9514, 0.9521, 0.9511, 0.9535, 0.9538, 0.9544, 0.9561, 0.9564, 0.9576, 0.9568, 0.9574, 0.9595, 0.9594, 0.9614, 0.9616, 0.9622, 0.9628, 0.9621, 0.9639, 0.9639, 0.9656, 0.965, 0.9665, 0.9675, 0.9683, 0.9686, 0.9698, 0.9688, 0.9686, 0.9702, 0.9708, 0.9733, 0.9729, 0.9727, 0.9741, 0.9741, 0.9745, 0.974, 0.9774, 0.9758, 0.9754, 0.9761, 0.9765, 0.9778, 0.9774, 0.979, 0.9788, 0.9792, 0.9793, 0.9803, 0.9813, 0.98, 0.9811, 0.9826, 0.982, 0.9823, 0.9825, 0.9827, 0.9828, 0.9828, 0.9837, 0.9845, 0.9839, 0.9835, 0.9842, 0.985, 0.9851, 0.9843, 0.9843, 0.9855, 0.9858, 0.9858, 0.9854, 0.9857, 0.9859, 0.9851, 0.9847, 0.9858, 0.9856]\n",
            "time:  [52.8, 46.99, 47.72, 48.28, 48.5, 48.69, 48.76, 48.75, 48.82, 48.85, 48.74, 48.84, 48.76, 48.83, 48.85, 48.8, 48.86, 48.69, 48.78, 48.79, 48.84, 48.82, 48.79, 48.78, 48.94, 48.69, 48.78, 48.8, 48.9, 48.82, 48.76, 49.05, 48.73, 48.84, 48.82, 48.84, 48.93, 48.84, 48.64, 49.02, 48.77, 48.83, 48.81, 48.67, 48.83, 48.8, 48.95, 48.55, 48.75, 48.74, 48.71, 48.67, 48.77, 48.74, 48.84, 48.73, 48.56, 48.76, 48.75, 48.66, 48.61, 48.89, 48.6, 48.7, 48.75, 48.8, 48.69, 48.65, 48.81, 48.86, 48.7, 48.79, 48.74, 48.74, 48.7, 48.85, 48.71, 48.59, 48.63, 48.75, 48.67, 48.72, 48.79, 48.77, 48.74, 48.77, 48.71, 48.71, 48.79, 48.84, 48.81, 48.6, 48.76, 48.68, 48.94, 48.79, 48.75, 48.89, 48.97, 48.76, 48.82, 48.73, 48.74, 48.67, 48.74, 48.98, 48.47, 48.76, 48.58, 48.71, 48.91, 48.67, 48.93, 48.69, 48.64, 48.89, 48.74, 48.69, 48.79, 48.63, 48.83, 48.65, 48.72, 48.79, 48.64, 48.85, 48.86, 48.75, 48.92, 48.75, 48.75, 48.72, 48.8, 48.89, 48.78, 48.9, 48.62, 48.74, 48.63, 48.73, 48.76, 48.78, 48.77, 48.85, 48.58, 48.76, 48.81, 48.71, 48.99, 48.85, 48.88, 49.09, 48.62, 48.76, 48.66, 48.71, 48.79, 48.67, 48.93, 48.57, 48.74, 48.78, 48.65, 48.73, 48.76, 48.86, 48.71, 48.67, 48.75, 48.75, 48.67, 48.78, 48.77, 48.8, 48.68, 48.64, 48.69, 48.84, 48.71, 48.62, 48.71, 48.87, 48.6, 48.71, 48.84, 48.75, 48.74, 48.78, 48.83, 48.63, 48.73, 48.71, 48.7, 48.86, 48.78, 48.88, 48.7, 48.62, 48.69, 48.72]\n"
          ]
        }
      ],
      "source": [
        "!python /content/trains.py \\\n",
        "    --optimizer FESAM \\\n",
        "    --rho 0.1 \\\n",
        "    --T 0.1 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --arch VGG16_BN \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR10 \\\n",
        "    --epochs 200 \\\n",
        "    --batch-size 128\n"
      ]
    }
  ]
}