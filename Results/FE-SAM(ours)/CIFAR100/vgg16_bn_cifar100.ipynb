{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8oUys+Pwrp6D5d3kZUnHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Results/FE-SAM(ours)/CIFAR100/vgg16_bn_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/trains.py \\\n",
        "    --optimizer FESAM \\\n",
        "    --rho 0.1 \\\n",
        "    --T 0.1 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --arch VGG16_BN \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR100 \\\n",
        "    --epochs 200 \\\n",
        "    --batch-size 128\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJW1P3AJhYcD",
        "outputId": "9552b91b-9cd4-4dea-9f06-9d59ff276d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: VGG16_BN\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar100 dataset!\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "391\n",
            "50000\n",
            "optimizer: FESAM\n",
            "FESAM (\n",
            "Parameter Group 0\n",
            "    T: 0.1\n",
            "    adaptive: False\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 0.1\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "Epoch: [0][0/391]\tTime 4.064 (4.064)\tData 0.247 (0.247)\tLoss 4.6090 (4.6090)\tPrec@1 1.562 (1.562)\n",
            "Epoch: [0][100/391]\tTime 0.125 (0.164)\tData 0.002 (0.004)\tLoss 4.4084 (4.5210)\tPrec@1 3.125 (1.934)\n",
            "Epoch: [0][200/391]\tTime 0.124 (0.145)\tData 0.000 (0.002)\tLoss 4.2371 (4.4220)\tPrec@1 3.125 (2.697)\n",
            "Epoch: [0][300/391]\tTime 0.123 (0.139)\tData 0.000 (0.002)\tLoss 4.1248 (4.3449)\tPrec@1 5.469 (3.449)\n",
            "Epoch: [0][390/391]\tTime 2.102 (0.140)\tData 0.000 (0.002)\tLoss 4.0312 (4.2867)\tPrec@1 6.250 (4.104)\n",
            "Total time : 54.915\n",
            "Train Loss: 4.2867, Train Accuracy: 0.0410\n",
            "Test Loss : 4.0141, Test Accuracy : 0.0575 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.645 (0.645)\tData 0.480 (0.480)\tLoss 4.0083 (4.0083)\tPrec@1 8.594 (8.594)\n",
            "Epoch: [1][100/391]\tTime 0.123 (0.129)\tData 0.000 (0.006)\tLoss 4.0584 (4.0236)\tPrec@1 3.125 (6.312)\n",
            "Epoch: [1][200/391]\tTime 0.127 (0.126)\tData 0.001 (0.004)\tLoss 3.9281 (4.0010)\tPrec@1 9.375 (6.755)\n",
            "Epoch: [1][300/391]\tTime 0.142 (0.126)\tData 0.000 (0.003)\tLoss 4.0133 (3.9740)\tPrec@1 10.156 (7.221)\n",
            "Epoch: [1][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 3.8908 (3.9508)\tPrec@1 11.250 (7.662)\n",
            "Total time : 48.924\n",
            "Train Loss: 3.9508, Train Accuracy: 0.0766\n",
            "Test Loss : 3.7489, Test Accuracy : 0.0901 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.419 (0.419)\tData 0.275 (0.275)\tLoss 3.7309 (3.7309)\tPrec@1 10.938 (10.938)\n",
            "Epoch: [2][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 3.8834 (3.8296)\tPrec@1 7.031 (9.739)\n",
            "Epoch: [2][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.002)\tLoss 3.6712 (3.8016)\tPrec@1 14.062 (10.012)\n",
            "Epoch: [2][300/391]\tTime 0.125 (0.125)\tData 0.004 (0.002)\tLoss 3.9268 (3.7799)\tPrec@1 9.375 (10.372)\n",
            "Epoch: [2][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 3.8216 (3.7659)\tPrec@1 15.000 (10.586)\n",
            "Total time : 48.757\n",
            "Train Loss: 3.7659, Train Accuracy: 0.1059\n",
            "Test Loss : 3.5793, Test Accuracy : 0.1190 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.430 (0.430)\tData 0.270 (0.270)\tLoss 3.6682 (3.6682)\tPrec@1 9.375 (9.375)\n",
            "Epoch: [3][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 3.5979 (3.6393)\tPrec@1 10.938 (12.438)\n",
            "Epoch: [3][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 3.5508 (3.6126)\tPrec@1 12.500 (12.982)\n",
            "Epoch: [3][300/391]\tTime 0.124 (0.125)\tData 0.001 (0.002)\tLoss 3.5239 (3.5816)\tPrec@1 14.062 (13.486)\n",
            "Epoch: [3][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 3.6350 (3.5593)\tPrec@1 11.250 (13.762)\n",
            "Total time : 48.728\n",
            "Train Loss: 3.5593, Train Accuracy: 0.1376\n",
            "Test Loss : 3.5022, Test Accuracy : 0.1300 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.441 (0.441)\tData 0.270 (0.270)\tLoss 3.5296 (3.5296)\tPrec@1 17.188 (17.188)\n",
            "Epoch: [4][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 3.4402 (3.4173)\tPrec@1 17.188 (16.089)\n",
            "Epoch: [4][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 3.3258 (3.3906)\tPrec@1 17.969 (16.783)\n",
            "Epoch: [4][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 3.3523 (3.3728)\tPrec@1 18.750 (17.084)\n",
            "Epoch: [4][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 3.4974 (3.3526)\tPrec@1 16.250 (17.526)\n",
            "Total time : 48.709\n",
            "Train Loss: 3.3526, Train Accuracy: 0.1753\n",
            "Test Loss : 3.0762, Test Accuracy : 0.2000 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.394 (0.394)\tData 0.212 (0.212)\tLoss 3.2645 (3.2645)\tPrec@1 21.875 (21.875)\n",
            "Epoch: [5][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 3.3980 (3.2233)\tPrec@1 18.750 (19.910)\n",
            "Epoch: [5][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 3.1497 (3.2070)\tPrec@1 20.312 (20.421)\n",
            "Epoch: [5][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 3.2974 (3.1847)\tPrec@1 16.406 (20.852)\n",
            "Epoch: [5][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 2.8504 (3.1733)\tPrec@1 27.500 (21.082)\n",
            "Total time : 48.836\n",
            "Train Loss: 3.1733, Train Accuracy: 0.2108\n",
            "Test Loss : 2.9334, Test Accuracy : 0.2335 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.426 (0.426)\tData 0.271 (0.271)\tLoss 2.8906 (2.8906)\tPrec@1 27.344 (27.344)\n",
            "Epoch: [6][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 2.9428 (3.0302)\tPrec@1 27.344 (23.956)\n",
            "Epoch: [6][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.7758 (3.0247)\tPrec@1 22.656 (24.001)\n",
            "Epoch: [6][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 2.9526 (3.0162)\tPrec@1 24.219 (24.367)\n",
            "Epoch: [6][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.8696 (3.0099)\tPrec@1 25.000 (24.610)\n",
            "Total time : 48.804\n",
            "Train Loss: 3.0099, Train Accuracy: 0.2461\n",
            "Test Loss : 2.8328, Test Accuracy : 0.2493 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.439 (0.439)\tData 0.296 (0.296)\tLoss 2.9333 (2.9333)\tPrec@1 27.344 (27.344)\n",
            "Epoch: [7][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 3.0879 (2.9395)\tPrec@1 27.344 (26.021)\n",
            "Epoch: [7][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 2.8916 (2.9368)\tPrec@1 25.000 (26.205)\n",
            "Epoch: [7][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 2.9858 (2.9159)\tPrec@1 25.000 (26.729)\n",
            "Epoch: [7][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 3.0198 (2.9018)\tPrec@1 22.500 (27.206)\n",
            "Total time : 48.805\n",
            "Train Loss: 2.9018, Train Accuracy: 0.2721\n",
            "Test Loss : 2.8346, Test Accuracy : 0.2613 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.393 (0.393)\tData 0.219 (0.219)\tLoss 2.6492 (2.6492)\tPrec@1 36.719 (36.719)\n",
            "Epoch: [8][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 2.9372 (2.8386)\tPrec@1 32.031 (28.922)\n",
            "Epoch: [8][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 2.9086 (2.8249)\tPrec@1 24.219 (28.965)\n",
            "Epoch: [8][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 2.9047 (2.8104)\tPrec@1 27.344 (29.397)\n",
            "Epoch: [8][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 2.5180 (2.8061)\tPrec@1 42.500 (29.722)\n",
            "Total time : 48.783\n",
            "Train Loss: 2.8061, Train Accuracy: 0.2972\n",
            "Test Loss : 2.6530, Test Accuracy : 0.2931 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.433 (0.433)\tData 0.286 (0.286)\tLoss 2.7996 (2.7996)\tPrec@1 30.469 (30.469)\n",
            "Epoch: [9][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 2.5512 (2.7282)\tPrec@1 30.469 (31.938)\n",
            "Epoch: [9][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 2.9094 (2.7301)\tPrec@1 37.500 (31.969)\n",
            "Epoch: [9][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 2.7294 (2.7229)\tPrec@1 37.500 (32.254)\n",
            "Epoch: [9][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 2.4666 (2.7124)\tPrec@1 38.750 (32.542)\n",
            "Total time : 48.936\n",
            "Train Loss: 2.7124, Train Accuracy: 0.3254\n",
            "Test Loss : 2.6078, Test Accuracy : 0.3059 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.472 (0.472)\tData 0.286 (0.286)\tLoss 2.8071 (2.8071)\tPrec@1 31.250 (31.250)\n",
            "Epoch: [10][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 2.8923 (2.6528)\tPrec@1 32.812 (33.926)\n",
            "Epoch: [10][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 2.5366 (2.6347)\tPrec@1 36.719 (34.266)\n",
            "Epoch: [10][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.5613 (2.6302)\tPrec@1 38.281 (34.344)\n",
            "Epoch: [10][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.4781 (2.6226)\tPrec@1 33.750 (34.544)\n",
            "Total time : 49.002\n",
            "Train Loss: 2.6226, Train Accuracy: 0.3454\n",
            "Test Loss : 2.4168, Test Accuracy : 0.3523 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.461 (0.461)\tData 0.300 (0.300)\tLoss 2.5859 (2.5859)\tPrec@1 32.812 (32.812)\n",
            "Epoch: [11][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 2.3973 (2.5639)\tPrec@1 39.062 (35.659)\n",
            "Epoch: [11][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 2.9363 (2.5706)\tPrec@1 29.688 (35.957)\n",
            "Epoch: [11][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.4548 (2.5631)\tPrec@1 36.719 (36.119)\n",
            "Epoch: [11][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.6978 (2.5651)\tPrec@1 40.000 (36.026)\n",
            "Total time : 49.018\n",
            "Train Loss: 2.5651, Train Accuracy: 0.3603\n",
            "Test Loss : 2.3399, Test Accuracy : 0.3555 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.456 (0.456)\tData 0.300 (0.300)\tLoss 2.5916 (2.5916)\tPrec@1 39.062 (39.062)\n",
            "Epoch: [12][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 2.4602 (2.5236)\tPrec@1 36.719 (37.191)\n",
            "Epoch: [12][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 2.5509 (2.5082)\tPrec@1 39.062 (37.582)\n",
            "Epoch: [12][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.4690 (2.5077)\tPrec@1 32.812 (37.661)\n",
            "Epoch: [12][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.5621 (2.5063)\tPrec@1 36.250 (37.758)\n",
            "Total time : 49.065\n",
            "Train Loss: 2.5063, Train Accuracy: 0.3776\n",
            "Test Loss : 2.4164, Test Accuracy : 0.3545 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.521 (0.521)\tData 0.367 (0.367)\tLoss 2.6303 (2.6303)\tPrec@1 32.812 (32.812)\n",
            "Epoch: [13][100/391]\tTime 0.124 (0.129)\tData 0.000 (0.005)\tLoss 2.3368 (2.4469)\tPrec@1 50.000 (39.488)\n",
            "Epoch: [13][200/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 2.2054 (2.4461)\tPrec@1 48.438 (39.785)\n",
            "Epoch: [13][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 2.3531 (2.4490)\tPrec@1 42.969 (39.509)\n",
            "Epoch: [13][390/391]\tTime 0.090 (0.126)\tData 0.000 (0.002)\tLoss 2.5891 (2.4507)\tPrec@1 43.750 (39.434)\n",
            "Total time : 49.180\n",
            "Train Loss: 2.4507, Train Accuracy: 0.3943\n",
            "Test Loss : 2.3598, Test Accuracy : 0.3620 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.432 (0.432)\tData 0.259 (0.259)\tLoss 2.2423 (2.2423)\tPrec@1 42.969 (42.969)\n",
            "Epoch: [14][100/391]\tTime 0.122 (0.128)\tData 0.001 (0.004)\tLoss 2.4073 (2.4235)\tPrec@1 40.625 (40.463)\n",
            "Epoch: [14][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 2.5496 (2.4170)\tPrec@1 44.531 (40.415)\n",
            "Epoch: [14][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 2.3599 (2.4195)\tPrec@1 35.938 (40.225)\n",
            "Epoch: [14][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.2654 (2.4181)\tPrec@1 41.250 (40.344)\n",
            "Total time : 48.987\n",
            "Train Loss: 2.4181, Train Accuracy: 0.4034\n",
            "Test Loss : 2.3189, Test Accuracy : 0.3821 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.400 (0.400)\tData 0.225 (0.225)\tLoss 2.3683 (2.3683)\tPrec@1 42.969 (42.969)\n",
            "Epoch: [15][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 2.3756 (2.3840)\tPrec@1 42.969 (41.252)\n",
            "Epoch: [15][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.3779 (2.3828)\tPrec@1 43.750 (41.465)\n",
            "Epoch: [15][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 2.4584 (2.3858)\tPrec@1 39.844 (41.635)\n",
            "Epoch: [15][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 2.1246 (2.3792)\tPrec@1 51.250 (41.734)\n",
            "Total time : 48.868\n",
            "Train Loss: 2.3792, Train Accuracy: 0.4173\n",
            "Test Loss : 2.1761, Test Accuracy : 0.4033 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.444 (0.444)\tData 0.300 (0.300)\tLoss 2.4188 (2.4188)\tPrec@1 39.844 (39.844)\n",
            "Epoch: [16][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 2.3685 (2.3264)\tPrec@1 47.656 (43.185)\n",
            "Epoch: [16][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 2.2519 (2.3416)\tPrec@1 41.406 (42.355)\n",
            "Epoch: [16][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 2.2806 (2.3430)\tPrec@1 44.531 (42.424)\n",
            "Epoch: [16][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 2.2856 (2.3400)\tPrec@1 43.750 (42.588)\n",
            "Total time : 48.828\n",
            "Train Loss: 2.3400, Train Accuracy: 0.4259\n",
            "Test Loss : 2.4297, Test Accuracy : 0.3726 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.429 (0.429)\tData 0.286 (0.286)\tLoss 2.4722 (2.4722)\tPrec@1 33.594 (33.594)\n",
            "Epoch: [17][100/391]\tTime 0.126 (0.128)\tData 0.000 (0.004)\tLoss 2.4766 (2.2924)\tPrec@1 42.188 (43.735)\n",
            "Epoch: [17][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 2.2904 (2.2936)\tPrec@1 45.312 (43.781)\n",
            "Epoch: [17][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.4191 (2.3009)\tPrec@1 42.969 (43.509)\n",
            "Epoch: [17][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.0369 (2.2996)\tPrec@1 52.500 (43.828)\n",
            "Total time : 49.019\n",
            "Train Loss: 2.2996, Train Accuracy: 0.4383\n",
            "Test Loss : 2.1668, Test Accuracy : 0.4186 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.452 (0.452)\tData 0.292 (0.292)\tLoss 2.4349 (2.4349)\tPrec@1 42.188 (42.188)\n",
            "Epoch: [18][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 2.5867 (2.2696)\tPrec@1 35.938 (44.647)\n",
            "Epoch: [18][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.2580 (2.2663)\tPrec@1 48.438 (44.675)\n",
            "Epoch: [18][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 2.2797 (2.2719)\tPrec@1 42.969 (44.775)\n",
            "Epoch: [18][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 2.0148 (2.2726)\tPrec@1 48.750 (44.842)\n",
            "Total time : 48.981\n",
            "Train Loss: 2.2726, Train Accuracy: 0.4484\n",
            "Test Loss : 2.4266, Test Accuracy : 0.3819 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.467 (0.467)\tData 0.293 (0.293)\tLoss 2.4626 (2.4626)\tPrec@1 38.281 (38.281)\n",
            "Epoch: [19][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.005)\tLoss 2.1127 (2.2489)\tPrec@1 50.000 (45.777)\n",
            "Epoch: [19][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.1381 (2.2486)\tPrec@1 52.344 (45.802)\n",
            "Epoch: [19][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.1851 (2.2468)\tPrec@1 51.562 (45.826)\n",
            "Epoch: [19][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 1.9300 (2.2398)\tPrec@1 58.750 (46.006)\n",
            "Total time : 48.966\n",
            "Train Loss: 2.2398, Train Accuracy: 0.4601\n",
            "Test Loss : 2.1315, Test Accuracy : 0.4329 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.631 (0.631)\tData 0.448 (0.448)\tLoss 2.1043 (2.1043)\tPrec@1 47.656 (47.656)\n",
            "Epoch: [20][100/391]\tTime 0.138 (0.130)\tData 0.009 (0.006)\tLoss 2.2907 (2.2366)\tPrec@1 42.969 (46.465)\n",
            "Epoch: [20][200/391]\tTime 0.127 (0.127)\tData 0.000 (0.003)\tLoss 2.2507 (2.2362)\tPrec@1 49.219 (46.583)\n",
            "Epoch: [20][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.4102 (2.2293)\tPrec@1 45.312 (46.610)\n",
            "Epoch: [20][390/391]\tTime 0.090 (0.126)\tData 0.000 (0.002)\tLoss 2.1552 (2.2274)\tPrec@1 43.750 (46.624)\n",
            "Total time : 49.172\n",
            "Train Loss: 2.2274, Train Accuracy: 0.4662\n",
            "Test Loss : 2.0383, Test Accuracy : 0.4426 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.532 (0.532)\tData 0.322 (0.322)\tLoss 2.0926 (2.0926)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [21][100/391]\tTime 0.151 (0.130)\tData 0.007 (0.005)\tLoss 2.3147 (2.2000)\tPrec@1 38.281 (47.780)\n",
            "Epoch: [21][200/391]\tTime 0.131 (0.127)\tData 0.007 (0.003)\tLoss 2.1546 (2.1943)\tPrec@1 46.094 (47.260)\n",
            "Epoch: [21][300/391]\tTime 0.128 (0.126)\tData 0.000 (0.002)\tLoss 2.2656 (2.2005)\tPrec@1 46.875 (47.176)\n",
            "Epoch: [21][390/391]\tTime 0.094 (0.126)\tData 0.000 (0.002)\tLoss 2.4258 (2.1977)\tPrec@1 45.000 (47.246)\n",
            "Total time : 49.114\n",
            "Train Loss: 2.1977, Train Accuracy: 0.4725\n",
            "Test Loss : 2.0526, Test Accuracy : 0.4458 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.450 (0.450)\tData 0.276 (0.276)\tLoss 2.1866 (2.1866)\tPrec@1 46.875 (46.875)\n",
            "Epoch: [22][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 2.0673 (2.1561)\tPrec@1 52.344 (48.167)\n",
            "Epoch: [22][200/391]\tTime 0.124 (0.126)\tData 0.006 (0.003)\tLoss 2.0612 (2.1626)\tPrec@1 43.750 (47.800)\n",
            "Epoch: [22][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 2.2149 (2.1645)\tPrec@1 52.344 (47.973)\n",
            "Epoch: [22][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.1390 (2.1650)\tPrec@1 43.750 (48.092)\n",
            "Total time : 48.787\n",
            "Train Loss: 2.1650, Train Accuracy: 0.4809\n",
            "Test Loss : 2.0964, Test Accuracy : 0.4420 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.498 (0.498)\tData 0.329 (0.329)\tLoss 2.1519 (2.1519)\tPrec@1 50.000 (50.000)\n",
            "Epoch: [23][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 2.0446 (2.1427)\tPrec@1 56.250 (49.002)\n",
            "Epoch: [23][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 2.4117 (2.1513)\tPrec@1 40.625 (48.861)\n",
            "Epoch: [23][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 2.0520 (2.1472)\tPrec@1 46.875 (48.806)\n",
            "Epoch: [23][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.0003 (2.1452)\tPrec@1 55.000 (48.902)\n",
            "Total time : 48.873\n",
            "Train Loss: 2.1452, Train Accuracy: 0.4890\n",
            "Test Loss : 1.9617, Test Accuracy : 0.4701 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.372 (0.372)\tData 0.208 (0.208)\tLoss 1.8289 (1.8289)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [24][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 2.2882 (2.1281)\tPrec@1 42.969 (49.358)\n",
            "Epoch: [24][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.0104 (2.1217)\tPrec@1 52.344 (49.596)\n",
            "Epoch: [24][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8395 (2.1239)\tPrec@1 60.938 (49.593)\n",
            "Epoch: [24][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.5821 (2.1198)\tPrec@1 40.000 (49.722)\n",
            "Total time : 48.868\n",
            "Train Loss: 2.1198, Train Accuracy: 0.4972\n",
            "Test Loss : 1.9466, Test Accuracy : 0.4744 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.438 (0.438)\tData 0.271 (0.271)\tLoss 1.8285 (1.8285)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [25][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 2.2457 (2.0916)\tPrec@1 53.125 (50.147)\n",
            "Epoch: [25][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.1516 (2.0985)\tPrec@1 55.469 (50.334)\n",
            "Epoch: [25][300/391]\tTime 0.123 (0.126)\tData 0.001 (0.002)\tLoss 1.9931 (2.1066)\tPrec@1 54.688 (50.161)\n",
            "Epoch: [25][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 2.1217 (2.1078)\tPrec@1 50.000 (50.186)\n",
            "Total time : 49.042\n",
            "Train Loss: 2.1078, Train Accuracy: 0.5019\n",
            "Test Loss : 1.8698, Test Accuracy : 0.4862 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.460 (0.460)\tData 0.281 (0.281)\tLoss 2.1624 (2.1624)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [26][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 2.2612 (2.0310)\tPrec@1 47.656 (51.485)\n",
            "Epoch: [26][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.1656 (2.0566)\tPrec@1 50.781 (51.197)\n",
            "Epoch: [26][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.0097 (2.0697)\tPrec@1 46.094 (50.963)\n",
            "Epoch: [26][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.0065 (2.0796)\tPrec@1 57.500 (50.834)\n",
            "Total time : 49.037\n",
            "Train Loss: 2.0796, Train Accuracy: 0.5083\n",
            "Test Loss : 1.9032, Test Accuracy : 0.4914 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.455 (0.455)\tData 0.274 (0.274)\tLoss 2.0886 (2.0886)\tPrec@1 44.531 (44.531)\n",
            "Epoch: [27][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.8937 (2.0170)\tPrec@1 54.688 (52.452)\n",
            "Epoch: [27][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 1.9297 (2.0393)\tPrec@1 53.125 (51.881)\n",
            "Epoch: [27][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 1.9613 (2.0537)\tPrec@1 47.656 (51.659)\n",
            "Epoch: [27][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9388 (2.0592)\tPrec@1 47.500 (51.574)\n",
            "Total time : 49.040\n",
            "Train Loss: 2.0592, Train Accuracy: 0.5157\n",
            "Test Loss : 1.8562, Test Accuracy : 0.5018 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.468 (0.468)\tData 0.289 (0.289)\tLoss 2.0721 (2.0721)\tPrec@1 48.438 (48.438)\n",
            "Epoch: [28][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.9018 (2.0257)\tPrec@1 57.031 (52.367)\n",
            "Epoch: [28][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.0543 (2.0270)\tPrec@1 51.562 (52.383)\n",
            "Epoch: [28][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 2.0385 (2.0335)\tPrec@1 52.344 (52.211)\n",
            "Epoch: [28][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.1002 (2.0405)\tPrec@1 57.500 (52.144)\n",
            "Total time : 49.056\n",
            "Train Loss: 2.0405, Train Accuracy: 0.5214\n",
            "Test Loss : 1.9211, Test Accuracy : 0.4847 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.437 (0.437)\tData 0.261 (0.261)\tLoss 1.9024 (1.9024)\tPrec@1 54.688 (54.688)\n",
            "Epoch: [29][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.9137 (2.0240)\tPrec@1 53.125 (52.955)\n",
            "Epoch: [29][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.0772 (2.0239)\tPrec@1 51.562 (52.973)\n",
            "Epoch: [29][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 2.0218 (2.0212)\tPrec@1 54.688 (52.987)\n",
            "Epoch: [29][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9757 (2.0312)\tPrec@1 60.000 (52.780)\n",
            "Total time : 48.916\n",
            "Train Loss: 2.0312, Train Accuracy: 0.5278\n",
            "Test Loss : 1.8616, Test Accuracy : 0.5039 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.482 (0.482)\tData 0.301 (0.301)\tLoss 2.0296 (2.0296)\tPrec@1 51.562 (51.562)\n",
            "Epoch: [30][100/391]\tTime 0.121 (0.129)\tData 0.000 (0.004)\tLoss 2.0086 (1.9922)\tPrec@1 52.344 (53.589)\n",
            "Epoch: [30][200/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 1.9860 (2.0128)\tPrec@1 54.688 (52.868)\n",
            "Epoch: [30][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 2.0750 (2.0221)\tPrec@1 46.875 (52.736)\n",
            "Epoch: [30][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 2.4334 (2.0170)\tPrec@1 48.750 (52.852)\n",
            "Total time : 48.972\n",
            "Train Loss: 2.0170, Train Accuracy: 0.5285\n",
            "Test Loss : 1.8478, Test Accuracy : 0.5018 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.441 (0.441)\tData 0.271 (0.271)\tLoss 1.9993 (1.9993)\tPrec@1 51.562 (51.562)\n",
            "Epoch: [31][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 1.8059 (1.9794)\tPrec@1 57.031 (53.434)\n",
            "Epoch: [31][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.9030 (1.9808)\tPrec@1 58.594 (53.591)\n",
            "Epoch: [31][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8895 (1.9879)\tPrec@1 56.250 (53.597)\n",
            "Epoch: [31][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9497 (1.9901)\tPrec@1 60.000 (53.624)\n",
            "Total time : 48.856\n",
            "Train Loss: 1.9901, Train Accuracy: 0.5362\n",
            "Test Loss : 1.8978, Test Accuracy : 0.4852 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.465 (0.465)\tData 0.336 (0.336)\tLoss 1.7450 (1.7450)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [32][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 1.9540 (1.9552)\tPrec@1 57.031 (54.703)\n",
            "Epoch: [32][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.8627 (1.9612)\tPrec@1 53.906 (54.388)\n",
            "Epoch: [32][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8724 (1.9712)\tPrec@1 60.938 (54.288)\n",
            "Epoch: [32][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.8646 (1.9757)\tPrec@1 61.250 (54.184)\n",
            "Total time : 48.968\n",
            "Train Loss: 1.9757, Train Accuracy: 0.5418\n",
            "Test Loss : 1.8738, Test Accuracy : 0.4915 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.465 (0.465)\tData 0.303 (0.303)\tLoss 1.8481 (1.8481)\tPrec@1 56.250 (56.250)\n",
            "Epoch: [33][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.9724 (1.9534)\tPrec@1 55.469 (54.347)\n",
            "Epoch: [33][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.9136 (1.9575)\tPrec@1 54.688 (54.684)\n",
            "Epoch: [33][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.9505 (1.9641)\tPrec@1 51.562 (54.576)\n",
            "Epoch: [33][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.0505 (1.9666)\tPrec@1 52.500 (54.498)\n",
            "Total time : 48.921\n",
            "Train Loss: 1.9666, Train Accuracy: 0.5450\n",
            "Test Loss : 1.8870, Test Accuracy : 0.4901 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.491 (0.491)\tData 0.343 (0.343)\tLoss 2.0485 (2.0485)\tPrec@1 55.469 (55.469)\n",
            "Epoch: [34][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.005)\tLoss 1.8982 (1.9079)\tPrec@1 52.344 (56.204)\n",
            "Epoch: [34][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 2.0117 (1.9374)\tPrec@1 52.344 (55.698)\n",
            "Epoch: [34][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8521 (1.9431)\tPrec@1 54.688 (55.274)\n",
            "Epoch: [34][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 2.0632 (1.9529)\tPrec@1 60.000 (54.890)\n",
            "Total time : 48.936\n",
            "Train Loss: 1.9529, Train Accuracy: 0.5489\n",
            "Test Loss : 1.7986, Test Accuracy : 0.5096 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.451 (0.451)\tData 0.272 (0.272)\tLoss 1.9612 (1.9612)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [35][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 2.1623 (1.8986)\tPrec@1 52.344 (55.825)\n",
            "Epoch: [35][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.9671 (1.9058)\tPrec@1 60.156 (55.772)\n",
            "Epoch: [35][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.7465 (1.9183)\tPrec@1 52.344 (55.391)\n",
            "Epoch: [35][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9747 (1.9283)\tPrec@1 57.500 (55.316)\n",
            "Total time : 48.997\n",
            "Train Loss: 1.9283, Train Accuracy: 0.5532\n",
            "Test Loss : 1.8171, Test Accuracy : 0.5094 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.459 (0.459)\tData 0.275 (0.275)\tLoss 1.9343 (1.9343)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [36][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 2.0761 (1.9167)\tPrec@1 57.031 (55.724)\n",
            "Epoch: [36][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.9621 (1.9263)\tPrec@1 57.031 (55.550)\n",
            "Epoch: [36][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.7844 (1.9237)\tPrec@1 63.281 (55.617)\n",
            "Epoch: [36][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 2.0380 (1.9284)\tPrec@1 55.000 (55.664)\n",
            "Total time : 49.031\n",
            "Train Loss: 1.9284, Train Accuracy: 0.5566\n",
            "Test Loss : 1.8816, Test Accuracy : 0.5008 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.461 (0.461)\tData 0.278 (0.278)\tLoss 2.0235 (2.0235)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [37][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.7845 (1.9220)\tPrec@1 60.938 (55.987)\n",
            "Epoch: [37][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 1.9378 (1.9236)\tPrec@1 57.031 (55.690)\n",
            "Epoch: [37][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.8165 (1.9171)\tPrec@1 60.156 (55.811)\n",
            "Epoch: [37][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.0190 (1.9122)\tPrec@1 53.750 (56.064)\n",
            "Total time : 48.982\n",
            "Train Loss: 1.9122, Train Accuracy: 0.5606\n",
            "Test Loss : 1.8591, Test Accuracy : 0.5084 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.546 (0.546)\tData 0.370 (0.370)\tLoss 2.1265 (2.1265)\tPrec@1 46.875 (46.875)\n",
            "Epoch: [38][100/391]\tTime 0.122 (0.129)\tData 0.000 (0.005)\tLoss 1.9468 (1.8780)\tPrec@1 57.812 (57.116)\n",
            "Epoch: [38][200/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 1.8161 (1.8714)\tPrec@1 63.281 (57.148)\n",
            "Epoch: [38][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.8892 (1.8873)\tPrec@1 59.375 (56.907)\n",
            "Epoch: [38][390/391]\tTime 0.089 (0.126)\tData 0.000 (0.002)\tLoss 1.7115 (1.8948)\tPrec@1 63.750 (56.856)\n",
            "Total time : 49.111\n",
            "Train Loss: 1.8948, Train Accuracy: 0.5686\n",
            "Test Loss : 1.7071, Test Accuracy : 0.5372 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.674 (0.674)\tData 0.479 (0.479)\tLoss 1.8013 (1.8013)\tPrec@1 53.906 (53.906)\n",
            "Epoch: [39][100/391]\tTime 0.132 (0.131)\tData 0.013 (0.006)\tLoss 1.7073 (1.8648)\tPrec@1 63.281 (56.730)\n",
            "Epoch: [39][200/391]\tTime 0.130 (0.127)\tData 0.000 (0.004)\tLoss 1.8174 (1.8793)\tPrec@1 60.938 (56.666)\n",
            "Epoch: [39][300/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 1.5725 (1.8909)\tPrec@1 67.969 (56.504)\n",
            "Epoch: [39][390/391]\tTime 0.091 (0.126)\tData 0.000 (0.003)\tLoss 1.9227 (1.8951)\tPrec@1 56.250 (56.468)\n",
            "Total time : 49.104\n",
            "Train Loss: 1.8951, Train Accuracy: 0.5647\n",
            "Test Loss : 1.7913, Test Accuracy : 0.5226 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.676 (0.676)\tData 0.456 (0.456)\tLoss 1.8589 (1.8589)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [40][100/391]\tTime 0.129 (0.130)\tData 0.000 (0.006)\tLoss 2.0225 (1.8516)\tPrec@1 52.344 (57.109)\n",
            "Epoch: [40][200/391]\tTime 0.134 (0.127)\tData 0.011 (0.004)\tLoss 1.6354 (1.8578)\tPrec@1 66.406 (57.191)\n",
            "Epoch: [40][300/391]\tTime 0.135 (0.126)\tData 0.008 (0.003)\tLoss 2.0743 (1.8747)\tPrec@1 51.562 (56.899)\n",
            "Epoch: [40][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.8692 (1.8834)\tPrec@1 61.250 (56.752)\n",
            "Total time : 48.906\n",
            "Train Loss: 1.8834, Train Accuracy: 0.5675\n",
            "Test Loss : 1.8658, Test Accuracy : 0.5059 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.452 (0.452)\tData 0.271 (0.271)\tLoss 1.8773 (1.8773)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [41][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.7015 (1.8435)\tPrec@1 61.719 (57.379)\n",
            "Epoch: [41][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.8897 (1.8540)\tPrec@1 56.250 (57.455)\n",
            "Epoch: [41][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 2.0150 (1.8718)\tPrec@1 50.000 (57.127)\n",
            "Epoch: [41][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 2.0521 (1.8704)\tPrec@1 45.000 (57.164)\n",
            "Total time : 48.673\n",
            "Train Loss: 1.8704, Train Accuracy: 0.5716\n",
            "Test Loss : 1.7692, Test Accuracy : 0.5255 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.454 (0.454)\tData 0.283 (0.283)\tLoss 2.0456 (2.0456)\tPrec@1 51.562 (51.562)\n",
            "Epoch: [42][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 2.0112 (1.8561)\tPrec@1 52.344 (57.882)\n",
            "Epoch: [42][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.7997 (1.8484)\tPrec@1 62.500 (58.201)\n",
            "Epoch: [42][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.9592 (1.8582)\tPrec@1 50.781 (57.929)\n",
            "Epoch: [42][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9461 (1.8644)\tPrec@1 57.500 (57.654)\n",
            "Total time : 48.756\n",
            "Train Loss: 1.8644, Train Accuracy: 0.5765\n",
            "Test Loss : 1.7029, Test Accuracy : 0.5481 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.426 (0.426)\tData 0.266 (0.266)\tLoss 1.6895 (1.6895)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [43][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.8365 (1.8348)\tPrec@1 58.594 (58.439)\n",
            "Epoch: [43][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.003)\tLoss 1.7396 (1.8522)\tPrec@1 64.062 (57.952)\n",
            "Epoch: [43][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.9655 (1.8486)\tPrec@1 53.125 (57.986)\n",
            "Epoch: [43][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.9847 (1.8541)\tPrec@1 60.000 (57.838)\n",
            "Total time : 48.901\n",
            "Train Loss: 1.8541, Train Accuracy: 0.5784\n",
            "Test Loss : 1.7199, Test Accuracy : 0.5350 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.462 (0.462)\tData 0.276 (0.276)\tLoss 1.6575 (1.6575)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [44][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 2.0108 (1.7804)\tPrec@1 53.906 (59.793)\n",
            "Epoch: [44][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 2.1188 (1.8238)\tPrec@1 52.344 (59.087)\n",
            "Epoch: [44][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.6431 (1.8217)\tPrec@1 65.625 (58.905)\n",
            "Epoch: [44][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.8333 (1.8340)\tPrec@1 62.500 (58.478)\n",
            "Total time : 48.852\n",
            "Train Loss: 1.8340, Train Accuracy: 0.5848\n",
            "Test Loss : 1.6819, Test Accuracy : 0.5382 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.471 (0.471)\tData 0.323 (0.323)\tLoss 1.6853 (1.6853)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [45][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.8744 (1.8152)\tPrec@1 55.469 (59.305)\n",
            "Epoch: [45][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 1.8328 (1.8179)\tPrec@1 57.812 (58.936)\n",
            "Epoch: [45][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4763 (1.8315)\tPrec@1 63.281 (58.524)\n",
            "Epoch: [45][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9413 (1.8390)\tPrec@1 66.250 (58.468)\n",
            "Total time : 48.930\n",
            "Train Loss: 1.8390, Train Accuracy: 0.5847\n",
            "Test Loss : 1.7328, Test Accuracy : 0.5332 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.461 (0.461)\tData 0.312 (0.312)\tLoss 1.6001 (1.6001)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [46][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.4796 (1.7586)\tPrec@1 69.531 (59.831)\n",
            "Epoch: [46][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 1.5518 (1.7795)\tPrec@1 65.625 (59.569)\n",
            "Epoch: [46][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 2.0799 (1.8031)\tPrec@1 57.031 (59.183)\n",
            "Epoch: [46][390/391]\tTime 0.091 (0.126)\tData 0.000 (0.002)\tLoss 1.3257 (1.8182)\tPrec@1 73.750 (58.826)\n",
            "Total time : 49.086\n",
            "Train Loss: 1.8182, Train Accuracy: 0.5883\n",
            "Test Loss : 1.7400, Test Accuracy : 0.5318 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.482 (0.482)\tData 0.314 (0.314)\tLoss 1.7814 (1.7814)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [47][100/391]\tTime 0.121 (0.129)\tData 0.000 (0.004)\tLoss 1.9071 (1.7563)\tPrec@1 57.031 (60.628)\n",
            "Epoch: [47][200/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 1.8411 (1.7870)\tPrec@1 61.719 (59.946)\n",
            "Epoch: [47][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.9091 (1.8048)\tPrec@1 56.250 (59.417)\n",
            "Epoch: [47][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.7665 (1.8143)\tPrec@1 73.750 (59.316)\n",
            "Total time : 49.030\n",
            "Train Loss: 1.8143, Train Accuracy: 0.5932\n",
            "Test Loss : 1.7129, Test Accuracy : 0.5325 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.424 (0.424)\tData 0.263 (0.263)\tLoss 1.7041 (1.7041)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [48][100/391]\tTime 0.120 (0.128)\tData 0.000 (0.004)\tLoss 1.9481 (1.7575)\tPrec@1 53.906 (60.450)\n",
            "Epoch: [48][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.9172 (1.7773)\tPrec@1 54.688 (60.168)\n",
            "Epoch: [48][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.6869 (1.7889)\tPrec@1 64.062 (59.850)\n",
            "Epoch: [48][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9500 (1.8014)\tPrec@1 67.500 (59.550)\n",
            "Total time : 48.810\n",
            "Train Loss: 1.8014, Train Accuracy: 0.5955\n",
            "Test Loss : 1.6579, Test Accuracy : 0.5522 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.461 (0.461)\tData 0.299 (0.299)\tLoss 1.7555 (1.7555)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [49][100/391]\tTime 0.120 (0.127)\tData 0.000 (0.005)\tLoss 1.7022 (1.7440)\tPrec@1 60.938 (60.914)\n",
            "Epoch: [49][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 2.0074 (1.7679)\tPrec@1 60.156 (60.421)\n",
            "Epoch: [49][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.8259 (1.7815)\tPrec@1 57.812 (59.930)\n",
            "Epoch: [49][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 1.6983 (1.7869)\tPrec@1 63.750 (59.764)\n",
            "Total time : 48.840\n",
            "Train Loss: 1.7869, Train Accuracy: 0.5976\n",
            "Test Loss : 1.6389, Test Accuracy : 0.5556 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.429 (0.429)\tData 0.280 (0.280)\tLoss 1.7589 (1.7589)\tPrec@1 53.125 (53.125)\n",
            "Epoch: [50][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 1.7245 (1.7663)\tPrec@1 57.812 (60.381)\n",
            "Epoch: [50][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 1.6801 (1.7595)\tPrec@1 66.406 (60.607)\n",
            "Epoch: [50][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8482 (1.7748)\tPrec@1 61.719 (60.281)\n",
            "Epoch: [50][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.7350 (1.7854)\tPrec@1 62.500 (59.918)\n",
            "Total time : 48.708\n",
            "Train Loss: 1.7854, Train Accuracy: 0.5992\n",
            "Test Loss : 1.6899, Test Accuracy : 0.5483 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.438 (0.438)\tData 0.310 (0.310)\tLoss 1.6600 (1.6600)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [51][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 1.8925 (1.7052)\tPrec@1 57.812 (61.804)\n",
            "Epoch: [51][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 1.8575 (1.7394)\tPrec@1 56.250 (60.856)\n",
            "Epoch: [51][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.6888 (1.7546)\tPrec@1 62.500 (60.416)\n",
            "Epoch: [51][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.8795 (1.7637)\tPrec@1 57.500 (60.410)\n",
            "Total time : 48.818\n",
            "Train Loss: 1.7637, Train Accuracy: 0.6041\n",
            "Test Loss : 1.7435, Test Accuracy : 0.5447 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.493 (0.493)\tData 0.348 (0.348)\tLoss 1.7198 (1.7198)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [52][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 1.6356 (1.7278)\tPrec@1 63.281 (61.247)\n",
            "Epoch: [52][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.7163 (1.7462)\tPrec@1 56.250 (60.813)\n",
            "Epoch: [52][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.8383 (1.7517)\tPrec@1 62.500 (60.714)\n",
            "Epoch: [52][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 2.0131 (1.7523)\tPrec@1 66.250 (60.722)\n",
            "Total time : 49.025\n",
            "Train Loss: 1.7523, Train Accuracy: 0.6072\n",
            "Test Loss : 1.7029, Test Accuracy : 0.5513 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.481 (0.481)\tData 0.309 (0.309)\tLoss 1.7475 (1.7475)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [53][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.8250 (1.7273)\tPrec@1 60.938 (61.456)\n",
            "Epoch: [53][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.6962 (1.7256)\tPrec@1 60.156 (61.198)\n",
            "Epoch: [53][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.8847 (1.7395)\tPrec@1 65.625 (60.979)\n",
            "Epoch: [53][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.7844 (1.7498)\tPrec@1 61.250 (60.766)\n",
            "Total time : 48.868\n",
            "Train Loss: 1.7498, Train Accuracy: 0.6077\n",
            "Test Loss : 1.6162, Test Accuracy : 0.5614 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.441 (0.441)\tData 0.271 (0.271)\tLoss 1.3968 (1.3968)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [54][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.7082 (1.7118)\tPrec@1 57.812 (61.781)\n",
            "Epoch: [54][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.4968 (1.7194)\tPrec@1 63.281 (61.419)\n",
            "Epoch: [54][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8134 (1.7300)\tPrec@1 64.062 (61.509)\n",
            "Epoch: [54][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.8903 (1.7429)\tPrec@1 67.500 (61.116)\n",
            "Total time : 48.793\n",
            "Train Loss: 1.7429, Train Accuracy: 0.6112\n",
            "Test Loss : 1.6115, Test Accuracy : 0.5723 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.418 (0.418)\tData 0.266 (0.266)\tLoss 1.7053 (1.7053)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [55][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.5390 (1.6941)\tPrec@1 68.750 (62.283)\n",
            "Epoch: [55][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.6972 (1.7136)\tPrec@1 60.938 (61.956)\n",
            "Epoch: [55][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 2.0232 (1.7263)\tPrec@1 47.656 (61.431)\n",
            "Epoch: [55][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 1.8566 (1.7285)\tPrec@1 67.500 (61.342)\n",
            "Total time : 48.965\n",
            "Train Loss: 1.7285, Train Accuracy: 0.6134\n",
            "Test Loss : 1.6306, Test Accuracy : 0.5626 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.618 (0.618)\tData 0.446 (0.446)\tLoss 1.6625 (1.6625)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [56][100/391]\tTime 0.127 (0.129)\tData 0.007 (0.005)\tLoss 1.8697 (1.6989)\tPrec@1 61.719 (62.523)\n",
            "Epoch: [56][200/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 1.8394 (1.7266)\tPrec@1 57.031 (61.866)\n",
            "Epoch: [56][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.5442 (1.7255)\tPrec@1 66.406 (61.558)\n",
            "Epoch: [56][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.7429 (1.7269)\tPrec@1 71.250 (61.490)\n",
            "Total time : 49.027\n",
            "Train Loss: 1.7269, Train Accuracy: 0.6149\n",
            "Test Loss : 1.7408, Test Accuracy : 0.5373 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.708 (0.708)\tData 0.535 (0.535)\tLoss 1.6994 (1.6994)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [57][100/391]\tTime 0.130 (0.130)\tData 0.008 (0.006)\tLoss 1.7723 (1.6898)\tPrec@1 60.938 (62.237)\n",
            "Epoch: [57][200/391]\tTime 0.123 (0.127)\tData 0.002 (0.004)\tLoss 1.7170 (1.7037)\tPrec@1 56.250 (61.793)\n",
            "Epoch: [57][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.7783 (1.7051)\tPrec@1 60.938 (61.734)\n",
            "Epoch: [57][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.003)\tLoss 1.4898 (1.7069)\tPrec@1 65.000 (61.746)\n",
            "Total time : 49.023\n",
            "Train Loss: 1.7069, Train Accuracy: 0.6175\n",
            "Test Loss : 1.7511, Test Accuracy : 0.5422 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.611 (0.611)\tData 0.411 (0.411)\tLoss 1.6557 (1.6557)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [58][100/391]\tTime 0.124 (0.129)\tData 0.000 (0.005)\tLoss 1.7642 (1.6614)\tPrec@1 58.594 (63.405)\n",
            "Epoch: [58][200/391]\tTime 0.129 (0.126)\tData 0.000 (0.003)\tLoss 1.7833 (1.6871)\tPrec@1 57.812 (62.722)\n",
            "Epoch: [58][300/391]\tTime 0.125 (0.125)\tData 0.000 (0.003)\tLoss 1.5379 (1.6917)\tPrec@1 67.188 (62.378)\n",
            "Epoch: [58][390/391]\tTime 0.087 (0.125)\tData 0.000 (0.002)\tLoss 1.6503 (1.7035)\tPrec@1 68.750 (62.114)\n",
            "Total time : 48.732\n",
            "Train Loss: 1.7035, Train Accuracy: 0.6211\n",
            "Test Loss : 1.6860, Test Accuracy : 0.5534 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.444 (0.444)\tData 0.285 (0.285)\tLoss 1.6582 (1.6582)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [59][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.7450 (1.6741)\tPrec@1 63.281 (63.011)\n",
            "Epoch: [59][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.002)\tLoss 1.7799 (1.6883)\tPrec@1 64.062 (62.823)\n",
            "Epoch: [59][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4535 (1.6933)\tPrec@1 67.188 (62.516)\n",
            "Epoch: [59][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 1.7249 (1.6926)\tPrec@1 65.000 (62.540)\n",
            "Total time : 48.611\n",
            "Train Loss: 1.6926, Train Accuracy: 0.6254\n",
            "Test Loss : 1.6585, Test Accuracy : 0.5557 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.441 (0.441)\tData 0.269 (0.269)\tLoss 1.5021 (1.5021)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [60][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.6213 (1.6462)\tPrec@1 71.094 (63.390)\n",
            "Epoch: [60][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.6683 (1.6596)\tPrec@1 67.188 (63.067)\n",
            "Epoch: [60][300/391]\tTime 0.122 (0.125)\tData 0.001 (0.002)\tLoss 1.7291 (1.6752)\tPrec@1 59.375 (62.700)\n",
            "Epoch: [60][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 1.8243 (1.6905)\tPrec@1 63.750 (62.580)\n",
            "Total time : 48.749\n",
            "Train Loss: 1.6905, Train Accuracy: 0.6258\n",
            "Test Loss : 1.6195, Test Accuracy : 0.5654 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.362 (0.362)\tData 0.189 (0.189)\tLoss 1.5994 (1.5994)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [61][100/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.6703 (1.6081)\tPrec@1 65.625 (64.488)\n",
            "Epoch: [61][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.5234 (1.6372)\tPrec@1 64.062 (63.868)\n",
            "Epoch: [61][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.5751 (1.6553)\tPrec@1 65.625 (63.419)\n",
            "Epoch: [61][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 2.1250 (1.6636)\tPrec@1 63.750 (63.220)\n",
            "Total time : 48.635\n",
            "Train Loss: 1.6636, Train Accuracy: 0.6322\n",
            "Test Loss : 1.6281, Test Accuracy : 0.5674 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.403 (0.403)\tData 0.260 (0.260)\tLoss 1.6207 (1.6207)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [62][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.5797 (1.6407)\tPrec@1 64.844 (64.093)\n",
            "Epoch: [62][200/391]\tTime 0.122 (0.126)\tData 0.001 (0.003)\tLoss 1.6696 (1.6445)\tPrec@1 59.375 (63.755)\n",
            "Epoch: [62][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.7838 (1.6561)\tPrec@1 59.375 (63.357)\n",
            "Epoch: [62][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.6281 (1.6670)\tPrec@1 62.500 (63.166)\n",
            "Total time : 49.033\n",
            "Train Loss: 1.6670, Train Accuracy: 0.6317\n",
            "Test Loss : 1.5882, Test Accuracy : 0.5596 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.444 (0.444)\tData 0.274 (0.274)\tLoss 1.6689 (1.6689)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [63][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.5284 (1.6456)\tPrec@1 66.406 (63.459)\n",
            "Epoch: [63][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 1.3351 (1.6551)\tPrec@1 76.562 (63.273)\n",
            "Epoch: [63][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.6397 (1.6495)\tPrec@1 60.938 (63.349)\n",
            "Epoch: [63][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.7010 (1.6607)\tPrec@1 65.000 (63.102)\n",
            "Total time : 49.024\n",
            "Train Loss: 1.6607, Train Accuracy: 0.6310\n",
            "Test Loss : 1.5764, Test Accuracy : 0.5752 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.448 (0.448)\tData 0.279 (0.279)\tLoss 1.5392 (1.5392)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [64][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.7721 (1.6140)\tPrec@1 57.812 (64.325)\n",
            "Epoch: [64][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4497 (1.6315)\tPrec@1 64.844 (64.086)\n",
            "Epoch: [64][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.7223 (1.6324)\tPrec@1 67.188 (63.943)\n",
            "Epoch: [64][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 1.7497 (1.6428)\tPrec@1 65.000 (63.740)\n",
            "Total time : 48.783\n",
            "Train Loss: 1.6428, Train Accuracy: 0.6374\n",
            "Test Loss : 1.5827, Test Accuracy : 0.5808 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.515 (0.515)\tData 0.302 (0.302)\tLoss 1.6456 (1.6456)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [65][100/391]\tTime 0.123 (0.128)\tData 0.001 (0.004)\tLoss 1.6623 (1.5908)\tPrec@1 60.938 (64.573)\n",
            "Epoch: [65][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 1.5564 (1.6099)\tPrec@1 68.750 (64.346)\n",
            "Epoch: [65][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.4790 (1.6256)\tPrec@1 69.531 (64.153)\n",
            "Epoch: [65][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 2.0284 (1.6363)\tPrec@1 58.750 (63.896)\n",
            "Total time : 49.068\n",
            "Train Loss: 1.6363, Train Accuracy: 0.6390\n",
            "Test Loss : 1.5914, Test Accuracy : 0.5734 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.501 (0.501)\tData 0.310 (0.310)\tLoss 1.6968 (1.6968)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [66][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 1.5983 (1.5882)\tPrec@1 64.062 (64.759)\n",
            "Epoch: [66][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.4562 (1.6081)\tPrec@1 67.969 (64.630)\n",
            "Epoch: [66][300/391]\tTime 0.124 (0.126)\tData 0.000 (0.002)\tLoss 1.6908 (1.6246)\tPrec@1 58.594 (64.031)\n",
            "Epoch: [66][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 2.1777 (1.6262)\tPrec@1 53.750 (64.032)\n",
            "Total time : 48.911\n",
            "Train Loss: 1.6262, Train Accuracy: 0.6403\n",
            "Test Loss : 1.5077, Test Accuracy : 0.5927 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.443 (0.443)\tData 0.281 (0.281)\tLoss 1.4969 (1.4969)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [67][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.6523 (1.5675)\tPrec@1 62.500 (65.207)\n",
            "Epoch: [67][200/391]\tTime 0.122 (0.125)\tData 0.001 (0.002)\tLoss 1.4990 (1.5875)\tPrec@1 64.062 (64.921)\n",
            "Epoch: [67][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.5407 (1.5948)\tPrec@1 60.156 (64.574)\n",
            "Epoch: [67][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.9380 (1.6108)\tPrec@1 68.750 (64.238)\n",
            "Total time : 48.842\n",
            "Train Loss: 1.6108, Train Accuracy: 0.6424\n",
            "Test Loss : 1.6665, Test Accuracy : 0.5584 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.399 (0.399)\tData 0.236 (0.236)\tLoss 1.6151 (1.6151)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [68][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 1.6145 (1.5903)\tPrec@1 65.625 (64.890)\n",
            "Epoch: [68][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.6458 (1.6017)\tPrec@1 60.938 (64.657)\n",
            "Epoch: [68][300/391]\tTime 0.125 (0.125)\tData 0.003 (0.002)\tLoss 1.8014 (1.6081)\tPrec@1 59.375 (64.532)\n",
            "Epoch: [68][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.4022 (1.6092)\tPrec@1 67.500 (64.542)\n",
            "Total time : 48.757\n",
            "Train Loss: 1.6092, Train Accuracy: 0.6454\n",
            "Test Loss : 1.5873, Test Accuracy : 0.5756 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.471 (0.471)\tData 0.344 (0.344)\tLoss 1.5731 (1.5731)\tPrec@1 62.500 (62.500)\n",
            "Epoch: [69][100/391]\tTime 0.122 (0.129)\tData 0.001 (0.005)\tLoss 1.4627 (1.5762)\tPrec@1 66.406 (65.316)\n",
            "Epoch: [69][200/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 1.5974 (1.5817)\tPrec@1 69.531 (65.225)\n",
            "Epoch: [69][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.5224 (1.5878)\tPrec@1 62.500 (64.958)\n",
            "Epoch: [69][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.6491 (1.5980)\tPrec@1 66.250 (64.760)\n",
            "Total time : 49.045\n",
            "Train Loss: 1.5980, Train Accuracy: 0.6476\n",
            "Test Loss : 1.5659, Test Accuracy : 0.5768 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.420 (0.420)\tData 0.290 (0.290)\tLoss 1.3949 (1.3949)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [70][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 1.7571 (1.5704)\tPrec@1 57.031 (65.192)\n",
            "Epoch: [70][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.003)\tLoss 1.5810 (1.5555)\tPrec@1 68.750 (65.878)\n",
            "Epoch: [70][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.8891 (1.5756)\tPrec@1 56.250 (65.524)\n",
            "Epoch: [70][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.4153 (1.5828)\tPrec@1 70.000 (65.300)\n",
            "Total time : 48.804\n",
            "Train Loss: 1.5828, Train Accuracy: 0.6530\n",
            "Test Loss : 1.5745, Test Accuracy : 0.5758 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.413 (0.413)\tData 0.272 (0.272)\tLoss 1.5873 (1.5873)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [71][100/391]\tTime 0.121 (0.130)\tData 0.000 (0.004)\tLoss 1.5251 (1.5508)\tPrec@1 67.188 (66.074)\n",
            "Epoch: [71][200/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 1.4006 (1.5543)\tPrec@1 70.312 (65.920)\n",
            "Epoch: [71][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 1.5156 (1.5699)\tPrec@1 71.094 (65.529)\n",
            "Epoch: [71][390/391]\tTime 0.090 (0.126)\tData 0.000 (0.002)\tLoss 1.8323 (1.5746)\tPrec@1 61.250 (65.524)\n",
            "Total time : 49.105\n",
            "Train Loss: 1.5746, Train Accuracy: 0.6552\n",
            "Test Loss : 1.5252, Test Accuracy : 0.5953 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.413 (0.413)\tData 0.210 (0.210)\tLoss 1.4401 (1.4401)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [72][100/391]\tTime 0.122 (0.133)\tData 0.000 (0.006)\tLoss 1.4255 (1.5424)\tPrec@1 69.531 (66.329)\n",
            "Epoch: [72][200/391]\tTime 0.123 (0.128)\tData 0.000 (0.003)\tLoss 1.3980 (1.5413)\tPrec@1 68.750 (66.262)\n",
            "Epoch: [72][300/391]\tTime 0.119 (0.127)\tData 0.000 (0.003)\tLoss 1.7378 (1.5558)\tPrec@1 64.062 (65.895)\n",
            "Epoch: [72][390/391]\tTime 0.092 (0.126)\tData 0.000 (0.002)\tLoss 2.0062 (1.5691)\tPrec@1 62.500 (65.632)\n",
            "Total time : 49.346\n",
            "Train Loss: 1.5691, Train Accuracy: 0.6563\n",
            "Test Loss : 1.4574, Test Accuracy : 0.6055 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.621 (0.621)\tData 0.453 (0.453)\tLoss 1.4865 (1.4865)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [73][100/391]\tTime 0.120 (0.140)\tData 0.000 (0.014)\tLoss 1.4855 (1.5167)\tPrec@1 68.750 (67.056)\n",
            "Epoch: [73][200/391]\tTime 0.139 (0.132)\tData 0.000 (0.008)\tLoss 1.4092 (1.5439)\tPrec@1 63.281 (66.274)\n",
            "Epoch: [73][300/391]\tTime 0.135 (0.129)\tData 0.007 (0.006)\tLoss 1.3410 (1.5461)\tPrec@1 71.094 (66.305)\n",
            "Epoch: [73][390/391]\tTime 0.095 (0.128)\tData 0.000 (0.004)\tLoss 1.7868 (1.5568)\tPrec@1 65.000 (66.094)\n",
            "Total time : 49.872\n",
            "Train Loss: 1.5568, Train Accuracy: 0.6609\n",
            "Test Loss : 1.5108, Test Accuracy : 0.5924 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.422 (0.422)\tData 0.265 (0.265)\tLoss 1.8379 (1.8379)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [74][100/391]\tTime 0.122 (0.127)\tData 0.001 (0.004)\tLoss 1.5538 (1.5267)\tPrec@1 62.500 (66.197)\n",
            "Epoch: [74][200/391]\tTime 0.123 (0.127)\tData 0.001 (0.003)\tLoss 1.6734 (1.5347)\tPrec@1 65.625 (66.227)\n",
            "Epoch: [74][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 1.6652 (1.5471)\tPrec@1 67.969 (65.923)\n",
            "Epoch: [74][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.7219 (1.5471)\tPrec@1 67.500 (65.978)\n",
            "Total time : 48.987\n",
            "Train Loss: 1.5471, Train Accuracy: 0.6598\n",
            "Test Loss : 1.4616, Test Accuracy : 0.6012 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.454 (0.454)\tData 0.293 (0.293)\tLoss 1.3468 (1.3468)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [75][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 1.5094 (1.5188)\tPrec@1 65.625 (66.909)\n",
            "Epoch: [75][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.5204 (1.5301)\tPrec@1 72.656 (66.387)\n",
            "Epoch: [75][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.2206 (1.5306)\tPrec@1 69.531 (66.523)\n",
            "Epoch: [75][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.8823 (1.5364)\tPrec@1 63.750 (66.366)\n",
            "Total time : 48.898\n",
            "Train Loss: 1.5364, Train Accuracy: 0.6637\n",
            "Test Loss : 1.5203, Test Accuracy : 0.5971 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.469 (0.469)\tData 0.304 (0.304)\tLoss 1.3656 (1.3656)\tPrec@1 64.844 (64.844)\n",
            "Epoch: [76][100/391]\tTime 0.120 (0.128)\tData 0.000 (0.005)\tLoss 1.8547 (1.4881)\tPrec@1 60.156 (67.667)\n",
            "Epoch: [76][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.5004 (1.5096)\tPrec@1 68.750 (67.219)\n",
            "Epoch: [76][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4818 (1.5227)\tPrec@1 69.531 (66.785)\n",
            "Epoch: [76][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.4932 (1.5252)\tPrec@1 71.250 (66.682)\n",
            "Total time : 48.846\n",
            "Train Loss: 1.5252, Train Accuracy: 0.6668\n",
            "Test Loss : 1.4463, Test Accuracy : 0.6077 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.434 (0.434)\tData 0.248 (0.248)\tLoss 1.5464 (1.5464)\tPrec@1 63.281 (63.281)\n",
            "Epoch: [77][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 1.4328 (1.5088)\tPrec@1 64.844 (66.623)\n",
            "Epoch: [77][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.003)\tLoss 1.5891 (1.5219)\tPrec@1 67.969 (66.531)\n",
            "Epoch: [77][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 1.3623 (1.5244)\tPrec@1 67.969 (66.591)\n",
            "Epoch: [77][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 1.3067 (1.5292)\tPrec@1 75.000 (66.566)\n",
            "Total time : 49.055\n",
            "Train Loss: 1.5292, Train Accuracy: 0.6657\n",
            "Test Loss : 1.4124, Test Accuracy : 0.6122 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.458 (0.458)\tData 0.318 (0.318)\tLoss 1.5409 (1.5409)\tPrec@1 66.406 (66.406)\n",
            "Epoch: [78][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 1.6353 (1.4605)\tPrec@1 60.938 (68.363)\n",
            "Epoch: [78][200/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 1.6684 (1.4862)\tPrec@1 62.500 (67.607)\n",
            "Epoch: [78][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.6587 (1.4938)\tPrec@1 67.969 (67.411)\n",
            "Epoch: [78][390/391]\tTime 0.089 (0.126)\tData 0.000 (0.002)\tLoss 1.2540 (1.4968)\tPrec@1 76.250 (67.454)\n",
            "Total time : 49.242\n",
            "Train Loss: 1.4968, Train Accuracy: 0.6745\n",
            "Test Loss : 1.4486, Test Accuracy : 0.6066 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.366 (0.366)\tData 0.205 (0.205)\tLoss 1.3425 (1.3425)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [79][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.5583 (1.4762)\tPrec@1 64.062 (67.721)\n",
            "Epoch: [79][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.4838 (1.4990)\tPrec@1 67.969 (67.378)\n",
            "Epoch: [79][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.7278 (1.5018)\tPrec@1 64.062 (67.437)\n",
            "Epoch: [79][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 1.3126 (1.5091)\tPrec@1 72.500 (67.180)\n",
            "Total time : 48.777\n",
            "Train Loss: 1.5091, Train Accuracy: 0.6718\n",
            "Test Loss : 1.5459, Test Accuracy : 0.5938 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.442 (0.442)\tData 0.274 (0.274)\tLoss 1.2080 (1.2080)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [80][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 1.2859 (1.4549)\tPrec@1 66.406 (68.386)\n",
            "Epoch: [80][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.8354 (1.4815)\tPrec@1 59.375 (67.914)\n",
            "Epoch: [80][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.5553 (1.4891)\tPrec@1 64.844 (67.699)\n",
            "Epoch: [80][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.4965 (1.4971)\tPrec@1 66.250 (67.424)\n",
            "Total time : 48.811\n",
            "Train Loss: 1.4971, Train Accuracy: 0.6742\n",
            "Test Loss : 1.4922, Test Accuracy : 0.6027 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.416 (0.416)\tData 0.274 (0.274)\tLoss 1.5120 (1.5120)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [81][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.4752 (1.4340)\tPrec@1 60.156 (69.114)\n",
            "Epoch: [81][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 1.5013 (1.4512)\tPrec@1 67.969 (68.575)\n",
            "Epoch: [81][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.5095 (1.4645)\tPrec@1 66.406 (68.252)\n",
            "Epoch: [81][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.7392 (1.4672)\tPrec@1 68.750 (68.192)\n",
            "Total time : 48.808\n",
            "Train Loss: 1.4672, Train Accuracy: 0.6819\n",
            "Test Loss : 1.5884, Test Accuracy : 0.5800 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.447 (0.447)\tData 0.284 (0.284)\tLoss 1.2816 (1.2816)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [82][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.2651 (1.4399)\tPrec@1 71.094 (68.936)\n",
            "Epoch: [82][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.5440 (1.4579)\tPrec@1 64.844 (68.291)\n",
            "Epoch: [82][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.5289 (1.4609)\tPrec@1 66.406 (68.293)\n",
            "Epoch: [82][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.3806 (1.4666)\tPrec@1 70.000 (68.084)\n",
            "Total time : 48.744\n",
            "Train Loss: 1.4666, Train Accuracy: 0.6808\n",
            "Test Loss : 1.3805, Test Accuracy : 0.6225 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.440 (0.440)\tData 0.295 (0.295)\tLoss 1.1844 (1.1844)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [83][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.2511 (1.4336)\tPrec@1 71.094 (69.199)\n",
            "Epoch: [83][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 1.5264 (1.4425)\tPrec@1 67.188 (69.115)\n",
            "Epoch: [83][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.6223 (1.4498)\tPrec@1 64.062 (68.763)\n",
            "Epoch: [83][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.4109 (1.4564)\tPrec@1 73.750 (68.490)\n",
            "Total time : 48.759\n",
            "Train Loss: 1.4564, Train Accuracy: 0.6849\n",
            "Test Loss : 1.4141, Test Accuracy : 0.6116 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.485 (0.485)\tData 0.290 (0.290)\tLoss 1.4570 (1.4570)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [84][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.5808 (1.4158)\tPrec@1 64.062 (69.694)\n",
            "Epoch: [84][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.6279 (1.4227)\tPrec@1 67.969 (69.551)\n",
            "Epoch: [84][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4154 (1.4425)\tPrec@1 71.875 (69.007)\n",
            "Epoch: [84][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 1.2549 (1.4505)\tPrec@1 77.500 (68.658)\n",
            "Total time : 48.885\n",
            "Train Loss: 1.4505, Train Accuracy: 0.6866\n",
            "Test Loss : 1.3596, Test Accuracy : 0.6301 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.460 (0.460)\tData 0.307 (0.307)\tLoss 1.5659 (1.5659)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [85][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 1.5941 (1.3692)\tPrec@1 67.969 (70.312)\n",
            "Epoch: [85][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.2616 (1.3940)\tPrec@1 74.219 (69.644)\n",
            "Epoch: [85][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.4372 (1.4172)\tPrec@1 75.000 (69.256)\n",
            "Epoch: [85][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.3086 (1.4282)\tPrec@1 73.750 (69.148)\n",
            "Total time : 48.748\n",
            "Train Loss: 1.4282, Train Accuracy: 0.6915\n",
            "Test Loss : 1.3867, Test Accuracy : 0.6201 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.414 (0.414)\tData 0.269 (0.269)\tLoss 1.2625 (1.2625)\tPrec@1 68.750 (68.750)\n",
            "Epoch: [86][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.3771 (1.3951)\tPrec@1 68.750 (69.848)\n",
            "Epoch: [86][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 1.3839 (1.4119)\tPrec@1 68.750 (69.726)\n",
            "Epoch: [86][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.4013 (1.4249)\tPrec@1 67.969 (69.305)\n",
            "Epoch: [86][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.6749 (1.4297)\tPrec@1 67.500 (69.078)\n",
            "Total time : 48.813\n",
            "Train Loss: 1.4297, Train Accuracy: 0.6908\n",
            "Test Loss : 1.3930, Test Accuracy : 0.6221 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.465 (0.465)\tData 0.284 (0.284)\tLoss 1.3273 (1.3273)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [87][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 1.4901 (1.3785)\tPrec@1 65.625 (70.166)\n",
            "Epoch: [87][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.4480 (1.3999)\tPrec@1 72.656 (69.753)\n",
            "Epoch: [87][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.5745 (1.4145)\tPrec@1 66.406 (69.498)\n",
            "Epoch: [87][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.4633 (1.4225)\tPrec@1 76.250 (69.426)\n",
            "Total time : 49.039\n",
            "Train Loss: 1.4225, Train Accuracy: 0.6943\n",
            "Test Loss : 1.3913, Test Accuracy : 0.6213 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.638 (0.638)\tData 0.427 (0.427)\tLoss 1.3901 (1.3901)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [88][100/391]\tTime 0.134 (0.130)\tData 0.000 (0.006)\tLoss 1.2150 (1.3782)\tPrec@1 70.312 (70.196)\n",
            "Epoch: [88][200/391]\tTime 0.134 (0.126)\tData 0.000 (0.003)\tLoss 1.3762 (1.3925)\tPrec@1 70.312 (69.998)\n",
            "Epoch: [88][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.4478 (1.4076)\tPrec@1 71.875 (69.542)\n",
            "Epoch: [88][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.3232 (1.4167)\tPrec@1 77.500 (69.474)\n",
            "Total time : 48.980\n",
            "Train Loss: 1.4167, Train Accuracy: 0.6947\n",
            "Test Loss : 1.4525, Test Accuracy : 0.6079 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.623 (0.623)\tData 0.442 (0.442)\tLoss 1.5198 (1.5198)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [89][100/391]\tTime 0.132 (0.129)\tData 0.007 (0.005)\tLoss 1.4149 (1.3805)\tPrec@1 68.750 (69.964)\n",
            "Epoch: [89][200/391]\tTime 0.127 (0.126)\tData 0.000 (0.003)\tLoss 1.4316 (1.3756)\tPrec@1 69.531 (70.099)\n",
            "Epoch: [89][300/391]\tTime 0.135 (0.126)\tData 0.008 (0.002)\tLoss 1.1140 (1.3895)\tPrec@1 80.469 (69.895)\n",
            "Epoch: [89][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.5267 (1.3980)\tPrec@1 67.500 (69.736)\n",
            "Total time : 48.935\n",
            "Train Loss: 1.3980, Train Accuracy: 0.6974\n",
            "Test Loss : 1.4015, Test Accuracy : 0.6258 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.434 (0.434)\tData 0.278 (0.278)\tLoss 1.3823 (1.3823)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [90][100/391]\tTime 0.134 (0.127)\tData 0.017 (0.004)\tLoss 1.2992 (1.3413)\tPrec@1 76.562 (70.877)\n",
            "Epoch: [90][200/391]\tTime 0.130 (0.125)\tData 0.006 (0.002)\tLoss 1.3398 (1.3711)\tPrec@1 71.875 (70.072)\n",
            "Epoch: [90][300/391]\tTime 0.134 (0.125)\tData 0.000 (0.002)\tLoss 1.3950 (1.3800)\tPrec@1 71.094 (69.874)\n",
            "Epoch: [90][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.001)\tLoss 1.3438 (1.3827)\tPrec@1 70.000 (69.940)\n",
            "Total time : 48.557\n",
            "Train Loss: 1.3827, Train Accuracy: 0.6994\n",
            "Test Loss : 1.3831, Test Accuracy : 0.6220 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.485 (0.485)\tData 0.292 (0.292)\tLoss 1.1413 (1.1413)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [91][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.2806 (1.3322)\tPrec@1 77.344 (70.885)\n",
            "Epoch: [91][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.4436 (1.3570)\tPrec@1 67.969 (70.616)\n",
            "Epoch: [91][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.5646 (1.3722)\tPrec@1 63.281 (70.367)\n",
            "Epoch: [91][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 1.5683 (1.3830)\tPrec@1 68.750 (70.168)\n",
            "Total time : 48.661\n",
            "Train Loss: 1.3830, Train Accuracy: 0.7017\n",
            "Test Loss : 1.3493, Test Accuracy : 0.6319 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.452 (0.452)\tData 0.306 (0.306)\tLoss 1.2908 (1.2908)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [92][100/391]\tTime 0.122 (0.128)\tData 0.001 (0.004)\tLoss 1.1835 (1.3067)\tPrec@1 77.344 (72.107)\n",
            "Epoch: [92][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.2695 (1.3187)\tPrec@1 75.000 (71.716)\n",
            "Epoch: [92][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.4363 (1.3420)\tPrec@1 64.844 (71.052)\n",
            "Epoch: [92][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.1084 (1.3558)\tPrec@1 75.000 (70.684)\n",
            "Total time : 48.764\n",
            "Train Loss: 1.3558, Train Accuracy: 0.7068\n",
            "Test Loss : 1.3576, Test Accuracy : 0.6305 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.436 (0.436)\tData 0.271 (0.271)\tLoss 1.2088 (1.2088)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [93][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.2514 (1.3284)\tPrec@1 73.438 (71.457)\n",
            "Epoch: [93][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.3038 (1.3340)\tPrec@1 70.312 (71.354)\n",
            "Epoch: [93][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4360 (1.3472)\tPrec@1 74.219 (71.169)\n",
            "Epoch: [93][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.2371 (1.3511)\tPrec@1 82.500 (71.048)\n",
            "Total time : 48.776\n",
            "Train Loss: 1.3511, Train Accuracy: 0.7105\n",
            "Test Loss : 1.3703, Test Accuracy : 0.6293 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.427 (0.427)\tData 0.271 (0.271)\tLoss 1.2343 (1.2343)\tPrec@1 79.688 (79.688)\n",
            "Epoch: [94][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.3044 (1.3307)\tPrec@1 68.750 (71.202)\n",
            "Epoch: [94][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.4627 (1.3304)\tPrec@1 75.000 (71.284)\n",
            "Epoch: [94][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.2071 (1.3439)\tPrec@1 76.562 (71.161)\n",
            "Epoch: [94][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.1155 (1.3418)\tPrec@1 78.750 (71.224)\n",
            "Total time : 48.855\n",
            "Train Loss: 1.3418, Train Accuracy: 0.7122\n",
            "Test Loss : 1.3045, Test Accuracy : 0.6445 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.412 (0.412)\tData 0.261 (0.261)\tLoss 1.4138 (1.4138)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [95][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.4381 (1.2939)\tPrec@1 67.969 (72.231)\n",
            "Epoch: [95][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.3245 (1.3060)\tPrec@1 69.531 (71.774)\n",
            "Epoch: [95][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.4284 (1.3148)\tPrec@1 70.312 (71.678)\n",
            "Epoch: [95][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.1295 (1.3167)\tPrec@1 81.250 (71.490)\n",
            "Total time : 48.787\n",
            "Train Loss: 1.3167, Train Accuracy: 0.7149\n",
            "Test Loss : 1.3683, Test Accuracy : 0.6263 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.431 (0.431)\tData 0.273 (0.273)\tLoss 1.1819 (1.1819)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [96][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.3775 (1.2903)\tPrec@1 70.312 (72.208)\n",
            "Epoch: [96][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 1.2025 (1.2973)\tPrec@1 74.219 (72.108)\n",
            "Epoch: [96][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 1.5023 (1.3056)\tPrec@1 67.188 (71.808)\n",
            "Epoch: [96][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.4764 (1.3160)\tPrec@1 73.750 (71.482)\n",
            "Total time : 48.711\n",
            "Train Loss: 1.3160, Train Accuracy: 0.7148\n",
            "Test Loss : 1.3229, Test Accuracy : 0.6434 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.466 (0.466)\tData 0.309 (0.309)\tLoss 1.3785 (1.3785)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [97][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.1792 (1.2924)\tPrec@1 75.781 (72.416)\n",
            "Epoch: [97][200/391]\tTime 0.124 (0.125)\tData 0.000 (0.003)\tLoss 1.1475 (1.2919)\tPrec@1 78.125 (72.338)\n",
            "Epoch: [97][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.4078 (1.3012)\tPrec@1 67.969 (72.142)\n",
            "Epoch: [97][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 1.6145 (1.3075)\tPrec@1 63.750 (71.860)\n",
            "Total time : 48.648\n",
            "Train Loss: 1.3075, Train Accuracy: 0.7186\n",
            "Test Loss : 1.3501, Test Accuracy : 0.6332 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.460 (0.460)\tData 0.292 (0.292)\tLoss 1.3293 (1.3293)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [98][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 1.3586 (1.2773)\tPrec@1 74.219 (72.765)\n",
            "Epoch: [98][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.3667 (1.2832)\tPrec@1 72.656 (72.660)\n",
            "Epoch: [98][300/391]\tTime 0.121 (0.126)\tData 0.001 (0.003)\tLoss 1.3851 (1.2928)\tPrec@1 71.094 (72.433)\n",
            "Epoch: [98][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.4647 (1.3008)\tPrec@1 70.000 (72.094)\n",
            "Total time : 49.034\n",
            "Train Loss: 1.3008, Train Accuracy: 0.7209\n",
            "Test Loss : 1.4109, Test Accuracy : 0.6216 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.428 (0.428)\tData 0.257 (0.257)\tLoss 1.2918 (1.2918)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [99][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.1846 (1.2670)\tPrec@1 72.656 (73.128)\n",
            "Epoch: [99][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 1.5463 (1.2841)\tPrec@1 67.188 (72.384)\n",
            "Epoch: [99][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.4321 (1.2908)\tPrec@1 70.312 (72.158)\n",
            "Epoch: [99][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.2740 (1.2895)\tPrec@1 77.500 (72.172)\n",
            "Total time : 48.738\n",
            "Train Loss: 1.2895, Train Accuracy: 0.7217\n",
            "Test Loss : 1.3504, Test Accuracy : 0.6404 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.419 (0.419)\tData 0.286 (0.286)\tLoss 1.2610 (1.2610)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [100][100/391]\tTime 0.123 (0.127)\tData 0.001 (0.004)\tLoss 1.4623 (1.2070)\tPrec@1 61.719 (73.940)\n",
            "Epoch: [100][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.5708 (1.2432)\tPrec@1 65.625 (73.321)\n",
            "Epoch: [100][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 1.3816 (1.2574)\tPrec@1 70.312 (72.898)\n",
            "Epoch: [100][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 1.4992 (1.2641)\tPrec@1 68.750 (72.724)\n",
            "Total time : 48.873\n",
            "Train Loss: 1.2641, Train Accuracy: 0.7272\n",
            "Test Loss : 1.3407, Test Accuracy : 0.6335 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.451 (0.451)\tData 0.289 (0.289)\tLoss 1.3751 (1.3751)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [101][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.1930 (1.2225)\tPrec@1 70.312 (73.956)\n",
            "Epoch: [101][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.2401 (1.2471)\tPrec@1 71.094 (73.255)\n",
            "Epoch: [101][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.3610 (1.2581)\tPrec@1 71.875 (73.072)\n",
            "Epoch: [101][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.2888 (1.2584)\tPrec@1 76.250 (73.028)\n",
            "Total time : 48.761\n",
            "Train Loss: 1.2584, Train Accuracy: 0.7303\n",
            "Test Loss : 1.3594, Test Accuracy : 0.6307 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.405 (0.405)\tData 0.231 (0.231)\tLoss 1.1960 (1.1960)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [102][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 1.2109 (1.2242)\tPrec@1 74.219 (73.592)\n",
            "Epoch: [102][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.3809 (1.2357)\tPrec@1 71.094 (73.395)\n",
            "Epoch: [102][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.3104 (1.2483)\tPrec@1 70.312 (73.316)\n",
            "Epoch: [102][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.3919 (1.2450)\tPrec@1 71.250 (73.336)\n",
            "Total time : 48.790\n",
            "Train Loss: 1.2450, Train Accuracy: 0.7334\n",
            "Test Loss : 1.3160, Test Accuracy : 0.6448 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.448 (0.448)\tData 0.296 (0.296)\tLoss 1.2084 (1.2084)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [103][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.2012 (1.2080)\tPrec@1 71.875 (74.049)\n",
            "Epoch: [103][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.2845 (1.2128)\tPrec@1 70.312 (73.958)\n",
            "Epoch: [103][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.3317 (1.2285)\tPrec@1 74.219 (73.502)\n",
            "Epoch: [103][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.4526 (1.2333)\tPrec@1 70.000 (73.448)\n",
            "Total time : 48.763\n",
            "Train Loss: 1.2333, Train Accuracy: 0.7345\n",
            "Test Loss : 1.2775, Test Accuracy : 0.6469 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.394 (0.394)\tData 0.247 (0.247)\tLoss 1.0766 (1.0766)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [104][100/391]\tTime 0.122 (0.126)\tData 0.000 (0.004)\tLoss 1.3644 (1.2095)\tPrec@1 67.188 (74.234)\n",
            "Epoch: [104][200/391]\tTime 0.124 (0.125)\tData 0.003 (0.002)\tLoss 1.4337 (1.2152)\tPrec@1 74.219 (74.246)\n",
            "Epoch: [104][300/391]\tTime 0.122 (0.125)\tData 0.001 (0.002)\tLoss 1.3685 (1.2143)\tPrec@1 67.969 (74.214)\n",
            "Epoch: [104][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.1687 (1.2320)\tPrec@1 72.500 (73.762)\n",
            "Total time : 48.745\n",
            "Train Loss: 1.2320, Train Accuracy: 0.7376\n",
            "Test Loss : 1.3003, Test Accuracy : 0.6420 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.461 (0.461)\tData 0.307 (0.307)\tLoss 1.3857 (1.3857)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [105][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 1.2563 (1.1923)\tPrec@1 70.312 (74.946)\n",
            "Epoch: [105][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.0266 (1.1907)\tPrec@1 78.125 (74.825)\n",
            "Epoch: [105][300/391]\tTime 0.123 (0.125)\tData 0.001 (0.002)\tLoss 1.2065 (1.2092)\tPrec@1 75.781 (74.278)\n",
            "Epoch: [105][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.2153 (1.2107)\tPrec@1 78.750 (74.208)\n",
            "Total time : 48.912\n",
            "Train Loss: 1.2107, Train Accuracy: 0.7421\n",
            "Test Loss : 1.2609, Test Accuracy : 0.6587 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.424 (0.424)\tData 0.262 (0.262)\tLoss 1.3246 (1.3246)\tPrec@1 67.969 (67.969)\n",
            "Epoch: [106][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 1.1905 (1.1444)\tPrec@1 75.000 (75.541)\n",
            "Epoch: [106][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 1.3911 (1.1743)\tPrec@1 73.438 (74.984)\n",
            "Epoch: [106][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.1699 (1.1813)\tPrec@1 73.438 (74.766)\n",
            "Epoch: [106][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 1.1664 (1.1861)\tPrec@1 70.000 (74.752)\n",
            "Total time : 48.712\n",
            "Train Loss: 1.1861, Train Accuracy: 0.7475\n",
            "Test Loss : 1.2381, Test Accuracy : 0.6610 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.422 (0.422)\tData 0.265 (0.265)\tLoss 1.0896 (1.0896)\tPrec@1 72.656 (72.656)\n",
            "Epoch: [107][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.1579 (1.1624)\tPrec@1 77.344 (75.294)\n",
            "Epoch: [107][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.1514 (1.1678)\tPrec@1 75.781 (75.222)\n",
            "Epoch: [107][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.1971 (1.1846)\tPrec@1 73.438 (74.842)\n",
            "Epoch: [107][390/391]\tTime 0.093 (0.125)\tData 0.000 (0.002)\tLoss 1.3987 (1.1952)\tPrec@1 68.750 (74.508)\n",
            "Total time : 48.816\n",
            "Train Loss: 1.1952, Train Accuracy: 0.7451\n",
            "Test Loss : 1.2476, Test Accuracy : 0.6576 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.454 (0.454)\tData 0.270 (0.270)\tLoss 1.2270 (1.2270)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [108][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 1.0820 (1.1345)\tPrec@1 78.125 (75.766)\n",
            "Epoch: [108][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.0490 (1.1444)\tPrec@1 75.000 (75.599)\n",
            "Epoch: [108][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.1411 (1.1659)\tPrec@1 78.906 (75.016)\n",
            "Epoch: [108][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.9447 (1.1760)\tPrec@1 82.500 (74.808)\n",
            "Total time : 48.908\n",
            "Train Loss: 1.1760, Train Accuracy: 0.7481\n",
            "Test Loss : 1.2992, Test Accuracy : 0.6447 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.451 (0.451)\tData 0.316 (0.316)\tLoss 0.9377 (0.9377)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [109][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.005)\tLoss 1.0104 (1.1440)\tPrec@1 72.656 (75.704)\n",
            "Epoch: [109][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 1.1791 (1.1488)\tPrec@1 78.906 (75.424)\n",
            "Epoch: [109][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.2537 (1.1647)\tPrec@1 71.875 (74.940)\n",
            "Epoch: [109][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.1912 (1.1624)\tPrec@1 76.250 (75.056)\n",
            "Total time : 48.729\n",
            "Train Loss: 1.1624, Train Accuracy: 0.7506\n",
            "Test Loss : 1.3112, Test Accuracy : 0.6470 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.461 (0.461)\tData 0.269 (0.269)\tLoss 1.2739 (1.2739)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [110][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 0.9634 (1.1085)\tPrec@1 80.469 (76.462)\n",
            "Epoch: [110][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.0172 (1.1232)\tPrec@1 79.688 (75.913)\n",
            "Epoch: [110][300/391]\tTime 0.122 (0.126)\tData 0.001 (0.002)\tLoss 1.1610 (1.1401)\tPrec@1 77.344 (75.815)\n",
            "Epoch: [110][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.1628 (1.1496)\tPrec@1 77.500 (75.538)\n",
            "Total time : 48.913\n",
            "Train Loss: 1.1496, Train Accuracy: 0.7554\n",
            "Test Loss : 1.2274, Test Accuracy : 0.6630 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.523 (0.523)\tData 0.343 (0.343)\tLoss 1.1740 (1.1740)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [111][100/391]\tTime 0.127 (0.129)\tData 0.000 (0.005)\tLoss 1.1572 (1.0736)\tPrec@1 73.438 (77.150)\n",
            "Epoch: [111][200/391]\tTime 0.129 (0.126)\tData 0.000 (0.003)\tLoss 1.1537 (1.1057)\tPrec@1 79.688 (76.473)\n",
            "Epoch: [111][300/391]\tTime 0.147 (0.125)\tData 0.006 (0.002)\tLoss 1.1134 (1.1223)\tPrec@1 78.906 (76.134)\n",
            "Epoch: [111][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.3006 (1.1301)\tPrec@1 71.250 (75.928)\n",
            "Total time : 48.873\n",
            "Train Loss: 1.1301, Train Accuracy: 0.7593\n",
            "Test Loss : 1.2242, Test Accuracy : 0.6628 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.697 (0.697)\tData 0.460 (0.460)\tLoss 1.0502 (1.0502)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [112][100/391]\tTime 0.124 (0.130)\tData 0.000 (0.006)\tLoss 1.2208 (1.1002)\tPrec@1 73.438 (76.671)\n",
            "Epoch: [112][200/391]\tTime 0.129 (0.127)\tData 0.000 (0.003)\tLoss 1.1379 (1.1089)\tPrec@1 81.250 (76.500)\n",
            "Epoch: [112][300/391]\tTime 0.142 (0.126)\tData 0.011 (0.003)\tLoss 1.2091 (1.1160)\tPrec@1 76.562 (76.378)\n",
            "Epoch: [112][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.3062 (1.1221)\tPrec@1 77.500 (76.224)\n",
            "Total time : 48.910\n",
            "Train Loss: 1.1221, Train Accuracy: 0.7622\n",
            "Test Loss : 1.2423, Test Accuracy : 0.6641 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.452 (0.452)\tData 0.263 (0.263)\tLoss 1.2120 (1.2120)\tPrec@1 71.875 (71.875)\n",
            "Epoch: [113][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.1303 (1.1109)\tPrec@1 74.219 (76.524)\n",
            "Epoch: [113][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.4557 (1.1078)\tPrec@1 67.969 (76.559)\n",
            "Epoch: [113][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.3230 (1.1156)\tPrec@1 71.875 (76.137)\n",
            "Epoch: [113][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 1.1661 (1.1110)\tPrec@1 77.500 (76.236)\n",
            "Total time : 48.667\n",
            "Train Loss: 1.1110, Train Accuracy: 0.7624\n",
            "Test Loss : 1.2466, Test Accuracy : 0.6611 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.430 (0.430)\tData 0.274 (0.274)\tLoss 1.0161 (1.0161)\tPrec@1 75.000 (75.000)\n",
            "Epoch: [114][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 1.0903 (1.0995)\tPrec@1 75.781 (76.849)\n",
            "Epoch: [114][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.9523 (1.0991)\tPrec@1 76.562 (76.609)\n",
            "Epoch: [114][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.2200 (1.1047)\tPrec@1 75.781 (76.599)\n",
            "Epoch: [114][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.3399 (1.1093)\tPrec@1 73.750 (76.436)\n",
            "Total time : 48.781\n",
            "Train Loss: 1.1093, Train Accuracy: 0.7644\n",
            "Test Loss : 1.2101, Test Accuracy : 0.6645 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.457 (0.457)\tData 0.283 (0.283)\tLoss 0.9305 (0.9305)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [115][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.2000 (1.0492)\tPrec@1 75.000 (78.001)\n",
            "Epoch: [115][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.9429 (1.0644)\tPrec@1 76.562 (77.589)\n",
            "Epoch: [115][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.9335 (1.0737)\tPrec@1 81.250 (77.227)\n",
            "Epoch: [115][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.2426 (1.0924)\tPrec@1 70.000 (76.722)\n",
            "Total time : 48.879\n",
            "Train Loss: 1.0924, Train Accuracy: 0.7672\n",
            "Test Loss : 1.1983, Test Accuracy : 0.6698 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.455 (0.455)\tData 0.306 (0.306)\tLoss 0.9006 (0.9006)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [116][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.1185 (1.0452)\tPrec@1 78.906 (77.738)\n",
            "Epoch: [116][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.0094 (1.0665)\tPrec@1 78.125 (77.425)\n",
            "Epoch: [116][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.0752 (1.0671)\tPrec@1 81.250 (77.336)\n",
            "Epoch: [116][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.9915 (1.0732)\tPrec@1 77.500 (77.198)\n",
            "Total time : 48.899\n",
            "Train Loss: 1.0732, Train Accuracy: 0.7720\n",
            "Test Loss : 1.1775, Test Accuracy : 0.6719 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.460 (0.460)\tData 0.276 (0.276)\tLoss 0.9575 (0.9575)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [117][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 1.0500 (1.0208)\tPrec@1 75.781 (78.628)\n",
            "Epoch: [117][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.2097 (1.0223)\tPrec@1 77.344 (78.657)\n",
            "Epoch: [117][300/391]\tTime 0.122 (0.125)\tData 0.001 (0.002)\tLoss 0.9333 (1.0333)\tPrec@1 79.688 (78.128)\n",
            "Epoch: [117][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.1104 (1.0451)\tPrec@1 73.750 (77.828)\n",
            "Total time : 48.872\n",
            "Train Loss: 1.0451, Train Accuracy: 0.7783\n",
            "Test Loss : 1.1721, Test Accuracy : 0.6765 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.473 (0.473)\tData 0.318 (0.318)\tLoss 1.0867 (1.0867)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [118][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.005)\tLoss 1.1341 (0.9996)\tPrec@1 78.125 (79.061)\n",
            "Epoch: [118][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.1127 (1.0258)\tPrec@1 72.656 (78.284)\n",
            "Epoch: [118][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 1.1751 (1.0397)\tPrec@1 76.562 (78.047)\n",
            "Epoch: [118][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.1590 (1.0469)\tPrec@1 78.750 (77.908)\n",
            "Total time : 48.834\n",
            "Train Loss: 1.0469, Train Accuracy: 0.7791\n",
            "Test Loss : 1.2130, Test Accuracy : 0.6669 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.465 (0.465)\tData 0.284 (0.284)\tLoss 1.1670 (1.1670)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [119][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 1.1709 (0.9998)\tPrec@1 75.000 (79.038)\n",
            "Epoch: [119][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 1.1005 (1.0059)\tPrec@1 77.344 (78.825)\n",
            "Epoch: [119][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.0040 (1.0160)\tPrec@1 78.125 (78.488)\n",
            "Epoch: [119][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.2793 (1.0274)\tPrec@1 78.750 (78.174)\n",
            "Total time : 48.759\n",
            "Train Loss: 1.0274, Train Accuracy: 0.7817\n",
            "Test Loss : 1.2168, Test Accuracy : 0.6727 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.364 (0.364)\tData 0.203 (0.203)\tLoss 1.0414 (1.0414)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [120][100/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 1.0523 (0.9779)\tPrec@1 81.250 (79.332)\n",
            "Epoch: [120][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.0414 (0.9938)\tPrec@1 79.688 (78.778)\n",
            "Epoch: [120][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 1.0673 (1.0042)\tPrec@1 75.781 (78.712)\n",
            "Epoch: [120][390/391]\tTime 0.088 (0.124)\tData 0.000 (0.002)\tLoss 1.1780 (1.0181)\tPrec@1 80.000 (78.404)\n",
            "Total time : 48.661\n",
            "Train Loss: 1.0181, Train Accuracy: 0.7840\n",
            "Test Loss : 1.1539, Test Accuracy : 0.6847 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.419 (0.419)\tData 0.293 (0.293)\tLoss 0.9524 (0.9524)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [121][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 1.0352 (0.9406)\tPrec@1 78.906 (80.036)\n",
            "Epoch: [121][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.003)\tLoss 0.9287 (0.9801)\tPrec@1 78.906 (79.307)\n",
            "Epoch: [121][300/391]\tTime 0.123 (0.125)\tData 0.001 (0.002)\tLoss 1.1488 (0.9886)\tPrec@1 72.656 (79.101)\n",
            "Epoch: [121][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.8439 (0.9999)\tPrec@1 80.000 (78.672)\n",
            "Total time : 48.910\n",
            "Train Loss: 0.9999, Train Accuracy: 0.7867\n",
            "Test Loss : 1.1623, Test Accuracy : 0.6825 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.493 (0.493)\tData 0.342 (0.342)\tLoss 0.9877 (0.9877)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [122][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 0.9106 (0.9671)\tPrec@1 81.250 (79.355)\n",
            "Epoch: [122][200/391]\tTime 0.123 (0.126)\tData 0.001 (0.003)\tLoss 1.0367 (0.9787)\tPrec@1 78.125 (79.303)\n",
            "Epoch: [122][300/391]\tTime 0.128 (0.126)\tData 0.004 (0.002)\tLoss 1.0390 (0.9789)\tPrec@1 79.688 (79.176)\n",
            "Epoch: [122][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.2278 (0.9842)\tPrec@1 80.000 (79.016)\n",
            "Total time : 48.996\n",
            "Train Loss: 0.9842, Train Accuracy: 0.7902\n",
            "Test Loss : 1.1380, Test Accuracy : 0.6859 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.461 (0.461)\tData 0.319 (0.319)\tLoss 0.9886 (0.9886)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [123][100/391]\tTime 0.125 (0.128)\tData 0.000 (0.004)\tLoss 0.8415 (0.9298)\tPrec@1 83.594 (80.616)\n",
            "Epoch: [123][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.9774 (0.9502)\tPrec@1 84.375 (80.049)\n",
            "Epoch: [123][300/391]\tTime 0.123 (0.125)\tData 0.001 (0.002)\tLoss 0.9797 (0.9646)\tPrec@1 82.031 (79.797)\n",
            "Epoch: [123][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.1946 (0.9715)\tPrec@1 73.750 (79.572)\n",
            "Total time : 48.968\n",
            "Train Loss: 0.9715, Train Accuracy: 0.7957\n",
            "Test Loss : 1.1556, Test Accuracy : 0.6793 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.464 (0.464)\tData 0.284 (0.284)\tLoss 0.8989 (0.8989)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [124][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 1.0112 (0.9410)\tPrec@1 81.250 (80.252)\n",
            "Epoch: [124][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 1.0309 (0.9396)\tPrec@1 80.469 (80.340)\n",
            "Epoch: [124][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.8053 (0.9512)\tPrec@1 85.156 (80.056)\n",
            "Epoch: [124][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 1.1002 (0.9589)\tPrec@1 80.000 (79.812)\n",
            "Total time : 48.878\n",
            "Train Loss: 0.9589, Train Accuracy: 0.7981\n",
            "Test Loss : 1.1218, Test Accuracy : 0.6929 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.429 (0.429)\tData 0.289 (0.289)\tLoss 0.9099 (0.9099)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [125][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 0.9165 (0.9164)\tPrec@1 85.156 (81.026)\n",
            "Epoch: [125][200/391]\tTime 0.122 (0.126)\tData 0.001 (0.003)\tLoss 0.7729 (0.9201)\tPrec@1 87.500 (80.768)\n",
            "Epoch: [125][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.7841 (0.9312)\tPrec@1 86.719 (80.432)\n",
            "Epoch: [125][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.0287 (0.9445)\tPrec@1 80.000 (80.138)\n",
            "Total time : 48.879\n",
            "Train Loss: 0.9445, Train Accuracy: 0.8014\n",
            "Test Loss : 1.1238, Test Accuracy : 0.6905 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.459 (0.459)\tData 0.296 (0.296)\tLoss 0.9094 (0.9094)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [126][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.8570 (0.8955)\tPrec@1 85.156 (81.119)\n",
            "Epoch: [126][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.9215 (0.9202)\tPrec@1 82.031 (80.554)\n",
            "Epoch: [126][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.9110 (0.9269)\tPrec@1 82.812 (80.440)\n",
            "Epoch: [126][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.8227 (0.9297)\tPrec@1 85.000 (80.402)\n",
            "Total time : 48.785\n",
            "Train Loss: 0.9297, Train Accuracy: 0.8040\n",
            "Test Loss : 1.1341, Test Accuracy : 0.6881 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.410 (0.410)\tData 0.222 (0.222)\tLoss 0.8538 (0.8538)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [127][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.8391 (0.8767)\tPrec@1 85.156 (81.528)\n",
            "Epoch: [127][200/391]\tTime 0.120 (0.125)\tData 0.000 (0.002)\tLoss 1.0475 (0.9008)\tPrec@1 75.000 (81.308)\n",
            "Epoch: [127][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.7414 (0.9083)\tPrec@1 87.500 (81.042)\n",
            "Epoch: [127][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.9634 (0.9169)\tPrec@1 87.500 (80.784)\n",
            "Total time : 48.657\n",
            "Train Loss: 0.9169, Train Accuracy: 0.8078\n",
            "Test Loss : 1.1083, Test Accuracy : 0.6958 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.459 (0.459)\tData 0.326 (0.326)\tLoss 0.9521 (0.9521)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [128][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.005)\tLoss 0.8587 (0.8558)\tPrec@1 86.719 (81.938)\n",
            "Epoch: [128][200/391]\tTime 0.126 (0.126)\tData 0.007 (0.003)\tLoss 1.0693 (0.8687)\tPrec@1 76.562 (81.755)\n",
            "Epoch: [128][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.9601 (0.8779)\tPrec@1 80.469 (81.554)\n",
            "Epoch: [128][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.8753 (0.8879)\tPrec@1 86.250 (81.404)\n",
            "Total time : 48.868\n",
            "Train Loss: 0.8879, Train Accuracy: 0.8140\n",
            "Test Loss : 1.0918, Test Accuracy : 0.6974 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.469 (0.469)\tData 0.310 (0.310)\tLoss 0.8118 (0.8118)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [129][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.8963 (0.8584)\tPrec@1 78.125 (81.915)\n",
            "Epoch: [129][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.003)\tLoss 0.9792 (0.8646)\tPrec@1 77.344 (81.845)\n",
            "Epoch: [129][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.7680 (0.8753)\tPrec@1 84.375 (81.850)\n",
            "Epoch: [129][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 1.0408 (0.8821)\tPrec@1 77.500 (81.694)\n",
            "Total time : 48.828\n",
            "Train Loss: 0.8821, Train Accuracy: 0.8169\n",
            "Test Loss : 1.0905, Test Accuracy : 0.7011 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.381 (0.381)\tData 0.210 (0.210)\tLoss 0.8647 (0.8647)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [130][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.8968 (0.8530)\tPrec@1 83.594 (82.410)\n",
            "Epoch: [130][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.7454 (0.8611)\tPrec@1 82.812 (82.261)\n",
            "Epoch: [130][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.9498 (0.8714)\tPrec@1 81.250 (81.935)\n",
            "Epoch: [130][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.9609 (0.8741)\tPrec@1 77.500 (81.802)\n",
            "Total time : 48.774\n",
            "Train Loss: 0.8741, Train Accuracy: 0.8180\n",
            "Test Loss : 1.1194, Test Accuracy : 0.6900 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.385 (0.385)\tData 0.203 (0.203)\tLoss 0.8586 (0.8586)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [131][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 0.7039 (0.8234)\tPrec@1 86.719 (83.168)\n",
            "Epoch: [131][200/391]\tTime 0.120 (0.125)\tData 0.000 (0.002)\tLoss 1.0910 (0.8393)\tPrec@1 79.688 (82.696)\n",
            "Epoch: [131][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 1.1641 (0.8487)\tPrec@1 74.219 (82.504)\n",
            "Epoch: [131][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.9478 (0.8573)\tPrec@1 77.500 (82.174)\n",
            "Total time : 48.667\n",
            "Train Loss: 0.8573, Train Accuracy: 0.8217\n",
            "Test Loss : 1.0787, Test Accuracy : 0.7036 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.452 (0.452)\tData 0.315 (0.315)\tLoss 0.7874 (0.7874)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [132][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.7195 (0.8215)\tPrec@1 88.281 (83.045)\n",
            "Epoch: [132][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.8899 (0.8333)\tPrec@1 78.906 (82.859)\n",
            "Epoch: [132][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.7302 (0.8392)\tPrec@1 78.906 (82.589)\n",
            "Epoch: [132][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.8361 (0.8421)\tPrec@1 87.500 (82.494)\n",
            "Total time : 48.794\n",
            "Train Loss: 0.8421, Train Accuracy: 0.8249\n",
            "Test Loss : 1.1175, Test Accuracy : 0.6939 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.549 (0.549)\tData 0.322 (0.322)\tLoss 0.7777 (0.7777)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [133][100/391]\tTime 0.136 (0.129)\tData 0.007 (0.004)\tLoss 0.8682 (0.8047)\tPrec@1 75.781 (82.952)\n",
            "Epoch: [133][200/391]\tTime 0.121 (0.127)\tData 0.000 (0.003)\tLoss 1.0506 (0.8145)\tPrec@1 75.000 (82.952)\n",
            "Epoch: [133][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.8445 (0.8234)\tPrec@1 79.688 (82.846)\n",
            "Epoch: [133][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.9597 (0.8314)\tPrec@1 80.000 (82.726)\n",
            "Total time : 49.038\n",
            "Train Loss: 0.8314, Train Accuracy: 0.8273\n",
            "Test Loss : 1.0709, Test Accuracy : 0.7020 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.653 (0.653)\tData 0.451 (0.451)\tLoss 0.8229 (0.8229)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [134][100/391]\tTime 0.125 (0.129)\tData 0.000 (0.005)\tLoss 0.8504 (0.7916)\tPrec@1 80.469 (83.594)\n",
            "Epoch: [134][200/391]\tTime 0.128 (0.126)\tData 0.000 (0.003)\tLoss 0.8185 (0.7920)\tPrec@1 81.250 (83.590)\n",
            "Epoch: [134][300/391]\tTime 0.131 (0.126)\tData 0.000 (0.003)\tLoss 0.8829 (0.8014)\tPrec@1 82.031 (83.480)\n",
            "Epoch: [134][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.7254 (0.8150)\tPrec@1 90.000 (83.092)\n",
            "Total time : 48.939\n",
            "Train Loss: 0.8150, Train Accuracy: 0.8309\n",
            "Test Loss : 1.0736, Test Accuracy : 0.7050 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.643 (0.643)\tData 0.435 (0.435)\tLoss 0.5686 (0.5686)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [135][100/391]\tTime 0.142 (0.129)\tData 0.012 (0.006)\tLoss 0.7353 (0.7858)\tPrec@1 84.375 (83.400)\n",
            "Epoch: [135][200/391]\tTime 0.135 (0.126)\tData 0.013 (0.003)\tLoss 0.9126 (0.7895)\tPrec@1 85.938 (83.644)\n",
            "Epoch: [135][300/391]\tTime 0.131 (0.126)\tData 0.000 (0.003)\tLoss 0.8391 (0.7954)\tPrec@1 83.594 (83.544)\n",
            "Epoch: [135][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.8081 (0.7991)\tPrec@1 78.750 (83.534)\n",
            "Total time : 48.819\n",
            "Train Loss: 0.7991, Train Accuracy: 0.8353\n",
            "Test Loss : 1.0474, Test Accuracy : 0.7097 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.454 (0.454)\tData 0.285 (0.285)\tLoss 0.7591 (0.7591)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [136][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.7330 (0.7541)\tPrec@1 88.281 (84.762)\n",
            "Epoch: [136][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.7151 (0.7623)\tPrec@1 88.281 (84.387)\n",
            "Epoch: [136][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.8600 (0.7754)\tPrec@1 78.125 (84.141)\n",
            "Epoch: [136][390/391]\tTime 0.094 (0.125)\tData 0.000 (0.002)\tLoss 0.8734 (0.7816)\tPrec@1 80.000 (83.974)\n",
            "Total time : 48.812\n",
            "Train Loss: 0.7816, Train Accuracy: 0.8397\n",
            "Test Loss : 1.0298, Test Accuracy : 0.7147 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.436 (0.436)\tData 0.284 (0.284)\tLoss 0.6749 (0.6749)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [137][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.8304 (0.7502)\tPrec@1 81.250 (84.398)\n",
            "Epoch: [137][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.003)\tLoss 0.9171 (0.7518)\tPrec@1 82.031 (84.426)\n",
            "Epoch: [137][300/391]\tTime 0.126 (0.125)\tData 0.002 (0.002)\tLoss 0.8590 (0.7587)\tPrec@1 83.594 (84.320)\n",
            "Epoch: [137][390/391]\tTime 0.092 (0.124)\tData 0.000 (0.002)\tLoss 0.8997 (0.7673)\tPrec@1 82.500 (84.082)\n",
            "Total time : 48.618\n",
            "Train Loss: 0.7673, Train Accuracy: 0.8408\n",
            "Test Loss : 1.0579, Test Accuracy : 0.7074 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.441 (0.441)\tData 0.269 (0.269)\tLoss 0.7122 (0.7122)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [138][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.6977 (0.7028)\tPrec@1 83.594 (85.938)\n",
            "Epoch: [138][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.8366 (0.7258)\tPrec@1 86.719 (85.063)\n",
            "Epoch: [138][300/391]\tTime 0.125 (0.125)\tData 0.000 (0.002)\tLoss 0.7473 (0.7357)\tPrec@1 84.375 (84.904)\n",
            "Epoch: [138][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 1.0982 (0.7432)\tPrec@1 80.000 (84.760)\n",
            "Total time : 48.844\n",
            "Train Loss: 0.7432, Train Accuracy: 0.8476\n",
            "Test Loss : 1.0511, Test Accuracy : 0.7146 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.482 (0.482)\tData 0.349 (0.349)\tLoss 0.6343 (0.6343)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [139][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 0.7010 (0.6973)\tPrec@1 82.031 (86.038)\n",
            "Epoch: [139][200/391]\tTime 0.121 (0.126)\tData 0.001 (0.003)\tLoss 0.8611 (0.7212)\tPrec@1 83.594 (85.195)\n",
            "Epoch: [139][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.7115 (0.7305)\tPrec@1 84.375 (85.086)\n",
            "Epoch: [139][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.9102 (0.7368)\tPrec@1 86.250 (85.000)\n",
            "Total time : 48.798\n",
            "Train Loss: 0.7368, Train Accuracy: 0.8500\n",
            "Test Loss : 1.0252, Test Accuracy : 0.7195 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.408 (0.408)\tData 0.236 (0.236)\tLoss 0.6688 (0.6688)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [140][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.7756 (0.6751)\tPrec@1 82.031 (86.347)\n",
            "Epoch: [140][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.7359 (0.6990)\tPrec@1 87.500 (85.864)\n",
            "Epoch: [140][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.7149 (0.7120)\tPrec@1 86.719 (85.616)\n",
            "Epoch: [140][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.8014 (0.7227)\tPrec@1 86.250 (85.376)\n",
            "Total time : 48.774\n",
            "Train Loss: 0.7227, Train Accuracy: 0.8538\n",
            "Test Loss : 1.0188, Test Accuracy : 0.7205 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.455 (0.455)\tData 0.295 (0.295)\tLoss 0.7201 (0.7201)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [141][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.6112 (0.6692)\tPrec@1 87.500 (86.966)\n",
            "Epoch: [141][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.7071 (0.6782)\tPrec@1 84.375 (86.431)\n",
            "Epoch: [141][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6036 (0.6932)\tPrec@1 89.062 (86.034)\n",
            "Epoch: [141][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.6054 (0.7008)\tPrec@1 90.000 (85.794)\n",
            "Total time : 48.869\n",
            "Train Loss: 0.7008, Train Accuracy: 0.8579\n",
            "Test Loss : 1.0054, Test Accuracy : 0.7244 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.436 (0.436)\tData 0.274 (0.274)\tLoss 0.6312 (0.6312)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [142][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.005)\tLoss 0.7319 (0.6718)\tPrec@1 84.375 (86.340)\n",
            "Epoch: [142][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.6321 (0.6804)\tPrec@1 89.062 (86.381)\n",
            "Epoch: [142][300/391]\tTime 0.124 (0.125)\tData 0.000 (0.002)\tLoss 0.7000 (0.6870)\tPrec@1 86.719 (86.109)\n",
            "Epoch: [142][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.7880 (0.6929)\tPrec@1 87.500 (86.024)\n",
            "Total time : 48.712\n",
            "Train Loss: 0.6929, Train Accuracy: 0.8602\n",
            "Test Loss : 1.0102, Test Accuracy : 0.7210 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.378 (0.378)\tData 0.224 (0.224)\tLoss 0.7229 (0.7229)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [143][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.6051 (0.6371)\tPrec@1 88.281 (87.500)\n",
            "Epoch: [143][200/391]\tTime 0.120 (0.125)\tData 0.000 (0.002)\tLoss 0.6650 (0.6559)\tPrec@1 86.719 (87.026)\n",
            "Epoch: [143][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.6834 (0.6591)\tPrec@1 85.938 (86.797)\n",
            "Epoch: [143][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.5980 (0.6660)\tPrec@1 92.500 (86.606)\n",
            "Total time : 48.715\n",
            "Train Loss: 0.6660, Train Accuracy: 0.8661\n",
            "Test Loss : 0.9913, Test Accuracy : 0.7257 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.448 (0.448)\tData 0.273 (0.273)\tLoss 0.5080 (0.5080)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [144][100/391]\tTime 0.121 (0.127)\tData 0.001 (0.004)\tLoss 0.6957 (0.6467)\tPrec@1 86.719 (86.897)\n",
            "Epoch: [144][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 0.6655 (0.6541)\tPrec@1 82.031 (86.637)\n",
            "Epoch: [144][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.7722 (0.6588)\tPrec@1 82.812 (86.490)\n",
            "Epoch: [144][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.7266 (0.6616)\tPrec@1 90.000 (86.442)\n",
            "Total time : 48.895\n",
            "Train Loss: 0.6616, Train Accuracy: 0.8644\n",
            "Test Loss : 1.0090, Test Accuracy : 0.7222 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.380 (0.380)\tData 0.210 (0.210)\tLoss 0.8062 (0.8062)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [145][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.5496 (0.6127)\tPrec@1 88.281 (87.941)\n",
            "Epoch: [145][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.7665 (0.6303)\tPrec@1 82.812 (87.341)\n",
            "Epoch: [145][300/391]\tTime 0.125 (0.125)\tData 0.000 (0.002)\tLoss 0.7346 (0.6368)\tPrec@1 82.031 (87.111)\n",
            "Epoch: [145][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.6986 (0.6448)\tPrec@1 88.750 (86.992)\n",
            "Total time : 48.871\n",
            "Train Loss: 0.6448, Train Accuracy: 0.8699\n",
            "Test Loss : 0.9775, Test Accuracy : 0.7292 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.449 (0.449)\tData 0.285 (0.285)\tLoss 0.6761 (0.6761)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [146][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4691 (0.5953)\tPrec@1 91.406 (88.072)\n",
            "Epoch: [146][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.6766 (0.5999)\tPrec@1 85.938 (87.928)\n",
            "Epoch: [146][300/391]\tTime 0.125 (0.125)\tData 0.000 (0.002)\tLoss 0.6700 (0.6176)\tPrec@1 86.719 (87.534)\n",
            "Epoch: [146][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.6148 (0.6248)\tPrec@1 90.000 (87.336)\n",
            "Total time : 48.763\n",
            "Train Loss: 0.6248, Train Accuracy: 0.8734\n",
            "Test Loss : 0.9940, Test Accuracy : 0.7280 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.461 (0.461)\tData 0.335 (0.335)\tLoss 0.5126 (0.5126)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [147][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.6339 (0.6058)\tPrec@1 87.500 (87.701)\n",
            "Epoch: [147][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 0.6615 (0.6038)\tPrec@1 89.062 (88.040)\n",
            "Epoch: [147][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.6996 (0.6068)\tPrec@1 81.250 (87.840)\n",
            "Epoch: [147][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.6358 (0.6121)\tPrec@1 90.000 (87.696)\n",
            "Total time : 48.722\n",
            "Train Loss: 0.6121, Train Accuracy: 0.8770\n",
            "Test Loss : 1.0189, Test Accuracy : 0.7220 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.401 (0.401)\tData 0.237 (0.237)\tLoss 0.6184 (0.6184)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [148][100/391]\tTime 0.126 (0.127)\tData 0.006 (0.004)\tLoss 0.5885 (0.5740)\tPrec@1 91.406 (88.691)\n",
            "Epoch: [148][200/391]\tTime 0.125 (0.126)\tData 0.000 (0.003)\tLoss 0.6151 (0.5780)\tPrec@1 85.156 (88.612)\n",
            "Epoch: [148][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4703 (0.5799)\tPrec@1 92.188 (88.489)\n",
            "Epoch: [148][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.5099 (0.5862)\tPrec@1 92.500 (88.372)\n",
            "Total time : 48.859\n",
            "Train Loss: 0.5862, Train Accuracy: 0.8837\n",
            "Test Loss : 0.9885, Test Accuracy : 0.7269 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.485 (0.485)\tData 0.300 (0.300)\tLoss 0.6613 (0.6613)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [149][100/391]\tTime 0.123 (0.128)\tData 0.004 (0.004)\tLoss 0.4899 (0.5641)\tPrec@1 93.750 (88.629)\n",
            "Epoch: [149][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.5527 (0.5706)\tPrec@1 89.062 (88.549)\n",
            "Epoch: [149][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.5137 (0.5775)\tPrec@1 92.188 (88.351)\n",
            "Epoch: [149][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.6108 (0.5801)\tPrec@1 88.750 (88.286)\n",
            "Total time : 48.936\n",
            "Train Loss: 0.5801, Train Accuracy: 0.8829\n",
            "Test Loss : 0.9913, Test Accuracy : 0.7298 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.340 (0.340)\tData 0.190 (0.190)\tLoss 0.5449 (0.5449)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [150][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.003)\tLoss 0.5262 (0.5469)\tPrec@1 90.625 (89.217)\n",
            "Epoch: [150][200/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4180 (0.5493)\tPrec@1 92.188 (89.152)\n",
            "Epoch: [150][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4742 (0.5576)\tPrec@1 92.188 (88.912)\n",
            "Epoch: [150][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.7968 (0.5615)\tPrec@1 81.250 (88.800)\n",
            "Total time : 48.720\n",
            "Train Loss: 0.5615, Train Accuracy: 0.8880\n",
            "Test Loss : 0.9673, Test Accuracy : 0.7338 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.468 (0.468)\tData 0.281 (0.281)\tLoss 0.5349 (0.5349)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [151][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 0.4917 (0.5261)\tPrec@1 89.062 (89.720)\n",
            "Epoch: [151][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.5635 (0.5366)\tPrec@1 85.156 (89.440)\n",
            "Epoch: [151][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.5490 (0.5426)\tPrec@1 89.844 (89.187)\n",
            "Epoch: [151][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5094 (0.5507)\tPrec@1 95.000 (89.066)\n",
            "Total time : 48.887\n",
            "Train Loss: 0.5507, Train Accuracy: 0.8907\n",
            "Test Loss : 0.9978, Test Accuracy : 0.7323 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.449 (0.449)\tData 0.284 (0.284)\tLoss 0.5349 (0.5349)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [152][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.4100 (0.5193)\tPrec@1 93.750 (89.975)\n",
            "Epoch: [152][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.4566 (0.5250)\tPrec@1 92.969 (89.568)\n",
            "Epoch: [152][300/391]\tTime 0.125 (0.125)\tData 0.000 (0.002)\tLoss 0.4198 (0.5375)\tPrec@1 93.750 (89.371)\n",
            "Epoch: [152][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.5056 (0.5426)\tPrec@1 91.250 (89.202)\n",
            "Total time : 48.916\n",
            "Train Loss: 0.5426, Train Accuracy: 0.8920\n",
            "Test Loss : 0.9628, Test Accuracy : 0.7307 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.440 (0.440)\tData 0.284 (0.284)\tLoss 0.6668 (0.6668)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [153][100/391]\tTime 0.124 (0.127)\tData 0.000 (0.004)\tLoss 0.6418 (0.5166)\tPrec@1 85.938 (90.114)\n",
            "Epoch: [153][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.6033 (0.5138)\tPrec@1 87.500 (90.061)\n",
            "Epoch: [153][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.6024 (0.5213)\tPrec@1 89.062 (89.750)\n",
            "Epoch: [153][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4783 (0.5256)\tPrec@1 93.750 (89.610)\n",
            "Total time : 48.747\n",
            "Train Loss: 0.5256, Train Accuracy: 0.8961\n",
            "Test Loss : 0.9640, Test Accuracy : 0.7357 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.467 (0.467)\tData 0.337 (0.337)\tLoss 0.5043 (0.5043)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [154][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.5676 (0.4825)\tPrec@1 90.625 (90.370)\n",
            "Epoch: [154][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.4597 (0.4945)\tPrec@1 90.625 (90.244)\n",
            "Epoch: [154][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4729 (0.4993)\tPrec@1 92.188 (90.108)\n",
            "Epoch: [154][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5928 (0.5049)\tPrec@1 86.250 (90.028)\n",
            "Total time : 48.873\n",
            "Train Loss: 0.5049, Train Accuracy: 0.9003\n",
            "Test Loss : 0.9480, Test Accuracy : 0.7411 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.439 (0.439)\tData 0.273 (0.273)\tLoss 0.5207 (0.5207)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [155][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.004)\tLoss 0.4740 (0.4728)\tPrec@1 91.406 (90.880)\n",
            "Epoch: [155][200/391]\tTime 0.122 (0.126)\tData 0.001 (0.003)\tLoss 0.4794 (0.4783)\tPrec@1 90.625 (90.489)\n",
            "Epoch: [155][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.6751 (0.4849)\tPrec@1 84.375 (90.451)\n",
            "Epoch: [155][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4850 (0.4935)\tPrec@1 92.500 (90.228)\n",
            "Total time : 48.871\n",
            "Train Loss: 0.4935, Train Accuracy: 0.9023\n",
            "Test Loss : 0.9361, Test Accuracy : 0.7420 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.477 (0.477)\tData 0.285 (0.285)\tLoss 0.4868 (0.4868)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [156][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.4234 (0.4591)\tPrec@1 95.312 (91.190)\n",
            "Epoch: [156][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.4954 (0.4673)\tPrec@1 89.062 (90.858)\n",
            "Epoch: [156][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4664 (0.4771)\tPrec@1 89.844 (90.602)\n",
            "Epoch: [156][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.5878 (0.4797)\tPrec@1 86.250 (90.576)\n",
            "Total time : 48.772\n",
            "Train Loss: 0.4797, Train Accuracy: 0.9058\n",
            "Test Loss : 0.9516, Test Accuracy : 0.7384 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.620 (0.620)\tData 0.433 (0.433)\tLoss 0.4108 (0.4108)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [157][100/391]\tTime 0.134 (0.129)\tData 0.012 (0.005)\tLoss 0.3527 (0.4518)\tPrec@1 92.969 (91.166)\n",
            "Epoch: [157][200/391]\tTime 0.131 (0.127)\tData 0.000 (0.003)\tLoss 0.4334 (0.4510)\tPrec@1 90.625 (91.189)\n",
            "Epoch: [157][300/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.4944 (0.4565)\tPrec@1 89.062 (91.017)\n",
            "Epoch: [157][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.5161 (0.4583)\tPrec@1 88.750 (90.958)\n",
            "Total time : 49.001\n",
            "Train Loss: 0.4583, Train Accuracy: 0.9096\n",
            "Test Loss : 0.9348, Test Accuracy : 0.7437 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.554 (0.554)\tData 0.390 (0.390)\tLoss 0.3790 (0.3790)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [158][100/391]\tTime 0.144 (0.129)\tData 0.012 (0.005)\tLoss 0.5015 (0.4346)\tPrec@1 92.188 (91.368)\n",
            "Epoch: [158][200/391]\tTime 0.148 (0.126)\tData 0.013 (0.003)\tLoss 0.4082 (0.4435)\tPrec@1 93.750 (91.165)\n",
            "Epoch: [158][300/391]\tTime 0.120 (0.126)\tData 0.000 (0.002)\tLoss 0.4992 (0.4489)\tPrec@1 89.062 (91.064)\n",
            "Epoch: [158][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.5008 (0.4508)\tPrec@1 90.000 (91.004)\n",
            "Total time : 48.858\n",
            "Train Loss: 0.4508, Train Accuracy: 0.9100\n",
            "Test Loss : 0.9138, Test Accuracy : 0.7515 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.659 (0.659)\tData 0.450 (0.450)\tLoss 0.3147 (0.3147)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [159][100/391]\tTime 0.138 (0.129)\tData 0.003 (0.006)\tLoss 0.3479 (0.4103)\tPrec@1 91.406 (91.963)\n",
            "Epoch: [159][200/391]\tTime 0.132 (0.126)\tData 0.008 (0.003)\tLoss 0.4227 (0.4177)\tPrec@1 93.750 (91.772)\n",
            "Epoch: [159][300/391]\tTime 0.126 (0.125)\tData 0.000 (0.003)\tLoss 0.4381 (0.4240)\tPrec@1 85.938 (91.609)\n",
            "Epoch: [159][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.6388 (0.4292)\tPrec@1 88.750 (91.552)\n",
            "Total time : 48.827\n",
            "Train Loss: 0.4292, Train Accuracy: 0.9155\n",
            "Test Loss : 0.9340, Test Accuracy : 0.7410 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.428 (0.428)\tData 0.270 (0.270)\tLoss 0.4069 (0.4069)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [160][100/391]\tTime 0.125 (0.127)\tData 0.000 (0.004)\tLoss 0.3969 (0.3956)\tPrec@1 90.625 (92.203)\n",
            "Epoch: [160][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.5070 (0.4094)\tPrec@1 91.406 (92.020)\n",
            "Epoch: [160][300/391]\tTime 0.126 (0.125)\tData 0.007 (0.002)\tLoss 0.4441 (0.4144)\tPrec@1 89.844 (91.905)\n",
            "Epoch: [160][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.3102 (0.4182)\tPrec@1 96.250 (91.800)\n",
            "Total time : 48.525\n",
            "Train Loss: 0.4182, Train Accuracy: 0.9180\n",
            "Test Loss : 0.9215, Test Accuracy : 0.7500 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.347 (0.347)\tData 0.175 (0.175)\tLoss 0.4080 (0.4080)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [161][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 0.3756 (0.4016)\tPrec@1 92.188 (92.118)\n",
            "Epoch: [161][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.4987 (0.4046)\tPrec@1 91.406 (92.013)\n",
            "Epoch: [161][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.4024 (0.4090)\tPrec@1 90.625 (91.936)\n",
            "Epoch: [161][390/391]\tTime 0.087 (0.124)\tData 0.000 (0.002)\tLoss 0.5690 (0.4116)\tPrec@1 90.000 (91.912)\n",
            "Total time : 48.668\n",
            "Train Loss: 0.4116, Train Accuracy: 0.9191\n",
            "Test Loss : 0.9111, Test Accuracy : 0.7526 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.444 (0.444)\tData 0.278 (0.278)\tLoss 0.4415 (0.4415)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [162][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.5101 (0.3921)\tPrec@1 91.406 (92.613)\n",
            "Epoch: [162][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.3252 (0.3937)\tPrec@1 95.312 (92.452)\n",
            "Epoch: [162][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3865 (0.3961)\tPrec@1 93.750 (92.325)\n",
            "Epoch: [162][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3705 (0.3991)\tPrec@1 91.250 (92.218)\n",
            "Total time : 48.743\n",
            "Train Loss: 0.3991, Train Accuracy: 0.9222\n",
            "Test Loss : 0.9113, Test Accuracy : 0.7561 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.410 (0.410)\tData 0.271 (0.271)\tLoss 0.3991 (0.3991)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [163][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.4112 (0.3708)\tPrec@1 93.750 (92.690)\n",
            "Epoch: [163][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.3321 (0.3798)\tPrec@1 92.969 (92.701)\n",
            "Epoch: [163][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2969 (0.3828)\tPrec@1 94.531 (92.675)\n",
            "Epoch: [163][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4842 (0.3849)\tPrec@1 88.750 (92.614)\n",
            "Total time : 48.708\n",
            "Train Loss: 0.3849, Train Accuracy: 0.9261\n",
            "Test Loss : 0.9288, Test Accuracy : 0.7513 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.440 (0.440)\tData 0.271 (0.271)\tLoss 0.4737 (0.4737)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [164][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4698 (0.3602)\tPrec@1 90.625 (93.077)\n",
            "Epoch: [164][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.3585 (0.3645)\tPrec@1 93.750 (93.070)\n",
            "Epoch: [164][300/391]\tTime 0.127 (0.126)\tData 0.007 (0.002)\tLoss 0.3451 (0.3631)\tPrec@1 96.094 (93.101)\n",
            "Epoch: [164][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.4738 (0.3671)\tPrec@1 92.500 (92.902)\n",
            "Total time : 48.971\n",
            "Train Loss: 0.3671, Train Accuracy: 0.9290\n",
            "Test Loss : 0.9058, Test Accuracy : 0.7532 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.452 (0.452)\tData 0.262 (0.262)\tLoss 0.4189 (0.4189)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [165][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3971 (0.3427)\tPrec@1 90.625 (93.356)\n",
            "Epoch: [165][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.2609 (0.3485)\tPrec@1 93.750 (93.361)\n",
            "Epoch: [165][300/391]\tTime 0.131 (0.125)\tData 0.000 (0.002)\tLoss 0.3649 (0.3523)\tPrec@1 91.406 (93.223)\n",
            "Epoch: [165][390/391]\tTime 0.091 (0.124)\tData 0.000 (0.002)\tLoss 0.3089 (0.3575)\tPrec@1 96.250 (93.118)\n",
            "Total time : 48.657\n",
            "Train Loss: 0.3575, Train Accuracy: 0.9312\n",
            "Test Loss : 0.9042, Test Accuracy : 0.7568 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.491 (0.491)\tData 0.339 (0.339)\tLoss 0.3236 (0.3236)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [166][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.3597 (0.3452)\tPrec@1 93.750 (93.294)\n",
            "Epoch: [166][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.3106 (0.3493)\tPrec@1 94.531 (93.167)\n",
            "Epoch: [166][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2957 (0.3496)\tPrec@1 95.312 (93.192)\n",
            "Epoch: [166][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.2861 (0.3485)\tPrec@1 96.250 (93.188)\n",
            "Total time : 48.752\n",
            "Train Loss: 0.3485, Train Accuracy: 0.9319\n",
            "Test Loss : 0.8969, Test Accuracy : 0.7556 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.454 (0.454)\tData 0.301 (0.301)\tLoss 0.3915 (0.3915)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [167][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4978 (0.3324)\tPrec@1 89.844 (93.897)\n",
            "Epoch: [167][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.3420 (0.3343)\tPrec@1 90.625 (93.715)\n",
            "Epoch: [167][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.3530 (0.3368)\tPrec@1 92.969 (93.628)\n",
            "Epoch: [167][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3430 (0.3391)\tPrec@1 93.750 (93.400)\n",
            "Total time : 48.755\n",
            "Train Loss: 0.3391, Train Accuracy: 0.9340\n",
            "Test Loss : 0.9099, Test Accuracy : 0.7542 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.417 (0.417)\tData 0.284 (0.284)\tLoss 0.2862 (0.2862)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [168][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.3468 (0.3211)\tPrec@1 92.969 (93.696)\n",
            "Epoch: [168][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.3184 (0.3197)\tPrec@1 92.188 (93.661)\n",
            "Epoch: [168][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3293 (0.3223)\tPrec@1 95.312 (93.638)\n",
            "Epoch: [168][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.4669 (0.3205)\tPrec@1 91.250 (93.742)\n",
            "Total time : 48.697\n",
            "Train Loss: 0.3205, Train Accuracy: 0.9374\n",
            "Test Loss : 0.9043, Test Accuracy : 0.7600 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.437 (0.437)\tData 0.302 (0.302)\tLoss 0.3300 (0.3300)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [169][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3287 (0.3064)\tPrec@1 96.094 (94.152)\n",
            "Epoch: [169][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2984 (0.3085)\tPrec@1 92.969 (94.034)\n",
            "Epoch: [169][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3659 (0.3120)\tPrec@1 93.750 (93.926)\n",
            "Epoch: [169][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3791 (0.3169)\tPrec@1 93.750 (93.788)\n",
            "Total time : 48.756\n",
            "Train Loss: 0.3169, Train Accuracy: 0.9379\n",
            "Test Loss : 0.9227, Test Accuracy : 0.7582 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.455 (0.455)\tData 0.309 (0.309)\tLoss 0.4159 (0.4159)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [170][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3195 (0.3142)\tPrec@1 93.750 (94.121)\n",
            "Epoch: [170][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.2797 (0.3078)\tPrec@1 96.875 (94.170)\n",
            "Epoch: [170][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2926 (0.3108)\tPrec@1 93.750 (94.093)\n",
            "Epoch: [170][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2366 (0.3099)\tPrec@1 96.250 (94.082)\n",
            "Total time : 48.819\n",
            "Train Loss: 0.3099, Train Accuracy: 0.9408\n",
            "Test Loss : 0.9046, Test Accuracy : 0.7610 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.434 (0.434)\tData 0.273 (0.273)\tLoss 0.3286 (0.3286)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [171][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.3494 (0.2940)\tPrec@1 96.094 (94.609)\n",
            "Epoch: [171][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2817 (0.2995)\tPrec@1 95.312 (94.290)\n",
            "Epoch: [171][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2558 (0.3016)\tPrec@1 96.094 (94.215)\n",
            "Epoch: [171][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2301 (0.3019)\tPrec@1 97.500 (94.264)\n",
            "Total time : 48.857\n",
            "Train Loss: 0.3019, Train Accuracy: 0.9426\n",
            "Test Loss : 0.9055, Test Accuracy : 0.7581 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.447 (0.447)\tData 0.285 (0.285)\tLoss 0.2682 (0.2682)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [172][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2735 (0.2910)\tPrec@1 92.969 (94.570)\n",
            "Epoch: [172][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.2618 (0.2895)\tPrec@1 96.094 (94.520)\n",
            "Epoch: [172][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2219 (0.2924)\tPrec@1 94.531 (94.381)\n",
            "Epoch: [172][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3989 (0.2956)\tPrec@1 91.250 (94.318)\n",
            "Total time : 48.738\n",
            "Train Loss: 0.2956, Train Accuracy: 0.9432\n",
            "Test Loss : 0.8961, Test Accuracy : 0.7614 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.426 (0.426)\tData 0.281 (0.281)\tLoss 0.3641 (0.3641)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [173][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.3517 (0.2771)\tPrec@1 94.531 (94.709)\n",
            "Epoch: [173][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.2088 (0.2720)\tPrec@1 96.875 (94.815)\n",
            "Epoch: [173][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2982 (0.2752)\tPrec@1 93.750 (94.739)\n",
            "Epoch: [173][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3333 (0.2760)\tPrec@1 93.750 (94.682)\n",
            "Total time : 48.745\n",
            "Train Loss: 0.2760, Train Accuracy: 0.9468\n",
            "Test Loss : 0.9027, Test Accuracy : 0.7642 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.512 (0.512)\tData 0.314 (0.314)\tLoss 0.2412 (0.2412)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [174][100/391]\tTime 0.123 (0.129)\tData 0.000 (0.005)\tLoss 0.1941 (0.2684)\tPrec@1 99.219 (95.158)\n",
            "Epoch: [174][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.2861 (0.2727)\tPrec@1 95.312 (94.866)\n",
            "Epoch: [174][300/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.3412 (0.2741)\tPrec@1 94.531 (94.770)\n",
            "Epoch: [174][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.3114 (0.2742)\tPrec@1 95.000 (94.682)\n",
            "Total time : 48.928\n",
            "Train Loss: 0.2742, Train Accuracy: 0.9468\n",
            "Test Loss : 0.9105, Test Accuracy : 0.7658 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.480 (0.480)\tData 0.321 (0.321)\tLoss 0.2817 (0.2817)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [175][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.4187 (0.2639)\tPrec@1 89.062 (94.663)\n",
            "Epoch: [175][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.2575 (0.2630)\tPrec@1 94.531 (94.784)\n",
            "Epoch: [175][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2810 (0.2654)\tPrec@1 94.531 (94.747)\n",
            "Epoch: [175][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.4319 (0.2687)\tPrec@1 92.500 (94.694)\n",
            "Total time : 48.851\n",
            "Train Loss: 0.2687, Train Accuracy: 0.9469\n",
            "Test Loss : 0.9055, Test Accuracy : 0.7644 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.427 (0.427)\tData 0.255 (0.255)\tLoss 0.2653 (0.2653)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [176][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.4148 (0.2585)\tPrec@1 88.281 (95.050)\n",
            "Epoch: [176][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.2189 (0.2573)\tPrec@1 95.312 (95.099)\n",
            "Epoch: [176][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3157 (0.2573)\tPrec@1 93.750 (95.061)\n",
            "Epoch: [176][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2620 (0.2578)\tPrec@1 95.000 (95.050)\n",
            "Total time : 48.748\n",
            "Train Loss: 0.2578, Train Accuracy: 0.9505\n",
            "Test Loss : 0.9033, Test Accuracy : 0.7640 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.439 (0.439)\tData 0.290 (0.290)\tLoss 0.2370 (0.2370)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [177][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.2607 (0.2517)\tPrec@1 96.094 (95.011)\n",
            "Epoch: [177][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.002)\tLoss 0.2960 (0.2496)\tPrec@1 95.312 (95.013)\n",
            "Epoch: [177][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1816 (0.2505)\tPrec@1 97.656 (95.030)\n",
            "Epoch: [177][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.2691 (0.2505)\tPrec@1 96.250 (95.024)\n",
            "Total time : 48.840\n",
            "Train Loss: 0.2505, Train Accuracy: 0.9502\n",
            "Test Loss : 0.8989, Test Accuracy : 0.7667 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.424 (0.424)\tData 0.274 (0.274)\tLoss 0.3251 (0.3251)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [178][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.2435 (0.2541)\tPrec@1 96.094 (95.204)\n",
            "Epoch: [178][200/391]\tTime 0.121 (0.125)\tData 0.000 (0.003)\tLoss 0.1928 (0.2527)\tPrec@1 96.875 (95.204)\n",
            "Epoch: [178][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1909 (0.2483)\tPrec@1 97.656 (95.222)\n",
            "Epoch: [178][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1513 (0.2454)\tPrec@1 100.000 (95.278)\n",
            "Total time : 48.700\n",
            "Train Loss: 0.2454, Train Accuracy: 0.9528\n",
            "Test Loss : 0.9093, Test Accuracy : 0.7654 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.447 (0.447)\tData 0.310 (0.310)\tLoss 0.2737 (0.2737)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [179][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.005)\tLoss 0.2775 (0.2460)\tPrec@1 93.750 (95.204)\n",
            "Epoch: [179][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.2971 (0.2437)\tPrec@1 96.094 (95.351)\n",
            "Epoch: [179][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.2256 (0.2426)\tPrec@1 96.094 (95.375)\n",
            "Epoch: [179][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2812 (0.2429)\tPrec@1 93.750 (95.336)\n",
            "Total time : 48.940\n",
            "Train Loss: 0.2429, Train Accuracy: 0.9534\n",
            "Test Loss : 0.9115, Test Accuracy : 0.7631 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.445 (0.445)\tData 0.270 (0.270)\tLoss 0.2113 (0.2113)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [180][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.2211 (0.2330)\tPrec@1 97.656 (95.661)\n",
            "Epoch: [180][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1785 (0.2306)\tPrec@1 96.875 (95.585)\n",
            "Epoch: [180][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3738 (0.2301)\tPrec@1 92.188 (95.523)\n",
            "Epoch: [180][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3746 (0.2332)\tPrec@1 88.750 (95.478)\n",
            "Total time : 48.933\n",
            "Train Loss: 0.2332, Train Accuracy: 0.9548\n",
            "Test Loss : 0.8948, Test Accuracy : 0.7667 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.454 (0.454)\tData 0.289 (0.289)\tLoss 0.2305 (0.2305)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [181][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.004)\tLoss 0.1620 (0.2333)\tPrec@1 97.656 (95.320)\n",
            "Epoch: [181][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.002)\tLoss 0.2434 (0.2330)\tPrec@1 93.750 (95.347)\n",
            "Epoch: [181][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.3333 (0.2313)\tPrec@1 91.406 (95.453)\n",
            "Epoch: [181][390/391]\tTime 0.087 (0.125)\tData 0.000 (0.002)\tLoss 0.1128 (0.2299)\tPrec@1 97.500 (95.480)\n",
            "Total time : 48.860\n",
            "Train Loss: 0.2299, Train Accuracy: 0.9548\n",
            "Test Loss : 0.9085, Test Accuracy : 0.7677 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.463 (0.463)\tData 0.328 (0.328)\tLoss 0.1889 (0.1889)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [182][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 0.2369 (0.2148)\tPrec@1 96.094 (95.761)\n",
            "Epoch: [182][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.003)\tLoss 0.1678 (0.2185)\tPrec@1 99.219 (95.701)\n",
            "Epoch: [182][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.3017 (0.2205)\tPrec@1 92.969 (95.655)\n",
            "Epoch: [182][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3537 (0.2226)\tPrec@1 88.750 (95.598)\n",
            "Total time : 48.876\n",
            "Train Loss: 0.2226, Train Accuracy: 0.9560\n",
            "Test Loss : 0.9090, Test Accuracy : 0.7678 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.428 (0.428)\tData 0.278 (0.278)\tLoss 0.2269 (0.2269)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [183][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.1990 (0.2092)\tPrec@1 94.531 (95.993)\n",
            "Epoch: [183][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.2324 (0.2104)\tPrec@1 96.094 (96.024)\n",
            "Epoch: [183][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2154 (0.2100)\tPrec@1 94.531 (96.013)\n",
            "Epoch: [183][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1942 (0.2107)\tPrec@1 96.250 (95.998)\n",
            "Total time : 48.812\n",
            "Train Loss: 0.2107, Train Accuracy: 0.9600\n",
            "Test Loss : 0.9100, Test Accuracy : 0.7702 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.472 (0.472)\tData 0.293 (0.293)\tLoss 0.2078 (0.2078)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [184][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.004)\tLoss 0.2170 (0.2087)\tPrec@1 94.531 (95.978)\n",
            "Epoch: [184][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1461 (0.2119)\tPrec@1 97.656 (95.892)\n",
            "Epoch: [184][300/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 0.2351 (0.2151)\tPrec@1 96.094 (95.762)\n",
            "Epoch: [184][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.1700 (0.2155)\tPrec@1 98.750 (95.768)\n",
            "Total time : 49.001\n",
            "Train Loss: 0.2155, Train Accuracy: 0.9577\n",
            "Test Loss : 0.9128, Test Accuracy : 0.7696 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.446 (0.446)\tData 0.312 (0.312)\tLoss 0.2282 (0.2282)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [185][100/391]\tTime 0.123 (0.128)\tData 0.000 (0.005)\tLoss 0.2058 (0.2187)\tPrec@1 96.094 (95.738)\n",
            "Epoch: [185][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.003)\tLoss 0.2576 (0.2154)\tPrec@1 94.531 (95.806)\n",
            "Epoch: [185][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2567 (0.2142)\tPrec@1 93.750 (95.860)\n",
            "Epoch: [185][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1539 (0.2132)\tPrec@1 96.250 (95.864)\n",
            "Total time : 48.918\n",
            "Train Loss: 0.2132, Train Accuracy: 0.9586\n",
            "Test Loss : 0.9201, Test Accuracy : 0.7674 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.571 (0.571)\tData 0.404 (0.404)\tLoss 0.1547 (0.1547)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [186][100/391]\tTime 0.121 (0.129)\tData 0.000 (0.005)\tLoss 0.2206 (0.2094)\tPrec@1 93.750 (95.854)\n",
            "Epoch: [186][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1937 (0.2112)\tPrec@1 96.094 (95.857)\n",
            "Epoch: [186][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2569 (0.2122)\tPrec@1 95.312 (95.819)\n",
            "Epoch: [186][390/391]\tTime 0.090 (0.125)\tData 0.000 (0.002)\tLoss 0.3248 (0.2127)\tPrec@1 92.500 (95.756)\n",
            "Total time : 48.913\n",
            "Train Loss: 0.2127, Train Accuracy: 0.9576\n",
            "Test Loss : 0.9222, Test Accuracy : 0.7705 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.647 (0.647)\tData 0.373 (0.373)\tLoss 0.2290 (0.2290)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [187][100/391]\tTime 0.141 (0.130)\tData 0.008 (0.005)\tLoss 0.2377 (0.2157)\tPrec@1 93.750 (95.753)\n",
            "Epoch: [187][200/391]\tTime 0.132 (0.127)\tData 0.011 (0.003)\tLoss 0.2153 (0.2135)\tPrec@1 94.531 (95.783)\n",
            "Epoch: [187][300/391]\tTime 0.132 (0.126)\tData 0.000 (0.003)\tLoss 0.1955 (0.2115)\tPrec@1 95.312 (95.816)\n",
            "Epoch: [187][390/391]\tTime 0.092 (0.125)\tData 0.000 (0.002)\tLoss 0.3071 (0.2095)\tPrec@1 93.750 (95.876)\n",
            "Total time : 48.960\n",
            "Train Loss: 0.2095, Train Accuracy: 0.9588\n",
            "Test Loss : 0.9147, Test Accuracy : 0.7713 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.705 (0.705)\tData 0.449 (0.449)\tLoss 0.1977 (0.1977)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [188][100/391]\tTime 0.131 (0.130)\tData 0.000 (0.006)\tLoss 0.1626 (0.2009)\tPrec@1 96.094 (95.885)\n",
            "Epoch: [188][200/391]\tTime 0.126 (0.127)\tData 0.005 (0.003)\tLoss 0.2136 (0.2007)\tPrec@1 95.312 (95.911)\n",
            "Epoch: [188][300/391]\tTime 0.128 (0.126)\tData 0.000 (0.002)\tLoss 0.1930 (0.2025)\tPrec@1 96.875 (95.935)\n",
            "Epoch: [188][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3276 (0.2025)\tPrec@1 96.250 (95.922)\n",
            "Total time : 48.834\n",
            "Train Loss: 0.2025, Train Accuracy: 0.9592\n",
            "Test Loss : 0.9184, Test Accuracy : 0.7707 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.382 (0.382)\tData 0.192 (0.192)\tLoss 0.1551 (0.1551)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [189][100/391]\tTime 0.123 (0.127)\tData 0.000 (0.003)\tLoss 0.2780 (0.2012)\tPrec@1 92.969 (96.078)\n",
            "Epoch: [189][200/391]\tTime 0.125 (0.125)\tData 0.000 (0.002)\tLoss 0.2117 (0.2019)\tPrec@1 95.312 (96.012)\n",
            "Epoch: [189][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1823 (0.2025)\tPrec@1 96.875 (96.047)\n",
            "Epoch: [189][390/391]\tTime 0.089 (0.124)\tData 0.000 (0.002)\tLoss 0.1708 (0.2021)\tPrec@1 95.000 (96.034)\n",
            "Total time : 48.568\n",
            "Train Loss: 0.2021, Train Accuracy: 0.9603\n",
            "Test Loss : 0.9074, Test Accuracy : 0.7733 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.366 (0.366)\tData 0.226 (0.226)\tLoss 0.2206 (0.2206)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [190][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.2602 (0.2087)\tPrec@1 93.750 (95.769)\n",
            "Epoch: [190][200/391]\tTime 0.122 (0.125)\tData 0.000 (0.003)\tLoss 0.1674 (0.2026)\tPrec@1 97.656 (95.958)\n",
            "Epoch: [190][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1647 (0.1999)\tPrec@1 96.094 (96.050)\n",
            "Epoch: [190][390/391]\tTime 0.090 (0.124)\tData 0.000 (0.002)\tLoss 0.2494 (0.2006)\tPrec@1 95.000 (96.026)\n",
            "Total time : 48.634\n",
            "Train Loss: 0.2006, Train Accuracy: 0.9603\n",
            "Test Loss : 0.9193, Test Accuracy : 0.7737 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.467 (0.467)\tData 0.321 (0.321)\tLoss 0.1523 (0.1523)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [191][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.1550 (0.2019)\tPrec@1 97.656 (96.016)\n",
            "Epoch: [191][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 0.1979 (0.1995)\tPrec@1 95.312 (96.125)\n",
            "Epoch: [191][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.1661 (0.1983)\tPrec@1 97.656 (96.172)\n",
            "Epoch: [191][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.3137 (0.1983)\tPrec@1 91.250 (96.148)\n",
            "Total time : 48.768\n",
            "Train Loss: 0.1983, Train Accuracy: 0.9615\n",
            "Test Loss : 0.9182, Test Accuracy : 0.7708 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.504 (0.504)\tData 0.328 (0.328)\tLoss 0.1617 (0.1617)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [192][100/391]\tTime 0.120 (0.128)\tData 0.000 (0.004)\tLoss 0.1408 (0.1981)\tPrec@1 96.094 (96.148)\n",
            "Epoch: [192][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.1944 (0.1978)\tPrec@1 95.312 (96.125)\n",
            "Epoch: [192][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.2031 (0.1991)\tPrec@1 95.312 (96.076)\n",
            "Epoch: [192][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2432 (0.2006)\tPrec@1 93.750 (95.998)\n",
            "Total time : 48.834\n",
            "Train Loss: 0.2006, Train Accuracy: 0.9600\n",
            "Test Loss : 0.9108, Test Accuracy : 0.7710 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.484 (0.484)\tData 0.317 (0.317)\tLoss 0.2090 (0.2090)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [193][100/391]\tTime 0.121 (0.128)\tData 0.000 (0.005)\tLoss 0.1530 (0.1925)\tPrec@1 96.094 (96.210)\n",
            "Epoch: [193][200/391]\tTime 0.124 (0.126)\tData 0.000 (0.003)\tLoss 0.1703 (0.1938)\tPrec@1 96.875 (96.078)\n",
            "Epoch: [193][300/391]\tTime 0.123 (0.125)\tData 0.000 (0.002)\tLoss 0.2208 (0.1953)\tPrec@1 95.312 (95.954)\n",
            "Epoch: [193][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1922 (0.1953)\tPrec@1 97.500 (95.994)\n",
            "Total time : 48.840\n",
            "Train Loss: 0.1953, Train Accuracy: 0.9599\n",
            "Test Loss : 0.9134, Test Accuracy : 0.7741 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.458 (0.458)\tData 0.285 (0.285)\tLoss 0.2057 (0.2057)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [194][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.004)\tLoss 0.1955 (0.1905)\tPrec@1 94.531 (96.318)\n",
            "Epoch: [194][200/391]\tTime 0.122 (0.126)\tData 0.000 (0.003)\tLoss 0.2389 (0.1973)\tPrec@1 93.750 (96.137)\n",
            "Epoch: [194][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1910 (0.1959)\tPrec@1 96.875 (96.216)\n",
            "Epoch: [194][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1397 (0.1958)\tPrec@1 96.250 (96.142)\n",
            "Total time : 48.829\n",
            "Train Loss: 0.1958, Train Accuracy: 0.9614\n",
            "Test Loss : 0.9180, Test Accuracy : 0.7711 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.440 (0.440)\tData 0.302 (0.302)\tLoss 0.1481 (0.1481)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [195][100/391]\tTime 0.122 (0.128)\tData 0.000 (0.005)\tLoss 0.2051 (0.1988)\tPrec@1 96.094 (96.086)\n",
            "Epoch: [195][200/391]\tTime 0.120 (0.126)\tData 0.000 (0.003)\tLoss 0.1439 (0.1953)\tPrec@1 96.875 (96.067)\n",
            "Epoch: [195][300/391]\tTime 0.126 (0.125)\tData 0.000 (0.002)\tLoss 0.1834 (0.1974)\tPrec@1 96.875 (96.083)\n",
            "Epoch: [195][390/391]\tTime 0.088 (0.125)\tData 0.000 (0.002)\tLoss 0.2224 (0.1966)\tPrec@1 96.250 (96.138)\n",
            "Total time : 48.835\n",
            "Train Loss: 0.1966, Train Accuracy: 0.9614\n",
            "Test Loss : 0.9253, Test Accuracy : 0.7725 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.483 (0.483)\tData 0.303 (0.303)\tLoss 0.2271 (0.2271)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [196][100/391]\tTime 0.121 (0.127)\tData 0.000 (0.004)\tLoss 0.2298 (0.1936)\tPrec@1 94.531 (96.117)\n",
            "Epoch: [196][200/391]\tTime 0.123 (0.126)\tData 0.000 (0.003)\tLoss 0.1853 (0.1963)\tPrec@1 96.875 (96.094)\n",
            "Epoch: [196][300/391]\tTime 0.121 (0.125)\tData 0.000 (0.002)\tLoss 0.1765 (0.1944)\tPrec@1 96.094 (96.143)\n",
            "Epoch: [196][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.1330 (0.1954)\tPrec@1 97.500 (96.088)\n",
            "Total time : 48.917\n",
            "Train Loss: 0.1954, Train Accuracy: 0.9609\n",
            "Test Loss : 0.9139, Test Accuracy : 0.7739 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.452 (0.452)\tData 0.280 (0.280)\tLoss 0.2181 (0.2181)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [197][100/391]\tTime 0.122 (0.127)\tData 0.000 (0.004)\tLoss 0.1778 (0.1929)\tPrec@1 96.094 (96.326)\n",
            "Epoch: [197][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.002)\tLoss 0.1043 (0.1892)\tPrec@1 98.438 (96.385)\n",
            "Epoch: [197][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1439 (0.1907)\tPrec@1 98.438 (96.262)\n",
            "Epoch: [197][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2735 (0.1910)\tPrec@1 93.750 (96.222)\n",
            "Total time : 48.782\n",
            "Train Loss: 0.1910, Train Accuracy: 0.9622\n",
            "Test Loss : 0.9090, Test Accuracy : 0.7739 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.448 (0.448)\tData 0.281 (0.281)\tLoss 0.1369 (0.1369)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [198][100/391]\tTime 0.120 (0.128)\tData 0.000 (0.004)\tLoss 0.3313 (0.1912)\tPrec@1 92.969 (96.364)\n",
            "Epoch: [198][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.1280 (0.1953)\tPrec@1 98.438 (96.090)\n",
            "Epoch: [198][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.2127 (0.1934)\tPrec@1 96.094 (96.182)\n",
            "Epoch: [198][390/391]\tTime 0.091 (0.125)\tData 0.000 (0.002)\tLoss 0.2156 (0.1946)\tPrec@1 96.250 (96.142)\n",
            "Total time : 48.867\n",
            "Train Loss: 0.1946, Train Accuracy: 0.9614\n",
            "Test Loss : 0.9197, Test Accuracy : 0.7729 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.440 (0.440)\tData 0.278 (0.278)\tLoss 0.2212 (0.2212)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [199][100/391]\tTime 0.122 (0.127)\tData 0.001 (0.004)\tLoss 0.2068 (0.1850)\tPrec@1 96.094 (96.434)\n",
            "Epoch: [199][200/391]\tTime 0.121 (0.126)\tData 0.000 (0.003)\tLoss 0.2320 (0.1898)\tPrec@1 95.312 (96.319)\n",
            "Epoch: [199][300/391]\tTime 0.122 (0.125)\tData 0.000 (0.002)\tLoss 0.1632 (0.1884)\tPrec@1 95.312 (96.296)\n",
            "Epoch: [199][390/391]\tTime 0.089 (0.125)\tData 0.000 (0.002)\tLoss 0.2899 (0.1909)\tPrec@1 93.750 (96.192)\n",
            "Total time : 48.806\n",
            "Train Loss: 0.1909, Train Accuracy: 0.9619\n",
            "Test Loss : 0.9195, Test Accuracy : 0.7714 \n",
            "\n",
            "train loss:  [4.2867, 3.9508, 3.7659, 3.5593, 3.3526, 3.1733, 3.0099, 2.9018, 2.8061, 2.7124, 2.6226, 2.5651, 2.5063, 2.4507, 2.4181, 2.3792, 2.34, 2.2996, 2.2726, 2.2398, 2.2274, 2.1977, 2.165, 2.1452, 2.1198, 2.1078, 2.0796, 2.0592, 2.0405, 2.0312, 2.017, 1.9901, 1.9757, 1.9666, 1.9529, 1.9283, 1.9284, 1.9122, 1.8948, 1.8951, 1.8834, 1.8704, 1.8644, 1.8541, 1.834, 1.839, 1.8182, 1.8143, 1.8014, 1.7869, 1.7854, 1.7637, 1.7523, 1.7498, 1.7429, 1.7285, 1.7269, 1.7069, 1.7035, 1.6926, 1.6905, 1.6636, 1.667, 1.6607, 1.6428, 1.6363, 1.6262, 1.6108, 1.6092, 1.598, 1.5828, 1.5746, 1.5691, 1.5568, 1.5471, 1.5364, 1.5252, 1.5292, 1.4968, 1.5091, 1.4971, 1.4672, 1.4666, 1.4564, 1.4505, 1.4282, 1.4297, 1.4225, 1.4167, 1.398, 1.3827, 1.383, 1.3558, 1.3511, 1.3418, 1.3167, 1.316, 1.3075, 1.3008, 1.2895, 1.2641, 1.2584, 1.245, 1.2333, 1.232, 1.2107, 1.1861, 1.1952, 1.176, 1.1624, 1.1496, 1.1301, 1.1221, 1.111, 1.1093, 1.0924, 1.0732, 1.0451, 1.0469, 1.0274, 1.0181, 0.9999, 0.9842, 0.9715, 0.9589, 0.9445, 0.9297, 0.9169, 0.8879, 0.8821, 0.8741, 0.8573, 0.8421, 0.8314, 0.815, 0.7991, 0.7816, 0.7673, 0.7432, 0.7368, 0.7227, 0.7008, 0.6929, 0.666, 0.6616, 0.6448, 0.6248, 0.6121, 0.5862, 0.5801, 0.5615, 0.5507, 0.5426, 0.5256, 0.5049, 0.4935, 0.4797, 0.4583, 0.4508, 0.4292, 0.4182, 0.4116, 0.3991, 0.3849, 0.3671, 0.3575, 0.3485, 0.3391, 0.3205, 0.3169, 0.3099, 0.3019, 0.2956, 0.276, 0.2742, 0.2687, 0.2578, 0.2505, 0.2454, 0.2429, 0.2332, 0.2299, 0.2226, 0.2107, 0.2155, 0.2132, 0.2127, 0.2095, 0.2025, 0.2021, 0.2006, 0.1983, 0.2006, 0.1953, 0.1958, 0.1966, 0.1954, 0.191, 0.1946, 0.1909]\n",
            "train err:  [0.959, 0.9234, 0.8941, 0.8624, 0.8247, 0.7892, 0.7539, 0.7279, 0.7028, 0.6746, 0.6546, 0.6397, 0.6224, 0.6057, 0.5966, 0.5827, 0.5741, 0.5617, 0.5516, 0.5399, 0.5338, 0.5275, 0.5191, 0.511, 0.5028, 0.4981, 0.4917, 0.4843, 0.4786, 0.4722, 0.4715, 0.4638, 0.4582, 0.455, 0.4511, 0.4468, 0.4434, 0.4394, 0.4314, 0.4353, 0.4325, 0.4284, 0.4235, 0.4216, 0.4152, 0.4153, 0.4117, 0.4068, 0.4045, 0.4024, 0.4008, 0.3959, 0.3928, 0.3923, 0.3888, 0.3866, 0.3851, 0.3825, 0.3789, 0.3746, 0.3742, 0.3678, 0.3683, 0.369, 0.3626, 0.361, 0.3597, 0.3576, 0.3546, 0.3524, 0.347, 0.3448, 0.3437, 0.3391, 0.3402, 0.3363, 0.3332, 0.3343, 0.3255, 0.3282, 0.3258, 0.3181, 0.3192, 0.3151, 0.3134, 0.3085, 0.3092, 0.3057, 0.3053, 0.3026, 0.3006, 0.2983, 0.2932, 0.2895, 0.2878, 0.2851, 0.2852, 0.2814, 0.2791, 0.2783, 0.2728, 0.2697, 0.2666, 0.2655, 0.2624, 0.2579, 0.2525, 0.2549, 0.2519, 0.2494, 0.2446, 0.2407, 0.2378, 0.2376, 0.2356, 0.2328, 0.228, 0.2217, 0.2209, 0.2183, 0.216, 0.2133, 0.2098, 0.2043, 0.2019, 0.1986, 0.196, 0.1922, 0.186, 0.1831, 0.182, 0.1783, 0.1751, 0.1727, 0.1691, 0.1647, 0.1603, 0.1592, 0.1524, 0.15, 0.1462, 0.1421, 0.1398, 0.1339, 0.1356, 0.1301, 0.1266, 0.123, 0.1163, 0.1171, 0.112, 0.1093, 0.108, 0.1039, 0.0997, 0.0977, 0.0942, 0.0904, 0.09, 0.0845, 0.082, 0.0809, 0.0778, 0.0739, 0.071, 0.0688, 0.0681, 0.066, 0.0626, 0.0621, 0.0592, 0.0574, 0.0568, 0.0532, 0.0532, 0.0531, 0.0495, 0.0498, 0.0472, 0.0466, 0.0452, 0.0452, 0.044, 0.04, 0.0423, 0.0414, 0.0424, 0.0412, 0.0408, 0.0397, 0.0397, 0.0385, 0.04, 0.0401, 0.0386, 0.0386, 0.0391, 0.0378, 0.0386, 0.0381]\n",
            "train acc:  [0.041, 0.0766, 0.1059, 0.1376, 0.1753, 0.2108, 0.2461, 0.2721, 0.2972, 0.3254, 0.3454, 0.3603, 0.3776, 0.3943, 0.4034, 0.4173, 0.4259, 0.4383, 0.4484, 0.4601, 0.4662, 0.4725, 0.4809, 0.489, 0.4972, 0.5019, 0.5083, 0.5157, 0.5214, 0.5278, 0.5285, 0.5362, 0.5418, 0.545, 0.5489, 0.5532, 0.5566, 0.5606, 0.5686, 0.5647, 0.5675, 0.5716, 0.5765, 0.5784, 0.5848, 0.5847, 0.5883, 0.5932, 0.5955, 0.5976, 0.5992, 0.6041, 0.6072, 0.6077, 0.6112, 0.6134, 0.6149, 0.6175, 0.6211, 0.6254, 0.6258, 0.6322, 0.6317, 0.631, 0.6374, 0.639, 0.6403, 0.6424, 0.6454, 0.6476, 0.653, 0.6552, 0.6563, 0.6609, 0.6598, 0.6637, 0.6668, 0.6657, 0.6745, 0.6718, 0.6742, 0.6819, 0.6808, 0.6849, 0.6866, 0.6915, 0.6908, 0.6943, 0.6947, 0.6974, 0.6994, 0.7017, 0.7068, 0.7105, 0.7122, 0.7149, 0.7148, 0.7186, 0.7209, 0.7217, 0.7272, 0.7303, 0.7334, 0.7345, 0.7376, 0.7421, 0.7475, 0.7451, 0.7481, 0.7506, 0.7554, 0.7593, 0.7622, 0.7624, 0.7644, 0.7672, 0.772, 0.7783, 0.7791, 0.7817, 0.784, 0.7867, 0.7902, 0.7957, 0.7981, 0.8014, 0.804, 0.8078, 0.814, 0.8169, 0.818, 0.8217, 0.8249, 0.8273, 0.8309, 0.8353, 0.8397, 0.8408, 0.8476, 0.85, 0.8538, 0.8579, 0.8602, 0.8661, 0.8644, 0.8699, 0.8734, 0.877, 0.8837, 0.8829, 0.888, 0.8907, 0.892, 0.8961, 0.9003, 0.9023, 0.9058, 0.9096, 0.91, 0.9155, 0.918, 0.9191, 0.9222, 0.9261, 0.929, 0.9312, 0.9319, 0.934, 0.9374, 0.9379, 0.9408, 0.9426, 0.9432, 0.9468, 0.9468, 0.9469, 0.9505, 0.9502, 0.9528, 0.9534, 0.9548, 0.9548, 0.956, 0.96, 0.9577, 0.9586, 0.9576, 0.9588, 0.9592, 0.9603, 0.9603, 0.9615, 0.96, 0.9599, 0.9614, 0.9614, 0.9609, 0.9622, 0.9614, 0.9619]\n",
            "test loss:  [4.0141, 3.7489, 3.5793, 3.5022, 3.0762, 2.9334, 2.8328, 2.8346, 2.653, 2.6078, 2.4168, 2.3399, 2.4164, 2.3598, 2.3189, 2.1761, 2.4297, 2.1668, 2.4266, 2.1315, 2.0383, 2.0526, 2.0964, 1.9617, 1.9466, 1.8698, 1.9032, 1.8562, 1.9211, 1.8616, 1.8478, 1.8978, 1.8738, 1.887, 1.7986, 1.8171, 1.8816, 1.8591, 1.7071, 1.7913, 1.8658, 1.7692, 1.7029, 1.7199, 1.6819, 1.7328, 1.74, 1.7129, 1.6579, 1.6389, 1.6899, 1.7435, 1.7029, 1.6162, 1.6115, 1.6306, 1.7408, 1.7511, 1.686, 1.6585, 1.6195, 1.6281, 1.5882, 1.5764, 1.5827, 1.5914, 1.5077, 1.6665, 1.5873, 1.5659, 1.5745, 1.5252, 1.4574, 1.5108, 1.4616, 1.5203, 1.4463, 1.4124, 1.4486, 1.5459, 1.4922, 1.5884, 1.3805, 1.4141, 1.3596, 1.3867, 1.393, 1.3913, 1.4525, 1.4015, 1.3831, 1.3493, 1.3576, 1.3703, 1.3045, 1.3683, 1.3229, 1.3501, 1.4109, 1.3504, 1.3407, 1.3594, 1.316, 1.2775, 1.3003, 1.2609, 1.2381, 1.2476, 1.2992, 1.3112, 1.2274, 1.2242, 1.2423, 1.2466, 1.2101, 1.1983, 1.1775, 1.1721, 1.213, 1.2168, 1.1539, 1.1623, 1.138, 1.1556, 1.1218, 1.1238, 1.1341, 1.1083, 1.0918, 1.0905, 1.1194, 1.0787, 1.1175, 1.0709, 1.0736, 1.0474, 1.0298, 1.0579, 1.0511, 1.0252, 1.0188, 1.0054, 1.0102, 0.9913, 1.009, 0.9775, 0.994, 1.0189, 0.9885, 0.9913, 0.9673, 0.9978, 0.9628, 0.964, 0.948, 0.9361, 0.9516, 0.9348, 0.9138, 0.934, 0.9215, 0.9111, 0.9113, 0.9288, 0.9058, 0.9042, 0.8969, 0.9099, 0.9043, 0.9227, 0.9046, 0.9055, 0.8961, 0.9027, 0.9105, 0.9055, 0.9033, 0.8989, 0.9093, 0.9115, 0.8948, 0.9085, 0.909, 0.91, 0.9128, 0.9201, 0.9222, 0.9147, 0.9184, 0.9074, 0.9193, 0.9182, 0.9108, 0.9134, 0.918, 0.9253, 0.9139, 0.909, 0.9197, 0.9195]\n",
            "test err:  [0.9425, 0.9099, 0.881, 0.87, 0.8, 0.7665, 0.7507, 0.7387, 0.7069, 0.6941, 0.6477, 0.6445, 0.6455, 0.638, 0.6179, 0.5967, 0.6274, 0.5814, 0.6181, 0.5671, 0.5574, 0.5542, 0.558, 0.5299, 0.5256, 0.5138, 0.5086, 0.4982, 0.5153, 0.4961, 0.4982, 0.5148, 0.5085, 0.5099, 0.4904, 0.4906, 0.4992, 0.4916, 0.4628, 0.4774, 0.4941, 0.4745, 0.4519, 0.465, 0.4618, 0.4668, 0.4682, 0.4675, 0.4478, 0.4444, 0.4517, 0.4553, 0.4487, 0.4386, 0.4277, 0.4374, 0.4627, 0.4578, 0.4466, 0.4443, 0.4346, 0.4326, 0.4404, 0.4248, 0.4192, 0.4266, 0.4073, 0.4416, 0.4244, 0.4232, 0.4242, 0.4047, 0.3945, 0.4076, 0.3988, 0.4029, 0.3923, 0.3878, 0.3934, 0.4062, 0.3973, 0.42, 0.3775, 0.3884, 0.3699, 0.3799, 0.3779, 0.3787, 0.3921, 0.3742, 0.378, 0.3681, 0.3695, 0.3707, 0.3555, 0.3737, 0.3566, 0.3668, 0.3784, 0.3596, 0.3665, 0.3693, 0.3552, 0.3531, 0.358, 0.3413, 0.339, 0.3424, 0.3553, 0.353, 0.337, 0.3372, 0.3359, 0.3389, 0.3355, 0.3302, 0.3281, 0.3235, 0.3331, 0.3273, 0.3153, 0.3175, 0.3141, 0.3207, 0.3071, 0.3095, 0.3119, 0.3042, 0.3026, 0.2989, 0.31, 0.2964, 0.3061, 0.298, 0.295, 0.2903, 0.2853, 0.2926, 0.2854, 0.2805, 0.2795, 0.2756, 0.279, 0.2743, 0.2778, 0.2708, 0.272, 0.278, 0.2731, 0.2702, 0.2662, 0.2677, 0.2693, 0.2643, 0.2589, 0.258, 0.2616, 0.2563, 0.2485, 0.259, 0.25, 0.2474, 0.2439, 0.2487, 0.2468, 0.2432, 0.2444, 0.2458, 0.24, 0.2418, 0.239, 0.2419, 0.2386, 0.2358, 0.2342, 0.2356, 0.236, 0.2333, 0.2346, 0.2369, 0.2333, 0.2323, 0.2322, 0.2298, 0.2304, 0.2326, 0.2295, 0.2287, 0.2293, 0.2267, 0.2263, 0.2292, 0.229, 0.2259, 0.2289, 0.2275, 0.2261, 0.2261, 0.2271, 0.2286]\n",
            "test acc:  [0.0575, 0.0901, 0.119, 0.13, 0.2, 0.2335, 0.2493, 0.2613, 0.2931, 0.3059, 0.3523, 0.3555, 0.3545, 0.362, 0.3821, 0.4033, 0.3726, 0.4186, 0.3819, 0.4329, 0.4426, 0.4458, 0.442, 0.4701, 0.4744, 0.4862, 0.4914, 0.5018, 0.4847, 0.5039, 0.5018, 0.4852, 0.4915, 0.4901, 0.5096, 0.5094, 0.5008, 0.5084, 0.5372, 0.5226, 0.5059, 0.5255, 0.5481, 0.535, 0.5382, 0.5332, 0.5318, 0.5325, 0.5522, 0.5556, 0.5483, 0.5447, 0.5513, 0.5614, 0.5723, 0.5626, 0.5373, 0.5422, 0.5534, 0.5557, 0.5654, 0.5674, 0.5596, 0.5752, 0.5808, 0.5734, 0.5927, 0.5584, 0.5756, 0.5768, 0.5758, 0.5953, 0.6055, 0.5924, 0.6012, 0.5971, 0.6077, 0.6122, 0.6066, 0.5938, 0.6027, 0.58, 0.6225, 0.6116, 0.6301, 0.6201, 0.6221, 0.6213, 0.6079, 0.6258, 0.622, 0.6319, 0.6305, 0.6293, 0.6445, 0.6263, 0.6434, 0.6332, 0.6216, 0.6404, 0.6335, 0.6307, 0.6448, 0.6469, 0.642, 0.6587, 0.661, 0.6576, 0.6447, 0.647, 0.663, 0.6628, 0.6641, 0.6611, 0.6645, 0.6698, 0.6719, 0.6765, 0.6669, 0.6727, 0.6847, 0.6825, 0.6859, 0.6793, 0.6929, 0.6905, 0.6881, 0.6958, 0.6974, 0.7011, 0.69, 0.7036, 0.6939, 0.702, 0.705, 0.7097, 0.7147, 0.7074, 0.7146, 0.7195, 0.7205, 0.7244, 0.721, 0.7257, 0.7222, 0.7292, 0.728, 0.722, 0.7269, 0.7298, 0.7338, 0.7323, 0.7307, 0.7357, 0.7411, 0.742, 0.7384, 0.7437, 0.7515, 0.741, 0.75, 0.7526, 0.7561, 0.7513, 0.7532, 0.7568, 0.7556, 0.7542, 0.76, 0.7582, 0.761, 0.7581, 0.7614, 0.7642, 0.7658, 0.7644, 0.764, 0.7667, 0.7654, 0.7631, 0.7667, 0.7677, 0.7678, 0.7702, 0.7696, 0.7674, 0.7705, 0.7713, 0.7707, 0.7733, 0.7737, 0.7708, 0.771, 0.7741, 0.7711, 0.7725, 0.7739, 0.7739, 0.7729, 0.7714]\n",
            "ori train loss:  [4.2867, 3.9508, 3.7659, 3.5593, 3.3526, 3.1733, 3.0099, 2.9018, 2.8061, 2.7124, 2.6226, 2.5651, 2.5063, 2.4507, 2.4181, 2.3792, 2.34, 2.2996, 2.2726, 2.2398, 2.2274, 2.1977, 2.165, 2.1452, 2.1198, 2.1078, 2.0796, 2.0592, 2.0405, 2.0312, 2.017, 1.9901, 1.9757, 1.9666, 1.9529, 1.9283, 1.9284, 1.9122, 1.8948, 1.8951, 1.8834, 1.8704, 1.8644, 1.8541, 1.834, 1.839, 1.8182, 1.8143, 1.8014, 1.7869, 1.7854, 1.7637, 1.7523, 1.7498, 1.7429, 1.7285, 1.7269, 1.7069, 1.7035, 1.6926, 1.6905, 1.6636, 1.667, 1.6607, 1.6428, 1.6363, 1.6262, 1.6108, 1.6092, 1.598, 1.5828, 1.5746, 1.5691, 1.5568, 1.5471, 1.5364, 1.5252, 1.5292, 1.4968, 1.5091, 1.4971, 1.4672, 1.4666, 1.4564, 1.4505, 1.4282, 1.4297, 1.4225, 1.4167, 1.398, 1.3827, 1.383, 1.3558, 1.3511, 1.3418, 1.3167, 1.316, 1.3075, 1.3008, 1.2895, 1.2641, 1.2584, 1.245, 1.2333, 1.232, 1.2107, 1.1861, 1.1952, 1.176, 1.1624, 1.1496, 1.1301, 1.1221, 1.111, 1.1093, 1.0924, 1.0732, 1.0451, 1.0469, 1.0274, 1.0181, 0.9999, 0.9842, 0.9715, 0.9589, 0.9445, 0.9297, 0.9169, 0.8879, 0.8821, 0.8741, 0.8573, 0.8421, 0.8314, 0.815, 0.7991, 0.7816, 0.7673, 0.7432, 0.7368, 0.7227, 0.7008, 0.6929, 0.666, 0.6616, 0.6448, 0.6248, 0.6121, 0.5862, 0.5801, 0.5615, 0.5507, 0.5426, 0.5256, 0.5049, 0.4935, 0.4797, 0.4583, 0.4508, 0.4292, 0.4182, 0.4116, 0.3991, 0.3849, 0.3671, 0.3575, 0.3485, 0.3391, 0.3205, 0.3169, 0.3099, 0.3019, 0.2956, 0.276, 0.2742, 0.2687, 0.2578, 0.2505, 0.2454, 0.2429, 0.2332, 0.2299, 0.2226, 0.2107, 0.2155, 0.2132, 0.2127, 0.2095, 0.2025, 0.2021, 0.2006, 0.1983, 0.2006, 0.1953, 0.1958, 0.1966, 0.1954, 0.191, 0.1946, 0.1909]\n",
            "ori train err:  [0.959, 0.9234, 0.8941, 0.8624, 0.8247, 0.7892, 0.7539, 0.7279, 0.7028, 0.6746, 0.6546, 0.6397, 0.6224, 0.6057, 0.5966, 0.5827, 0.5741, 0.5617, 0.5516, 0.5399, 0.5338, 0.5275, 0.5191, 0.511, 0.5028, 0.4981, 0.4917, 0.4843, 0.4786, 0.4722, 0.4715, 0.4638, 0.4582, 0.455, 0.4511, 0.4468, 0.4434, 0.4394, 0.4314, 0.4353, 0.4325, 0.4284, 0.4235, 0.4216, 0.4152, 0.4153, 0.4117, 0.4068, 0.4045, 0.4024, 0.4008, 0.3959, 0.3928, 0.3923, 0.3888, 0.3866, 0.3851, 0.3825, 0.3789, 0.3746, 0.3742, 0.3678, 0.3683, 0.369, 0.3626, 0.361, 0.3597, 0.3576, 0.3546, 0.3524, 0.347, 0.3448, 0.3437, 0.3391, 0.3402, 0.3363, 0.3332, 0.3343, 0.3255, 0.3282, 0.3258, 0.3181, 0.3192, 0.3151, 0.3134, 0.3085, 0.3092, 0.3057, 0.3053, 0.3026, 0.3006, 0.2983, 0.2932, 0.2895, 0.2878, 0.2851, 0.2852, 0.2814, 0.2791, 0.2783, 0.2728, 0.2697, 0.2666, 0.2655, 0.2624, 0.2579, 0.2525, 0.2549, 0.2519, 0.2494, 0.2446, 0.2407, 0.2378, 0.2376, 0.2356, 0.2328, 0.228, 0.2217, 0.2209, 0.2183, 0.216, 0.2133, 0.2098, 0.2043, 0.2019, 0.1986, 0.196, 0.1922, 0.186, 0.1831, 0.182, 0.1783, 0.1751, 0.1727, 0.1691, 0.1647, 0.1603, 0.1592, 0.1524, 0.15, 0.1462, 0.1421, 0.1398, 0.1339, 0.1356, 0.1301, 0.1266, 0.123, 0.1163, 0.1171, 0.112, 0.1093, 0.108, 0.1039, 0.0997, 0.0977, 0.0942, 0.0904, 0.09, 0.0845, 0.082, 0.0809, 0.0778, 0.0739, 0.071, 0.0688, 0.0681, 0.066, 0.0626, 0.0621, 0.0592, 0.0574, 0.0568, 0.0532, 0.0532, 0.0531, 0.0495, 0.0498, 0.0472, 0.0466, 0.0452, 0.0452, 0.044, 0.04, 0.0423, 0.0414, 0.0424, 0.0412, 0.0408, 0.0397, 0.0397, 0.0385, 0.04, 0.0401, 0.0386, 0.0386, 0.0391, 0.0378, 0.0386, 0.0381]\n",
            "ori train acc:  [0.041, 0.0766, 0.1059, 0.1376, 0.1753, 0.2108, 0.2461, 0.2721, 0.2972, 0.3254, 0.3454, 0.3603, 0.3776, 0.3943, 0.4034, 0.4173, 0.4259, 0.4383, 0.4484, 0.4601, 0.4662, 0.4725, 0.4809, 0.489, 0.4972, 0.5019, 0.5083, 0.5157, 0.5214, 0.5278, 0.5285, 0.5362, 0.5418, 0.545, 0.5489, 0.5532, 0.5566, 0.5606, 0.5686, 0.5647, 0.5675, 0.5716, 0.5765, 0.5784, 0.5848, 0.5847, 0.5883, 0.5932, 0.5955, 0.5976, 0.5992, 0.6041, 0.6072, 0.6077, 0.6112, 0.6134, 0.6149, 0.6175, 0.6211, 0.6254, 0.6258, 0.6322, 0.6317, 0.631, 0.6374, 0.639, 0.6403, 0.6424, 0.6454, 0.6476, 0.653, 0.6552, 0.6563, 0.6609, 0.6598, 0.6637, 0.6668, 0.6657, 0.6745, 0.6718, 0.6742, 0.6819, 0.6808, 0.6849, 0.6866, 0.6915, 0.6908, 0.6943, 0.6947, 0.6974, 0.6994, 0.7017, 0.7068, 0.7105, 0.7122, 0.7149, 0.7148, 0.7186, 0.7209, 0.7217, 0.7272, 0.7303, 0.7334, 0.7345, 0.7376, 0.7421, 0.7475, 0.7451, 0.7481, 0.7506, 0.7554, 0.7593, 0.7622, 0.7624, 0.7644, 0.7672, 0.772, 0.7783, 0.7791, 0.7817, 0.784, 0.7867, 0.7902, 0.7957, 0.7981, 0.8014, 0.804, 0.8078, 0.814, 0.8169, 0.818, 0.8217, 0.8249, 0.8273, 0.8309, 0.8353, 0.8397, 0.8408, 0.8476, 0.85, 0.8538, 0.8579, 0.8602, 0.8661, 0.8644, 0.8699, 0.8734, 0.877, 0.8837, 0.8829, 0.888, 0.8907, 0.892, 0.8961, 0.9003, 0.9023, 0.9058, 0.9096, 0.91, 0.9155, 0.918, 0.9191, 0.9222, 0.9261, 0.929, 0.9312, 0.9319, 0.934, 0.9374, 0.9379, 0.9408, 0.9426, 0.9432, 0.9468, 0.9468, 0.9469, 0.9505, 0.9502, 0.9528, 0.9534, 0.9548, 0.9548, 0.956, 0.96, 0.9577, 0.9586, 0.9576, 0.9588, 0.9592, 0.9603, 0.9603, 0.9615, 0.96, 0.9599, 0.9614, 0.9614, 0.9609, 0.9622, 0.9614, 0.9619]\n",
            "time:  [54.92, 48.92, 48.76, 48.73, 48.71, 48.84, 48.8, 48.8, 48.78, 48.94, 49.0, 49.02, 49.06, 49.18, 48.99, 48.87, 48.83, 49.02, 48.98, 48.97, 49.17, 49.11, 48.79, 48.87, 48.87, 49.04, 49.04, 49.04, 49.06, 48.92, 48.97, 48.86, 48.97, 48.92, 48.94, 49.0, 49.03, 48.98, 49.11, 49.1, 48.91, 48.67, 48.76, 48.9, 48.85, 48.93, 49.09, 49.03, 48.81, 48.84, 48.71, 48.82, 49.03, 48.87, 48.79, 48.97, 49.03, 49.02, 48.73, 48.61, 48.75, 48.63, 49.03, 49.02, 48.78, 49.07, 48.91, 48.84, 48.76, 49.05, 48.8, 49.1, 49.35, 49.87, 48.99, 48.9, 48.85, 49.05, 49.24, 48.78, 48.81, 48.81, 48.74, 48.76, 48.89, 48.75, 48.81, 49.04, 48.98, 48.94, 48.56, 48.66, 48.76, 48.78, 48.85, 48.79, 48.71, 48.65, 49.03, 48.74, 48.87, 48.76, 48.79, 48.76, 48.75, 48.91, 48.71, 48.82, 48.91, 48.73, 48.91, 48.87, 48.91, 48.67, 48.78, 48.88, 48.9, 48.87, 48.83, 48.76, 48.66, 48.91, 49.0, 48.97, 48.88, 48.88, 48.78, 48.66, 48.87, 48.83, 48.77, 48.67, 48.79, 49.04, 48.94, 48.82, 48.81, 48.62, 48.84, 48.8, 48.77, 48.87, 48.71, 48.71, 48.9, 48.87, 48.76, 48.72, 48.86, 48.94, 48.72, 48.89, 48.92, 48.75, 48.87, 48.87, 48.77, 49.0, 48.86, 48.83, 48.53, 48.67, 48.74, 48.71, 48.97, 48.66, 48.75, 48.76, 48.7, 48.76, 48.82, 48.86, 48.74, 48.75, 48.93, 48.85, 48.75, 48.84, 48.7, 48.94, 48.93, 48.86, 48.88, 48.81, 49.0, 48.92, 48.91, 48.96, 48.83, 48.57, 48.63, 48.77, 48.83, 48.84, 48.83, 48.84, 48.92, 48.78, 48.87, 48.81]\n"
          ]
        }
      ]
    }
  ]
}