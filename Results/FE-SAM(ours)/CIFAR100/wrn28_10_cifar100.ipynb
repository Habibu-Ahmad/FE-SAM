{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOC5HzhPnoPjh2+Fqp/pkFM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/FE-SAM/blob/main/Results/FE-SAM(ours)/CIFAR100/wrn28_10_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/trains.py \\\n",
        "    --optimizer FESAM \\\n",
        "    --rho 0.2 \\\n",
        "    --T 0.1 \\\n",
        "    --beta 0.9 \\\n",
        "    --lr 0.05 \\\n",
        "    --cutout \\\n",
        "    --arch WRN28_10 \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-3 \\\n",
        "    --datasets CIFAR100 \\\n",
        "    --epochs 200 \\\n",
        "    --batch-size 128\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zihrnq7SkGZO",
        "outputId": "6927030b-9e6c-4cdd-bbb3-1d2b572b1186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save dir: save_temp\n",
            "log dir: save_temp\n",
            "Model: WRN28_10\n",
            "cutout: True\n",
            "cutout!\n",
            "cifar100 dataset!\n",
            "391\n",
            "50000\n",
            "optimizer: FESAM\n",
            "FESAM (\n",
            "Parameter Group 0\n",
            "    T: 0.1\n",
            "    adaptive: False\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.05\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    rho: 0.2\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "Start training:  0 -> 200\n",
            "current lr 5.00000e-02\n",
            "Epoch: [0][0/391]\tTime 1.364 (1.364)\tData 0.132 (0.132)\tLoss 4.6052 (4.6052)\tPrec@1 3.125 (3.125)\n",
            "Epoch: [0][100/391]\tTime 0.208 (0.219)\tData 0.000 (0.002)\tLoss 4.1719 (4.4084)\tPrec@1 6.250 (3.365)\n",
            "Epoch: [0][200/391]\tTime 0.208 (0.213)\tData 0.000 (0.001)\tLoss 4.1089 (4.2562)\tPrec@1 8.594 (5.115)\n",
            "Epoch: [0][300/391]\tTime 0.207 (0.211)\tData 0.000 (0.001)\tLoss 3.9259 (4.1460)\tPrec@1 6.250 (6.424)\n",
            "Epoch: [0][390/391]\tTime 0.429 (0.211)\tData 0.000 (0.001)\tLoss 3.8703 (4.0672)\tPrec@1 13.750 (7.470)\n",
            "Total time : 82.532\n",
            "Train Loss: 4.0672, Train Accuracy: 0.0747\n",
            "Test Loss : 3.7000, Test Accuracy : 0.1179 \n",
            "\n",
            "current lr 4.99969e-02\n",
            "Epoch: [1][0/391]\tTime 0.380 (0.380)\tData 0.160 (0.160)\tLoss 3.5982 (3.5982)\tPrec@1 13.281 (13.281)\n",
            "Epoch: [1][100/391]\tTime 0.208 (0.210)\tData 0.000 (0.002)\tLoss 3.5900 (3.6883)\tPrec@1 12.500 (13.212)\n",
            "Epoch: [1][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 3.6106 (3.6469)\tPrec@1 16.406 (13.837)\n",
            "Epoch: [1][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 3.5558 (3.6069)\tPrec@1 17.188 (14.597)\n",
            "Epoch: [1][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 3.5141 (3.5628)\tPrec@1 17.500 (15.286)\n",
            "Total time : 81.406\n",
            "Train Loss: 3.5628, Train Accuracy: 0.1529\n",
            "Test Loss : 3.3350, Test Accuracy : 0.1779 \n",
            "\n",
            "current lr 4.99877e-02\n",
            "Epoch: [2][0/391]\tTime 0.373 (0.373)\tData 0.164 (0.164)\tLoss 3.4107 (3.4107)\tPrec@1 15.625 (15.625)\n",
            "Epoch: [2][100/391]\tTime 0.208 (0.210)\tData 0.000 (0.002)\tLoss 3.3030 (3.3098)\tPrec@1 21.094 (20.382)\n",
            "Epoch: [2][200/391]\tTime 0.211 (0.209)\tData 0.000 (0.001)\tLoss 2.9886 (3.2576)\tPrec@1 31.250 (21.514)\n",
            "Epoch: [2][300/391]\tTime 0.209 (0.209)\tData 0.000 (0.001)\tLoss 3.0257 (3.1995)\tPrec@1 26.562 (22.778)\n",
            "Epoch: [2][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 2.8054 (3.1473)\tPrec@1 35.000 (23.768)\n",
            "Total time : 81.427\n",
            "Train Loss: 3.1473, Train Accuracy: 0.2377\n",
            "Test Loss : 2.9111, Test Accuracy : 0.2563 \n",
            "\n",
            "current lr 4.99722e-02\n",
            "Epoch: [3][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 3.1398 (3.1398)\tPrec@1 27.344 (27.344)\n",
            "Epoch: [3][100/391]\tTime 0.208 (0.210)\tData 0.000 (0.002)\tLoss 3.0572 (2.8879)\tPrec@1 24.219 (28.922)\n",
            "Epoch: [3][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 2.7027 (2.8310)\tPrec@1 35.938 (30.212)\n",
            "Epoch: [3][300/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 2.8078 (2.7943)\tPrec@1 30.469 (31.099)\n",
            "Epoch: [3][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 2.7332 (2.7556)\tPrec@1 33.750 (31.976)\n",
            "Total time : 81.465\n",
            "Train Loss: 2.7556, Train Accuracy: 0.3198\n",
            "Test Loss : 2.5375, Test Accuracy : 0.3269 \n",
            "\n",
            "current lr 4.99507e-02\n",
            "Epoch: [4][0/391]\tTime 0.361 (0.361)\tData 0.154 (0.154)\tLoss 2.6151 (2.6151)\tPrec@1 42.969 (42.969)\n",
            "Epoch: [4][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 2.4459 (2.5555)\tPrec@1 38.281 (36.456)\n",
            "Epoch: [4][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 2.1797 (2.5215)\tPrec@1 49.219 (37.259)\n",
            "Epoch: [4][300/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 2.3735 (2.4853)\tPrec@1 42.188 (38.180)\n",
            "Epoch: [4][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 2.3627 (2.4624)\tPrec@1 43.750 (38.776)\n",
            "Total time : 81.425\n",
            "Train Loss: 2.4624, Train Accuracy: 0.3878\n",
            "Test Loss : 2.2241, Test Accuracy : 0.3908 \n",
            "\n",
            "current lr 4.99229e-02\n",
            "Epoch: [5][0/391]\tTime 0.364 (0.364)\tData 0.155 (0.155)\tLoss 2.5125 (2.5125)\tPrec@1 40.625 (40.625)\n",
            "Epoch: [5][100/391]\tTime 0.208 (0.210)\tData 0.000 (0.002)\tLoss 2.5957 (2.2926)\tPrec@1 39.844 (42.667)\n",
            "Epoch: [5][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 2.2712 (2.2693)\tPrec@1 47.656 (43.151)\n",
            "Epoch: [5][300/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 2.4161 (2.2481)\tPrec@1 35.156 (43.589)\n",
            "Epoch: [5][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 2.0670 (2.2312)\tPrec@1 42.500 (44.106)\n",
            "Total time : 81.425\n",
            "Train Loss: 2.2312, Train Accuracy: 0.4411\n",
            "Test Loss : 2.0321, Test Accuracy : 0.4411 \n",
            "\n",
            "current lr 4.98890e-02\n",
            "Epoch: [6][0/391]\tTime 0.362 (0.362)\tData 0.153 (0.153)\tLoss 2.3310 (2.3310)\tPrec@1 43.750 (43.750)\n",
            "Epoch: [6][100/391]\tTime 0.208 (0.210)\tData 0.000 (0.002)\tLoss 1.9403 (2.0621)\tPrec@1 53.906 (48.159)\n",
            "Epoch: [6][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 1.9760 (2.0512)\tPrec@1 50.000 (48.585)\n",
            "Epoch: [6][300/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 1.9279 (2.0442)\tPrec@1 46.875 (48.681)\n",
            "Epoch: [6][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.9448 (2.0291)\tPrec@1 51.250 (49.080)\n",
            "Total time : 81.410\n",
            "Train Loss: 2.0291, Train Accuracy: 0.4908\n",
            "Test Loss : 1.8541, Test Accuracy : 0.4773 \n",
            "\n",
            "current lr 4.98490e-02\n",
            "Epoch: [7][0/391]\tTime 0.378 (0.378)\tData 0.169 (0.169)\tLoss 1.9273 (1.9273)\tPrec@1 49.219 (49.219)\n",
            "Epoch: [7][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.9091 (1.9065)\tPrec@1 55.469 (52.545)\n",
            "Epoch: [7][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 1.8725 (1.9152)\tPrec@1 53.125 (52.398)\n",
            "Epoch: [7][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.8987 (1.9037)\tPrec@1 52.344 (52.536)\n",
            "Epoch: [7][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 2.1325 (1.8955)\tPrec@1 40.000 (52.674)\n",
            "Total time : 81.335\n",
            "Train Loss: 1.8955, Train Accuracy: 0.5267\n",
            "Test Loss : 1.7601, Test Accuracy : 0.5080 \n",
            "\n",
            "current lr 4.98029e-02\n",
            "Epoch: [8][0/391]\tTime 0.369 (0.369)\tData 0.160 (0.160)\tLoss 1.5822 (1.5822)\tPrec@1 61.719 (61.719)\n",
            "Epoch: [8][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.5965 (1.7903)\tPrec@1 64.844 (55.546)\n",
            "Epoch: [8][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.9005 (1.7985)\tPrec@1 48.438 (55.438)\n",
            "Epoch: [8][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.7388 (1.7954)\tPrec@1 58.594 (55.479)\n",
            "Epoch: [8][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.9310 (1.7905)\tPrec@1 51.250 (55.508)\n",
            "Total time : 81.293\n",
            "Train Loss: 1.7905, Train Accuracy: 0.5551\n",
            "Test Loss : 1.6721, Test Accuracy : 0.5186 \n",
            "\n",
            "current lr 4.97506e-02\n",
            "Epoch: [9][0/391]\tTime 0.363 (0.363)\tData 0.154 (0.154)\tLoss 1.6116 (1.6116)\tPrec@1 64.062 (64.062)\n",
            "Epoch: [9][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.5633 (1.6805)\tPrec@1 58.594 (58.509)\n",
            "Epoch: [9][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.7530 (1.6941)\tPrec@1 52.344 (58.178)\n",
            "Epoch: [9][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.6821 (1.7057)\tPrec@1 60.938 (58.145)\n",
            "Epoch: [9][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.4625 (1.6983)\tPrec@1 68.750 (58.264)\n",
            "Total time : 81.272\n",
            "Train Loss: 1.6983, Train Accuracy: 0.5826\n",
            "Test Loss : 1.5623, Test Accuracy : 0.5629 \n",
            "\n",
            "current lr 4.96922e-02\n",
            "Epoch: [10][0/391]\tTime 0.371 (0.371)\tData 0.162 (0.162)\tLoss 1.5445 (1.5445)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [10][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.6639 (1.6164)\tPrec@1 61.719 (60.466)\n",
            "Epoch: [10][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.6845 (1.6284)\tPrec@1 58.594 (60.421)\n",
            "Epoch: [10][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.7103 (1.6205)\tPrec@1 58.594 (60.470)\n",
            "Epoch: [10][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.8405 (1.6202)\tPrec@1 65.000 (60.524)\n",
            "Total time : 81.282\n",
            "Train Loss: 1.6202, Train Accuracy: 0.6052\n",
            "Test Loss : 1.5314, Test Accuracy : 0.5606 \n",
            "\n",
            "current lr 4.96277e-02\n",
            "Epoch: [11][0/391]\tTime 0.363 (0.363)\tData 0.153 (0.153)\tLoss 1.6415 (1.6415)\tPrec@1 57.812 (57.812)\n",
            "Epoch: [11][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.3350 (1.5500)\tPrec@1 60.156 (62.051)\n",
            "Epoch: [11][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.5789 (1.5532)\tPrec@1 60.156 (62.154)\n",
            "Epoch: [11][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.6367 (1.5505)\tPrec@1 60.156 (62.508)\n",
            "Epoch: [11][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.5432 (1.5550)\tPrec@1 63.750 (62.462)\n",
            "Total time : 81.182\n",
            "Train Loss: 1.5550, Train Accuracy: 0.6246\n",
            "Test Loss : 1.4621, Test Accuracy : 0.5840 \n",
            "\n",
            "current lr 4.95572e-02\n",
            "Epoch: [12][0/391]\tTime 0.370 (0.370)\tData 0.162 (0.162)\tLoss 1.6275 (1.6275)\tPrec@1 58.594 (58.594)\n",
            "Epoch: [12][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.4422 (1.4865)\tPrec@1 67.188 (64.248)\n",
            "Epoch: [12][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.4193 (1.4903)\tPrec@1 65.625 (64.237)\n",
            "Epoch: [12][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.7108 (1.4977)\tPrec@1 54.688 (64.044)\n",
            "Epoch: [12][390/391]\tTime 0.139 (0.208)\tData 0.000 (0.001)\tLoss 1.5360 (1.4999)\tPrec@1 62.500 (63.984)\n",
            "Total time : 81.230\n",
            "Train Loss: 1.4999, Train Accuracy: 0.6398\n",
            "Test Loss : 1.3973, Test Accuracy : 0.5975 \n",
            "\n",
            "current lr 4.94806e-02\n",
            "Epoch: [13][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 1.4699 (1.4699)\tPrec@1 59.375 (59.375)\n",
            "Epoch: [13][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.3826 (1.4345)\tPrec@1 67.969 (65.486)\n",
            "Epoch: [13][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2618 (1.4483)\tPrec@1 75.781 (65.458)\n",
            "Epoch: [13][300/391]\tTime 0.209 (0.208)\tData 0.000 (0.001)\tLoss 1.1996 (1.4529)\tPrec@1 72.656 (65.420)\n",
            "Epoch: [13][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.5046 (1.4474)\tPrec@1 68.750 (65.622)\n",
            "Total time : 81.200\n",
            "Train Loss: 1.4474, Train Accuracy: 0.6562\n",
            "Test Loss : 1.3959, Test Accuracy : 0.5936 \n",
            "\n",
            "current lr 4.93979e-02\n",
            "Epoch: [14][0/391]\tTime 0.365 (0.365)\tData 0.155 (0.155)\tLoss 1.6531 (1.6531)\tPrec@1 60.156 (60.156)\n",
            "Epoch: [14][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.4023 (1.3883)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [14][200/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 1.4100 (1.4058)\tPrec@1 67.188 (66.845)\n",
            "Epoch: [14][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.6321 (1.4028)\tPrec@1 60.938 (66.899)\n",
            "Epoch: [14][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.2148 (1.4047)\tPrec@1 78.750 (66.950)\n",
            "Total time : 81.193\n",
            "Train Loss: 1.4047, Train Accuracy: 0.6695\n",
            "Test Loss : 1.3289, Test Accuracy : 0.6122 \n",
            "\n",
            "current lr 4.93092e-02\n",
            "Epoch: [15][0/391]\tTime 0.363 (0.363)\tData 0.154 (0.154)\tLoss 1.4078 (1.4078)\tPrec@1 67.188 (67.188)\n",
            "Epoch: [15][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.6430 (1.3456)\tPrec@1 58.594 (68.781)\n",
            "Epoch: [15][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.2457 (1.3519)\tPrec@1 71.094 (68.544)\n",
            "Epoch: [15][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.4541 (1.3617)\tPrec@1 64.062 (68.304)\n",
            "Epoch: [15][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.5236 (1.3662)\tPrec@1 66.250 (68.214)\n",
            "Total time : 81.207\n",
            "Train Loss: 1.3662, Train Accuracy: 0.6821\n",
            "Test Loss : 1.2832, Test Accuracy : 0.6333 \n",
            "\n",
            "current lr 4.92146e-02\n",
            "Epoch: [16][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 1.2703 (1.2703)\tPrec@1 74.219 (74.219)\n",
            "Epoch: [16][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.2892 (1.2946)\tPrec@1 72.656 (69.848)\n",
            "Epoch: [16][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.4111 (1.3176)\tPrec@1 67.969 (69.325)\n",
            "Epoch: [16][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.3768 (1.3197)\tPrec@1 70.312 (69.246)\n",
            "Epoch: [16][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.4878 (1.3217)\tPrec@1 62.500 (69.204)\n",
            "Total time : 81.201\n",
            "Train Loss: 1.3217, Train Accuracy: 0.6920\n",
            "Test Loss : 1.2636, Test Accuracy : 0.6329 \n",
            "\n",
            "current lr 4.91139e-02\n",
            "Epoch: [17][0/391]\tTime 0.378 (0.378)\tData 0.170 (0.170)\tLoss 1.4214 (1.4214)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [17][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.3667 (1.2717)\tPrec@1 70.312 (71.140)\n",
            "Epoch: [17][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.4074 (1.2831)\tPrec@1 67.969 (70.655)\n",
            "Epoch: [17][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2491 (1.2909)\tPrec@1 71.875 (70.411)\n",
            "Epoch: [17][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.1995 (1.2971)\tPrec@1 81.250 (70.144)\n",
            "Total time : 81.178\n",
            "Train Loss: 1.2971, Train Accuracy: 0.7014\n",
            "Test Loss : 1.3195, Test Accuracy : 0.6237 \n",
            "\n",
            "current lr 4.90073e-02\n",
            "Epoch: [18][0/391]\tTime 0.379 (0.379)\tData 0.170 (0.170)\tLoss 1.2341 (1.2341)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [18][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.3194 (1.2342)\tPrec@1 68.750 (72.030)\n",
            "Epoch: [18][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.3291 (1.2417)\tPrec@1 66.406 (72.050)\n",
            "Epoch: [18][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.1159 (1.2535)\tPrec@1 75.781 (71.693)\n",
            "Epoch: [18][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.1149 (1.2608)\tPrec@1 78.750 (71.508)\n",
            "Total time : 81.170\n",
            "Train Loss: 1.2608, Train Accuracy: 0.7151\n",
            "Test Loss : 1.2276, Test Accuracy : 0.6410 \n",
            "\n",
            "current lr 4.88948e-02\n",
            "Epoch: [19][0/391]\tTime 0.398 (0.398)\tData 0.190 (0.190)\tLoss 1.2622 (1.2622)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [19][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.1262 (1.2222)\tPrec@1 73.438 (72.262)\n",
            "Epoch: [19][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.3076 (1.2159)\tPrec@1 69.531 (72.746)\n",
            "Epoch: [19][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.3889 (1.2294)\tPrec@1 70.312 (72.236)\n",
            "Epoch: [19][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.5353 (1.2322)\tPrec@1 67.500 (72.078)\n",
            "Total time : 81.241\n",
            "Train Loss: 1.2322, Train Accuracy: 0.7208\n",
            "Test Loss : 1.2046, Test Accuracy : 0.6482 \n",
            "\n",
            "current lr 4.87764e-02\n",
            "Epoch: [20][0/391]\tTime 0.376 (0.376)\tData 0.169 (0.169)\tLoss 1.1918 (1.1918)\tPrec@1 71.094 (71.094)\n",
            "Epoch: [20][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.1892 (1.1628)\tPrec@1 71.875 (74.575)\n",
            "Epoch: [20][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1021 (1.1800)\tPrec@1 74.219 (73.791)\n",
            "Epoch: [20][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2234 (1.1973)\tPrec@1 70.312 (73.354)\n",
            "Epoch: [20][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.2113 (1.2090)\tPrec@1 72.500 (73.016)\n",
            "Total time : 81.161\n",
            "Train Loss: 1.2090, Train Accuracy: 0.7302\n",
            "Test Loss : 1.1383, Test Accuracy : 0.6698 \n",
            "\n",
            "current lr 4.86521e-02\n",
            "Epoch: [21][0/391]\tTime 0.375 (0.375)\tData 0.167 (0.167)\tLoss 1.1179 (1.1179)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [21][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.3316 (1.1463)\tPrec@1 65.625 (74.675)\n",
            "Epoch: [21][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.1076 (1.1677)\tPrec@1 77.344 (74.207)\n",
            "Epoch: [21][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.2182 (1.1718)\tPrec@1 70.312 (74.206)\n",
            "Epoch: [21][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.1539 (1.1783)\tPrec@1 76.250 (74.008)\n",
            "Total time : 81.191\n",
            "Train Loss: 1.1783, Train Accuracy: 0.7401\n",
            "Test Loss : 1.1549, Test Accuracy : 0.6681 \n",
            "\n",
            "current lr 4.85220e-02\n",
            "Epoch: [22][0/391]\tTime 0.382 (0.382)\tData 0.174 (0.174)\tLoss 1.1713 (1.1713)\tPrec@1 73.438 (73.438)\n",
            "Epoch: [22][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0686 (1.1260)\tPrec@1 73.438 (75.348)\n",
            "Epoch: [22][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1360 (1.1407)\tPrec@1 69.531 (74.872)\n",
            "Epoch: [22][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2545 (1.1485)\tPrec@1 70.312 (74.852)\n",
            "Epoch: [22][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.1425 (1.1599)\tPrec@1 77.500 (74.590)\n",
            "Total time : 81.233\n",
            "Train Loss: 1.1599, Train Accuracy: 0.7459\n",
            "Test Loss : 1.1188, Test Accuracy : 0.6805 \n",
            "\n",
            "current lr 4.83861e-02\n",
            "Epoch: [23][0/391]\tTime 0.382 (0.382)\tData 0.174 (0.174)\tLoss 1.1688 (1.1688)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [23][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.0600 (1.1141)\tPrec@1 80.469 (75.967)\n",
            "Epoch: [23][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.9697 (1.1230)\tPrec@1 78.906 (75.626)\n",
            "Epoch: [23][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9897 (1.1300)\tPrec@1 78.125 (75.345)\n",
            "Epoch: [23][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.2757 (1.1370)\tPrec@1 77.500 (75.120)\n",
            "Total time : 81.188\n",
            "Train Loss: 1.1370, Train Accuracy: 0.7512\n",
            "Test Loss : 1.1707, Test Accuracy : 0.6606 \n",
            "\n",
            "current lr 4.82444e-02\n",
            "Epoch: [24][0/391]\tTime 0.384 (0.384)\tData 0.175 (0.175)\tLoss 1.0513 (1.0513)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [24][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.9924 (1.0797)\tPrec@1 78.906 (76.740)\n",
            "Epoch: [24][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1016 (1.1001)\tPrec@1 74.219 (76.376)\n",
            "Epoch: [24][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.2004 (1.1093)\tPrec@1 73.438 (76.080)\n",
            "Epoch: [24][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.9068 (1.1176)\tPrec@1 83.750 (75.838)\n",
            "Total time : 81.272\n",
            "Train Loss: 1.1176, Train Accuracy: 0.7584\n",
            "Test Loss : 1.1417, Test Accuracy : 0.6677 \n",
            "\n",
            "current lr 4.80970e-02\n",
            "Epoch: [25][0/391]\tTime 0.385 (0.385)\tData 0.175 (0.175)\tLoss 0.8979 (0.8979)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [25][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0472 (1.0639)\tPrec@1 80.469 (77.351)\n",
            "Epoch: [25][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.3360 (1.0821)\tPrec@1 70.312 (77.025)\n",
            "Epoch: [25][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2549 (1.0929)\tPrec@1 71.875 (76.534)\n",
            "Epoch: [25][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.0446 (1.0974)\tPrec@1 83.750 (76.500)\n",
            "Total time : 81.215\n",
            "Train Loss: 1.0974, Train Accuracy: 0.7650\n",
            "Test Loss : 1.1242, Test Accuracy : 0.6742 \n",
            "\n",
            "current lr 4.79439e-02\n",
            "Epoch: [26][0/391]\tTime 0.378 (0.378)\tData 0.170 (0.170)\tLoss 1.0136 (1.0136)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [26][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0475 (1.0480)\tPrec@1 80.469 (77.545)\n",
            "Epoch: [26][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.3001 (1.0727)\tPrec@1 68.750 (77.068)\n",
            "Epoch: [26][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1342 (1.0791)\tPrec@1 75.781 (76.861)\n",
            "Epoch: [26][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.4503 (1.0848)\tPrec@1 73.750 (76.746)\n",
            "Total time : 81.231\n",
            "Train Loss: 1.0848, Train Accuracy: 0.7675\n",
            "Test Loss : 1.0991, Test Accuracy : 0.6827 \n",
            "\n",
            "current lr 4.77851e-02\n",
            "Epoch: [27][0/391]\tTime 0.375 (0.375)\tData 0.168 (0.168)\tLoss 0.9854 (0.9854)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [27][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0322 (1.0221)\tPrec@1 81.250 (78.349)\n",
            "Epoch: [27][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.0345 (1.0479)\tPrec@1 78.125 (77.488)\n",
            "Epoch: [27][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9913 (1.0599)\tPrec@1 81.250 (77.320)\n",
            "Epoch: [27][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.2825 (1.0672)\tPrec@1 75.000 (77.200)\n",
            "Total time : 81.205\n",
            "Train Loss: 1.0672, Train Accuracy: 0.7720\n",
            "Test Loss : 1.0835, Test Accuracy : 0.6869 \n",
            "\n",
            "current lr 4.76207e-02\n",
            "Epoch: [28][0/391]\tTime 0.395 (0.395)\tData 0.187 (0.187)\tLoss 1.0203 (1.0203)\tPrec@1 76.562 (76.562)\n",
            "Epoch: [28][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0175 (0.9896)\tPrec@1 77.344 (78.914)\n",
            "Epoch: [28][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9979 (1.0192)\tPrec@1 78.906 (78.362)\n",
            "Epoch: [28][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.4225 (1.0430)\tPrec@1 67.969 (77.736)\n",
            "Epoch: [28][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.9013 (1.0490)\tPrec@1 83.750 (77.616)\n",
            "Total time : 81.253\n",
            "Train Loss: 1.0490, Train Accuracy: 0.7762\n",
            "Test Loss : 1.0593, Test Accuracy : 0.6925 \n",
            "\n",
            "current lr 4.74507e-02\n",
            "Epoch: [29][0/391]\tTime 0.385 (0.385)\tData 0.176 (0.176)\tLoss 0.8815 (0.8815)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [29][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.9360 (1.0054)\tPrec@1 82.031 (78.960)\n",
            "Epoch: [29][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2769 (1.0125)\tPrec@1 71.094 (79.015)\n",
            "Epoch: [29][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.2014 (1.0293)\tPrec@1 77.344 (78.439)\n",
            "Epoch: [29][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.0316 (1.0460)\tPrec@1 85.000 (78.004)\n",
            "Total time : 81.177\n",
            "Train Loss: 1.0460, Train Accuracy: 0.7800\n",
            "Test Loss : 1.0884, Test Accuracy : 0.6788 \n",
            "\n",
            "current lr 4.72752e-02\n",
            "Epoch: [30][0/391]\tTime 0.385 (0.385)\tData 0.177 (0.177)\tLoss 1.1559 (1.1559)\tPrec@1 75.781 (75.781)\n",
            "Epoch: [30][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0624 (0.9778)\tPrec@1 78.125 (79.780)\n",
            "Epoch: [30][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.0389 (0.9997)\tPrec@1 75.000 (79.237)\n",
            "Epoch: [30][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1762 (1.0138)\tPrec@1 75.000 (78.808)\n",
            "Epoch: [30][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.1314 (1.0258)\tPrec@1 77.500 (78.520)\n",
            "Total time : 81.150\n",
            "Train Loss: 1.0258, Train Accuracy: 0.7852\n",
            "Test Loss : 1.0531, Test Accuracy : 0.6997 \n",
            "\n",
            "current lr 4.70941e-02\n",
            "Epoch: [31][0/391]\tTime 0.380 (0.380)\tData 0.172 (0.172)\tLoss 0.8999 (0.8999)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [31][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0017 (0.9712)\tPrec@1 84.375 (80.121)\n",
            "Epoch: [31][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 1.2440 (0.9942)\tPrec@1 71.875 (79.583)\n",
            "Epoch: [31][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9860 (1.0027)\tPrec@1 79.688 (79.288)\n",
            "Epoch: [31][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.2577 (1.0101)\tPrec@1 77.500 (78.994)\n",
            "Total time : 81.154\n",
            "Train Loss: 1.0101, Train Accuracy: 0.7899\n",
            "Test Loss : 1.0399, Test Accuracy : 0.7011 \n",
            "\n",
            "current lr 4.69077e-02\n",
            "Epoch: [32][0/391]\tTime 0.376 (0.376)\tData 0.168 (0.168)\tLoss 0.9494 (0.9494)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [32][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.9046 (0.9615)\tPrec@1 79.688 (80.097)\n",
            "Epoch: [32][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9273 (0.9827)\tPrec@1 79.688 (79.921)\n",
            "Epoch: [32][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.9256 (0.9879)\tPrec@1 82.031 (79.765)\n",
            "Epoch: [32][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.0121 (0.9968)\tPrec@1 78.750 (79.618)\n",
            "Total time : 81.183\n",
            "Train Loss: 0.9968, Train Accuracy: 0.7962\n",
            "Test Loss : 1.0776, Test Accuracy : 0.6815 \n",
            "\n",
            "current lr 4.67158e-02\n",
            "Epoch: [33][0/391]\tTime 0.382 (0.382)\tData 0.174 (0.174)\tLoss 0.9648 (0.9648)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [33][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.9346 (0.9606)\tPrec@1 83.594 (80.623)\n",
            "Epoch: [33][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9313 (0.9717)\tPrec@1 82.031 (80.492)\n",
            "Epoch: [33][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.0883 (0.9778)\tPrec@1 78.125 (80.139)\n",
            "Epoch: [33][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.0109 (0.9868)\tPrec@1 78.750 (79.822)\n",
            "Total time : 81.251\n",
            "Train Loss: 0.9868, Train Accuracy: 0.7982\n",
            "Test Loss : 0.9776, Test Accuracy : 0.7159 \n",
            "\n",
            "current lr 4.65186e-02\n",
            "Epoch: [34][0/391]\tTime 0.377 (0.377)\tData 0.169 (0.169)\tLoss 1.0138 (1.0138)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [34][100/391]\tTime 0.209 (0.209)\tData 0.000 (0.002)\tLoss 1.0498 (0.9551)\tPrec@1 78.125 (80.600)\n",
            "Epoch: [34][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8228 (0.9556)\tPrec@1 81.250 (80.593)\n",
            "Epoch: [34][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1061 (0.9710)\tPrec@1 75.000 (80.118)\n",
            "Epoch: [34][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.9357 (0.9805)\tPrec@1 83.750 (79.810)\n",
            "Total time : 81.227\n",
            "Train Loss: 0.9805, Train Accuracy: 0.7981\n",
            "Test Loss : 1.0180, Test Accuracy : 0.7019 \n",
            "\n",
            "current lr 4.63160e-02\n",
            "Epoch: [35][0/391]\tTime 0.375 (0.375)\tData 0.167 (0.167)\tLoss 0.8004 (0.8004)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [35][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.0235 (0.9155)\tPrec@1 79.688 (81.621)\n",
            "Epoch: [35][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.0990 (0.9438)\tPrec@1 75.781 (80.962)\n",
            "Epoch: [35][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8709 (0.9558)\tPrec@1 82.812 (80.586)\n",
            "Epoch: [35][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.9806 (0.9644)\tPrec@1 80.000 (80.340)\n",
            "Total time : 81.202\n",
            "Train Loss: 0.9644, Train Accuracy: 0.8034\n",
            "Test Loss : 1.0018, Test Accuracy : 0.7104 \n",
            "\n",
            "current lr 4.61082e-02\n",
            "Epoch: [36][0/391]\tTime 0.384 (0.384)\tData 0.176 (0.176)\tLoss 1.0304 (1.0304)\tPrec@1 78.906 (78.906)\n",
            "Epoch: [36][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 1.0657 (0.9106)\tPrec@1 77.344 (81.884)\n",
            "Epoch: [36][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8514 (0.9294)\tPrec@1 79.688 (81.355)\n",
            "Epoch: [36][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9936 (0.9463)\tPrec@1 78.125 (80.892)\n",
            "Epoch: [36][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.9420 (0.9556)\tPrec@1 85.000 (80.614)\n",
            "Total time : 81.168\n",
            "Train Loss: 0.9556, Train Accuracy: 0.8061\n",
            "Test Loss : 1.0114, Test Accuracy : 0.7110 \n",
            "\n",
            "current lr 4.58952e-02\n",
            "Epoch: [37][0/391]\tTime 0.379 (0.379)\tData 0.172 (0.172)\tLoss 0.8755 (0.8755)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [37][100/391]\tTime 0.209 (0.209)\tData 0.000 (0.002)\tLoss 1.0660 (0.9213)\tPrec@1 76.562 (81.745)\n",
            "Epoch: [37][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7893 (0.9229)\tPrec@1 86.719 (81.452)\n",
            "Epoch: [37][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.1018 (0.9362)\tPrec@1 78.125 (81.071)\n",
            "Epoch: [37][390/391]\tTime 0.139 (0.208)\tData 0.000 (0.001)\tLoss 0.9462 (0.9484)\tPrec@1 83.750 (80.710)\n",
            "Total time : 81.238\n",
            "Train Loss: 0.9484, Train Accuracy: 0.8071\n",
            "Test Loss : 1.0155, Test Accuracy : 0.7052 \n",
            "\n",
            "current lr 4.56770e-02\n",
            "Epoch: [38][0/391]\tTime 0.376 (0.376)\tData 0.167 (0.167)\tLoss 1.0568 (1.0568)\tPrec@1 77.344 (77.344)\n",
            "Epoch: [38][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8927 (0.9036)\tPrec@1 83.594 (81.938)\n",
            "Epoch: [38][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9937 (0.9222)\tPrec@1 81.250 (81.884)\n",
            "Epoch: [38][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9986 (0.9313)\tPrec@1 79.688 (81.624)\n",
            "Epoch: [38][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.0607 (0.9381)\tPrec@1 82.500 (81.338)\n",
            "Total time : 81.137\n",
            "Train Loss: 0.9381, Train Accuracy: 0.8134\n",
            "Test Loss : 1.0007, Test Accuracy : 0.7066 \n",
            "\n",
            "current lr 4.54537e-02\n",
            "Epoch: [39][0/391]\tTime 0.375 (0.375)\tData 0.167 (0.167)\tLoss 0.8920 (0.8920)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [39][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.9833 (0.8968)\tPrec@1 79.688 (82.263)\n",
            "Epoch: [39][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 1.0564 (0.9115)\tPrec@1 74.219 (81.751)\n",
            "Epoch: [39][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7691 (0.9198)\tPrec@1 85.938 (81.673)\n",
            "Epoch: [39][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.0339 (0.9298)\tPrec@1 81.250 (81.362)\n",
            "Total time : 81.173\n",
            "Train Loss: 0.9298, Train Accuracy: 0.8136\n",
            "Test Loss : 1.0440, Test Accuracy : 0.6945 \n",
            "\n",
            "current lr 4.52254e-02\n",
            "Epoch: [40][0/391]\tTime 0.381 (0.381)\tData 0.173 (0.173)\tLoss 0.8168 (0.8168)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [40][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.8688 (0.9004)\tPrec@1 81.250 (82.433)\n",
            "Epoch: [40][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8806 (0.9083)\tPrec@1 81.250 (82.191)\n",
            "Epoch: [40][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9507 (0.9145)\tPrec@1 79.688 (81.959)\n",
            "Epoch: [40][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 1.0240 (0.9173)\tPrec@1 80.000 (81.894)\n",
            "Total time : 81.281\n",
            "Train Loss: 0.9173, Train Accuracy: 0.8189\n",
            "Test Loss : 0.9887, Test Accuracy : 0.7113 \n",
            "\n",
            "current lr 4.49921e-02\n",
            "Epoch: [41][0/391]\tTime 0.380 (0.380)\tData 0.171 (0.171)\tLoss 0.8811 (0.8811)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [41][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 1.1187 (0.8629)\tPrec@1 75.000 (83.045)\n",
            "Epoch: [41][200/391]\tTime 0.207 (0.209)\tData 0.000 (0.001)\tLoss 1.0234 (0.8821)\tPrec@1 82.031 (82.591)\n",
            "Epoch: [41][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9380 (0.8996)\tPrec@1 81.250 (82.016)\n",
            "Epoch: [41][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.0961 (0.9102)\tPrec@1 82.500 (81.824)\n",
            "Total time : 81.298\n",
            "Train Loss: 0.9102, Train Accuracy: 0.8182\n",
            "Test Loss : 0.9921, Test Accuracy : 0.7122 \n",
            "\n",
            "current lr 4.47539e-02\n",
            "Epoch: [42][0/391]\tTime 0.384 (0.384)\tData 0.176 (0.176)\tLoss 0.8206 (0.8206)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [42][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.9159 (0.8797)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [42][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8625 (0.8926)\tPrec@1 81.250 (82.400)\n",
            "Epoch: [42][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8259 (0.8990)\tPrec@1 81.250 (82.296)\n",
            "Epoch: [42][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.8184 (0.9025)\tPrec@1 85.000 (82.126)\n",
            "Total time : 81.203\n",
            "Train Loss: 0.9025, Train Accuracy: 0.8213\n",
            "Test Loss : 0.9759, Test Accuracy : 0.7165 \n",
            "\n",
            "current lr 4.45108e-02\n",
            "Epoch: [43][0/391]\tTime 0.384 (0.384)\tData 0.176 (0.176)\tLoss 0.7028 (0.7028)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [43][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8532 (0.8598)\tPrec@1 82.812 (83.803)\n",
            "Epoch: [43][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8947 (0.8748)\tPrec@1 82.812 (83.217)\n",
            "Epoch: [43][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9464 (0.8822)\tPrec@1 77.344 (82.919)\n",
            "Epoch: [43][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.0747 (0.8943)\tPrec@1 86.250 (82.488)\n",
            "Total time : 81.205\n",
            "Train Loss: 0.8943, Train Accuracy: 0.8249\n",
            "Test Loss : 0.9681, Test Accuracy : 0.7237 \n",
            "\n",
            "current lr 4.42628e-02\n",
            "Epoch: [44][0/391]\tTime 0.378 (0.378)\tData 0.169 (0.169)\tLoss 0.7923 (0.7923)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [44][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7979 (0.8224)\tPrec@1 82.812 (84.035)\n",
            "Epoch: [44][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8988 (0.8557)\tPrec@1 81.250 (83.217)\n",
            "Epoch: [44][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.8893 (0.8683)\tPrec@1 80.469 (83.012)\n",
            "Epoch: [44][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.2391 (0.8805)\tPrec@1 78.750 (82.758)\n",
            "Total time : 81.198\n",
            "Train Loss: 0.8805, Train Accuracy: 0.8276\n",
            "Test Loss : 0.9339, Test Accuracy : 0.7304 \n",
            "\n",
            "current lr 4.40101e-02\n",
            "Epoch: [45][0/391]\tTime 0.373 (0.373)\tData 0.164 (0.164)\tLoss 0.8251 (0.8251)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [45][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6747 (0.8502)\tPrec@1 85.938 (83.710)\n",
            "Epoch: [45][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7842 (0.8556)\tPrec@1 85.156 (83.298)\n",
            "Epoch: [45][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8124 (0.8693)\tPrec@1 82.812 (82.955)\n",
            "Epoch: [45][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.7226 (0.8765)\tPrec@1 95.000 (82.760)\n",
            "Total time : 81.213\n",
            "Train Loss: 0.8765, Train Accuracy: 0.8276\n",
            "Test Loss : 0.9552, Test Accuracy : 0.7233 \n",
            "\n",
            "current lr 4.37528e-02\n",
            "Epoch: [46][0/391]\tTime 0.377 (0.377)\tData 0.170 (0.170)\tLoss 0.8772 (0.8772)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [46][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7905 (0.8338)\tPrec@1 87.500 (84.205)\n",
            "Epoch: [46][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8345 (0.8489)\tPrec@1 84.375 (83.718)\n",
            "Epoch: [46][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9169 (0.8580)\tPrec@1 83.594 (83.516)\n",
            "Epoch: [46][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.8949 (0.8706)\tPrec@1 86.250 (83.052)\n",
            "Total time : 81.190\n",
            "Train Loss: 0.8706, Train Accuracy: 0.8305\n",
            "Test Loss : 0.9583, Test Accuracy : 0.7233 \n",
            "\n",
            "current lr 4.34908e-02\n",
            "Epoch: [47][0/391]\tTime 0.386 (0.386)\tData 0.177 (0.177)\tLoss 0.8817 (0.8817)\tPrec@1 82.031 (82.031)\n",
            "Epoch: [47][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.8849 (0.8246)\tPrec@1 82.812 (84.205)\n",
            "Epoch: [47][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6441 (0.8294)\tPrec@1 89.062 (84.227)\n",
            "Epoch: [47][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8725 (0.8465)\tPrec@1 80.469 (83.807)\n",
            "Epoch: [47][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.9300 (0.8535)\tPrec@1 86.250 (83.644)\n",
            "Total time : 81.211\n",
            "Train Loss: 0.8535, Train Accuracy: 0.8364\n",
            "Test Loss : 0.9288, Test Accuracy : 0.7268 \n",
            "\n",
            "current lr 4.32242e-02\n",
            "Epoch: [48][0/391]\tTime 0.378 (0.378)\tData 0.170 (0.170)\tLoss 0.7802 (0.7802)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [48][100/391]\tTime 0.211 (0.209)\tData 0.000 (0.002)\tLoss 0.7893 (0.8232)\tPrec@1 85.938 (84.097)\n",
            "Epoch: [48][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7149 (0.8403)\tPrec@1 88.281 (83.800)\n",
            "Epoch: [48][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8785 (0.8468)\tPrec@1 84.375 (83.653)\n",
            "Epoch: [48][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.9393 (0.8534)\tPrec@1 81.250 (83.488)\n",
            "Total time : 81.212\n",
            "Train Loss: 0.8534, Train Accuracy: 0.8349\n",
            "Test Loss : 0.9373, Test Accuracy : 0.7274 \n",
            "\n",
            "current lr 4.29532e-02\n",
            "Epoch: [49][0/391]\tTime 0.383 (0.383)\tData 0.175 (0.175)\tLoss 0.8088 (0.8088)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [49][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.9142 (0.7976)\tPrec@1 79.688 (85.326)\n",
            "Epoch: [49][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7812 (0.8201)\tPrec@1 87.500 (84.503)\n",
            "Epoch: [49][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7974 (0.8321)\tPrec@1 83.594 (84.183)\n",
            "Epoch: [49][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.8563 (0.8484)\tPrec@1 82.500 (83.696)\n",
            "Total time : 81.184\n",
            "Train Loss: 0.8484, Train Accuracy: 0.8370\n",
            "Test Loss : 0.9382, Test Accuracy : 0.7257 \n",
            "\n",
            "current lr 4.26777e-02\n",
            "Epoch: [50][0/391]\tTime 0.383 (0.383)\tData 0.174 (0.174)\tLoss 0.8973 (0.8973)\tPrec@1 78.125 (78.125)\n",
            "Epoch: [50][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.9457 (0.7936)\tPrec@1 78.906 (85.373)\n",
            "Epoch: [50][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6361 (0.8211)\tPrec@1 91.406 (84.577)\n",
            "Epoch: [50][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.7689 (0.8359)\tPrec@1 84.375 (84.084)\n",
            "Epoch: [50][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.9488 (0.8423)\tPrec@1 81.250 (83.850)\n",
            "Total time : 81.180\n",
            "Train Loss: 0.8423, Train Accuracy: 0.8385\n",
            "Test Loss : 0.9485, Test Accuracy : 0.7261 \n",
            "\n",
            "current lr 4.23978e-02\n",
            "Epoch: [51][0/391]\tTime 0.382 (0.382)\tData 0.173 (0.173)\tLoss 0.7781 (0.7781)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [51][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7044 (0.7818)\tPrec@1 86.719 (85.396)\n",
            "Epoch: [51][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.8246 (0.8032)\tPrec@1 85.156 (84.888)\n",
            "Epoch: [51][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8856 (0.8185)\tPrec@1 78.906 (84.528)\n",
            "Epoch: [51][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.7437 (0.8299)\tPrec@1 86.250 (84.286)\n",
            "Total time : 81.155\n",
            "Train Loss: 0.8299, Train Accuracy: 0.8429\n",
            "Test Loss : 0.9362, Test Accuracy : 0.7261 \n",
            "\n",
            "current lr 4.21137e-02\n",
            "Epoch: [52][0/391]\tTime 0.380 (0.380)\tData 0.173 (0.173)\tLoss 0.8034 (0.8034)\tPrec@1 85.156 (85.156)\n",
            "Epoch: [52][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7862 (0.7982)\tPrec@1 77.344 (84.924)\n",
            "Epoch: [52][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8987 (0.7980)\tPrec@1 83.594 (85.051)\n",
            "Epoch: [52][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7811 (0.8092)\tPrec@1 86.719 (84.816)\n",
            "Epoch: [52][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.9741 (0.8165)\tPrec@1 81.250 (84.642)\n",
            "Total time : 81.166\n",
            "Train Loss: 0.8165, Train Accuracy: 0.8464\n",
            "Test Loss : 0.9059, Test Accuracy : 0.7331 \n",
            "\n",
            "current lr 4.18253e-02\n",
            "Epoch: [53][0/391]\tTime 0.391 (0.391)\tData 0.183 (0.183)\tLoss 0.7787 (0.7787)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [53][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7619 (0.7624)\tPrec@1 84.375 (85.883)\n",
            "Epoch: [53][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8059 (0.7886)\tPrec@1 85.938 (85.386)\n",
            "Epoch: [53][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6781 (0.8035)\tPrec@1 88.281 (85.130)\n",
            "Epoch: [53][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.8852 (0.8155)\tPrec@1 90.000 (84.812)\n",
            "Total time : 81.145\n",
            "Train Loss: 0.8155, Train Accuracy: 0.8481\n",
            "Test Loss : 0.9643, Test Accuracy : 0.7224 \n",
            "\n",
            "current lr 4.15328e-02\n",
            "Epoch: [54][0/391]\tTime 0.364 (0.364)\tData 0.156 (0.156)\tLoss 0.7705 (0.7705)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [54][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.9541 (0.7618)\tPrec@1 81.250 (86.054)\n",
            "Epoch: [54][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7814 (0.7826)\tPrec@1 85.156 (85.522)\n",
            "Epoch: [54][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.7576 (0.7957)\tPrec@1 87.500 (85.187)\n",
            "Epoch: [54][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.8276 (0.8032)\tPrec@1 87.500 (84.978)\n",
            "Total time : 81.150\n",
            "Train Loss: 0.8032, Train Accuracy: 0.8498\n",
            "Test Loss : 0.8644, Test Accuracy : 0.7496 \n",
            "\n",
            "current lr 4.12362e-02\n",
            "Epoch: [55][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.8433 (0.8433)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [55][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8091 (0.7653)\tPrec@1 85.156 (86.069)\n",
            "Epoch: [55][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6569 (0.7668)\tPrec@1 85.938 (85.988)\n",
            "Epoch: [55][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9666 (0.7822)\tPrec@1 84.375 (85.540)\n",
            "Epoch: [55][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.1058 (0.7922)\tPrec@1 75.000 (85.238)\n",
            "Total time : 81.195\n",
            "Train Loss: 0.7922, Train Accuracy: 0.8524\n",
            "Test Loss : 0.8937, Test Accuracy : 0.7380 \n",
            "\n",
            "current lr 4.09356e-02\n",
            "Epoch: [56][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.5900 (0.5900)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [56][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6385 (0.7724)\tPrec@1 89.062 (86.154)\n",
            "Epoch: [56][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7595 (0.7694)\tPrec@1 84.375 (86.128)\n",
            "Epoch: [56][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5827 (0.7764)\tPrec@1 90.625 (85.847)\n",
            "Epoch: [56][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.7514 (0.7908)\tPrec@1 92.500 (85.390)\n",
            "Total time : 81.166\n",
            "Train Loss: 0.7908, Train Accuracy: 0.8539\n",
            "Test Loss : 0.8961, Test Accuracy : 0.7360 \n",
            "\n",
            "current lr 4.06311e-02\n",
            "Epoch: [57][0/391]\tTime 0.367 (0.367)\tData 0.160 (0.160)\tLoss 0.5950 (0.5950)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [57][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7764 (0.7513)\tPrec@1 80.469 (86.108)\n",
            "Epoch: [57][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8238 (0.7594)\tPrec@1 84.375 (86.066)\n",
            "Epoch: [57][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6937 (0.7728)\tPrec@1 88.281 (85.761)\n",
            "Epoch: [57][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.8622 (0.7791)\tPrec@1 85.000 (85.556)\n",
            "Total time : 81.161\n",
            "Train Loss: 0.7791, Train Accuracy: 0.8556\n",
            "Test Loss : 0.8742, Test Accuracy : 0.7491 \n",
            "\n",
            "current lr 4.03227e-02\n",
            "Epoch: [58][0/391]\tTime 0.369 (0.369)\tData 0.162 (0.162)\tLoss 0.7946 (0.7946)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [58][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.7511 (0.7422)\tPrec@1 82.031 (86.433)\n",
            "Epoch: [58][200/391]\tTime 0.211 (0.208)\tData 0.000 (0.001)\tLoss 0.7422 (0.7581)\tPrec@1 85.938 (86.105)\n",
            "Epoch: [58][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8073 (0.7690)\tPrec@1 85.938 (85.800)\n",
            "Epoch: [58][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.9837 (0.7777)\tPrec@1 83.750 (85.528)\n",
            "Total time : 81.231\n",
            "Train Loss: 0.7777, Train Accuracy: 0.8553\n",
            "Test Loss : 0.9204, Test Accuracy : 0.7308 \n",
            "\n",
            "current lr 4.00105e-02\n",
            "Epoch: [59][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.6740 (0.6740)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [59][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7359 (0.7279)\tPrec@1 87.500 (86.819)\n",
            "Epoch: [59][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7277 (0.7484)\tPrec@1 84.375 (86.346)\n",
            "Epoch: [59][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6792 (0.7540)\tPrec@1 92.188 (86.194)\n",
            "Epoch: [59][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 1.0070 (0.7656)\tPrec@1 83.750 (85.896)\n",
            "Total time : 81.215\n",
            "Train Loss: 0.7656, Train Accuracy: 0.8590\n",
            "Test Loss : 0.9100, Test Accuracy : 0.7341 \n",
            "\n",
            "current lr 3.96946e-02\n",
            "Epoch: [60][0/391]\tTime 0.373 (0.373)\tData 0.166 (0.166)\tLoss 0.6860 (0.6860)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [60][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8546 (0.7129)\tPrec@1 81.250 (87.214)\n",
            "Epoch: [60][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7267 (0.7319)\tPrec@1 86.719 (86.796)\n",
            "Epoch: [60][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7735 (0.7432)\tPrec@1 88.281 (86.534)\n",
            "Epoch: [60][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6565 (0.7576)\tPrec@1 88.750 (86.176)\n",
            "Total time : 81.151\n",
            "Train Loss: 0.7576, Train Accuracy: 0.8618\n",
            "Test Loss : 0.8722, Test Accuracy : 0.7465 \n",
            "\n",
            "current lr 3.93751e-02\n",
            "Epoch: [61][0/391]\tTime 0.371 (0.371)\tData 0.163 (0.163)\tLoss 0.6057 (0.6057)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [61][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7221 (0.7101)\tPrec@1 87.500 (87.454)\n",
            "Epoch: [61][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8470 (0.7353)\tPrec@1 82.812 (86.948)\n",
            "Epoch: [61][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8050 (0.7441)\tPrec@1 88.281 (86.682)\n",
            "Epoch: [61][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.7975 (0.7501)\tPrec@1 85.000 (86.384)\n",
            "Total time : 81.134\n",
            "Train Loss: 0.7501, Train Accuracy: 0.8638\n",
            "Test Loss : 0.8685, Test Accuracy : 0.7473 \n",
            "\n",
            "current lr 3.90521e-02\n",
            "Epoch: [62][0/391]\tTime 0.371 (0.371)\tData 0.162 (0.162)\tLoss 0.8206 (0.8206)\tPrec@1 80.469 (80.469)\n",
            "Epoch: [62][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6552 (0.7022)\tPrec@1 89.844 (87.809)\n",
            "Epoch: [62][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7462 (0.7198)\tPrec@1 88.281 (87.177)\n",
            "Epoch: [62][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7281 (0.7361)\tPrec@1 88.281 (86.862)\n",
            "Epoch: [62][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.8892 (0.7471)\tPrec@1 91.250 (86.494)\n",
            "Total time : 81.180\n",
            "Train Loss: 0.7471, Train Accuracy: 0.8649\n",
            "Test Loss : 0.8888, Test Accuracy : 0.7414 \n",
            "\n",
            "current lr 3.87256e-02\n",
            "Epoch: [63][0/391]\tTime 0.364 (0.364)\tData 0.155 (0.155)\tLoss 0.5639 (0.5639)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [63][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8012 (0.7120)\tPrec@1 82.031 (87.113)\n",
            "Epoch: [63][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7972 (0.7158)\tPrec@1 88.281 (87.142)\n",
            "Epoch: [63][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7384 (0.7267)\tPrec@1 90.625 (86.952)\n",
            "Epoch: [63][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.7847 (0.7387)\tPrec@1 90.000 (86.616)\n",
            "Total time : 81.183\n",
            "Train Loss: 0.7387, Train Accuracy: 0.8662\n",
            "Test Loss : 0.8455, Test Accuracy : 0.7559 \n",
            "\n",
            "current lr 3.83957e-02\n",
            "Epoch: [64][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.8138 (0.8138)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [64][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5798 (0.6818)\tPrec@1 88.281 (88.111)\n",
            "Epoch: [64][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7931 (0.7069)\tPrec@1 86.719 (87.372)\n",
            "Epoch: [64][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9070 (0.7280)\tPrec@1 82.031 (86.810)\n",
            "Epoch: [64][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.8689 (0.7381)\tPrec@1 86.250 (86.570)\n",
            "Total time : 81.197\n",
            "Train Loss: 0.7381, Train Accuracy: 0.8657\n",
            "Test Loss : 0.8719, Test Accuracy : 0.7482 \n",
            "\n",
            "current lr 3.80625e-02\n",
            "Epoch: [65][0/391]\tTime 0.368 (0.368)\tData 0.157 (0.157)\tLoss 0.6659 (0.6659)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [65][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7127 (0.6886)\tPrec@1 89.844 (88.235)\n",
            "Epoch: [65][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7886 (0.7042)\tPrec@1 85.156 (87.784)\n",
            "Epoch: [65][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8193 (0.7151)\tPrec@1 83.594 (87.456)\n",
            "Epoch: [65][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.7253 (0.7238)\tPrec@1 95.000 (87.170)\n",
            "Total time : 81.162\n",
            "Train Loss: 0.7238, Train Accuracy: 0.8717\n",
            "Test Loss : 0.8900, Test Accuracy : 0.7408 \n",
            "\n",
            "current lr 3.77260e-02\n",
            "Epoch: [66][0/391]\tTime 0.386 (0.386)\tData 0.178 (0.178)\tLoss 0.5230 (0.5230)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [66][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.7233 (0.6868)\tPrec@1 89.062 (88.041)\n",
            "Epoch: [66][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6605 (0.6998)\tPrec@1 87.500 (87.729)\n",
            "Epoch: [66][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7390 (0.7066)\tPrec@1 81.250 (87.471)\n",
            "Epoch: [66][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.7691 (0.7154)\tPrec@1 86.250 (87.232)\n",
            "Total time : 81.166\n",
            "Train Loss: 0.7154, Train Accuracy: 0.8723\n",
            "Test Loss : 0.8171, Test Accuracy : 0.7635 \n",
            "\n",
            "current lr 3.73865e-02\n",
            "Epoch: [67][0/391]\tTime 0.362 (0.362)\tData 0.153 (0.153)\tLoss 0.6925 (0.6925)\tPrec@1 83.594 (83.594)\n",
            "Epoch: [67][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6090 (0.6878)\tPrec@1 89.062 (87.941)\n",
            "Epoch: [67][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.9141 (0.6887)\tPrec@1 85.156 (88.025)\n",
            "Epoch: [67][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7043 (0.7012)\tPrec@1 90.625 (87.702)\n",
            "Epoch: [67][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6548 (0.7112)\tPrec@1 90.000 (87.390)\n",
            "Total time : 81.137\n",
            "Train Loss: 0.7112, Train Accuracy: 0.8739\n",
            "Test Loss : 0.8387, Test Accuracy : 0.7547 \n",
            "\n",
            "current lr 3.70438e-02\n",
            "Epoch: [68][0/391]\tTime 0.360 (0.360)\tData 0.152 (0.152)\tLoss 0.5821 (0.5821)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [68][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8772 (0.6710)\tPrec@1 81.250 (88.606)\n",
            "Epoch: [68][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7640 (0.6853)\tPrec@1 85.938 (88.161)\n",
            "Epoch: [68][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6205 (0.6941)\tPrec@1 88.281 (87.918)\n",
            "Epoch: [68][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.8872 (0.6999)\tPrec@1 82.500 (87.754)\n",
            "Total time : 81.151\n",
            "Train Loss: 0.6999, Train Accuracy: 0.8775\n",
            "Test Loss : 0.8414, Test Accuracy : 0.7573 \n",
            "\n",
            "current lr 3.66982e-02\n",
            "Epoch: [69][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.6599 (0.6599)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [69][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7684 (0.6599)\tPrec@1 82.812 (88.544)\n",
            "Epoch: [69][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6579 (0.6735)\tPrec@1 89.844 (88.301)\n",
            "Epoch: [69][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8466 (0.6837)\tPrec@1 82.812 (88.118)\n",
            "Epoch: [69][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.7144 (0.6935)\tPrec@1 90.000 (87.912)\n",
            "Total time : 81.187\n",
            "Train Loss: 0.6935, Train Accuracy: 0.8791\n",
            "Test Loss : 0.8740, Test Accuracy : 0.7439 \n",
            "\n",
            "current lr 3.63498e-02\n",
            "Epoch: [70][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.6518 (0.6518)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [70][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4989 (0.6411)\tPrec@1 92.188 (89.140)\n",
            "Epoch: [70][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6084 (0.6640)\tPrec@1 89.062 (88.320)\n",
            "Epoch: [70][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7154 (0.6774)\tPrec@1 90.625 (87.975)\n",
            "Epoch: [70][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6920 (0.6880)\tPrec@1 88.750 (87.854)\n",
            "Total time : 81.141\n",
            "Train Loss: 0.6880, Train Accuracy: 0.8785\n",
            "Test Loss : 0.8282, Test Accuracy : 0.7540 \n",
            "\n",
            "current lr 3.59985e-02\n",
            "Epoch: [71][0/391]\tTime 0.373 (0.373)\tData 0.164 (0.164)\tLoss 0.6502 (0.6502)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [71][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.8499 (0.6499)\tPrec@1 86.719 (88.575)\n",
            "Epoch: [71][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6708 (0.6609)\tPrec@1 86.719 (88.569)\n",
            "Epoch: [71][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7508 (0.6699)\tPrec@1 87.500 (88.266)\n",
            "Epoch: [71][390/391]\tTime 0.139 (0.208)\tData 0.000 (0.001)\tLoss 0.6466 (0.6808)\tPrec@1 88.750 (88.024)\n",
            "Total time : 81.160\n",
            "Train Loss: 0.6808, Train Accuracy: 0.8802\n",
            "Test Loss : 0.8440, Test Accuracy : 0.7539 \n",
            "\n",
            "current lr 3.56445e-02\n",
            "Epoch: [72][0/391]\tTime 0.374 (0.374)\tData 0.166 (0.166)\tLoss 0.6107 (0.6107)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [72][100/391]\tTime 0.210 (0.209)\tData 0.000 (0.002)\tLoss 0.7490 (0.6355)\tPrec@1 84.375 (89.233)\n",
            "Epoch: [72][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5676 (0.6556)\tPrec@1 92.969 (88.701)\n",
            "Epoch: [72][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.8416 (0.6666)\tPrec@1 80.469 (88.416)\n",
            "Epoch: [72][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6810 (0.6758)\tPrec@1 92.500 (88.168)\n",
            "Total time : 81.163\n",
            "Train Loss: 0.6758, Train Accuracy: 0.8817\n",
            "Test Loss : 0.8424, Test Accuracy : 0.7570 \n",
            "\n",
            "current lr 3.52879e-02\n",
            "Epoch: [73][0/391]\tTime 0.368 (0.368)\tData 0.160 (0.160)\tLoss 0.5168 (0.5168)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [73][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6008 (0.6512)\tPrec@1 88.281 (88.869)\n",
            "Epoch: [73][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7039 (0.6557)\tPrec@1 88.281 (88.631)\n",
            "Epoch: [73][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6051 (0.6615)\tPrec@1 90.625 (88.567)\n",
            "Epoch: [73][390/391]\tTime 0.141 (0.208)\tData 0.000 (0.001)\tLoss 0.8091 (0.6687)\tPrec@1 87.500 (88.456)\n",
            "Total time : 81.187\n",
            "Train Loss: 0.6687, Train Accuracy: 0.8846\n",
            "Test Loss : 0.8295, Test Accuracy : 0.7577 \n",
            "\n",
            "current lr 3.49287e-02\n",
            "Epoch: [74][0/391]\tTime 0.368 (0.368)\tData 0.160 (0.160)\tLoss 0.5625 (0.5625)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [74][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5880 (0.6164)\tPrec@1 88.281 (89.952)\n",
            "Epoch: [74][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5264 (0.6286)\tPrec@1 92.969 (89.669)\n",
            "Epoch: [74][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6413 (0.6435)\tPrec@1 92.188 (89.138)\n",
            "Epoch: [74][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.8702 (0.6554)\tPrec@1 86.250 (88.870)\n",
            "Total time : 81.163\n",
            "Train Loss: 0.6554, Train Accuracy: 0.8887\n",
            "Test Loss : 0.8215, Test Accuracy : 0.7605 \n",
            "\n",
            "current lr 3.45671e-02\n",
            "Epoch: [75][0/391]\tTime 0.367 (0.367)\tData 0.158 (0.158)\tLoss 0.6898 (0.6898)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [75][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7069 (0.6237)\tPrec@1 89.844 (89.488)\n",
            "Epoch: [75][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7096 (0.6337)\tPrec@1 88.281 (89.397)\n",
            "Epoch: [75][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7948 (0.6500)\tPrec@1 83.594 (89.073)\n",
            "Epoch: [75][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6075 (0.6582)\tPrec@1 93.750 (88.812)\n",
            "Total time : 81.175\n",
            "Train Loss: 0.6582, Train Accuracy: 0.8881\n",
            "Test Loss : 0.8045, Test Accuracy : 0.7643 \n",
            "\n",
            "current lr 3.42031e-02\n",
            "Epoch: [76][0/391]\tTime 0.367 (0.367)\tData 0.159 (0.159)\tLoss 0.4826 (0.4826)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [76][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.7372 (0.6127)\tPrec@1 84.375 (89.720)\n",
            "Epoch: [76][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6707 (0.6276)\tPrec@1 90.625 (89.506)\n",
            "Epoch: [76][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6950 (0.6398)\tPrec@1 85.938 (89.197)\n",
            "Epoch: [76][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.8329 (0.6470)\tPrec@1 87.500 (89.044)\n",
            "Total time : 81.175\n",
            "Train Loss: 0.6470, Train Accuracy: 0.8904\n",
            "Test Loss : 0.8131, Test Accuracy : 0.7610 \n",
            "\n",
            "current lr 3.38369e-02\n",
            "Epoch: [77][0/391]\tTime 0.368 (0.368)\tData 0.160 (0.160)\tLoss 0.5315 (0.5315)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [77][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5309 (0.6159)\tPrec@1 91.406 (89.619)\n",
            "Epoch: [77][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.7557 (0.6240)\tPrec@1 85.938 (89.416)\n",
            "Epoch: [77][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6006 (0.6305)\tPrec@1 88.281 (89.338)\n",
            "Epoch: [77][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6024 (0.6420)\tPrec@1 95.000 (89.038)\n",
            "Total time : 81.178\n",
            "Train Loss: 0.6420, Train Accuracy: 0.8904\n",
            "Test Loss : 0.8041, Test Accuracy : 0.7651 \n",
            "\n",
            "current lr 3.34684e-02\n",
            "Epoch: [78][0/391]\tTime 0.370 (0.370)\tData 0.162 (0.162)\tLoss 0.7102 (0.7102)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [78][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5576 (0.6029)\tPrec@1 93.750 (90.347)\n",
            "Epoch: [78][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6644 (0.6077)\tPrec@1 88.281 (90.054)\n",
            "Epoch: [78][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7738 (0.6198)\tPrec@1 85.156 (89.779)\n",
            "Epoch: [78][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.5767 (0.6298)\tPrec@1 95.000 (89.512)\n",
            "Total time : 81.173\n",
            "Train Loss: 0.6298, Train Accuracy: 0.8951\n",
            "Test Loss : 0.8586, Test Accuracy : 0.7492 \n",
            "\n",
            "current lr 3.30979e-02\n",
            "Epoch: [79][0/391]\tTime 0.367 (0.367)\tData 0.158 (0.158)\tLoss 0.6200 (0.6200)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [79][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6407 (0.5847)\tPrec@1 89.062 (90.656)\n",
            "Epoch: [79][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7065 (0.5956)\tPrec@1 89.062 (90.345)\n",
            "Epoch: [79][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7507 (0.6144)\tPrec@1 89.062 (89.841)\n",
            "Epoch: [79][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6746 (0.6240)\tPrec@1 90.000 (89.596)\n",
            "Total time : 81.177\n",
            "Train Loss: 0.6240, Train Accuracy: 0.8960\n",
            "Test Loss : 0.7881, Test Accuracy : 0.7698 \n",
            "\n",
            "current lr 3.27254e-02\n",
            "Epoch: [80][0/391]\tTime 0.365 (0.365)\tData 0.158 (0.158)\tLoss 0.6074 (0.6074)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [80][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5709 (0.5777)\tPrec@1 91.406 (90.718)\n",
            "Epoch: [80][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4721 (0.5961)\tPrec@1 95.312 (90.096)\n",
            "Epoch: [80][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5291 (0.6075)\tPrec@1 91.406 (89.820)\n",
            "Epoch: [80][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6291 (0.6184)\tPrec@1 88.750 (89.554)\n",
            "Total time : 81.164\n",
            "Train Loss: 0.6184, Train Accuracy: 0.8955\n",
            "Test Loss : 0.8307, Test Accuracy : 0.7565 \n",
            "\n",
            "current lr 3.23510e-02\n",
            "Epoch: [81][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.5868 (0.5868)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [81][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5366 (0.5604)\tPrec@1 89.844 (91.097)\n",
            "Epoch: [81][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6259 (0.5834)\tPrec@1 88.281 (90.567)\n",
            "Epoch: [81][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6958 (0.6016)\tPrec@1 88.281 (90.111)\n",
            "Epoch: [81][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.5408 (0.6099)\tPrec@1 93.750 (89.920)\n",
            "Total time : 81.112\n",
            "Train Loss: 0.6099, Train Accuracy: 0.8992\n",
            "Test Loss : 0.8067, Test Accuracy : 0.7622 \n",
            "\n",
            "current lr 3.19748e-02\n",
            "Epoch: [82][0/391]\tTime 0.368 (0.368)\tData 0.161 (0.161)\tLoss 0.6272 (0.6272)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [82][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5950 (0.5704)\tPrec@1 92.188 (90.965)\n",
            "Epoch: [82][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6226 (0.5805)\tPrec@1 89.844 (90.625)\n",
            "Epoch: [82][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6552 (0.5901)\tPrec@1 89.062 (90.443)\n",
            "Epoch: [82][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6667 (0.6014)\tPrec@1 90.000 (90.086)\n",
            "Total time : 81.149\n",
            "Train Loss: 0.6014, Train Accuracy: 0.9009\n",
            "Test Loss : 0.7769, Test Accuracy : 0.7763 \n",
            "\n",
            "current lr 3.15968e-02\n",
            "Epoch: [83][0/391]\tTime 0.365 (0.365)\tData 0.156 (0.156)\tLoss 0.5904 (0.5904)\tPrec@1 86.719 (86.719)\n",
            "Epoch: [83][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.5369 (0.5678)\tPrec@1 90.625 (90.950)\n",
            "Epoch: [83][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6000 (0.5796)\tPrec@1 90.625 (90.761)\n",
            "Epoch: [83][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5266 (0.5890)\tPrec@1 90.625 (90.555)\n",
            "Epoch: [83][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.5306 (0.5988)\tPrec@1 98.750 (90.276)\n",
            "Total time : 81.206\n",
            "Train Loss: 0.5988, Train Accuracy: 0.9028\n",
            "Test Loss : 0.7973, Test Accuracy : 0.7661 \n",
            "\n",
            "current lr 3.12172e-02\n",
            "Epoch: [84][0/391]\tTime 0.368 (0.368)\tData 0.160 (0.160)\tLoss 0.5279 (0.5279)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [84][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.5807 (0.5700)\tPrec@1 91.406 (90.671)\n",
            "Epoch: [84][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5298 (0.5814)\tPrec@1 92.969 (90.520)\n",
            "Epoch: [84][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.7260 (0.5854)\tPrec@1 85.938 (90.537)\n",
            "Epoch: [84][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6447 (0.5973)\tPrec@1 92.500 (90.094)\n",
            "Total time : 81.161\n",
            "Train Loss: 0.5973, Train Accuracy: 0.9009\n",
            "Test Loss : 0.7786, Test Accuracy : 0.7733 \n",
            "\n",
            "current lr 3.08361e-02\n",
            "Epoch: [85][0/391]\tTime 0.369 (0.369)\tData 0.162 (0.162)\tLoss 0.5479 (0.5479)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [85][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5031 (0.5500)\tPrec@1 91.406 (91.414)\n",
            "Epoch: [85][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5571 (0.5598)\tPrec@1 91.406 (90.990)\n",
            "Epoch: [85][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6835 (0.5726)\tPrec@1 87.500 (90.615)\n",
            "Epoch: [85][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6370 (0.5839)\tPrec@1 91.250 (90.318)\n",
            "Total time : 81.134\n",
            "Train Loss: 0.5839, Train Accuracy: 0.9032\n",
            "Test Loss : 0.7987, Test Accuracy : 0.7671 \n",
            "\n",
            "current lr 3.04536e-02\n",
            "Epoch: [86][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.6618 (0.6618)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [86][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.5593 (0.5438)\tPrec@1 92.188 (91.252)\n",
            "Epoch: [86][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4847 (0.5517)\tPrec@1 92.969 (91.173)\n",
            "Epoch: [86][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.5366 (0.5672)\tPrec@1 91.406 (90.755)\n",
            "Epoch: [86][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6863 (0.5762)\tPrec@1 90.000 (90.562)\n",
            "Total time : 81.172\n",
            "Train Loss: 0.5762, Train Accuracy: 0.9056\n",
            "Test Loss : 0.7843, Test Accuracy : 0.7710 \n",
            "\n",
            "current lr 3.00697e-02\n",
            "Epoch: [87][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.5233 (0.5233)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [87][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5077 (0.5209)\tPrec@1 91.406 (92.350)\n",
            "Epoch: [87][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5539 (0.5411)\tPrec@1 93.750 (91.725)\n",
            "Epoch: [87][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.5253 (0.5513)\tPrec@1 92.188 (91.328)\n",
            "Epoch: [87][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6051 (0.5626)\tPrec@1 90.000 (91.040)\n",
            "Total time : 81.205\n",
            "Train Loss: 0.5626, Train Accuracy: 0.9104\n",
            "Test Loss : 0.7623, Test Accuracy : 0.7760 \n",
            "\n",
            "current lr 2.96845e-02\n",
            "Epoch: [88][0/391]\tTime 0.361 (0.361)\tData 0.153 (0.153)\tLoss 0.5424 (0.5424)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [88][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5709 (0.5283)\tPrec@1 92.188 (91.770)\n",
            "Epoch: [88][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6110 (0.5411)\tPrec@1 93.750 (91.601)\n",
            "Epoch: [88][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5625 (0.5508)\tPrec@1 89.062 (91.383)\n",
            "Epoch: [88][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.6901 (0.5563)\tPrec@1 91.250 (91.224)\n",
            "Total time : 81.177\n",
            "Train Loss: 0.5563, Train Accuracy: 0.9122\n",
            "Test Loss : 0.7655, Test Accuracy : 0.7722 \n",
            "\n",
            "current lr 2.92982e-02\n",
            "Epoch: [89][0/391]\tTime 0.360 (0.360)\tData 0.152 (0.152)\tLoss 0.6266 (0.6266)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [89][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.4787 (0.5038)\tPrec@1 91.406 (92.528)\n",
            "Epoch: [89][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5319 (0.5224)\tPrec@1 94.531 (91.989)\n",
            "Epoch: [89][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5578 (0.5367)\tPrec@1 90.625 (91.642)\n",
            "Epoch: [89][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.5555 (0.5441)\tPrec@1 93.750 (91.462)\n",
            "Total time : 81.187\n",
            "Train Loss: 0.5441, Train Accuracy: 0.9146\n",
            "Test Loss : 0.7488, Test Accuracy : 0.7828 \n",
            "\n",
            "current lr 2.89109e-02\n",
            "Epoch: [90][0/391]\tTime 0.369 (0.369)\tData 0.157 (0.157)\tLoss 0.4683 (0.4683)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [90][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.5181 (0.5205)\tPrec@1 94.531 (92.188)\n",
            "Epoch: [90][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6806 (0.5326)\tPrec@1 85.156 (91.818)\n",
            "Epoch: [90][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5540 (0.5414)\tPrec@1 91.406 (91.570)\n",
            "Epoch: [90][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.5657 (0.5492)\tPrec@1 95.000 (91.350)\n",
            "Total time : 81.172\n",
            "Train Loss: 0.5492, Train Accuracy: 0.9135\n",
            "Test Loss : 0.7591, Test Accuracy : 0.7810 \n",
            "\n",
            "current lr 2.85225e-02\n",
            "Epoch: [91][0/391]\tTime 0.371 (0.371)\tData 0.163 (0.163)\tLoss 0.4949 (0.4949)\tPrec@1 91.406 (91.406)\n",
            "Epoch: [91][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6323 (0.5049)\tPrec@1 88.281 (92.327)\n",
            "Epoch: [91][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4902 (0.5175)\tPrec@1 90.625 (91.954)\n",
            "Epoch: [91][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.5400 (0.5312)\tPrec@1 89.844 (91.645)\n",
            "Epoch: [91][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3906 (0.5414)\tPrec@1 96.250 (91.400)\n",
            "Total time : 81.191\n",
            "Train Loss: 0.5414, Train Accuracy: 0.9140\n",
            "Test Loss : 0.7339, Test Accuracy : 0.7866 \n",
            "\n",
            "current lr 2.81333e-02\n",
            "Epoch: [92][0/391]\tTime 0.367 (0.367)\tData 0.159 (0.159)\tLoss 0.5636 (0.5636)\tPrec@1 88.281 (88.281)\n",
            "Epoch: [92][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.4255 (0.4945)\tPrec@1 92.969 (92.435)\n",
            "Epoch: [92][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5590 (0.4972)\tPrec@1 89.844 (92.475)\n",
            "Epoch: [92][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4555 (0.5157)\tPrec@1 93.750 (92.102)\n",
            "Epoch: [92][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.5935 (0.5265)\tPrec@1 86.250 (91.860)\n",
            "Total time : 81.180\n",
            "Train Loss: 0.5265, Train Accuracy: 0.9186\n",
            "Test Loss : 0.7958, Test Accuracy : 0.7675 \n",
            "\n",
            "current lr 2.77434e-02\n",
            "Epoch: [93][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.4661 (0.4661)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [93][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4046 (0.4960)\tPrec@1 96.875 (92.497)\n",
            "Epoch: [93][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.5534 (0.5046)\tPrec@1 88.281 (92.370)\n",
            "Epoch: [93][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5491 (0.5154)\tPrec@1 90.625 (92.040)\n",
            "Epoch: [93][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.5145 (0.5247)\tPrec@1 93.750 (91.888)\n",
            "Total time : 81.174\n",
            "Train Loss: 0.5247, Train Accuracy: 0.9189\n",
            "Test Loss : 0.7603, Test Accuracy : 0.7822 \n",
            "\n",
            "current lr 2.73527e-02\n",
            "Epoch: [94][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.3351 (0.3351)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [94][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4576 (0.4810)\tPrec@1 93.750 (92.938)\n",
            "Epoch: [94][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4539 (0.4961)\tPrec@1 94.531 (92.627)\n",
            "Epoch: [94][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5323 (0.5022)\tPrec@1 89.844 (92.398)\n",
            "Epoch: [94][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.7763 (0.5128)\tPrec@1 87.500 (92.132)\n",
            "Total time : 81.128\n",
            "Train Loss: 0.5128, Train Accuracy: 0.9213\n",
            "Test Loss : 0.7597, Test Accuracy : 0.7800 \n",
            "\n",
            "current lr 2.69615e-02\n",
            "Epoch: [95][0/391]\tTime 0.365 (0.365)\tData 0.157 (0.157)\tLoss 0.4901 (0.4901)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [95][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.6039 (0.4742)\tPrec@1 90.625 (92.845)\n",
            "Epoch: [95][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.6463 (0.4885)\tPrec@1 86.719 (92.522)\n",
            "Epoch: [95][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4622 (0.4983)\tPrec@1 92.969 (92.276)\n",
            "Epoch: [95][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.5305 (0.5064)\tPrec@1 92.500 (92.076)\n",
            "Total time : 81.128\n",
            "Train Loss: 0.5064, Train Accuracy: 0.9208\n",
            "Test Loss : 0.7402, Test Accuracy : 0.7861 \n",
            "\n",
            "current lr 2.65698e-02\n",
            "Epoch: [96][0/391]\tTime 0.365 (0.365)\tData 0.157 (0.157)\tLoss 0.4535 (0.4535)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [96][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4402 (0.4688)\tPrec@1 91.406 (93.154)\n",
            "Epoch: [96][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4354 (0.4780)\tPrec@1 94.531 (92.922)\n",
            "Epoch: [96][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4030 (0.4915)\tPrec@1 94.531 (92.637)\n",
            "Epoch: [96][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6838 (0.5005)\tPrec@1 92.500 (92.328)\n",
            "Total time : 81.199\n",
            "Train Loss: 0.5005, Train Accuracy: 0.9233\n",
            "Test Loss : 0.7562, Test Accuracy : 0.7813 \n",
            "\n",
            "current lr 2.61777e-02\n",
            "Epoch: [97][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.4243 (0.4243)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [97][100/391]\tTime 0.210 (0.209)\tData 0.000 (0.002)\tLoss 0.4345 (0.4718)\tPrec@1 92.188 (92.946)\n",
            "Epoch: [97][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4692 (0.4753)\tPrec@1 92.969 (92.879)\n",
            "Epoch: [97][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.5335 (0.4854)\tPrec@1 93.750 (92.678)\n",
            "Epoch: [97][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.5510 (0.4929)\tPrec@1 91.250 (92.572)\n",
            "Total time : 81.233\n",
            "Train Loss: 0.4929, Train Accuracy: 0.9257\n",
            "Test Loss : 0.7466, Test Accuracy : 0.7833 \n",
            "\n",
            "current lr 2.57853e-02\n",
            "Epoch: [98][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.3990 (0.3990)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [98][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3800 (0.4559)\tPrec@1 95.312 (93.495)\n",
            "Epoch: [98][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5174 (0.4690)\tPrec@1 94.531 (93.159)\n",
            "Epoch: [98][300/391]\tTime 0.209 (0.208)\tData 0.000 (0.001)\tLoss 0.4689 (0.4784)\tPrec@1 92.969 (93.070)\n",
            "Epoch: [98][390/391]\tTime 0.139 (0.208)\tData 0.000 (0.001)\tLoss 0.5048 (0.4867)\tPrec@1 95.000 (92.842)\n",
            "Total time : 81.201\n",
            "Train Loss: 0.4867, Train Accuracy: 0.9284\n",
            "Test Loss : 0.7129, Test Accuracy : 0.7905 \n",
            "\n",
            "current lr 2.53927e-02\n",
            "Epoch: [99][0/391]\tTime 0.361 (0.361)\tData 0.153 (0.153)\tLoss 0.4159 (0.4159)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [99][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4409 (0.4509)\tPrec@1 94.531 (93.665)\n",
            "Epoch: [99][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4652 (0.4598)\tPrec@1 92.188 (93.284)\n",
            "Epoch: [99][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4555 (0.4679)\tPrec@1 92.188 (93.161)\n",
            "Epoch: [99][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.4055 (0.4770)\tPrec@1 96.250 (92.992)\n",
            "Total time : 81.184\n",
            "Train Loss: 0.4770, Train Accuracy: 0.9299\n",
            "Test Loss : 0.7133, Test Accuracy : 0.7934 \n",
            "\n",
            "current lr 2.50000e-02\n",
            "Epoch: [100][0/391]\tTime 0.364 (0.364)\tData 0.155 (0.155)\tLoss 0.4539 (0.4539)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [100][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.4819 (0.4311)\tPrec@1 89.844 (94.114)\n",
            "Epoch: [100][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.6052 (0.4410)\tPrec@1 92.188 (93.808)\n",
            "Epoch: [100][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3351 (0.4526)\tPrec@1 96.875 (93.529)\n",
            "Epoch: [100][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4612 (0.4604)\tPrec@1 95.000 (93.332)\n",
            "Total time : 81.214\n",
            "Train Loss: 0.4604, Train Accuracy: 0.9333\n",
            "Test Loss : 0.7323, Test Accuracy : 0.7881 \n",
            "\n",
            "current lr 2.46073e-02\n",
            "Epoch: [101][0/391]\tTime 0.368 (0.368)\tData 0.160 (0.160)\tLoss 0.3755 (0.3755)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [101][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4815 (0.4283)\tPrec@1 93.750 (94.191)\n",
            "Epoch: [101][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4468 (0.4430)\tPrec@1 94.531 (93.754)\n",
            "Epoch: [101][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5096 (0.4542)\tPrec@1 91.406 (93.454)\n",
            "Epoch: [101][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.5019 (0.4623)\tPrec@1 97.500 (93.250)\n",
            "Total time : 81.175\n",
            "Train Loss: 0.4623, Train Accuracy: 0.9325\n",
            "Test Loss : 0.7216, Test Accuracy : 0.7884 \n",
            "\n",
            "current lr 2.42147e-02\n",
            "Epoch: [102][0/391]\tTime 0.372 (0.372)\tData 0.164 (0.164)\tLoss 0.4340 (0.4340)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [102][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.4396 (0.4202)\tPrec@1 96.094 (94.067)\n",
            "Epoch: [102][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4620 (0.4326)\tPrec@1 92.188 (93.758)\n",
            "Epoch: [102][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4390 (0.4428)\tPrec@1 92.969 (93.553)\n",
            "Epoch: [102][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.6454 (0.4482)\tPrec@1 90.000 (93.498)\n",
            "Total time : 81.150\n",
            "Train Loss: 0.4482, Train Accuracy: 0.9350\n",
            "Test Loss : 0.7361, Test Accuracy : 0.7841 \n",
            "\n",
            "current lr 2.38223e-02\n",
            "Epoch: [103][0/391]\tTime 0.368 (0.368)\tData 0.159 (0.159)\tLoss 0.3438 (0.3438)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [103][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4800 (0.4321)\tPrec@1 92.969 (93.812)\n",
            "Epoch: [103][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4766 (0.4379)\tPrec@1 93.750 (93.723)\n",
            "Epoch: [103][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4445 (0.4443)\tPrec@1 92.188 (93.646)\n",
            "Epoch: [103][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4044 (0.4503)\tPrec@1 95.000 (93.566)\n",
            "Total time : 81.200\n",
            "Train Loss: 0.4503, Train Accuracy: 0.9357\n",
            "Test Loss : 0.7211, Test Accuracy : 0.7898 \n",
            "\n",
            "current lr 2.34302e-02\n",
            "Epoch: [104][0/391]\tTime 0.367 (0.367)\tData 0.158 (0.158)\tLoss 0.4930 (0.4930)\tPrec@1 89.844 (89.844)\n",
            "Epoch: [104][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4422 (0.4174)\tPrec@1 94.531 (94.129)\n",
            "Epoch: [104][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4365 (0.4200)\tPrec@1 93.750 (94.108)\n",
            "Epoch: [104][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4970 (0.4326)\tPrec@1 94.531 (93.828)\n",
            "Epoch: [104][390/391]\tTime 0.139 (0.208)\tData 0.000 (0.001)\tLoss 0.5374 (0.4418)\tPrec@1 92.500 (93.634)\n",
            "Total time : 81.214\n",
            "Train Loss: 0.4418, Train Accuracy: 0.9363\n",
            "Test Loss : 0.7249, Test Accuracy : 0.7881 \n",
            "\n",
            "current lr 2.30385e-02\n",
            "Epoch: [105][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.4011 (0.4011)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [105][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.3229 (0.4140)\tPrec@1 96.094 (94.175)\n",
            "Epoch: [105][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.5312 (0.4181)\tPrec@1 92.969 (94.010)\n",
            "Epoch: [105][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4487 (0.4249)\tPrec@1 90.625 (93.898)\n",
            "Epoch: [105][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.3678 (0.4345)\tPrec@1 97.500 (93.782)\n",
            "Total time : 81.200\n",
            "Train Loss: 0.4345, Train Accuracy: 0.9378\n",
            "Test Loss : 0.7163, Test Accuracy : 0.7982 \n",
            "\n",
            "current lr 2.26473e-02\n",
            "Epoch: [106][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.4849 (0.4849)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [106][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.3660 (0.4111)\tPrec@1 95.312 (94.067)\n",
            "Epoch: [106][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4450 (0.4141)\tPrec@1 93.750 (94.135)\n",
            "Epoch: [106][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5123 (0.4190)\tPrec@1 92.969 (94.023)\n",
            "Epoch: [106][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.5349 (0.4240)\tPrec@1 93.750 (93.938)\n",
            "Total time : 81.150\n",
            "Train Loss: 0.4240, Train Accuracy: 0.9394\n",
            "Test Loss : 0.7061, Test Accuracy : 0.7979 \n",
            "\n",
            "current lr 2.22566e-02\n",
            "Epoch: [107][0/391]\tTime 0.365 (0.365)\tData 0.157 (0.157)\tLoss 0.4646 (0.4646)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [107][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.2994 (0.3836)\tPrec@1 95.312 (95.080)\n",
            "Epoch: [107][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3970 (0.3925)\tPrec@1 95.312 (94.749)\n",
            "Epoch: [107][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5002 (0.4050)\tPrec@1 92.188 (94.420)\n",
            "Epoch: [107][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4418 (0.4154)\tPrec@1 93.750 (94.184)\n",
            "Total time : 81.178\n",
            "Train Loss: 0.4154, Train Accuracy: 0.9418\n",
            "Test Loss : 0.6825, Test Accuracy : 0.8039 \n",
            "\n",
            "current lr 2.18667e-02\n",
            "Epoch: [108][0/391]\tTime 0.403 (0.403)\tData 0.195 (0.195)\tLoss 0.3308 (0.3308)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [108][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3528 (0.3875)\tPrec@1 96.094 (94.856)\n",
            "Epoch: [108][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3458 (0.3914)\tPrec@1 96.094 (94.714)\n",
            "Epoch: [108][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5101 (0.4015)\tPrec@1 92.969 (94.482)\n",
            "Epoch: [108][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.5931 (0.4114)\tPrec@1 90.000 (94.236)\n",
            "Total time : 81.231\n",
            "Train Loss: 0.4114, Train Accuracy: 0.9424\n",
            "Test Loss : 0.6988, Test Accuracy : 0.7937 \n",
            "\n",
            "current lr 2.14775e-02\n",
            "Epoch: [109][0/391]\tTime 0.364 (0.364)\tData 0.156 (0.156)\tLoss 0.3732 (0.3732)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [109][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3225 (0.3745)\tPrec@1 96.875 (95.057)\n",
            "Epoch: [109][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4072 (0.3851)\tPrec@1 96.875 (94.838)\n",
            "Epoch: [109][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3787 (0.3937)\tPrec@1 95.312 (94.513)\n",
            "Epoch: [109][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3368 (0.4006)\tPrec@1 98.750 (94.420)\n",
            "Total time : 81.220\n",
            "Train Loss: 0.4006, Train Accuracy: 0.9442\n",
            "Test Loss : 0.6838, Test Accuracy : 0.8022 \n",
            "\n",
            "current lr 2.10891e-02\n",
            "Epoch: [110][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.3786 (0.3786)\tPrec@1 92.969 (92.969)\n",
            "Epoch: [110][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.4195 (0.3822)\tPrec@1 94.531 (95.080)\n",
            "Epoch: [110][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3641 (0.3843)\tPrec@1 92.969 (94.943)\n",
            "Epoch: [110][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4238 (0.3940)\tPrec@1 96.094 (94.708)\n",
            "Epoch: [110][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.5498 (0.3980)\tPrec@1 90.000 (94.588)\n",
            "Total time : 81.096\n",
            "Train Loss: 0.3980, Train Accuracy: 0.9459\n",
            "Test Loss : 0.6825, Test Accuracy : 0.8025 \n",
            "\n",
            "current lr 2.07018e-02\n",
            "Epoch: [111][0/391]\tTime 0.368 (0.368)\tData 0.160 (0.160)\tLoss 0.4060 (0.4060)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [111][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3746 (0.3491)\tPrec@1 95.312 (95.583)\n",
            "Epoch: [111][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4913 (0.3660)\tPrec@1 92.969 (95.176)\n",
            "Epoch: [111][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3465 (0.3805)\tPrec@1 95.312 (94.928)\n",
            "Epoch: [111][390/391]\tTime 0.138 (0.207)\tData 0.000 (0.001)\tLoss 0.3383 (0.3869)\tPrec@1 96.250 (94.762)\n",
            "Total time : 81.111\n",
            "Train Loss: 0.3869, Train Accuracy: 0.9476\n",
            "Test Loss : 0.6876, Test Accuracy : 0.7962 \n",
            "\n",
            "current lr 2.03155e-02\n",
            "Epoch: [112][0/391]\tTime 0.363 (0.363)\tData 0.156 (0.156)\tLoss 0.3493 (0.3493)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [112][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3422 (0.3486)\tPrec@1 96.094 (95.722)\n",
            "Epoch: [112][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4149 (0.3570)\tPrec@1 94.531 (95.592)\n",
            "Epoch: [112][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.5001 (0.3640)\tPrec@1 92.188 (95.390)\n",
            "Epoch: [112][390/391]\tTime 0.141 (0.208)\tData 0.000 (0.001)\tLoss 0.5067 (0.3765)\tPrec@1 92.500 (95.088)\n",
            "Total time : 81.143\n",
            "Train Loss: 0.3765, Train Accuracy: 0.9509\n",
            "Test Loss : 0.6929, Test Accuracy : 0.7953 \n",
            "\n",
            "current lr 1.99303e-02\n",
            "Epoch: [113][0/391]\tTime 0.368 (0.368)\tData 0.159 (0.159)\tLoss 0.3535 (0.3535)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [113][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.3292 (0.3594)\tPrec@1 97.656 (95.452)\n",
            "Epoch: [113][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3976 (0.3653)\tPrec@1 95.312 (95.297)\n",
            "Epoch: [113][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3863 (0.3691)\tPrec@1 96.094 (95.133)\n",
            "Epoch: [113][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3981 (0.3747)\tPrec@1 93.750 (95.004)\n",
            "Total time : 81.175\n",
            "Train Loss: 0.3747, Train Accuracy: 0.9500\n",
            "Test Loss : 0.6636, Test Accuracy : 0.8076 \n",
            "\n",
            "current lr 1.95464e-02\n",
            "Epoch: [114][0/391]\tTime 0.368 (0.368)\tData 0.159 (0.159)\tLoss 0.3009 (0.3009)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [114][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3666 (0.3365)\tPrec@1 95.312 (95.777)\n",
            "Epoch: [114][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4084 (0.3481)\tPrec@1 95.312 (95.616)\n",
            "Epoch: [114][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.4397 (0.3561)\tPrec@1 92.969 (95.401)\n",
            "Epoch: [114][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4328 (0.3633)\tPrec@1 92.500 (95.206)\n",
            "Total time : 81.197\n",
            "Train Loss: 0.3633, Train Accuracy: 0.9521\n",
            "Test Loss : 0.6726, Test Accuracy : 0.8082 \n",
            "\n",
            "current lr 1.91639e-02\n",
            "Epoch: [115][0/391]\tTime 0.384 (0.384)\tData 0.176 (0.176)\tLoss 0.3017 (0.3017)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [115][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3375 (0.3379)\tPrec@1 94.531 (95.568)\n",
            "Epoch: [115][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3556 (0.3458)\tPrec@1 95.312 (95.491)\n",
            "Epoch: [115][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4290 (0.3521)\tPrec@1 93.750 (95.393)\n",
            "Epoch: [115][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4260 (0.3597)\tPrec@1 97.500 (95.260)\n",
            "Total time : 81.133\n",
            "Train Loss: 0.3597, Train Accuracy: 0.9526\n",
            "Test Loss : 0.6829, Test Accuracy : 0.8012 \n",
            "\n",
            "current lr 1.87828e-02\n",
            "Epoch: [116][0/391]\tTime 0.381 (0.381)\tData 0.173 (0.173)\tLoss 0.3764 (0.3764)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [116][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3873 (0.3382)\tPrec@1 92.969 (95.800)\n",
            "Epoch: [116][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2458 (0.3441)\tPrec@1 97.656 (95.577)\n",
            "Epoch: [116][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3418 (0.3498)\tPrec@1 95.312 (95.424)\n",
            "Epoch: [116][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.4344 (0.3548)\tPrec@1 93.750 (95.344)\n",
            "Total time : 81.155\n",
            "Train Loss: 0.3548, Train Accuracy: 0.9534\n",
            "Test Loss : 0.6565, Test Accuracy : 0.8085 \n",
            "\n",
            "current lr 1.84032e-02\n",
            "Epoch: [117][0/391]\tTime 0.381 (0.381)\tData 0.172 (0.172)\tLoss 0.2888 (0.2888)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [117][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3538 (0.3351)\tPrec@1 96.875 (95.908)\n",
            "Epoch: [117][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2931 (0.3350)\tPrec@1 97.656 (95.814)\n",
            "Epoch: [117][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.4796 (0.3403)\tPrec@1 91.406 (95.665)\n",
            "Epoch: [117][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3965 (0.3474)\tPrec@1 97.500 (95.526)\n",
            "Total time : 81.179\n",
            "Train Loss: 0.3474, Train Accuracy: 0.9553\n",
            "Test Loss : 0.6505, Test Accuracy : 0.8112 \n",
            "\n",
            "current lr 1.80252e-02\n",
            "Epoch: [118][0/391]\tTime 0.368 (0.368)\tData 0.161 (0.161)\tLoss 0.2656 (0.2656)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [118][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3141 (0.3246)\tPrec@1 97.656 (95.939)\n",
            "Epoch: [118][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2304 (0.3255)\tPrec@1 98.438 (95.853)\n",
            "Epoch: [118][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3087 (0.3350)\tPrec@1 97.656 (95.715)\n",
            "Epoch: [118][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.4471 (0.3434)\tPrec@1 95.000 (95.560)\n",
            "Total time : 81.211\n",
            "Train Loss: 0.3434, Train Accuracy: 0.9556\n",
            "Test Loss : 0.6633, Test Accuracy : 0.8104 \n",
            "\n",
            "current lr 1.76490e-02\n",
            "Epoch: [119][0/391]\tTime 0.380 (0.380)\tData 0.171 (0.171)\tLoss 0.3162 (0.3162)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [119][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3891 (0.3173)\tPrec@1 95.312 (96.148)\n",
            "Epoch: [119][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3976 (0.3227)\tPrec@1 92.969 (95.884)\n",
            "Epoch: [119][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3345 (0.3272)\tPrec@1 94.531 (95.826)\n",
            "Epoch: [119][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3768 (0.3330)\tPrec@1 96.250 (95.706)\n",
            "Total time : 81.207\n",
            "Train Loss: 0.3330, Train Accuracy: 0.9571\n",
            "Test Loss : 0.6633, Test Accuracy : 0.8062 \n",
            "\n",
            "current lr 1.72746e-02\n",
            "Epoch: [120][0/391]\tTime 0.377 (0.377)\tData 0.170 (0.170)\tLoss 0.3283 (0.3283)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [120][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2492 (0.3252)\tPrec@1 97.656 (95.722)\n",
            "Epoch: [120][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3760 (0.3246)\tPrec@1 92.969 (95.806)\n",
            "Epoch: [120][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3506 (0.3255)\tPrec@1 94.531 (95.871)\n",
            "Epoch: [120][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3603 (0.3299)\tPrec@1 95.000 (95.756)\n",
            "Total time : 81.148\n",
            "Train Loss: 0.3299, Train Accuracy: 0.9576\n",
            "Test Loss : 0.6489, Test Accuracy : 0.8087 \n",
            "\n",
            "current lr 1.69021e-02\n",
            "Epoch: [121][0/391]\tTime 0.383 (0.383)\tData 0.175 (0.175)\tLoss 0.3557 (0.3557)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [121][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3544 (0.3050)\tPrec@1 97.656 (96.187)\n",
            "Epoch: [121][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3835 (0.3117)\tPrec@1 94.531 (96.156)\n",
            "Epoch: [121][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3057 (0.3165)\tPrec@1 95.312 (96.011)\n",
            "Epoch: [121][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2477 (0.3215)\tPrec@1 98.750 (95.870)\n",
            "Total time : 81.165\n",
            "Train Loss: 0.3215, Train Accuracy: 0.9587\n",
            "Test Loss : 0.6500, Test Accuracy : 0.8110 \n",
            "\n",
            "current lr 1.65316e-02\n",
            "Epoch: [122][0/391]\tTime 0.375 (0.375)\tData 0.168 (0.168)\tLoss 0.2602 (0.2602)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [122][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3425 (0.2937)\tPrec@1 96.875 (96.434)\n",
            "Epoch: [122][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3638 (0.3046)\tPrec@1 96.094 (96.191)\n",
            "Epoch: [122][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2770 (0.3141)\tPrec@1 98.438 (95.995)\n",
            "Epoch: [122][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3826 (0.3179)\tPrec@1 96.250 (95.932)\n",
            "Total time : 81.167\n",
            "Train Loss: 0.3179, Train Accuracy: 0.9593\n",
            "Test Loss : 0.6485, Test Accuracy : 0.8134 \n",
            "\n",
            "current lr 1.61631e-02\n",
            "Epoch: [123][0/391]\tTime 0.385 (0.385)\tData 0.178 (0.178)\tLoss 0.2091 (0.2091)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [123][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.3282 (0.2849)\tPrec@1 95.312 (96.658)\n",
            "Epoch: [123][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2911 (0.2935)\tPrec@1 95.312 (96.405)\n",
            "Epoch: [123][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3659 (0.2997)\tPrec@1 94.531 (96.286)\n",
            "Epoch: [123][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.4040 (0.3073)\tPrec@1 96.250 (96.132)\n",
            "Total time : 81.225\n",
            "Train Loss: 0.3073, Train Accuracy: 0.9613\n",
            "Test Loss : 0.6478, Test Accuracy : 0.8150 \n",
            "\n",
            "current lr 1.57969e-02\n",
            "Epoch: [124][0/391]\tTime 0.375 (0.375)\tData 0.167 (0.167)\tLoss 0.2861 (0.2861)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [124][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3186 (0.2819)\tPrec@1 97.656 (96.612)\n",
            "Epoch: [124][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2634 (0.2899)\tPrec@1 95.312 (96.354)\n",
            "Epoch: [124][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3251 (0.2965)\tPrec@1 95.312 (96.200)\n",
            "Epoch: [124][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4678 (0.3013)\tPrec@1 95.000 (96.122)\n",
            "Total time : 81.162\n",
            "Train Loss: 0.3013, Train Accuracy: 0.9612\n",
            "Test Loss : 0.6328, Test Accuracy : 0.8174 \n",
            "\n",
            "current lr 1.54329e-02\n",
            "Epoch: [125][0/391]\tTime 0.382 (0.382)\tData 0.175 (0.175)\tLoss 0.2019 (0.2019)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [125][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2760 (0.2767)\tPrec@1 97.656 (96.597)\n",
            "Epoch: [125][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.3076 (0.2864)\tPrec@1 96.875 (96.362)\n",
            "Epoch: [125][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2917 (0.2915)\tPrec@1 97.656 (96.343)\n",
            "Epoch: [125][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.5118 (0.2971)\tPrec@1 95.000 (96.314)\n",
            "Total time : 81.189\n",
            "Train Loss: 0.2971, Train Accuracy: 0.9631\n",
            "Test Loss : 0.6381, Test Accuracy : 0.8139 \n",
            "\n",
            "current lr 1.50713e-02\n",
            "Epoch: [126][0/391]\tTime 0.387 (0.387)\tData 0.179 (0.179)\tLoss 0.2075 (0.2075)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [126][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3016 (0.2733)\tPrec@1 96.875 (96.774)\n",
            "Epoch: [126][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2722 (0.2826)\tPrec@1 97.656 (96.568)\n",
            "Epoch: [126][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3775 (0.2884)\tPrec@1 96.094 (96.499)\n",
            "Epoch: [126][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3950 (0.2910)\tPrec@1 93.750 (96.414)\n",
            "Total time : 81.163\n",
            "Train Loss: 0.2910, Train Accuracy: 0.9641\n",
            "Test Loss : 0.6628, Test Accuracy : 0.8079 \n",
            "\n",
            "current lr 1.47121e-02\n",
            "Epoch: [127][0/391]\tTime 0.387 (0.387)\tData 0.179 (0.179)\tLoss 0.2419 (0.2419)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [127][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3106 (0.2621)\tPrec@1 96.875 (96.883)\n",
            "Epoch: [127][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3297 (0.2700)\tPrec@1 95.312 (96.731)\n",
            "Epoch: [127][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2464 (0.2784)\tPrec@1 97.656 (96.589)\n",
            "Epoch: [127][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.2590 (0.2841)\tPrec@1 98.750 (96.516)\n",
            "Total time : 81.122\n",
            "Train Loss: 0.2841, Train Accuracy: 0.9652\n",
            "Test Loss : 0.6335, Test Accuracy : 0.8171 \n",
            "\n",
            "current lr 1.43555e-02\n",
            "Epoch: [128][0/391]\tTime 0.386 (0.386)\tData 0.176 (0.176)\tLoss 0.2666 (0.2666)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [128][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3875 (0.2642)\tPrec@1 92.188 (97.045)\n",
            "Epoch: [128][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2962 (0.2691)\tPrec@1 93.750 (96.789)\n",
            "Epoch: [128][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3069 (0.2725)\tPrec@1 96.094 (96.784)\n",
            "Epoch: [128][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3036 (0.2761)\tPrec@1 98.750 (96.710)\n",
            "Total time : 81.173\n",
            "Train Loss: 0.2761, Train Accuracy: 0.9671\n",
            "Test Loss : 0.6253, Test Accuracy : 0.8187 \n",
            "\n",
            "current lr 1.40015e-02\n",
            "Epoch: [129][0/391]\tTime 0.385 (0.385)\tData 0.178 (0.178)\tLoss 0.2513 (0.2513)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [129][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2187 (0.2485)\tPrec@1 99.219 (97.153)\n",
            "Epoch: [129][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2869 (0.2618)\tPrec@1 96.094 (96.844)\n",
            "Epoch: [129][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3163 (0.2677)\tPrec@1 96.094 (96.789)\n",
            "Epoch: [129][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3536 (0.2712)\tPrec@1 95.000 (96.718)\n",
            "Total time : 81.191\n",
            "Train Loss: 0.2712, Train Accuracy: 0.9672\n",
            "Test Loss : 0.6233, Test Accuracy : 0.8187 \n",
            "\n",
            "current lr 1.36502e-02\n",
            "Epoch: [130][0/391]\tTime 0.379 (0.379)\tData 0.172 (0.172)\tLoss 0.3070 (0.3070)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [130][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.3080 (0.2414)\tPrec@1 96.875 (97.324)\n",
            "Epoch: [130][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2845 (0.2442)\tPrec@1 95.312 (97.147)\n",
            "Epoch: [130][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2125 (0.2537)\tPrec@1 97.656 (96.950)\n",
            "Epoch: [130][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.3188 (0.2591)\tPrec@1 96.250 (96.854)\n",
            "Total time : 81.202\n",
            "Train Loss: 0.2591, Train Accuracy: 0.9685\n",
            "Test Loss : 0.6380, Test Accuracy : 0.8141 \n",
            "\n",
            "current lr 1.33018e-02\n",
            "Epoch: [131][0/391]\tTime 0.379 (0.379)\tData 0.171 (0.171)\tLoss 0.1804 (0.1804)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [131][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2556 (0.2501)\tPrec@1 96.875 (96.929)\n",
            "Epoch: [131][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3580 (0.2517)\tPrec@1 95.312 (97.038)\n",
            "Epoch: [131][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2584 (0.2570)\tPrec@1 93.750 (96.958)\n",
            "Epoch: [131][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.4133 (0.2616)\tPrec@1 93.750 (96.864)\n",
            "Total time : 81.152\n",
            "Train Loss: 0.2616, Train Accuracy: 0.9686\n",
            "Test Loss : 0.6353, Test Accuracy : 0.8149 \n",
            "\n",
            "current lr 1.29562e-02\n",
            "Epoch: [132][0/391]\tTime 0.376 (0.376)\tData 0.169 (0.169)\tLoss 0.1817 (0.1817)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [132][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2358 (0.2434)\tPrec@1 96.875 (97.138)\n",
            "Epoch: [132][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2620 (0.2495)\tPrec@1 98.438 (97.042)\n",
            "Epoch: [132][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2373 (0.2519)\tPrec@1 96.094 (97.026)\n",
            "Epoch: [132][390/391]\tTime 0.141 (0.208)\tData 0.000 (0.001)\tLoss 0.3249 (0.2548)\tPrec@1 96.250 (96.980)\n",
            "Total time : 81.204\n",
            "Train Loss: 0.2548, Train Accuracy: 0.9698\n",
            "Test Loss : 0.6150, Test Accuracy : 0.8230 \n",
            "\n",
            "current lr 1.26135e-02\n",
            "Epoch: [133][0/391]\tTime 0.378 (0.378)\tData 0.170 (0.170)\tLoss 0.2229 (0.2229)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [133][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1834 (0.2342)\tPrec@1 99.219 (97.262)\n",
            "Epoch: [133][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2809 (0.2361)\tPrec@1 95.312 (97.194)\n",
            "Epoch: [133][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2909 (0.2430)\tPrec@1 95.312 (97.088)\n",
            "Epoch: [133][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2712 (0.2482)\tPrec@1 95.000 (97.006)\n",
            "Total time : 81.187\n",
            "Train Loss: 0.2482, Train Accuracy: 0.9701\n",
            "Test Loss : 0.6157, Test Accuracy : 0.8215 \n",
            "\n",
            "current lr 1.22740e-02\n",
            "Epoch: [134][0/391]\tTime 0.381 (0.381)\tData 0.172 (0.172)\tLoss 0.2274 (0.2274)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [134][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2206 (0.2337)\tPrec@1 97.656 (97.192)\n",
            "Epoch: [134][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2287 (0.2362)\tPrec@1 96.094 (97.182)\n",
            "Epoch: [134][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2567 (0.2408)\tPrec@1 97.656 (97.192)\n",
            "Epoch: [134][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2929 (0.2449)\tPrec@1 100.000 (97.090)\n",
            "Total time : 81.170\n",
            "Train Loss: 0.2449, Train Accuracy: 0.9709\n",
            "Test Loss : 0.6243, Test Accuracy : 0.8215 \n",
            "\n",
            "current lr 1.19375e-02\n",
            "Epoch: [135][0/391]\tTime 0.377 (0.377)\tData 0.169 (0.169)\tLoss 0.2183 (0.2183)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [135][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2977 (0.2272)\tPrec@1 96.094 (97.347)\n",
            "Epoch: [135][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2876 (0.2362)\tPrec@1 93.750 (97.174)\n",
            "Epoch: [135][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2683 (0.2371)\tPrec@1 97.656 (97.137)\n",
            "Epoch: [135][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.3147 (0.2389)\tPrec@1 96.250 (97.136)\n",
            "Total time : 81.179\n",
            "Train Loss: 0.2389, Train Accuracy: 0.9714\n",
            "Test Loss : 0.6124, Test Accuracy : 0.8215 \n",
            "\n",
            "current lr 1.16043e-02\n",
            "Epoch: [136][0/391]\tTime 0.379 (0.379)\tData 0.172 (0.172)\tLoss 0.2483 (0.2483)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [136][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.2342 (0.2168)\tPrec@1 97.656 (97.432)\n",
            "Epoch: [136][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2532 (0.2214)\tPrec@1 96.875 (97.306)\n",
            "Epoch: [136][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2390 (0.2259)\tPrec@1 96.875 (97.262)\n",
            "Epoch: [136][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2659 (0.2302)\tPrec@1 96.250 (97.200)\n",
            "Total time : 81.213\n",
            "Train Loss: 0.2302, Train Accuracy: 0.9720\n",
            "Test Loss : 0.6055, Test Accuracy : 0.8251 \n",
            "\n",
            "current lr 1.12744e-02\n",
            "Epoch: [137][0/391]\tTime 0.378 (0.378)\tData 0.171 (0.171)\tLoss 0.1808 (0.1808)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [137][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1686 (0.2162)\tPrec@1 99.219 (97.563)\n",
            "Epoch: [137][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2865 (0.2197)\tPrec@1 97.656 (97.419)\n",
            "Epoch: [137][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2378 (0.2218)\tPrec@1 95.312 (97.386)\n",
            "Epoch: [137][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1900 (0.2271)\tPrec@1 96.250 (97.274)\n",
            "Total time : 81.185\n",
            "Train Loss: 0.2271, Train Accuracy: 0.9727\n",
            "Test Loss : 0.6195, Test Accuracy : 0.8222 \n",
            "\n",
            "current lr 1.09479e-02\n",
            "Epoch: [138][0/391]\tTime 0.359 (0.359)\tData 0.152 (0.152)\tLoss 0.1970 (0.1970)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [138][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1716 (0.2102)\tPrec@1 99.219 (97.718)\n",
            "Epoch: [138][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2416 (0.2124)\tPrec@1 95.312 (97.633)\n",
            "Epoch: [138][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1595 (0.2184)\tPrec@1 98.438 (97.508)\n",
            "Epoch: [138][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2125 (0.2202)\tPrec@1 100.000 (97.520)\n",
            "Total time : 81.138\n",
            "Train Loss: 0.2202, Train Accuracy: 0.9752\n",
            "Test Loss : 0.6136, Test Accuracy : 0.8231 \n",
            "\n",
            "current lr 1.06249e-02\n",
            "Epoch: [139][0/391]\tTime 0.383 (0.383)\tData 0.175 (0.175)\tLoss 0.1732 (0.1732)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [139][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2557 (0.2002)\tPrec@1 94.531 (97.703)\n",
            "Epoch: [139][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1730 (0.2078)\tPrec@1 97.656 (97.571)\n",
            "Epoch: [139][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2492 (0.2101)\tPrec@1 98.438 (97.526)\n",
            "Epoch: [139][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2230 (0.2145)\tPrec@1 98.750 (97.494)\n",
            "Total time : 81.139\n",
            "Train Loss: 0.2145, Train Accuracy: 0.9749\n",
            "Test Loss : 0.6081, Test Accuracy : 0.8218 \n",
            "\n",
            "current lr 1.03054e-02\n",
            "Epoch: [140][0/391]\tTime 0.390 (0.390)\tData 0.183 (0.183)\tLoss 0.2650 (0.2650)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [140][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2382 (0.2088)\tPrec@1 95.312 (97.618)\n",
            "Epoch: [140][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2465 (0.2098)\tPrec@1 96.875 (97.582)\n",
            "Epoch: [140][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2835 (0.2118)\tPrec@1 94.531 (97.519)\n",
            "Epoch: [140][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3758 (0.2142)\tPrec@1 95.000 (97.478)\n",
            "Total time : 81.274\n",
            "Train Loss: 0.2142, Train Accuracy: 0.9748\n",
            "Test Loss : 0.6081, Test Accuracy : 0.8244 \n",
            "\n",
            "current lr 9.98949e-03\n",
            "Epoch: [141][0/391]\tTime 0.385 (0.385)\tData 0.177 (0.177)\tLoss 0.2234 (0.2234)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [141][100/391]\tTime 0.208 (0.210)\tData 0.000 (0.002)\tLoss 0.1796 (0.1955)\tPrec@1 97.656 (97.788)\n",
            "Epoch: [141][200/391]\tTime 0.208 (0.209)\tData 0.000 (0.001)\tLoss 0.2229 (0.1978)\tPrec@1 96.875 (97.683)\n",
            "Epoch: [141][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1934 (0.2017)\tPrec@1 99.219 (97.641)\n",
            "Epoch: [141][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2601 (0.2054)\tPrec@1 97.500 (97.630)\n",
            "Total time : 81.288\n",
            "Train Loss: 0.2054, Train Accuracy: 0.9763\n",
            "Test Loss : 0.6083, Test Accuracy : 0.8242 \n",
            "\n",
            "current lr 9.67732e-03\n",
            "Epoch: [142][0/391]\tTime 0.384 (0.384)\tData 0.176 (0.176)\tLoss 0.1900 (0.1900)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [142][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2258 (0.2055)\tPrec@1 96.875 (97.556)\n",
            "Epoch: [142][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.3155 (0.2038)\tPrec@1 94.531 (97.559)\n",
            "Epoch: [142][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1719 (0.2063)\tPrec@1 98.438 (97.521)\n",
            "Epoch: [142][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2454 (0.2085)\tPrec@1 98.750 (97.474)\n",
            "Total time : 81.215\n",
            "Train Loss: 0.2085, Train Accuracy: 0.9747\n",
            "Test Loss : 0.6050, Test Accuracy : 0.8227 \n",
            "\n",
            "current lr 9.36893e-03\n",
            "Epoch: [143][0/391]\tTime 0.377 (0.377)\tData 0.169 (0.169)\tLoss 0.2218 (0.2218)\tPrec@1 94.531 (94.531)\n",
            "Epoch: [143][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2582 (0.1904)\tPrec@1 96.094 (97.795)\n",
            "Epoch: [143][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1475 (0.1947)\tPrec@1 98.438 (97.683)\n",
            "Epoch: [143][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.1233 (0.1995)\tPrec@1 100.000 (97.589)\n",
            "Epoch: [143][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1693 (0.1985)\tPrec@1 98.750 (97.608)\n",
            "Total time : 81.206\n",
            "Train Loss: 0.1985, Train Accuracy: 0.9761\n",
            "Test Loss : 0.6102, Test Accuracy : 0.8241 \n",
            "\n",
            "current lr 9.06440e-03\n",
            "Epoch: [144][0/391]\tTime 0.366 (0.366)\tData 0.157 (0.157)\tLoss 0.1952 (0.1952)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [144][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1722 (0.1909)\tPrec@1 98.438 (97.850)\n",
            "Epoch: [144][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1996 (0.1916)\tPrec@1 97.656 (97.870)\n",
            "Epoch: [144][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2254 (0.1928)\tPrec@1 96.875 (97.742)\n",
            "Epoch: [144][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2019 (0.1931)\tPrec@1 98.750 (97.708)\n",
            "Total time : 81.176\n",
            "Train Loss: 0.1931, Train Accuracy: 0.9771\n",
            "Test Loss : 0.5971, Test Accuracy : 0.8302 \n",
            "\n",
            "current lr 8.76380e-03\n",
            "Epoch: [145][0/391]\tTime 0.364 (0.364)\tData 0.156 (0.156)\tLoss 0.1741 (0.1741)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [145][100/391]\tTime 0.210 (0.209)\tData 0.000 (0.002)\tLoss 0.1469 (0.1810)\tPrec@1 98.438 (98.035)\n",
            "Epoch: [145][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1037 (0.1816)\tPrec@1 99.219 (97.956)\n",
            "Epoch: [145][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2827 (0.1826)\tPrec@1 96.094 (97.890)\n",
            "Epoch: [145][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2467 (0.1838)\tPrec@1 96.250 (97.880)\n",
            "Total time : 81.173\n",
            "Train Loss: 0.1838, Train Accuracy: 0.9788\n",
            "Test Loss : 0.5889, Test Accuracy : 0.8297 \n",
            "\n",
            "current lr 8.46720e-03\n",
            "Epoch: [146][0/391]\tTime 0.377 (0.377)\tData 0.168 (0.168)\tLoss 0.1651 (0.1651)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [146][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.2132 (0.1699)\tPrec@1 97.656 (98.074)\n",
            "Epoch: [146][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1554 (0.1734)\tPrec@1 97.656 (97.979)\n",
            "Epoch: [146][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1736 (0.1752)\tPrec@1 97.656 (97.939)\n",
            "Epoch: [146][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.2310 (0.1788)\tPrec@1 98.750 (97.910)\n",
            "Total time : 81.128\n",
            "Train Loss: 0.1788, Train Accuracy: 0.9791\n",
            "Test Loss : 0.5949, Test Accuracy : 0.8301 \n",
            "\n",
            "current lr 8.17469e-03\n",
            "Epoch: [147][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.1383 (0.1383)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [147][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1819 (0.1725)\tPrec@1 99.219 (98.058)\n",
            "Epoch: [147][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1831 (0.1744)\tPrec@1 96.875 (98.088)\n",
            "Epoch: [147][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1592 (0.1782)\tPrec@1 100.000 (97.965)\n",
            "Epoch: [147][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2136 (0.1814)\tPrec@1 97.500 (97.880)\n",
            "Total time : 81.164\n",
            "Train Loss: 0.1814, Train Accuracy: 0.9788\n",
            "Test Loss : 0.5795, Test Accuracy : 0.8311 \n",
            "\n",
            "current lr 7.88632e-03\n",
            "Epoch: [148][0/391]\tTime 0.364 (0.364)\tData 0.156 (0.156)\tLoss 0.1863 (0.1863)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [148][100/391]\tTime 0.209 (0.209)\tData 0.000 (0.002)\tLoss 0.1844 (0.1745)\tPrec@1 99.219 (98.020)\n",
            "Epoch: [148][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1847 (0.1745)\tPrec@1 96.875 (97.975)\n",
            "Epoch: [148][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2111 (0.1750)\tPrec@1 98.438 (97.968)\n",
            "Epoch: [148][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2074 (0.1764)\tPrec@1 98.750 (97.932)\n",
            "Total time : 81.208\n",
            "Train Loss: 0.1764, Train Accuracy: 0.9793\n",
            "Test Loss : 0.5905, Test Accuracy : 0.8306 \n",
            "\n",
            "current lr 7.60218e-03\n",
            "Epoch: [149][0/391]\tTime 0.367 (0.367)\tData 0.159 (0.159)\tLoss 0.2082 (0.2082)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [149][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1654 (0.1609)\tPrec@1 96.875 (98.051)\n",
            "Epoch: [149][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1680 (0.1620)\tPrec@1 99.219 (98.041)\n",
            "Epoch: [149][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1795 (0.1668)\tPrec@1 97.656 (97.963)\n",
            "Epoch: [149][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.3177 (0.1699)\tPrec@1 95.000 (97.910)\n",
            "Total time : 81.187\n",
            "Train Loss: 0.1699, Train Accuracy: 0.9791\n",
            "Test Loss : 0.5842, Test Accuracy : 0.8313 \n",
            "\n",
            "current lr 7.32233e-03\n",
            "Epoch: [150][0/391]\tTime 0.370 (0.370)\tData 0.162 (0.162)\tLoss 0.1591 (0.1591)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [150][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1564 (0.1627)\tPrec@1 98.438 (98.004)\n",
            "Epoch: [150][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0999 (0.1611)\tPrec@1 99.219 (98.002)\n",
            "Epoch: [150][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1951 (0.1635)\tPrec@1 96.875 (97.981)\n",
            "Epoch: [150][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.2184 (0.1650)\tPrec@1 98.750 (97.924)\n",
            "Total time : 81.168\n",
            "Train Loss: 0.1650, Train Accuracy: 0.9792\n",
            "Test Loss : 0.5932, Test Accuracy : 0.8290 \n",
            "\n",
            "current lr 7.04684e-03\n",
            "Epoch: [151][0/391]\tTime 0.377 (0.377)\tData 0.168 (0.168)\tLoss 0.1281 (0.1281)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [151][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1970 (0.1668)\tPrec@1 96.094 (97.912)\n",
            "Epoch: [151][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2190 (0.1660)\tPrec@1 97.656 (97.975)\n",
            "Epoch: [151][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1650 (0.1672)\tPrec@1 98.438 (97.960)\n",
            "Epoch: [151][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.1416 (0.1672)\tPrec@1 97.500 (97.966)\n",
            "Total time : 81.104\n",
            "Train Loss: 0.1672, Train Accuracy: 0.9797\n",
            "Test Loss : 0.5840, Test Accuracy : 0.8311 \n",
            "\n",
            "current lr 6.77578e-03\n",
            "Epoch: [152][0/391]\tTime 0.362 (0.362)\tData 0.152 (0.152)\tLoss 0.1831 (0.1831)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [152][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1589 (0.1560)\tPrec@1 98.438 (98.267)\n",
            "Epoch: [152][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1786 (0.1559)\tPrec@1 97.656 (98.235)\n",
            "Epoch: [152][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2174 (0.1583)\tPrec@1 97.656 (98.209)\n",
            "Epoch: [152][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1826 (0.1594)\tPrec@1 100.000 (98.194)\n",
            "Total time : 81.185\n",
            "Train Loss: 0.1594, Train Accuracy: 0.9819\n",
            "Test Loss : 0.5887, Test Accuracy : 0.8277 \n",
            "\n",
            "current lr 6.50922e-03\n",
            "Epoch: [153][0/391]\tTime 0.381 (0.381)\tData 0.174 (0.174)\tLoss 0.1653 (0.1653)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [153][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1407 (0.1536)\tPrec@1 97.656 (98.368)\n",
            "Epoch: [153][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1109 (0.1591)\tPrec@1 99.219 (98.177)\n",
            "Epoch: [153][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1635 (0.1615)\tPrec@1 98.438 (98.069)\n",
            "Epoch: [153][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2374 (0.1620)\tPrec@1 100.000 (98.056)\n",
            "Total time : 81.230\n",
            "Train Loss: 0.1620, Train Accuracy: 0.9806\n",
            "Test Loss : 0.5808, Test Accuracy : 0.8335 \n",
            "\n",
            "current lr 6.24722e-03\n",
            "Epoch: [154][0/391]\tTime 0.372 (0.372)\tData 0.165 (0.165)\tLoss 0.1241 (0.1241)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [154][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1799 (0.1510)\tPrec@1 97.656 (98.198)\n",
            "Epoch: [154][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1437 (0.1503)\tPrec@1 98.438 (98.212)\n",
            "Epoch: [154][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1096 (0.1512)\tPrec@1 99.219 (98.165)\n",
            "Epoch: [154][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1320 (0.1516)\tPrec@1 100.000 (98.164)\n",
            "Total time : 81.198\n",
            "Train Loss: 0.1516, Train Accuracy: 0.9816\n",
            "Test Loss : 0.5746, Test Accuracy : 0.8336 \n",
            "\n",
            "current lr 5.98985e-03\n",
            "Epoch: [155][0/391]\tTime 0.369 (0.369)\tData 0.162 (0.162)\tLoss 0.1760 (0.1760)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [155][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1937 (0.1454)\tPrec@1 96.094 (98.298)\n",
            "Epoch: [155][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1647 (0.1426)\tPrec@1 97.656 (98.344)\n",
            "Epoch: [155][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.2029 (0.1432)\tPrec@1 96.875 (98.328)\n",
            "Epoch: [155][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1630 (0.1465)\tPrec@1 96.250 (98.250)\n",
            "Total time : 81.138\n",
            "Train Loss: 0.1465, Train Accuracy: 0.9825\n",
            "Test Loss : 0.5717, Test Accuracy : 0.8374 \n",
            "\n",
            "current lr 5.73717e-03\n",
            "Epoch: [156][0/391]\tTime 0.369 (0.369)\tData 0.160 (0.160)\tLoss 0.1468 (0.1468)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [156][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1488 (0.1430)\tPrec@1 98.438 (98.159)\n",
            "Epoch: [156][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1353 (0.1411)\tPrec@1 97.656 (98.197)\n",
            "Epoch: [156][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1537 (0.1425)\tPrec@1 97.656 (98.194)\n",
            "Epoch: [156][390/391]\tTime 0.141 (0.208)\tData 0.000 (0.001)\tLoss 0.1748 (0.1448)\tPrec@1 96.250 (98.160)\n",
            "Total time : 81.147\n",
            "Train Loss: 0.1448, Train Accuracy: 0.9816\n",
            "Test Loss : 0.5712, Test Accuracy : 0.8373 \n",
            "\n",
            "current lr 5.48924e-03\n",
            "Epoch: [157][0/391]\tTime 0.368 (0.368)\tData 0.161 (0.161)\tLoss 0.1024 (0.1024)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [157][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1693 (0.1354)\tPrec@1 96.875 (98.260)\n",
            "Epoch: [157][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1400 (0.1356)\tPrec@1 95.312 (98.290)\n",
            "Epoch: [157][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.2176 (0.1368)\tPrec@1 96.094 (98.316)\n",
            "Epoch: [157][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1374 (0.1385)\tPrec@1 100.000 (98.324)\n",
            "Total time : 81.186\n",
            "Train Loss: 0.1385, Train Accuracy: 0.9832\n",
            "Test Loss : 0.5777, Test Accuracy : 0.8335 \n",
            "\n",
            "current lr 5.24612e-03\n",
            "Epoch: [158][0/391]\tTime 0.371 (0.371)\tData 0.163 (0.163)\tLoss 0.1185 (0.1185)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [158][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1186 (0.1354)\tPrec@1 99.219 (98.476)\n",
            "Epoch: [158][200/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.1427 (0.1353)\tPrec@1 98.438 (98.368)\n",
            "Epoch: [158][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0872 (0.1371)\tPrec@1 99.219 (98.328)\n",
            "Epoch: [158][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1288 (0.1381)\tPrec@1 100.000 (98.294)\n",
            "Total time : 81.158\n",
            "Train Loss: 0.1381, Train Accuracy: 0.9829\n",
            "Test Loss : 0.5774, Test Accuracy : 0.8365 \n",
            "\n",
            "current lr 5.00788e-03\n",
            "Epoch: [159][0/391]\tTime 0.373 (0.373)\tData 0.165 (0.165)\tLoss 0.1485 (0.1485)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [159][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1037 (0.1336)\tPrec@1 99.219 (98.368)\n",
            "Epoch: [159][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1858 (0.1330)\tPrec@1 96.875 (98.286)\n",
            "Epoch: [159][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1453 (0.1328)\tPrec@1 96.875 (98.336)\n",
            "Epoch: [159][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1749 (0.1339)\tPrec@1 98.750 (98.304)\n",
            "Total time : 81.155\n",
            "Train Loss: 0.1339, Train Accuracy: 0.9830\n",
            "Test Loss : 0.5845, Test Accuracy : 0.8334 \n",
            "\n",
            "current lr 4.77458e-03\n",
            "Epoch: [160][0/391]\tTime 0.367 (0.367)\tData 0.158 (0.158)\tLoss 0.1273 (0.1273)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [160][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1251 (0.1272)\tPrec@1 97.656 (98.484)\n",
            "Epoch: [160][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1206 (0.1278)\tPrec@1 98.438 (98.434)\n",
            "Epoch: [160][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1494 (0.1284)\tPrec@1 98.438 (98.476)\n",
            "Epoch: [160][390/391]\tTime 0.140 (0.208)\tData 0.000 (0.001)\tLoss 0.1121 (0.1281)\tPrec@1 100.000 (98.458)\n",
            "Total time : 81.143\n",
            "Train Loss: 0.1281, Train Accuracy: 0.9846\n",
            "Test Loss : 0.5692, Test Accuracy : 0.8362 \n",
            "\n",
            "current lr 4.54626e-03\n",
            "Epoch: [161][0/391]\tTime 0.365 (0.365)\tData 0.157 (0.157)\tLoss 0.1153 (0.1153)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [161][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1168 (0.1292)\tPrec@1 97.656 (98.383)\n",
            "Epoch: [161][200/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.1462 (0.1276)\tPrec@1 97.656 (98.430)\n",
            "Epoch: [161][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0770 (0.1266)\tPrec@1 100.000 (98.425)\n",
            "Epoch: [161][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0993 (0.1273)\tPrec@1 100.000 (98.414)\n",
            "Total time : 81.196\n",
            "Train Loss: 0.1273, Train Accuracy: 0.9841\n",
            "Test Loss : 0.5718, Test Accuracy : 0.8380 \n",
            "\n",
            "current lr 4.32299e-03\n",
            "Epoch: [162][0/391]\tTime 0.365 (0.365)\tData 0.157 (0.157)\tLoss 0.1054 (0.1054)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [162][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.0730 (0.1160)\tPrec@1 100.000 (98.631)\n",
            "Epoch: [162][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0771 (0.1191)\tPrec@1 100.000 (98.581)\n",
            "Epoch: [162][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1108 (0.1210)\tPrec@1 99.219 (98.557)\n",
            "Epoch: [162][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1547 (0.1201)\tPrec@1 98.750 (98.572)\n",
            "Total time : 81.185\n",
            "Train Loss: 0.1201, Train Accuracy: 0.9857\n",
            "Test Loss : 0.5848, Test Accuracy : 0.8386 \n",
            "\n",
            "current lr 4.10482e-03\n",
            "Epoch: [163][0/391]\tTime 0.385 (0.385)\tData 0.177 (0.177)\tLoss 0.1116 (0.1116)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [163][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1255 (0.1204)\tPrec@1 99.219 (98.461)\n",
            "Epoch: [163][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1267 (0.1171)\tPrec@1 98.438 (98.527)\n",
            "Epoch: [163][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1863 (0.1183)\tPrec@1 97.656 (98.479)\n",
            "Epoch: [163][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1984 (0.1197)\tPrec@1 95.000 (98.446)\n",
            "Total time : 81.192\n",
            "Train Loss: 0.1197, Train Accuracy: 0.9845\n",
            "Test Loss : 0.5692, Test Accuracy : 0.8419 \n",
            "\n",
            "current lr 3.89180e-03\n",
            "Epoch: [164][0/391]\tTime 0.374 (0.374)\tData 0.165 (0.165)\tLoss 0.1162 (0.1162)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [164][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1919 (0.1203)\tPrec@1 96.875 (98.345)\n",
            "Epoch: [164][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1424 (0.1195)\tPrec@1 97.656 (98.410)\n",
            "Epoch: [164][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1320 (0.1204)\tPrec@1 99.219 (98.435)\n",
            "Epoch: [164][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0908 (0.1207)\tPrec@1 100.000 (98.402)\n",
            "Total time : 81.165\n",
            "Train Loss: 0.1207, Train Accuracy: 0.9840\n",
            "Test Loss : 0.5736, Test Accuracy : 0.8391 \n",
            "\n",
            "current lr 3.68400e-03\n",
            "Epoch: [165][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.0913 (0.0913)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [165][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1207 (0.1134)\tPrec@1 99.219 (98.670)\n",
            "Epoch: [165][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1190 (0.1147)\tPrec@1 97.656 (98.597)\n",
            "Epoch: [165][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0972 (0.1148)\tPrec@1 99.219 (98.575)\n",
            "Epoch: [165][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1285 (0.1137)\tPrec@1 96.250 (98.576)\n",
            "Total time : 81.184\n",
            "Train Loss: 0.1137, Train Accuracy: 0.9858\n",
            "Test Loss : 0.5715, Test Accuracy : 0.8396 \n",
            "\n",
            "current lr 3.48145e-03\n",
            "Epoch: [166][0/391]\tTime 0.377 (0.377)\tData 0.168 (0.168)\tLoss 0.1299 (0.1299)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [166][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1286 (0.1111)\tPrec@1 98.438 (98.584)\n",
            "Epoch: [166][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0849 (0.1147)\tPrec@1 99.219 (98.504)\n",
            "Epoch: [166][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0930 (0.1134)\tPrec@1 99.219 (98.523)\n",
            "Epoch: [166][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1180 (0.1135)\tPrec@1 100.000 (98.530)\n",
            "Total time : 81.240\n",
            "Train Loss: 0.1135, Train Accuracy: 0.9853\n",
            "Test Loss : 0.5750, Test Accuracy : 0.8402 \n",
            "\n",
            "current lr 3.28421e-03\n",
            "Epoch: [167][0/391]\tTime 0.377 (0.377)\tData 0.167 (0.167)\tLoss 0.0983 (0.0983)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [167][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1692 (0.1085)\tPrec@1 98.438 (98.538)\n",
            "Epoch: [167][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0976 (0.1091)\tPrec@1 99.219 (98.601)\n",
            "Epoch: [167][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1165 (0.1097)\tPrec@1 99.219 (98.583)\n",
            "Epoch: [167][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0872 (0.1107)\tPrec@1 98.750 (98.546)\n",
            "Total time : 81.229\n",
            "Train Loss: 0.1107, Train Accuracy: 0.9855\n",
            "Test Loss : 0.5720, Test Accuracy : 0.8406 \n",
            "\n",
            "current lr 3.09233e-03\n",
            "Epoch: [168][0/391]\tTime 0.365 (0.365)\tData 0.158 (0.158)\tLoss 0.0837 (0.0837)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [168][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0799 (0.0943)\tPrec@1 98.438 (98.832)\n",
            "Epoch: [168][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0829 (0.0959)\tPrec@1 99.219 (98.780)\n",
            "Epoch: [168][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1085 (0.0977)\tPrec@1 97.656 (98.772)\n",
            "Epoch: [168][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1266 (0.1003)\tPrec@1 97.500 (98.704)\n",
            "Total time : 81.188\n",
            "Train Loss: 0.1003, Train Accuracy: 0.9870\n",
            "Test Loss : 0.5686, Test Accuracy : 0.8406 \n",
            "\n",
            "current lr 2.90586e-03\n",
            "Epoch: [169][0/391]\tTime 0.363 (0.363)\tData 0.155 (0.155)\tLoss 0.1140 (0.1140)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [169][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0939 (0.0997)\tPrec@1 98.438 (98.639)\n",
            "Epoch: [169][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1556 (0.0964)\tPrec@1 96.094 (98.745)\n",
            "Epoch: [169][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0957 (0.0970)\tPrec@1 98.438 (98.736)\n",
            "Epoch: [169][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1036 (0.0997)\tPrec@1 98.750 (98.676)\n",
            "Total time : 81.162\n",
            "Train Loss: 0.0997, Train Accuracy: 0.9868\n",
            "Test Loss : 0.5695, Test Accuracy : 0.8392 \n",
            "\n",
            "current lr 2.72484e-03\n",
            "Epoch: [170][0/391]\tTime 0.372 (0.372)\tData 0.161 (0.161)\tLoss 0.0788 (0.0788)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [170][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0869 (0.0959)\tPrec@1 98.438 (98.778)\n",
            "Epoch: [170][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1129 (0.0997)\tPrec@1 97.656 (98.694)\n",
            "Epoch: [170][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0874 (0.0983)\tPrec@1 97.656 (98.775)\n",
            "Epoch: [170][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1063 (0.0985)\tPrec@1 100.000 (98.786)\n",
            "Total time : 81.170\n",
            "Train Loss: 0.0985, Train Accuracy: 0.9879\n",
            "Test Loss : 0.5549, Test Accuracy : 0.8462 \n",
            "\n",
            "current lr 2.54931e-03\n",
            "Epoch: [171][0/391]\tTime 0.367 (0.367)\tData 0.159 (0.159)\tLoss 0.1492 (0.1492)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [171][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1297 (0.0992)\tPrec@1 99.219 (98.677)\n",
            "Epoch: [171][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1068 (0.0984)\tPrec@1 98.438 (98.710)\n",
            "Epoch: [171][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0975 (0.0978)\tPrec@1 98.438 (98.713)\n",
            "Epoch: [171][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1278 (0.0963)\tPrec@1 98.750 (98.744)\n",
            "Total time : 81.157\n",
            "Train Loss: 0.0963, Train Accuracy: 0.9874\n",
            "Test Loss : 0.5675, Test Accuracy : 0.8410 \n",
            "\n",
            "current lr 2.37932e-03\n",
            "Epoch: [172][0/391]\tTime 0.366 (0.366)\tData 0.157 (0.157)\tLoss 0.0904 (0.0904)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [172][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0772 (0.0917)\tPrec@1 98.438 (98.693)\n",
            "Epoch: [172][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0564 (0.0936)\tPrec@1 99.219 (98.737)\n",
            "Epoch: [172][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0930 (0.0940)\tPrec@1 98.438 (98.700)\n",
            "Epoch: [172][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.0498 (0.0940)\tPrec@1 100.000 (98.698)\n",
            "Total time : 81.204\n",
            "Train Loss: 0.0940, Train Accuracy: 0.9870\n",
            "Test Loss : 0.5617, Test Accuracy : 0.8447 \n",
            "\n",
            "current lr 2.21492e-03\n",
            "Epoch: [173][0/391]\tTime 0.367 (0.367)\tData 0.160 (0.160)\tLoss 0.1405 (0.1405)\tPrec@1 96.094 (96.094)\n",
            "Epoch: [173][100/391]\tTime 0.210 (0.209)\tData 0.000 (0.002)\tLoss 0.0793 (0.0940)\tPrec@1 100.000 (98.762)\n",
            "Epoch: [173][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0781 (0.0909)\tPrec@1 98.438 (98.745)\n",
            "Epoch: [173][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0660 (0.0891)\tPrec@1 100.000 (98.832)\n",
            "Epoch: [173][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.1244 (0.0880)\tPrec@1 96.250 (98.846)\n",
            "Total time : 81.182\n",
            "Train Loss: 0.0880, Train Accuracy: 0.9885\n",
            "Test Loss : 0.5543, Test Accuracy : 0.8455 \n",
            "\n",
            "current lr 2.05613e-03\n",
            "Epoch: [174][0/391]\tTime 0.366 (0.366)\tData 0.157 (0.157)\tLoss 0.1603 (0.1603)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [174][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0507 (0.0845)\tPrec@1 99.219 (98.840)\n",
            "Epoch: [174][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0897 (0.0873)\tPrec@1 99.219 (98.818)\n",
            "Epoch: [174][300/391]\tTime 0.211 (0.208)\tData 0.000 (0.001)\tLoss 0.1558 (0.0884)\tPrec@1 96.094 (98.798)\n",
            "Epoch: [174][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0471 (0.0887)\tPrec@1 100.000 (98.778)\n",
            "Total time : 81.155\n",
            "Train Loss: 0.0887, Train Accuracy: 0.9878\n",
            "Test Loss : 0.5638, Test Accuracy : 0.8429 \n",
            "\n",
            "current lr 1.90301e-03\n",
            "Epoch: [175][0/391]\tTime 0.367 (0.367)\tData 0.158 (0.158)\tLoss 0.0802 (0.0802)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [175][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.1270 (0.0858)\tPrec@1 98.438 (98.801)\n",
            "Epoch: [175][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0758 (0.0858)\tPrec@1 99.219 (98.772)\n",
            "Epoch: [175][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.1540 (0.0856)\tPrec@1 96.875 (98.801)\n",
            "Epoch: [175][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0783 (0.0857)\tPrec@1 100.000 (98.796)\n",
            "Total time : 81.194\n",
            "Train Loss: 0.0857, Train Accuracy: 0.9880\n",
            "Test Loss : 0.5584, Test Accuracy : 0.8452 \n",
            "\n",
            "current lr 1.75559e-03\n",
            "Epoch: [176][0/391]\tTime 0.366 (0.366)\tData 0.159 (0.159)\tLoss 0.0772 (0.0772)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [176][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0657 (0.0811)\tPrec@1 99.219 (98.863)\n",
            "Epoch: [176][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0746 (0.0816)\tPrec@1 99.219 (98.850)\n",
            "Epoch: [176][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0737 (0.0826)\tPrec@1 100.000 (98.842)\n",
            "Epoch: [176][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.1145 (0.0837)\tPrec@1 98.750 (98.824)\n",
            "Total time : 81.216\n",
            "Train Loss: 0.0837, Train Accuracy: 0.9882\n",
            "Test Loss : 0.5612, Test Accuracy : 0.8455 \n",
            "\n",
            "current lr 1.61390e-03\n",
            "Epoch: [177][0/391]\tTime 0.369 (0.369)\tData 0.161 (0.161)\tLoss 0.1072 (0.1072)\tPrec@1 97.656 (97.656)\n",
            "Epoch: [177][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0706 (0.0780)\tPrec@1 100.000 (98.886)\n",
            "Epoch: [177][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1607 (0.0790)\tPrec@1 96.094 (98.923)\n",
            "Epoch: [177][300/391]\tTime 0.211 (0.208)\tData 0.000 (0.001)\tLoss 0.1057 (0.0802)\tPrec@1 98.438 (98.892)\n",
            "Epoch: [177][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0420 (0.0804)\tPrec@1 100.000 (98.870)\n",
            "Total time : 81.177\n",
            "Train Loss: 0.0804, Train Accuracy: 0.9887\n",
            "Test Loss : 0.5590, Test Accuracy : 0.8442 \n",
            "\n",
            "current lr 1.47798e-03\n",
            "Epoch: [178][0/391]\tTime 0.366 (0.366)\tData 0.159 (0.159)\tLoss 0.0699 (0.0699)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [178][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0674 (0.0774)\tPrec@1 99.219 (99.010)\n",
            "Epoch: [178][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0760 (0.0759)\tPrec@1 100.000 (98.989)\n",
            "Epoch: [178][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0632 (0.0758)\tPrec@1 99.219 (98.970)\n",
            "Epoch: [178][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.0462 (0.0763)\tPrec@1 100.000 (98.956)\n",
            "Total time : 81.178\n",
            "Train Loss: 0.0763, Train Accuracy: 0.9896\n",
            "Test Loss : 0.5606, Test Accuracy : 0.8460 \n",
            "\n",
            "current lr 1.34787e-03\n",
            "Epoch: [179][0/391]\tTime 0.368 (0.368)\tData 0.159 (0.159)\tLoss 0.0906 (0.0906)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [179][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.1070 (0.0780)\tPrec@1 98.438 (98.971)\n",
            "Epoch: [179][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1997 (0.0784)\tPrec@1 96.094 (98.947)\n",
            "Epoch: [179][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0619 (0.0783)\tPrec@1 99.219 (98.912)\n",
            "Epoch: [179][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.2064 (0.0764)\tPrec@1 96.250 (98.948)\n",
            "Total time : 81.197\n",
            "Train Loss: 0.0764, Train Accuracy: 0.9895\n",
            "Test Loss : 0.5603, Test Accuracy : 0.8457 \n",
            "\n",
            "current lr 1.22359e-03\n",
            "Epoch: [180][0/391]\tTime 0.376 (0.376)\tData 0.167 (0.167)\tLoss 0.0764 (0.0764)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [180][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.0554 (0.0721)\tPrec@1 99.219 (98.963)\n",
            "Epoch: [180][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0891 (0.0721)\tPrec@1 98.438 (99.021)\n",
            "Epoch: [180][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0858 (0.0723)\tPrec@1 98.438 (99.006)\n",
            "Epoch: [180][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.0702 (0.0712)\tPrec@1 97.500 (99.022)\n",
            "Total time : 81.221\n",
            "Train Loss: 0.0712, Train Accuracy: 0.9902\n",
            "Test Loss : 0.5574, Test Accuracy : 0.8468 \n",
            "\n",
            "current lr 1.10517e-03\n",
            "Epoch: [181][0/391]\tTime 0.365 (0.365)\tData 0.157 (0.157)\tLoss 0.0576 (0.0576)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [181][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0429 (0.0733)\tPrec@1 100.000 (98.933)\n",
            "Epoch: [181][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0724 (0.0722)\tPrec@1 98.438 (98.986)\n",
            "Epoch: [181][300/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.1097 (0.0722)\tPrec@1 98.438 (99.029)\n",
            "Epoch: [181][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.0424 (0.0711)\tPrec@1 100.000 (99.048)\n",
            "Total time : 81.174\n",
            "Train Loss: 0.0711, Train Accuracy: 0.9905\n",
            "Test Loss : 0.5589, Test Accuracy : 0.8474 \n",
            "\n",
            "current lr 9.92658e-04\n",
            "Epoch: [182][0/391]\tTime 0.367 (0.367)\tData 0.158 (0.158)\tLoss 0.0714 (0.0714)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [182][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0616 (0.0684)\tPrec@1 99.219 (98.987)\n",
            "Epoch: [182][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0571 (0.0697)\tPrec@1 99.219 (98.962)\n",
            "Epoch: [182][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0678 (0.0696)\tPrec@1 99.219 (99.019)\n",
            "Epoch: [182][390/391]\tTime 0.139 (0.208)\tData 0.000 (0.001)\tLoss 0.0470 (0.0700)\tPrec@1 100.000 (99.016)\n",
            "Total time : 81.151\n",
            "Train Loss: 0.0700, Train Accuracy: 0.9902\n",
            "Test Loss : 0.5644, Test Accuracy : 0.8436 \n",
            "\n",
            "current lr 8.86065e-04\n",
            "Epoch: [183][0/391]\tTime 0.372 (0.372)\tData 0.164 (0.164)\tLoss 0.0876 (0.0876)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [183][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0870 (0.0643)\tPrec@1 99.219 (99.056)\n",
            "Epoch: [183][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0898 (0.0700)\tPrec@1 97.656 (98.947)\n",
            "Epoch: [183][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1091 (0.0687)\tPrec@1 98.438 (99.006)\n",
            "Epoch: [183][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0564 (0.0687)\tPrec@1 100.000 (99.002)\n",
            "Total time : 81.062\n",
            "Train Loss: 0.0687, Train Accuracy: 0.9900\n",
            "Test Loss : 0.5633, Test Accuracy : 0.8447 \n",
            "\n",
            "current lr 7.85421e-04\n",
            "Epoch: [184][0/391]\tTime 0.366 (0.366)\tData 0.157 (0.157)\tLoss 0.0345 (0.0345)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [184][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0575 (0.0649)\tPrec@1 100.000 (99.080)\n",
            "Epoch: [184][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1146 (0.0674)\tPrec@1 97.656 (99.021)\n",
            "Epoch: [184][300/391]\tTime 0.209 (0.208)\tData 0.000 (0.001)\tLoss 0.0442 (0.0666)\tPrec@1 99.219 (99.040)\n",
            "Epoch: [184][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.1243 (0.0661)\tPrec@1 97.500 (99.056)\n",
            "Total time : 81.128\n",
            "Train Loss: 0.0661, Train Accuracy: 0.9906\n",
            "Test Loss : 0.5570, Test Accuracy : 0.8462 \n",
            "\n",
            "current lr 6.90752e-04\n",
            "Epoch: [185][0/391]\tTime 0.367 (0.367)\tData 0.160 (0.160)\tLoss 0.0544 (0.0544)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [185][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0707 (0.0629)\tPrec@1 99.219 (99.141)\n",
            "Epoch: [185][200/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.0337 (0.0639)\tPrec@1 100.000 (99.102)\n",
            "Epoch: [185][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0713 (0.0647)\tPrec@1 99.219 (99.097)\n",
            "Epoch: [185][390/391]\tTime 0.138 (0.207)\tData 0.000 (0.001)\tLoss 0.1046 (0.0649)\tPrec@1 97.500 (99.076)\n",
            "Total time : 81.111\n",
            "Train Loss: 0.0649, Train Accuracy: 0.9908\n",
            "Test Loss : 0.5542, Test Accuracy : 0.8482 \n",
            "\n",
            "current lr 6.02081e-04\n",
            "Epoch: [186][0/391]\tTime 0.372 (0.372)\tData 0.164 (0.164)\tLoss 0.0530 (0.0530)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [186][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0572 (0.0628)\tPrec@1 100.000 (99.165)\n",
            "Epoch: [186][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0546 (0.0605)\tPrec@1 99.219 (99.164)\n",
            "Epoch: [186][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1079 (0.0636)\tPrec@1 97.656 (99.084)\n",
            "Epoch: [186][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0685 (0.0643)\tPrec@1 98.750 (99.052)\n",
            "Total time : 81.087\n",
            "Train Loss: 0.0643, Train Accuracy: 0.9905\n",
            "Test Loss : 0.5571, Test Accuracy : 0.8473 \n",
            "\n",
            "current lr 5.19430e-04\n",
            "Epoch: [187][0/391]\tTime 0.365 (0.365)\tData 0.158 (0.158)\tLoss 0.0740 (0.0740)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [187][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.0347 (0.0628)\tPrec@1 100.000 (98.963)\n",
            "Epoch: [187][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0529 (0.0623)\tPrec@1 98.438 (98.989)\n",
            "Epoch: [187][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0691 (0.0632)\tPrec@1 98.438 (99.029)\n",
            "Epoch: [187][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0760 (0.0620)\tPrec@1 98.750 (99.074)\n",
            "Total time : 81.117\n",
            "Train Loss: 0.0620, Train Accuracy: 0.9907\n",
            "Test Loss : 0.5538, Test Accuracy : 0.8479 \n",
            "\n",
            "current lr 4.42819e-04\n",
            "Epoch: [188][0/391]\tTime 0.370 (0.370)\tData 0.163 (0.163)\tLoss 0.0689 (0.0689)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [188][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0503 (0.0614)\tPrec@1 99.219 (99.056)\n",
            "Epoch: [188][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0323 (0.0616)\tPrec@1 100.000 (99.090)\n",
            "Epoch: [188][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1452 (0.0630)\tPrec@1 96.094 (99.071)\n",
            "Epoch: [188][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0824 (0.0638)\tPrec@1 97.500 (99.044)\n",
            "Total time : 81.147\n",
            "Train Loss: 0.0638, Train Accuracy: 0.9904\n",
            "Test Loss : 0.5567, Test Accuracy : 0.8499 \n",
            "\n",
            "current lr 3.72267e-04\n",
            "Epoch: [189][0/391]\tTime 0.372 (0.372)\tData 0.163 (0.163)\tLoss 0.0524 (0.0524)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [189][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0641 (0.0596)\tPrec@1 99.219 (99.134)\n",
            "Epoch: [189][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0554 (0.0587)\tPrec@1 99.219 (99.149)\n",
            "Epoch: [189][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0382 (0.0598)\tPrec@1 100.000 (99.125)\n",
            "Epoch: [189][390/391]\tTime 0.138 (0.207)\tData 0.000 (0.001)\tLoss 0.0577 (0.0603)\tPrec@1 100.000 (99.130)\n",
            "Total time : 81.119\n",
            "Train Loss: 0.0603, Train Accuracy: 0.9913\n",
            "Test Loss : 0.5488, Test Accuracy : 0.8484 \n",
            "\n",
            "current lr 3.07791e-04\n",
            "Epoch: [190][0/391]\tTime 0.375 (0.375)\tData 0.166 (0.166)\tLoss 0.1045 (0.1045)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [190][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.0627 (0.0633)\tPrec@1 97.656 (98.948)\n",
            "Epoch: [190][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0592 (0.0631)\tPrec@1 99.219 (98.986)\n",
            "Epoch: [190][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.0596 (0.0621)\tPrec@1 98.438 (99.029)\n",
            "Epoch: [190][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0475 (0.0623)\tPrec@1 100.000 (99.020)\n",
            "Total time : 81.111\n",
            "Train Loss: 0.0623, Train Accuracy: 0.9902\n",
            "Test Loss : 0.5486, Test Accuracy : 0.8497 \n",
            "\n",
            "current lr 2.49409e-04\n",
            "Epoch: [191][0/391]\tTime 0.361 (0.361)\tData 0.153 (0.153)\tLoss 0.0651 (0.0651)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [191][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0743 (0.0650)\tPrec@1 98.438 (98.948)\n",
            "Epoch: [191][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0641 (0.0606)\tPrec@1 99.219 (99.110)\n",
            "Epoch: [191][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0327 (0.0591)\tPrec@1 100.000 (99.133)\n",
            "Epoch: [191][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0846 (0.0594)\tPrec@1 97.500 (99.122)\n",
            "Total time : 81.096\n",
            "Train Loss: 0.0594, Train Accuracy: 0.9912\n",
            "Test Loss : 0.5567, Test Accuracy : 0.8486 \n",
            "\n",
            "current lr 1.97132e-04\n",
            "Epoch: [192][0/391]\tTime 0.366 (0.366)\tData 0.158 (0.158)\tLoss 0.0498 (0.0498)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [192][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.0770 (0.0593)\tPrec@1 98.438 (99.134)\n",
            "Epoch: [192][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0386 (0.0584)\tPrec@1 100.000 (99.168)\n",
            "Epoch: [192][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0287 (0.0577)\tPrec@1 100.000 (99.214)\n",
            "Epoch: [192][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0614 (0.0585)\tPrec@1 100.000 (99.194)\n",
            "Total time : 81.153\n",
            "Train Loss: 0.0585, Train Accuracy: 0.9919\n",
            "Test Loss : 0.5516, Test Accuracy : 0.8466 \n",
            "\n",
            "current lr 1.50976e-04\n",
            "Epoch: [193][0/391]\tTime 0.375 (0.375)\tData 0.167 (0.167)\tLoss 0.0441 (0.0441)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [193][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0569 (0.0577)\tPrec@1 98.438 (99.211)\n",
            "Epoch: [193][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0595 (0.0572)\tPrec@1 98.438 (99.195)\n",
            "Epoch: [193][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0587 (0.0582)\tPrec@1 98.438 (99.164)\n",
            "Epoch: [193][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0307 (0.0585)\tPrec@1 100.000 (99.168)\n",
            "Total time : 81.139\n",
            "Train Loss: 0.0585, Train Accuracy: 0.9917\n",
            "Test Loss : 0.5502, Test Accuracy : 0.8500 \n",
            "\n",
            "current lr 1.10951e-04\n",
            "Epoch: [194][0/391]\tTime 0.367 (0.367)\tData 0.159 (0.159)\tLoss 0.0833 (0.0833)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [194][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0659 (0.0613)\tPrec@1 98.438 (99.025)\n",
            "Epoch: [194][200/391]\tTime 0.208 (0.208)\tData 0.000 (0.001)\tLoss 0.0568 (0.0587)\tPrec@1 100.000 (99.145)\n",
            "Epoch: [194][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.1039 (0.0578)\tPrec@1 96.875 (99.154)\n",
            "Epoch: [194][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0886 (0.0582)\tPrec@1 97.500 (99.116)\n",
            "Total time : 81.102\n",
            "Train Loss: 0.0582, Train Accuracy: 0.9912\n",
            "Test Loss : 0.5520, Test Accuracy : 0.8492 \n",
            "\n",
            "current lr 7.70667e-05\n",
            "Epoch: [195][0/391]\tTime 0.364 (0.364)\tData 0.155 (0.155)\tLoss 0.0808 (0.0808)\tPrec@1 99.219 (99.219)\n",
            "Epoch: [195][100/391]\tTime 0.208 (0.209)\tData 0.000 (0.002)\tLoss 0.0670 (0.0580)\tPrec@1 99.219 (99.234)\n",
            "Epoch: [195][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0628 (0.0581)\tPrec@1 99.219 (99.172)\n",
            "Epoch: [195][300/391]\tTime 0.210 (0.208)\tData 0.000 (0.001)\tLoss 0.0608 (0.0589)\tPrec@1 99.219 (99.123)\n",
            "Epoch: [195][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0580 (0.0586)\tPrec@1 98.750 (99.122)\n",
            "Total time : 81.113\n",
            "Train Loss: 0.0586, Train Accuracy: 0.9912\n",
            "Test Loss : 0.5489, Test Accuracy : 0.8505 \n",
            "\n",
            "current lr 4.93318e-05\n",
            "Epoch: [196][0/391]\tTime 0.379 (0.379)\tData 0.171 (0.171)\tLoss 0.0806 (0.0806)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [196][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0899 (0.0595)\tPrec@1 97.656 (99.134)\n",
            "Epoch: [196][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0975 (0.0590)\tPrec@1 97.656 (99.129)\n",
            "Epoch: [196][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0581 (0.0585)\tPrec@1 100.000 (99.136)\n",
            "Epoch: [196][390/391]\tTime 0.138 (0.208)\tData 0.000 (0.001)\tLoss 0.0808 (0.0585)\tPrec@1 98.750 (99.136)\n",
            "Total time : 81.159\n",
            "Train Loss: 0.0585, Train Accuracy: 0.9914\n",
            "Test Loss : 0.5498, Test Accuracy : 0.8490 \n",
            "\n",
            "current lr 2.77531e-05\n",
            "Epoch: [197][0/391]\tTime 0.362 (0.362)\tData 0.154 (0.154)\tLoss 0.0475 (0.0475)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [197][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0731 (0.0595)\tPrec@1 99.219 (99.165)\n",
            "Epoch: [197][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0486 (0.0600)\tPrec@1 99.219 (99.133)\n",
            "Epoch: [197][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0397 (0.0589)\tPrec@1 99.219 (99.141)\n",
            "Epoch: [197][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0586 (0.0587)\tPrec@1 98.750 (99.138)\n",
            "Total time : 81.077\n",
            "Train Loss: 0.0587, Train Accuracy: 0.9914\n",
            "Test Loss : 0.5501, Test Accuracy : 0.8487 \n",
            "\n",
            "current lr 1.23360e-05\n",
            "Epoch: [198][0/391]\tTime 0.360 (0.360)\tData 0.152 (0.152)\tLoss 0.0352 (0.0352)\tPrec@1 100.000 (100.000)\n",
            "Epoch: [198][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0473 (0.0551)\tPrec@1 99.219 (99.296)\n",
            "Epoch: [198][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0422 (0.0564)\tPrec@1 99.219 (99.184)\n",
            "Epoch: [198][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0396 (0.0575)\tPrec@1 99.219 (99.162)\n",
            "Epoch: [198][390/391]\tTime 0.137 (0.207)\tData 0.000 (0.001)\tLoss 0.0747 (0.0571)\tPrec@1 98.750 (99.170)\n",
            "Total time : 81.111\n",
            "Train Loss: 0.0571, Train Accuracy: 0.9917\n",
            "Test Loss : 0.5509, Test Accuracy : 0.8501 \n",
            "\n",
            "current lr 3.08419e-06\n",
            "Epoch: [199][0/391]\tTime 0.366 (0.366)\tData 0.159 (0.159)\tLoss 0.0817 (0.0817)\tPrec@1 98.438 (98.438)\n",
            "Epoch: [199][100/391]\tTime 0.207 (0.209)\tData 0.000 (0.002)\tLoss 0.0296 (0.0588)\tPrec@1 100.000 (99.226)\n",
            "Epoch: [199][200/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0743 (0.0599)\tPrec@1 98.438 (99.149)\n",
            "Epoch: [199][300/391]\tTime 0.207 (0.208)\tData 0.000 (0.001)\tLoss 0.0757 (0.0594)\tPrec@1 98.438 (99.167)\n",
            "Epoch: [199][390/391]\tTime 0.137 (0.208)\tData 0.000 (0.001)\tLoss 0.0503 (0.0592)\tPrec@1 100.000 (99.146)\n",
            "Total time : 81.134\n",
            "Train Loss: 0.0592, Train Accuracy: 0.9915\n",
            "Test Loss : 0.5510, Test Accuracy : 0.8497 \n",
            "\n",
            "train loss:  [4.0672, 3.5628, 3.1473, 2.7556, 2.4624, 2.2312, 2.0291, 1.8955, 1.7905, 1.6983, 1.6202, 1.555, 1.4999, 1.4474, 1.4047, 1.3662, 1.3217, 1.2971, 1.2608, 1.2322, 1.209, 1.1783, 1.1599, 1.137, 1.1176, 1.0974, 1.0848, 1.0672, 1.049, 1.046, 1.0258, 1.0101, 0.9968, 0.9868, 0.9805, 0.9644, 0.9556, 0.9484, 0.9381, 0.9298, 0.9173, 0.9102, 0.9025, 0.8943, 0.8805, 0.8765, 0.8706, 0.8535, 0.8534, 0.8484, 0.8423, 0.8299, 0.8165, 0.8155, 0.8032, 0.7922, 0.7908, 0.7791, 0.7777, 0.7656, 0.7576, 0.7501, 0.7471, 0.7387, 0.7381, 0.7238, 0.7154, 0.7112, 0.6999, 0.6935, 0.688, 0.6808, 0.6758, 0.6687, 0.6554, 0.6582, 0.647, 0.642, 0.6298, 0.624, 0.6184, 0.6099, 0.6014, 0.5988, 0.5973, 0.5839, 0.5762, 0.5626, 0.5563, 0.5441, 0.5492, 0.5414, 0.5265, 0.5247, 0.5128, 0.5064, 0.5005, 0.4929, 0.4867, 0.477, 0.4604, 0.4623, 0.4482, 0.4503, 0.4418, 0.4345, 0.424, 0.4154, 0.4114, 0.4006, 0.398, 0.3869, 0.3765, 0.3747, 0.3633, 0.3597, 0.3548, 0.3474, 0.3434, 0.333, 0.3299, 0.3215, 0.3179, 0.3073, 0.3013, 0.2971, 0.291, 0.2841, 0.2761, 0.2712, 0.2591, 0.2616, 0.2548, 0.2482, 0.2449, 0.2389, 0.2302, 0.2271, 0.2202, 0.2145, 0.2142, 0.2054, 0.2085, 0.1985, 0.1931, 0.1838, 0.1788, 0.1814, 0.1764, 0.1699, 0.165, 0.1672, 0.1594, 0.162, 0.1516, 0.1465, 0.1448, 0.1385, 0.1381, 0.1339, 0.1281, 0.1273, 0.1201, 0.1197, 0.1207, 0.1137, 0.1135, 0.1107, 0.1003, 0.0997, 0.0985, 0.0963, 0.094, 0.088, 0.0887, 0.0857, 0.0837, 0.0804, 0.0763, 0.0764, 0.0712, 0.0711, 0.07, 0.0687, 0.0661, 0.0649, 0.0643, 0.062, 0.0638, 0.0603, 0.0623, 0.0594, 0.0585, 0.0585, 0.0582, 0.0586, 0.0585, 0.0587, 0.0571, 0.0592]\n",
            "train err:  [0.9253, 0.8471, 0.7623, 0.6802, 0.6122, 0.5589, 0.5092, 0.4733, 0.4449, 0.4174, 0.3948, 0.3754, 0.3602, 0.3438, 0.3305, 0.3179, 0.308, 0.2986, 0.2849, 0.2792, 0.2698, 0.2599, 0.2541, 0.2488, 0.2416, 0.235, 0.2325, 0.228, 0.2238, 0.22, 0.2148, 0.2101, 0.2038, 0.2018, 0.2019, 0.1966, 0.1939, 0.1929, 0.1866, 0.1864, 0.1811, 0.1818, 0.1787, 0.1751, 0.1724, 0.1724, 0.1695, 0.1636, 0.1651, 0.163, 0.1615, 0.1571, 0.1536, 0.1519, 0.1502, 0.1476, 0.1461, 0.1444, 0.1447, 0.141, 0.1382, 0.1362, 0.1351, 0.1338, 0.1343, 0.1283, 0.1277, 0.1261, 0.1225, 0.1209, 0.1215, 0.1198, 0.1183, 0.1154, 0.1113, 0.1119, 0.1096, 0.1096, 0.1049, 0.104, 0.1045, 0.1008, 0.0991, 0.0972, 0.0991, 0.0968, 0.0944, 0.0896, 0.0878, 0.0854, 0.0865, 0.086, 0.0814, 0.0811, 0.0787, 0.0792, 0.0767, 0.0743, 0.0716, 0.0701, 0.0667, 0.0675, 0.065, 0.0643, 0.0637, 0.0622, 0.0606, 0.0582, 0.0576, 0.0558, 0.0541, 0.0524, 0.0491, 0.05, 0.0479, 0.0474, 0.0466, 0.0447, 0.0444, 0.0429, 0.0424, 0.0413, 0.0407, 0.0387, 0.0388, 0.0369, 0.0359, 0.0348, 0.0329, 0.0328, 0.0315, 0.0314, 0.0302, 0.0299, 0.0291, 0.0286, 0.028, 0.0273, 0.0248, 0.0251, 0.0252, 0.0237, 0.0253, 0.0239, 0.0229, 0.0212, 0.0209, 0.0212, 0.0207, 0.0209, 0.0208, 0.0203, 0.0181, 0.0194, 0.0184, 0.0175, 0.0184, 0.0168, 0.0171, 0.017, 0.0154, 0.0159, 0.0143, 0.0155, 0.016, 0.0142, 0.0147, 0.0145, 0.013, 0.0132, 0.0121, 0.0126, 0.013, 0.0115, 0.0122, 0.012, 0.0118, 0.0113, 0.0104, 0.0105, 0.0098, 0.0095, 0.0098, 0.01, 0.0094, 0.0092, 0.0095, 0.0093, 0.0096, 0.0087, 0.0098, 0.0088, 0.0081, 0.0083, 0.0088, 0.0088, 0.0086, 0.0086, 0.0083, 0.0085]\n",
            "train acc:  [0.0747, 0.1529, 0.2377, 0.3198, 0.3878, 0.4411, 0.4908, 0.5267, 0.5551, 0.5826, 0.6052, 0.6246, 0.6398, 0.6562, 0.6695, 0.6821, 0.692, 0.7014, 0.7151, 0.7208, 0.7302, 0.7401, 0.7459, 0.7512, 0.7584, 0.765, 0.7675, 0.772, 0.7762, 0.78, 0.7852, 0.7899, 0.7962, 0.7982, 0.7981, 0.8034, 0.8061, 0.8071, 0.8134, 0.8136, 0.8189, 0.8182, 0.8213, 0.8249, 0.8276, 0.8276, 0.8305, 0.8364, 0.8349, 0.837, 0.8385, 0.8429, 0.8464, 0.8481, 0.8498, 0.8524, 0.8539, 0.8556, 0.8553, 0.859, 0.8618, 0.8638, 0.8649, 0.8662, 0.8657, 0.8717, 0.8723, 0.8739, 0.8775, 0.8791, 0.8785, 0.8802, 0.8817, 0.8846, 0.8887, 0.8881, 0.8904, 0.8904, 0.8951, 0.896, 0.8955, 0.8992, 0.9009, 0.9028, 0.9009, 0.9032, 0.9056, 0.9104, 0.9122, 0.9146, 0.9135, 0.914, 0.9186, 0.9189, 0.9213, 0.9208, 0.9233, 0.9257, 0.9284, 0.9299, 0.9333, 0.9325, 0.935, 0.9357, 0.9363, 0.9378, 0.9394, 0.9418, 0.9424, 0.9442, 0.9459, 0.9476, 0.9509, 0.95, 0.9521, 0.9526, 0.9534, 0.9553, 0.9556, 0.9571, 0.9576, 0.9587, 0.9593, 0.9613, 0.9612, 0.9631, 0.9641, 0.9652, 0.9671, 0.9672, 0.9685, 0.9686, 0.9698, 0.9701, 0.9709, 0.9714, 0.972, 0.9727, 0.9752, 0.9749, 0.9748, 0.9763, 0.9747, 0.9761, 0.9771, 0.9788, 0.9791, 0.9788, 0.9793, 0.9791, 0.9792, 0.9797, 0.9819, 0.9806, 0.9816, 0.9825, 0.9816, 0.9832, 0.9829, 0.983, 0.9846, 0.9841, 0.9857, 0.9845, 0.984, 0.9858, 0.9853, 0.9855, 0.987, 0.9868, 0.9879, 0.9874, 0.987, 0.9885, 0.9878, 0.988, 0.9882, 0.9887, 0.9896, 0.9895, 0.9902, 0.9905, 0.9902, 0.99, 0.9906, 0.9908, 0.9905, 0.9907, 0.9904, 0.9913, 0.9902, 0.9912, 0.9919, 0.9917, 0.9912, 0.9912, 0.9914, 0.9914, 0.9917, 0.9915]\n",
            "test loss:  [3.7, 3.335, 2.9111, 2.5375, 2.2241, 2.0321, 1.8541, 1.7601, 1.6721, 1.5623, 1.5314, 1.4621, 1.3973, 1.3959, 1.3289, 1.2832, 1.2636, 1.3195, 1.2276, 1.2046, 1.1383, 1.1549, 1.1188, 1.1707, 1.1417, 1.1242, 1.0991, 1.0835, 1.0593, 1.0884, 1.0531, 1.0399, 1.0776, 0.9776, 1.018, 1.0018, 1.0114, 1.0155, 1.0007, 1.044, 0.9887, 0.9921, 0.9759, 0.9681, 0.9339, 0.9552, 0.9583, 0.9288, 0.9373, 0.9382, 0.9485, 0.9362, 0.9059, 0.9643, 0.8644, 0.8937, 0.8961, 0.8742, 0.9204, 0.91, 0.8722, 0.8685, 0.8888, 0.8455, 0.8719, 0.89, 0.8171, 0.8387, 0.8414, 0.874, 0.8282, 0.844, 0.8424, 0.8295, 0.8215, 0.8045, 0.8131, 0.8041, 0.8586, 0.7881, 0.8307, 0.8067, 0.7769, 0.7973, 0.7786, 0.7987, 0.7843, 0.7623, 0.7655, 0.7488, 0.7591, 0.7339, 0.7958, 0.7603, 0.7597, 0.7402, 0.7562, 0.7466, 0.7129, 0.7133, 0.7323, 0.7216, 0.7361, 0.7211, 0.7249, 0.7163, 0.7061, 0.6825, 0.6988, 0.6838, 0.6825, 0.6876, 0.6929, 0.6636, 0.6726, 0.6829, 0.6565, 0.6505, 0.6633, 0.6633, 0.6489, 0.65, 0.6485, 0.6478, 0.6328, 0.6381, 0.6628, 0.6335, 0.6253, 0.6233, 0.638, 0.6353, 0.615, 0.6157, 0.6243, 0.6124, 0.6055, 0.6195, 0.6136, 0.6081, 0.6081, 0.6083, 0.605, 0.6102, 0.5971, 0.5889, 0.5949, 0.5795, 0.5905, 0.5842, 0.5932, 0.584, 0.5887, 0.5808, 0.5746, 0.5717, 0.5712, 0.5777, 0.5774, 0.5845, 0.5692, 0.5718, 0.5848, 0.5692, 0.5736, 0.5715, 0.575, 0.572, 0.5686, 0.5695, 0.5549, 0.5675, 0.5617, 0.5543, 0.5638, 0.5584, 0.5612, 0.559, 0.5606, 0.5603, 0.5574, 0.5589, 0.5644, 0.5633, 0.557, 0.5542, 0.5571, 0.5538, 0.5567, 0.5488, 0.5486, 0.5567, 0.5516, 0.5502, 0.552, 0.5489, 0.5498, 0.5501, 0.5509, 0.551]\n",
            "test err:  [0.8821, 0.8221, 0.7437, 0.6731, 0.6092, 0.5589, 0.5227, 0.492, 0.4814, 0.4371, 0.4394, 0.416, 0.4025, 0.4064, 0.3878, 0.3667, 0.3671, 0.3763, 0.359, 0.3518, 0.3302, 0.3319, 0.3195, 0.3394, 0.3323, 0.3258, 0.3173, 0.3131, 0.3075, 0.3212, 0.3003, 0.2989, 0.3185, 0.2841, 0.2981, 0.2896, 0.289, 0.2948, 0.2934, 0.3055, 0.2887, 0.2878, 0.2835, 0.2763, 0.2696, 0.2767, 0.2767, 0.2732, 0.2726, 0.2743, 0.2739, 0.2739, 0.2669, 0.2776, 0.2504, 0.262, 0.264, 0.2509, 0.2692, 0.2659, 0.2535, 0.2527, 0.2586, 0.2441, 0.2518, 0.2592, 0.2365, 0.2453, 0.2427, 0.2561, 0.246, 0.2461, 0.243, 0.2423, 0.2395, 0.2357, 0.239, 0.2349, 0.2508, 0.2302, 0.2435, 0.2378, 0.2237, 0.2339, 0.2267, 0.2329, 0.229, 0.224, 0.2278, 0.2172, 0.219, 0.2134, 0.2325, 0.2178, 0.22, 0.2139, 0.2187, 0.2167, 0.2095, 0.2066, 0.2119, 0.2116, 0.2159, 0.2102, 0.2119, 0.2018, 0.2021, 0.1961, 0.2063, 0.1978, 0.1975, 0.2038, 0.2047, 0.1924, 0.1918, 0.1988, 0.1915, 0.1888, 0.1896, 0.1938, 0.1913, 0.189, 0.1866, 0.185, 0.1826, 0.1861, 0.1921, 0.1829, 0.1813, 0.1813, 0.1859, 0.1851, 0.177, 0.1785, 0.1785, 0.1785, 0.1749, 0.1778, 0.1769, 0.1782, 0.1756, 0.1758, 0.1773, 0.1759, 0.1698, 0.1703, 0.1699, 0.1689, 0.1694, 0.1687, 0.171, 0.1689, 0.1723, 0.1665, 0.1664, 0.1626, 0.1627, 0.1665, 0.1635, 0.1666, 0.1638, 0.162, 0.1614, 0.1581, 0.1609, 0.1604, 0.1598, 0.1594, 0.1594, 0.1608, 0.1538, 0.159, 0.1553, 0.1545, 0.1571, 0.1548, 0.1545, 0.1558, 0.154, 0.1543, 0.1532, 0.1526, 0.1564, 0.1553, 0.1538, 0.1518, 0.1527, 0.1521, 0.1501, 0.1516, 0.1503, 0.1514, 0.1534, 0.15, 0.1508, 0.1495, 0.151, 0.1513, 0.1499, 0.1503]\n",
            "test acc:  [0.1179, 0.1779, 0.2563, 0.3269, 0.3908, 0.4411, 0.4773, 0.508, 0.5186, 0.5629, 0.5606, 0.584, 0.5975, 0.5936, 0.6122, 0.6333, 0.6329, 0.6237, 0.641, 0.6482, 0.6698, 0.6681, 0.6805, 0.6606, 0.6677, 0.6742, 0.6827, 0.6869, 0.6925, 0.6788, 0.6997, 0.7011, 0.6815, 0.7159, 0.7019, 0.7104, 0.711, 0.7052, 0.7066, 0.6945, 0.7113, 0.7122, 0.7165, 0.7237, 0.7304, 0.7233, 0.7233, 0.7268, 0.7274, 0.7257, 0.7261, 0.7261, 0.7331, 0.7224, 0.7496, 0.738, 0.736, 0.7491, 0.7308, 0.7341, 0.7465, 0.7473, 0.7414, 0.7559, 0.7482, 0.7408, 0.7635, 0.7547, 0.7573, 0.7439, 0.754, 0.7539, 0.757, 0.7577, 0.7605, 0.7643, 0.761, 0.7651, 0.7492, 0.7698, 0.7565, 0.7622, 0.7763, 0.7661, 0.7733, 0.7671, 0.771, 0.776, 0.7722, 0.7828, 0.781, 0.7866, 0.7675, 0.7822, 0.78, 0.7861, 0.7813, 0.7833, 0.7905, 0.7934, 0.7881, 0.7884, 0.7841, 0.7898, 0.7881, 0.7982, 0.7979, 0.8039, 0.7937, 0.8022, 0.8025, 0.7962, 0.7953, 0.8076, 0.8082, 0.8012, 0.8085, 0.8112, 0.8104, 0.8062, 0.8087, 0.811, 0.8134, 0.815, 0.8174, 0.8139, 0.8079, 0.8171, 0.8187, 0.8187, 0.8141, 0.8149, 0.823, 0.8215, 0.8215, 0.8215, 0.8251, 0.8222, 0.8231, 0.8218, 0.8244, 0.8242, 0.8227, 0.8241, 0.8302, 0.8297, 0.8301, 0.8311, 0.8306, 0.8313, 0.829, 0.8311, 0.8277, 0.8335, 0.8336, 0.8374, 0.8373, 0.8335, 0.8365, 0.8334, 0.8362, 0.838, 0.8386, 0.8419, 0.8391, 0.8396, 0.8402, 0.8406, 0.8406, 0.8392, 0.8462, 0.841, 0.8447, 0.8455, 0.8429, 0.8452, 0.8455, 0.8442, 0.846, 0.8457, 0.8468, 0.8474, 0.8436, 0.8447, 0.8462, 0.8482, 0.8473, 0.8479, 0.8499, 0.8484, 0.8497, 0.8486, 0.8466, 0.85, 0.8492, 0.8505, 0.849, 0.8487, 0.8501, 0.8497]\n",
            "ori train loss:  [4.0672, 3.5628, 3.1473, 2.7556, 2.4624, 2.2312, 2.0291, 1.8955, 1.7905, 1.6983, 1.6202, 1.555, 1.4999, 1.4474, 1.4047, 1.3662, 1.3217, 1.2971, 1.2608, 1.2322, 1.209, 1.1783, 1.1599, 1.137, 1.1176, 1.0974, 1.0848, 1.0672, 1.049, 1.046, 1.0258, 1.0101, 0.9968, 0.9868, 0.9805, 0.9644, 0.9556, 0.9484, 0.9381, 0.9298, 0.9173, 0.9102, 0.9025, 0.8943, 0.8805, 0.8765, 0.8706, 0.8535, 0.8534, 0.8484, 0.8423, 0.8299, 0.8165, 0.8155, 0.8032, 0.7922, 0.7908, 0.7791, 0.7777, 0.7656, 0.7576, 0.7501, 0.7471, 0.7387, 0.7381, 0.7238, 0.7154, 0.7112, 0.6999, 0.6935, 0.688, 0.6808, 0.6758, 0.6687, 0.6554, 0.6582, 0.647, 0.642, 0.6298, 0.624, 0.6184, 0.6099, 0.6014, 0.5988, 0.5973, 0.5839, 0.5762, 0.5626, 0.5563, 0.5441, 0.5492, 0.5414, 0.5265, 0.5247, 0.5128, 0.5064, 0.5005, 0.4929, 0.4867, 0.477, 0.4604, 0.4623, 0.4482, 0.4503, 0.4418, 0.4345, 0.424, 0.4154, 0.4114, 0.4006, 0.398, 0.3869, 0.3765, 0.3747, 0.3633, 0.3597, 0.3548, 0.3474, 0.3434, 0.333, 0.3299, 0.3215, 0.3179, 0.3073, 0.3013, 0.2971, 0.291, 0.2841, 0.2761, 0.2712, 0.2591, 0.2616, 0.2548, 0.2482, 0.2449, 0.2389, 0.2302, 0.2271, 0.2202, 0.2145, 0.2142, 0.2054, 0.2085, 0.1985, 0.1931, 0.1838, 0.1788, 0.1814, 0.1764, 0.1699, 0.165, 0.1672, 0.1594, 0.162, 0.1516, 0.1465, 0.1448, 0.1385, 0.1381, 0.1339, 0.1281, 0.1273, 0.1201, 0.1197, 0.1207, 0.1137, 0.1135, 0.1107, 0.1003, 0.0997, 0.0985, 0.0963, 0.094, 0.088, 0.0887, 0.0857, 0.0837, 0.0804, 0.0763, 0.0764, 0.0712, 0.0711, 0.07, 0.0687, 0.0661, 0.0649, 0.0643, 0.062, 0.0638, 0.0603, 0.0623, 0.0594, 0.0585, 0.0585, 0.0582, 0.0586, 0.0585, 0.0587, 0.0571, 0.0592]\n",
            "ori train err:  [0.9253, 0.8471, 0.7623, 0.6802, 0.6122, 0.5589, 0.5092, 0.4733, 0.4449, 0.4174, 0.3948, 0.3754, 0.3602, 0.3438, 0.3305, 0.3179, 0.308, 0.2986, 0.2849, 0.2792, 0.2698, 0.2599, 0.2541, 0.2488, 0.2416, 0.235, 0.2325, 0.228, 0.2238, 0.22, 0.2148, 0.2101, 0.2038, 0.2018, 0.2019, 0.1966, 0.1939, 0.1929, 0.1866, 0.1864, 0.1811, 0.1818, 0.1787, 0.1751, 0.1724, 0.1724, 0.1695, 0.1636, 0.1651, 0.163, 0.1615, 0.1571, 0.1536, 0.1519, 0.1502, 0.1476, 0.1461, 0.1444, 0.1447, 0.141, 0.1382, 0.1362, 0.1351, 0.1338, 0.1343, 0.1283, 0.1277, 0.1261, 0.1225, 0.1209, 0.1215, 0.1198, 0.1183, 0.1154, 0.1113, 0.1119, 0.1096, 0.1096, 0.1049, 0.104, 0.1045, 0.1008, 0.0991, 0.0972, 0.0991, 0.0968, 0.0944, 0.0896, 0.0878, 0.0854, 0.0865, 0.086, 0.0814, 0.0811, 0.0787, 0.0792, 0.0767, 0.0743, 0.0716, 0.0701, 0.0667, 0.0675, 0.065, 0.0643, 0.0637, 0.0622, 0.0606, 0.0582, 0.0576, 0.0558, 0.0541, 0.0524, 0.0491, 0.05, 0.0479, 0.0474, 0.0466, 0.0447, 0.0444, 0.0429, 0.0424, 0.0413, 0.0407, 0.0387, 0.0388, 0.0369, 0.0359, 0.0348, 0.0329, 0.0328, 0.0315, 0.0314, 0.0302, 0.0299, 0.0291, 0.0286, 0.028, 0.0273, 0.0248, 0.0251, 0.0252, 0.0237, 0.0253, 0.0239, 0.0229, 0.0212, 0.0209, 0.0212, 0.0207, 0.0209, 0.0208, 0.0203, 0.0181, 0.0194, 0.0184, 0.0175, 0.0184, 0.0168, 0.0171, 0.017, 0.0154, 0.0159, 0.0143, 0.0155, 0.016, 0.0142, 0.0147, 0.0145, 0.013, 0.0132, 0.0121, 0.0126, 0.013, 0.0115, 0.0122, 0.012, 0.0118, 0.0113, 0.0104, 0.0105, 0.0098, 0.0095, 0.0098, 0.01, 0.0094, 0.0092, 0.0095, 0.0093, 0.0096, 0.0087, 0.0098, 0.0088, 0.0081, 0.0083, 0.0088, 0.0088, 0.0086, 0.0086, 0.0083, 0.0085]\n",
            "ori train acc:  [0.0747, 0.1529, 0.2377, 0.3198, 0.3878, 0.4411, 0.4908, 0.5267, 0.5551, 0.5826, 0.6052, 0.6246, 0.6398, 0.6562, 0.6695, 0.6821, 0.692, 0.7014, 0.7151, 0.7208, 0.7302, 0.7401, 0.7459, 0.7512, 0.7584, 0.765, 0.7675, 0.772, 0.7762, 0.78, 0.7852, 0.7899, 0.7962, 0.7982, 0.7981, 0.8034, 0.8061, 0.8071, 0.8134, 0.8136, 0.8189, 0.8182, 0.8213, 0.8249, 0.8276, 0.8276, 0.8305, 0.8364, 0.8349, 0.837, 0.8385, 0.8429, 0.8464, 0.8481, 0.8498, 0.8524, 0.8539, 0.8556, 0.8553, 0.859, 0.8618, 0.8638, 0.8649, 0.8662, 0.8657, 0.8717, 0.8723, 0.8739, 0.8775, 0.8791, 0.8785, 0.8802, 0.8817, 0.8846, 0.8887, 0.8881, 0.8904, 0.8904, 0.8951, 0.896, 0.8955, 0.8992, 0.9009, 0.9028, 0.9009, 0.9032, 0.9056, 0.9104, 0.9122, 0.9146, 0.9135, 0.914, 0.9186, 0.9189, 0.9213, 0.9208, 0.9233, 0.9257, 0.9284, 0.9299, 0.9333, 0.9325, 0.935, 0.9357, 0.9363, 0.9378, 0.9394, 0.9418, 0.9424, 0.9442, 0.9459, 0.9476, 0.9509, 0.95, 0.9521, 0.9526, 0.9534, 0.9553, 0.9556, 0.9571, 0.9576, 0.9587, 0.9593, 0.9613, 0.9612, 0.9631, 0.9641, 0.9652, 0.9671, 0.9672, 0.9685, 0.9686, 0.9698, 0.9701, 0.9709, 0.9714, 0.972, 0.9727, 0.9752, 0.9749, 0.9748, 0.9763, 0.9747, 0.9761, 0.9771, 0.9788, 0.9791, 0.9788, 0.9793, 0.9791, 0.9792, 0.9797, 0.9819, 0.9806, 0.9816, 0.9825, 0.9816, 0.9832, 0.9829, 0.983, 0.9846, 0.9841, 0.9857, 0.9845, 0.984, 0.9858, 0.9853, 0.9855, 0.987, 0.9868, 0.9879, 0.9874, 0.987, 0.9885, 0.9878, 0.988, 0.9882, 0.9887, 0.9896, 0.9895, 0.9902, 0.9905, 0.9902, 0.99, 0.9906, 0.9908, 0.9905, 0.9907, 0.9904, 0.9913, 0.9902, 0.9912, 0.9919, 0.9917, 0.9912, 0.9912, 0.9914, 0.9914, 0.9917, 0.9915]\n",
            "time:  [82.53, 81.41, 81.43, 81.46, 81.42, 81.43, 81.41, 81.34, 81.29, 81.27, 81.28, 81.18, 81.23, 81.2, 81.19, 81.21, 81.2, 81.18, 81.17, 81.24, 81.16, 81.19, 81.23, 81.19, 81.27, 81.22, 81.23, 81.2, 81.25, 81.18, 81.15, 81.15, 81.18, 81.25, 81.23, 81.2, 81.17, 81.24, 81.14, 81.17, 81.28, 81.3, 81.2, 81.2, 81.2, 81.21, 81.19, 81.21, 81.21, 81.18, 81.18, 81.15, 81.17, 81.15, 81.15, 81.2, 81.17, 81.16, 81.23, 81.22, 81.15, 81.13, 81.18, 81.18, 81.2, 81.16, 81.17, 81.14, 81.15, 81.19, 81.14, 81.16, 81.16, 81.19, 81.16, 81.17, 81.17, 81.18, 81.17, 81.18, 81.16, 81.11, 81.15, 81.21, 81.16, 81.13, 81.17, 81.2, 81.18, 81.19, 81.17, 81.19, 81.18, 81.17, 81.13, 81.13, 81.2, 81.23, 81.2, 81.18, 81.21, 81.17, 81.15, 81.2, 81.21, 81.2, 81.15, 81.18, 81.23, 81.22, 81.1, 81.11, 81.14, 81.18, 81.2, 81.13, 81.16, 81.18, 81.21, 81.21, 81.15, 81.16, 81.17, 81.22, 81.16, 81.19, 81.16, 81.12, 81.17, 81.19, 81.2, 81.15, 81.2, 81.19, 81.17, 81.18, 81.21, 81.18, 81.14, 81.14, 81.27, 81.29, 81.21, 81.21, 81.18, 81.17, 81.13, 81.16, 81.21, 81.19, 81.17, 81.1, 81.18, 81.23, 81.2, 81.14, 81.15, 81.19, 81.16, 81.16, 81.14, 81.2, 81.19, 81.19, 81.17, 81.18, 81.24, 81.23, 81.19, 81.16, 81.17, 81.16, 81.2, 81.18, 81.15, 81.19, 81.22, 81.18, 81.18, 81.2, 81.22, 81.17, 81.15, 81.06, 81.13, 81.11, 81.09, 81.12, 81.15, 81.12, 81.11, 81.1, 81.15, 81.14, 81.1, 81.11, 81.16, 81.08, 81.11, 81.13]\n"
          ]
        }
      ]
    }
  ]
}